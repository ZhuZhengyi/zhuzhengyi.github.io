<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Justice的小站</title><link>https://justice.bj.cn/</link><description>Recent content on Justice的小站</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 30 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://justice.bj.cn/index.xml" rel="self" type="application/rss+xml"/><item><title>Justice's Blog</title><link>https://justice.bj.cn/homepage/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/about/</guid><description>&lt;h2 id="self-introduction">Self Introduction&lt;/h2>
&lt;p>Cras ex dui, tristique a libero eget, consectetur semper ligula. Nunc augue arcu, malesuada a nisi et, molestie finibus metus. Sed lacus odio, ultricies a nisl vitae, sollicitudin tempor ipsum. Vivamus quis feugiat arcu. Sed mi nunc, efficitur quis tellus vitae, posuere mattis metus. Phasellus in mattis dui. Nullam blandit, augue non ullamcorper dapibus, lacus dui molestie massa, in iaculis purus lectus eu lectus. Duis hendrerit lacinia tellus, sit amet feugiat dolor placerat id. Aenean ac velit massa. Vivamus feugiat dui at magna viverra, ut dictum nunc rutrum. Duis eget sapien finibus, lobortis orci id, vestibulum tellus. Maecenas lobortis urna libero, quis fermentum lectus lobortis nec. Nullam laoreet volutpat libero, ac mattis magna ullamcorper quis. Duis eget ipsum eu nisi mattis cursus et vitae turpis.&lt;/p>
&lt;p>Aliquam pretium diam eget leo feugiat finibus. Donec malesuada commodo ipsum. Aenean a massa in lacus venenatis vestibulum. Duis vel sem quis elit iaculis consectetur et quis dolor. Morbi eu ipsum hendrerit, malesuada ante sed, dapibus est. Suspendisse feugiat nulla ut gravida convallis. Phasellus id massa posuere, rhoncus justo ut, porttitor dolor. Nulla ultrices malesuada egestas. Nunc fermentum tincidunt sem ac vulputate. Donec mollis sollicitudin justo eget varius. Donec ornare velit et felis blandit, id molestie sapien lobortis. Morbi eget tristique justo. Mauris posuere, nibh eu laoreet ultricies, ligula erat iaculis sapien, vel dapibus lacus libero ut diam. Etiam viverra ante felis, et scelerisque nunc pellentesque vitae. Praesent feugiat dictum molestie.&lt;/p>
&lt;h2 id="details">Details&lt;/h2>
&lt;p>Nunc pellentesque vitae:&lt;/p>
&lt;ul>
&lt;li>Morbi accumsan nibh efficitur diam molestie, non dignissim diam facilisis.&lt;/li>
&lt;li>Donec dignissim leo in mollis faucibus.&lt;/li>
&lt;li>Donec blandit lacus a pellentesque fermentum.&lt;/li>
&lt;/ul>
&lt;p>Donec mollis sollicitudin:&lt;/p>
&lt;ul>
&lt;li>Nunc dictum purus ornare purus consectetur, eu pellentesque massa ullamcorper.&lt;/li>
&lt;li>Aliquam eu leo vitae justo aliquam tincidunt.&lt;/li>
&lt;li>Fusce non massa id augue interdum feugiat sed et nulla.&lt;/li>
&lt;li>Vivamus molestie augue in tristique laoreet.&lt;/li>
&lt;/ul></description></item><item><title>Pages</title><link>https://justice.bj.cn/homepage/pages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/pages/</guid><description/></item><item><title>Experiences</title><link>https://justice.bj.cn/homepage/experiences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/experiences/</guid><description/></item><item><title>Vintage</title><link>https://justice.bj.cn/homepage/vintage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/vintage/</guid><description/></item><item><title>Blank</title><link>https://justice.bj.cn/homepage/blank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/blank/</guid><description>
&lt;div style="text-align:center">
&lt;p>Write anything you like here!&lt;/p>
&lt;/div></description></item><item><title>Golang Runtime</title><link>https://justice.bj.cn/post/14.language/golang/golang-runtime/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/golang-runtime/</guid><description>&lt;h1 id="golang-runtime">Golang Runtime&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;h2 id="go调度器的演化">Go调度器的演化&lt;/h2>
&lt;h2 id="源码分析">源码分析&lt;/h2>
&lt;p>Go 程序启动后需要对自身运行时进行初始化，其真正的程序入口由 runtime 包控制。 以 AMD64 架构上的 Linux 和 macOS 为例，分别位于：&lt;code>src/runtime/rt0_linux_amd64.s&lt;/code> 和 &lt;code>src/runtime/rt0_darwin_amd64.s&lt;/code>。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8
JMP _rt0_amd64(SB)
TEXT _rt0_amd64_darwin(SB),NOSPLIT,$-8
JMP _rt0_amd64(SB)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>两者均跳转到了 &lt;code>_rt0_amd64&lt;/code> 函数:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">TEXT _rt0_amd64(SB),NOSPLIT,$-8
MOVQ 0(SP), DI // argc
LEAQ 8(SP), SI // argv
JMP runtime·rt0_go(SB)
TEXT runtime·rt0_go(SB),NOSPLIT,$0
// 将参数向前复制到一个偶数栈上
MOVQ DI, AX // argc
MOVQ SI, BX // argv
SUBQ $(4*8+7), SP // 2args 2auto
ANDQ $~15, SP
MOVQ AX, 16(SP)
MOVQ BX, 24(SP)
// 初始化 g0 执行栈
MOVQ $runtime·g0(SB), DI // DI = g0
LEAQ (-64*1024+104)(SP), BX
MOVQ BX, g_stackguard0(DI) // g0.stackguard0 = SP + (-64*1024+104)
MOVQ BX, g_stackguard1(DI) // g0.stackguard1 = SP + (-64*1024+104)
MOVQ BX, (g_stack+stack_lo)(DI) // g0.stack.lo = SP + (-64*1024+104)
MOVQ SP, (g_stack+stack_hi)(DI) // g0.stack.hi = SP
// 确定 CPU 处理器的信息
MOVL $0, AX
CPUID // CPUID 会设置 AX 的值
MOVL AX, SI
(...)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/01/25-16-54-30-2021-01-25-16-54-23-image.png" alt="golang-runtime启动流程">&lt;/p>
&lt;h2 id="sysmon">sysmon&lt;/h2>
&lt;p>在main.main执行之前，Go语言的runtime库会初始化一些后台任务，其中一个任务就是sysmon。&lt;/p>
&lt;p>sysmon是一个物理线程，主要处理两个事件：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>对于网络的epoll;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>抢占式调度的检测: sysmon会根据系统当前的繁忙程度睡一小段时间，然后每隔10ms至少进行一次epoll并唤醒相应的goroutine&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="n">newm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sysmon&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">nil&lt;/span>&lt;span class="p">);&lt;/span> &lt;span class="c1">//sysmon 是一个m, 物理线程；
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="k">for&lt;/span>&lt;span class="p">(;;)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">usleep&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">delay&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">lastpoll&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">lastpoll&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="mi">1000&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="mi">1000&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">now&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">netpoll&lt;/span>&lt;span class="p">();&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="n">retake&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">now&lt;/span>&lt;span class="p">);&lt;/span> &lt;span class="c1">// 根据每个P的状态和运行时间决定是否要进行抢占
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="scavenger">scavenger&lt;/h2>
&lt;p>scavenger是一个goroutine，执行的是runtime·MHeap_Scavenger函数。它将一些不再使用的内存归还给操作系统，用于执行内存回收；&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="n">runtime&lt;/span>&lt;span class="err">·&lt;/span>&lt;span class="n">newproc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">scavenger&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">nil&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">runtime&lt;/span>&lt;span class="err">·&lt;/span>&lt;span class="n">main&lt;/span>&lt;span class="p">);&lt;/span> &lt;span class="c1">//scavenger 是一个goroutine
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="go-关键字">go 关键字&lt;/h2>
&lt;p>Go语言中，表达式go f(x, y, z)会启动一个新的goroutine运行函数f(x, y, z)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="k">go&lt;/span> &lt;span class="nf">f&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">args&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">//go 关键字是如下语句的一个包装
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">newproc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">f&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">args&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="defer">defer&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>defer关键字的实现跟go关键字很类似，不同的是它调用的是runtime.deferproc而不是runtime.newproc。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在defer出现的地方，插入了指令&lt;code>call runtime.deferproc&lt;/code>，然后在函数返回之前的地方，插入指令&lt;code>call runtime.deferreturn&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>goroutine的控制结构中，有一张表记录defer，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>调用runtime.deferproc时会将需要defer的表达式记录在表中，而在调用&lt;code>runtime.deferreturn&lt;/code>的时候，则会依次从defer表中出栈并执行。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">//无defer函数返回
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">add&lt;/span> &lt;span class="nx">xx&lt;/span> &lt;span class="nx">SP&lt;/span>
&lt;span class="k">return&lt;/span>
&lt;span class="c1">//defer 函数返回
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">call&lt;/span> &lt;span class="nx">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">deferreturn&lt;/span>&lt;span class="err">，&lt;/span>
&lt;span class="nx">add&lt;/span> &lt;span class="nx">xx&lt;/span> &lt;span class="nx">SP&lt;/span>
&lt;span class="k">return&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="go-routine-栈">Go Routine 栈&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>每个goroutine需要能够运行，都有自己的栈。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>初始时只给栈分配很小的空间，然后随着使用过程中的需要自动地增长&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Go1.3版本之后则使用的是continuous stack；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个Go函数调用的前几条指令，先比较栈指针寄存器跟g-&amp;gt;stackguard，检测是否发生栈溢出。如果栈指针寄存器值超越了stackguard就需要扩展栈空间；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="sysmon-1">sysmon&lt;/h3>
&lt;p>前面讲Go程序的初始化过程中有提到过，runtime开了一条后台线程，运行一个sysmon函数。这个函数会周期性地做epoll操作，同时它还会检测每个P是否运行了较长时间。&lt;/p>
&lt;p>如果检测到某个P状态处于Psyscall超过了一个sysmon的时间周期(20us)，并且还有其它可运行的任务，则切换P。&lt;/p>
&lt;p>如果检测到某个P的状态为Prunning，并且它已经运行了超过10ms，则会将P的当前的G的stackguard设置为StackPreempt。这个操作其实是相当于加上一个标记，通知这个G在合适时机进行调度。&lt;/p>
&lt;p>目前这里只是尽最大努力送达，但并不保证收到消息的goroutine一定会执行调度让出运行权。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://www.bookstack.cn/read/go-internals/zh-04.1.md">Go语言程序初始化过程 - 系统初始化 - 《深入解析Go》 - 书栈网 · BookStack&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://golang.design/under-the-hood/zh-cn/part1basic/ch05life/boot/">https://golang.design/under-the-hood/zh-cn/part1basic/ch05life/boot/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.cnblogs.com/mafeng/p/10305419.html">深入理解golang 的栈 - ma_fighting - 博客园&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://www.huamo.online/2019/06/25/%E6%B7%B1%E5%85%A5%E7%A0%94%E7%A9%B6goroutine%E6%A0%88/">深入研究goroutine栈 | 花木兰&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/237870981">https://zhuanlan.zhihu.com/p/237870981&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://segmentfault.com/a/1190000019570427">https://segmentfault.com/a/1190000019570427&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Golang 内存管理</title><link>https://justice.bj.cn/post/14.language/golang/golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/golang%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid><description>&lt;h1 id="golang-内存管理">Golang 内存管理&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Golang内存管理采用类似&lt;code>tcmalloc&lt;/code>的分级分配算法，主要由&lt;code>MHeap&lt;/code>、&lt;code>MCentral&lt;/code>、&lt;code>MCache&lt;/code> 3 级组成。按分配对象的大小不同，选择相应的区域进行分配。&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/12/28-10-17-33-2021-12-28-10-17-27-image.png" alt="">&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-49-29-image-20190919152951111.png" alt="image-20190919152951111">&lt;/p>
&lt;h2 id="内存布局">内存布局&lt;/h2>
&lt;p>golang程序启动时，会根据OS类型向OS申请一大块连续虚拟内存空间如下：&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-49-34-2020-05-04-09-32-44-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>arena&lt;/code>：&lt;/p>
&lt;ul>
&lt;li>由连续的page(8KB)组成，用于具体的对象分配；&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>spans&lt;/code>：&lt;/p>
&lt;ul>
&lt;li>存放了&lt;code>mspan&lt;/code>的指针(8Byte)，表示arena区中的某一页(page)属于哪个&lt;code>mspan&lt;/code>，用于管理arena；&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>bitmap&lt;/code>：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>用于标记&lt;code>arena&lt;/code>(即heap)中的对象, 每个对象使用两个bit进行标记，分别表示gc状态和是否分配；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>高地址部分指向arena区域的低地址部分，地址是由高地址向低地址增长的；&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-49-42-2020-05-04-09-36-04-image.png" alt="">&lt;/p>
&lt;h2 id="基本数据结构">基本数据结构&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>MHeap&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>代表了golang的整个堆内存;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>全局唯一的;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>大对象(&amp;gt;32KB)直接在MHeap中分配；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>mheap 包含free，large两个域：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>free: free包含一个256单元的数组&lt;/p>
&lt;/li>
&lt;li>
&lt;p>large:&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>给MCentral和MCache等下层提供空间；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-49-48-2020-05-04-09-39-31-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>MCentral&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>集中管理不同类型（67种）的MSpan，对应TCMalloc中的CentralCache；&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>每个mcentral包含两个mspan列表:
&lt;ul>
&lt;li>noempty: 表示已被mcache的mspan list；&lt;/li>
&lt;li>empty: 表示未被使用(empty)的mspan 链表。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>当某个goroutine中的mcache内存不够时，就会从mcentral的empty链表中分配对应的mspan。&lt;/li>
&lt;li>如果mcentral内存不够，就会从MHeap中分配；&lt;/li>
&lt;li>mcentral中有锁，以为多个goroutine分配提供互斥；&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-49-08-2020-05-04-09-38-29-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>MCache&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>是各个goroutine自有的局部内存;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>向&lt;code>mcentral&lt;/code>申请得到的;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>小对象(&amp;lt;=32KB)的分配直接在goroutine内部进行，不用加锁，提高分配速度。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>mcache 内存不够时，会向mcentral重新申请；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-49-13-2020-05-04-09-38-54-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>MSpan&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>内存管理基本单元，由一片连续的8KB页组成的双向链表，进行内存对象的数据分配;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为满足不同大小对象分配的需要，减少内存碎片，同时兼顾内存利用率，golang将span分层不同的大小类型（总共67种）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对象分配内存时，根据对象大小，选择最合适的mspan进行分配。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-49-19-2020-05-04-09-37-59-image.png" alt="">&lt;/p>
&lt;h2 id="内存分配">内存分配&lt;/h2>
&lt;p>Go的内存分配器在分配对象时，根据对象的大小，分成三类：&lt;/p>
&lt;ul>
&lt;li>Tiny对象： (0, 16B]，使用mcache的tiny分配器分配，多个tiny对象可组合在一个mspan中&lt;/li>
&lt;li>Small对象：(16B, 32KB ]，在mcache中选择相应规格大小的mspan进行分配；&lt;/li>
&lt;li>大对象：&amp;gt;32KB, 直接从MHeap中分配；&lt;/li>
&lt;/ul>
&lt;p>golang变量是在栈上分配还是在堆上分配，是由逃逸分析的结果决定的。&lt;/p>
&lt;p>通常情况下，编译器是倾向于将变量分配到栈上的，因为它的开销小。&lt;/p>
&lt;p>分配顺序：&lt;/p>
&lt;ul>
&lt;li>首先通过计算使用的大小规格&lt;/li>
&lt;li>然后&lt;code>mcache&lt;/code>中对应大小规格的块分配。&lt;/li>
&lt;li>如果&lt;code>mcache&lt;/code> free 链表不够分配&lt;/li>
&lt;li>如果&lt;code>mcentral&lt;/code>中没有可用的块，则向&lt;code>mheap&lt;/code>申请，并根据算法找到最合适的&lt;code>mspan&lt;/code>。&lt;/li>
&lt;li>如果申请到的&lt;code>mspan&lt;/code> 超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的 mspan 放回 mheap 的空闲列表。&lt;/li>
&lt;li>如果 mheap 中没有可用 span，则向操作系统申请一系列新的页（最小 1MB）。&lt;/li>
&lt;/ul>
&lt;h2 id="gc流程">GC流程&lt;/h2>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/27807169">https://zhuanlan.zhihu.com/p/27807169&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.jianshu.com/p/2904efc7f1a8">图解Golang的内存分配&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/29216091">https://zhuanlan.zhihu.com/p/29216091&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/76802887">https://zhuanlan.zhihu.com/p/76802887&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://yq.aliyun.com/articles/652551">&lt;strong>简单易懂的 Go 内存分配原理解读&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://juejin.im/post/5c888a79e51d456ed11955a8">https://juejin.im/post/5c888a79e51d456ed11955a8&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/225190602">白话Go语言内存管理三部曲（一）内存分配原理&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://segmentfault.com/a/1190000022499402">go怎样做stw&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>JQ</title><link>https://justice.bj.cn/post/70.tool/jq/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/70.tool/jq/</guid><description>&lt;h1 id="jq">JQ&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>jq是一个shell下的json解析工具，功能强大。&lt;/p>
&lt;h2 id="用法">用法&lt;/h2>
&lt;h3 id="格式化json">格式化json&lt;/h3>
&lt;p>不加任何选项和表达式的作用是格式化json字符串,比较实用&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;key&amp;#34;:&amp;#34;va&amp;#34;, &amp;#34;key2&amp;#34;:&amp;#34;val2&amp;#34;}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="c1">#格式化echo里面的json&lt;/span>
$ cat t.txt&lt;span class="p">|&lt;/span>jq &lt;span class="c1">#格式化t.txt里面的json&lt;/span>
$ jq . t.txt &lt;span class="c1">#jq打开文件,并格式化t.txt里面的json&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="根据key查询json的值">根据key查询json的值&lt;/h3>
&lt;p>根据key查询json可以写成.key,如果key是特殊的字符,比如全数字需要用引号括起来: .&amp;ldquo;key&amp;rdquo;&lt;br>
.foo.bar的形式类似于shell的管道符|,.foo.bar等于.foo|.bar&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#如果key对应的val存在则输出val&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;foo&amp;#34;: 42, &amp;#34;bar&amp;#34;: &amp;#34;less interesting data&amp;#34;}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.foo&amp;#39;&lt;/span>
&amp;gt; &lt;span class="m">42&lt;/span>
&lt;span class="c1">#如果key对应的val值不存在则输出null&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;notfoo&amp;#34;: true, &amp;#34;alsonotfoo&amp;#34;: false}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.foo&amp;#39;&lt;/span>
&amp;gt; null
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;111&amp;#34;:&amp;#34;222&amp;#34;, &amp;#34;333&amp;#34;:&amp;#34;444&amp;#34;}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[&amp;#34;111&amp;#34;]&amp;#39;&lt;/span>
&amp;gt; &lt;span class="s2">&amp;#34;222&amp;#34;&lt;/span>
&lt;span class="c1">#效果和上面一条一样&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;111&amp;#34;:&amp;#34;222&amp;#34;, &amp;#34;333&amp;#34;:&amp;#34;444&amp;#34;}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.&amp;#34;111&amp;#34;&amp;#39;&lt;/span>
&amp;gt; &lt;span class="s2">&amp;#34;222&amp;#34;&lt;/span>
&lt;span class="c1">## 根据key, 更新value&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;111&amp;#34;:&amp;#34;222&amp;#34;, &amp;#34;333&amp;#34;:&amp;#34;444&amp;#34;}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.&amp;#34;111&amp;#34; = &amp;#34;aaa&amp;#34; &amp;#39;&lt;/span>
&amp;gt; &lt;span class="s1">&amp;#39;{&amp;#34;111&amp;#34;:&amp;#34;aaa&amp;#34;, &amp;#34;333&amp;#34;:&amp;#34;444&amp;#34;}&amp;#39;&lt;/span>
&lt;span class="c1">## 根据key, 更新value, 使用变量&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;111&amp;#34;:&amp;#34;222&amp;#34;, &amp;#34;333&amp;#34;:&amp;#34;444&amp;#34;}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq -- &lt;span class="s1">&amp;#39;.&amp;#34;111&amp;#34; = &amp;#34;aaa&amp;#34; &amp;#39;&lt;/span>
&amp;gt; &lt;span class="s1">&amp;#39;{&amp;#34;111&amp;#34;:&amp;#34;aaa&amp;#34;, &amp;#34;333&amp;#34;:&amp;#34;444&amp;#34;}&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="数组">数组&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#查询数组第1个元素&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[{&amp;#34;name&amp;#34;:&amp;#34;JSON&amp;#34;, &amp;#34;good&amp;#34;:true}, {&amp;#34;name&amp;#34;:&amp;#34;XML&amp;#34;, &amp;#34;good&amp;#34;:false}]&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[0]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;JSON&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;good&amp;#34;&lt;/span>: &lt;span class="nb">true&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="c1">#查询第3个元素,需要注意的是数组的下标是从0开始算的&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[{&amp;#34;name&amp;#34;:&amp;#34;JSON&amp;#34;, &amp;#34;good&amp;#34;:true}, {&amp;#34;name&amp;#34;:&amp;#34;XML&amp;#34;, &amp;#34;good&amp;#34;:false}]&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.[2]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
null
&lt;span class="c1">#查询下标为2到3之间的元素&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;,&amp;#34;d&amp;#34;,&amp;#34;e&amp;#34;]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.[2:4]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;c&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;d&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span>
&lt;span class="c1">#查询下标为3之前的元素&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;,&amp;#34;d&amp;#34;,&amp;#34;e&amp;#34;]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.[:3]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;a&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;b&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;c&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span>
&lt;span class="c1">#查询倒数第1-2个元素&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;,&amp;#34;d&amp;#34;,&amp;#34;e&amp;#34;]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.[-2:]&amp;#39;&lt;/span>
&amp;gt; &lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;d&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;e&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span>
&lt;span class="c1">#查询倒数第2个元素&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;,&amp;#34;d&amp;#34;,&amp;#34;e&amp;#34;]&amp;#39;&lt;/span> jq &lt;span class="s1">&amp;#39;.[-2]&amp;#39;&lt;/span>
&amp;gt; &lt;span class="s2">&amp;#34;d&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="-查询所有val">.[]: 查询所有val&lt;/h3>
&lt;p>可以使用.[]语法,查询json对象的所有值&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#拿到key的val以及key2的val2&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;key&amp;#34;:&amp;#34;val&amp;#34;, &amp;#34;key2&amp;#34;:&amp;#34;val2&amp;#34;}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[]&amp;#39;&lt;/span>
&amp;gt; &lt;span class="s2">&amp;#34;val&amp;#34;&lt;/span>
&amp;gt; &lt;span class="s2">&amp;#34;val2&amp;#34;&lt;/span>
&lt;span class="c1">#拿到key的val(一个object),key2的val&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;key&amp;#34;:{&amp;#34;key3&amp;#34;:&amp;#34;val3&amp;#34;, &amp;#34;key4&amp;#34;:&amp;#34;val4&amp;#34;}, &amp;#34;key2&amp;#34;:&amp;#34;val2&amp;#34;}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&amp;gt; &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;key3&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;val3&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;key4&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;val4&amp;#34;&lt;/span> &lt;span class="o">}&lt;/span>
&amp;gt; &lt;span class="s2">&amp;#34;val2&amp;#34;&lt;/span>
&lt;span class="c1">#拿到json数组里面的值&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39; [{&amp;#34;name&amp;#34;:&amp;#34;JSON&amp;#34;, &amp;#34;good&amp;#34;:true}, {&amp;#34;name&amp;#34;:&amp;#34;XML&amp;#34;, &amp;#34;good&amp;#34;:false}]&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[]&amp;#39;&lt;/span>
&amp;gt; &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;JSON&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;good&amp;#34;&lt;/span>: &lt;span class="nb">true&lt;/span> &lt;span class="o">}&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;XML&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;good&amp;#34;&lt;/span>: &lt;span class="nb">false&lt;/span> &lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="多条件">,:多条件&lt;/h3>
&lt;p>如果要写多个过滤条件使用,号,现输出,左边的结果在输出,右边的结果&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;foo&amp;#34;: 42, &amp;#34;bar&amp;#34;: &amp;#34;something else&amp;#34;, &amp;#34;baz&amp;#34;: true}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.foo,.bar,.baz&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="m">42&lt;/span>
&lt;span class="s2">&amp;#34;something else&amp;#34;&lt;/span>
&lt;span class="nb">true&lt;/span>
&lt;span class="c1">#.key和[]表达式可以组合使用&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;user&amp;#34;:&amp;#34;stedolan&amp;#34;, &amp;#34;projects&amp;#34;: [&amp;#34;jq&amp;#34;, &amp;#34;wikiflow&amp;#34;]}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.user,.projects[]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="s2">&amp;#34;stedolan&amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;jq&amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;wikiflow&amp;#34;&lt;/span>
&lt;span class="c1">#可以使用,一次查询数组里的多个元素&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;,&amp;#34;d&amp;#34;,&amp;#34;e&amp;#34;]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.[4,3]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="s2">&amp;#34;e&amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;d&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="管道符号">|:管道符号&lt;/h3>
&lt;p>shell里面的|是连接各个shell命令的通道,像大管道套小管道,过滤器就是命令,可以很方便的过滤出想要的数据来&lt;br>
jq里面也有|符号&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#可以先用.[]拿到值,再使用|(管道)拿到name&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[{&amp;#34;name&amp;#34;:&amp;#34;JSON&amp;#34;, &amp;#34;good&amp;#34;:true}, {&amp;#34;name&amp;#34;:&amp;#34;XML&amp;#34;, &amp;#34;good&amp;#34;:false}]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.[] | .name&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="s2">&amp;#34;JSON&amp;#34;&lt;/span>
&lt;span class="s2">&amp;#34;XML&amp;#34;&lt;/span>
&lt;span class="c1">######把查询结果包装成一个数组(array)--使用[]符号&lt;/span>
&lt;span class="o">[]&lt;/span>在jq里面表示数组,可以现查询再使用&lt;span class="o">[]&lt;/span>把查询结果包装成数组
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[{&amp;#34;name&amp;#34;:&amp;#34;JSON&amp;#34;, &amp;#34;good&amp;#34;:true}, {&amp;#34;name&amp;#34;:&amp;#34;XML&amp;#34;, &amp;#34;good&amp;#34;:false}]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;[.[]|.name]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;JSON&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;XML&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="符号">{}符号&lt;/h3>
&lt;p>把查询结果包装成一个对象(object)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#修改json的key名&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;user&amp;#34;:&amp;#34;stedolan&amp;#34;,&amp;#34;titles&amp;#34;:[&amp;#34;JQ Primer&amp;#34;, &amp;#34;More JQ&amp;#34;]}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;{user1: .user, title2: .titles}&amp;#39;&lt;/span>
&amp;gt; &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;user1&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;stedolan&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;title2&amp;#34;&lt;/span>: &lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;JQ Primer&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;More JQ&amp;#34;&lt;/span> &lt;span class="o">]}&lt;/span>
&lt;span class="c1">#如果其中一个表达式产生多个结果,那最终生成的json也有多个结果&lt;/span>
&lt;span class="c1">#其中.titles[]会查询出两个结果,那最终生成的json也是两个&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;user&amp;#34;:&amp;#34;stedolan&amp;#34;,&amp;#34;titles&amp;#34;:[&amp;#34;JQ Primer&amp;#34;, &amp;#34;More JQ&amp;#34;]}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;{user, titles:.titles[]}&amp;#39;&lt;/span>
&amp;gt; &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;user&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;stedolan&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;titles&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;JQ Primer&amp;#34;&lt;/span> &lt;span class="o">}{&lt;/span> &lt;span class="s2">&amp;#34;user&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;stedolan&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;titles&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;More JQ&amp;#34;&lt;/span>&lt;span class="o">}&lt;/span>
&lt;span class="c1">#如果想使用原来的json某个key的值作新的json的key,可以使用(.key)语法&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;user&amp;#34;:&amp;#34;stedolan&amp;#34;,&amp;#34;titles&amp;#34;:[&amp;#34;JQ Primer&amp;#34;, &amp;#34;More JQ&amp;#34;]}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;{(.user): .titles}&amp;#39;&lt;/span>
&amp;gt; &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;stedolan&amp;#34;&lt;/span>: &lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;JQ Primer&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;More JQ&amp;#34;&lt;/span> &lt;span class="o">]}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="运算符">+运算符&lt;/h3>
&lt;p>+运算符需要两个相同输入,并把结果加在一起&lt;/p>
&lt;ul>
&lt;li>数字常规的加法&lt;/li>
&lt;li>array拼接成一个大的数组&lt;/li>
&lt;li>string拼接成一个大的string&lt;/li>
&lt;li>object也是合并操作,如果有两个key相同的object新的覆盖旧的&lt;/li>
&lt;/ul>
&lt;p>null可以与任何值相加,返回另外一个值&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#数字相加&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;a&amp;#34;:1}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.a + 1&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="m">2&lt;/span>
&lt;span class="c1">#array相加&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;a&amp;#34;: [1,2], &amp;#34;b&amp;#34;: [3,4]}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.a+.b&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> 1, 2, 3, 4&lt;span class="o">]&lt;/span>
&lt;span class="c1">#string相加&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;a&amp;#34;: &amp;#34;hello&amp;#34;, &amp;#34;b&amp;#34;: &amp;#34;world&amp;#34;}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.a+.b&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="s2">&amp;#34;helloworld&amp;#34;&lt;/span>
&lt;span class="c1">#object相加&lt;/span>
$ &lt;span class="nb">echo&lt;/span> null &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;{a: 42} + {b: 2} + {c: 3} + {a: 1}&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;a&amp;#34;&lt;/span>: 1, &lt;span class="s2">&amp;#34;b&amp;#34;&lt;/span>: 2, &lt;span class="s2">&amp;#34;c&amp;#34;&lt;/span>: 3&lt;span class="o">}&lt;/span>
&lt;span class="c1">#有空值相加的情况&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;a&amp;#34;: 1}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;null +.a&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="m">1&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;.a+1&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="m">1&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="-运算符">-运算符&lt;/h3>
&lt;p>-号运算符用于数字,用于数组,会在第一个数组删除第二个数组中出现的所有项&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#数字相减&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;a&amp;#34;:4}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;4 - .a&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="m">0&lt;/span>
&lt;span class="c1">#数组相减&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39; [&amp;#34;xml&amp;#34;, &amp;#34;yaml&amp;#34;, &amp;#34;json&amp;#34;]&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;. - [&amp;#34;xml&amp;#34;, &amp;#34;json&amp;#34;]&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;yaml&amp;#34;&lt;/span>
&lt;span class="o">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="乘法除法运算符">乘法*除法运算符&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>/只能用在数字类型上&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">echo&lt;/span> 5&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;10 / . * 3&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="m">6&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h3 id="length">length&lt;/h3>
&lt;p>length用于不同类型值的长度&lt;/p>
&lt;ul>
&lt;li>string:返回字符串中字符的个数,如果有中文返回中文的个数&lt;/li>
&lt;li>array: 返回数组元素的个数&lt;/li>
&lt;li>object: 返回键-值对的个数&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;郭&amp;#34;, [1,2], &amp;#34;string&amp;#34;, {&amp;#34;a&amp;#34;:2}, null]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[]|length&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="m">12610&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="keys-and-keys_unsorted">keys and keys_unsorted&lt;/h3>
&lt;p>keys可以返回json键名数组,其中keys与keys_unsorted区别是keys返回的数组是排过序的&lt;br>
keys_unsorted返回的数组是不排序&lt;br>
当json的顶层元素是数组时,keys返回数组的下标&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;abc&amp;#34;: 1, &amp;#34;abcd&amp;#34;: 2, &amp;#34;Foo&amp;#34;: 3}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;keys&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;Foo&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;abc&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;abcd&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;abc&amp;#34;: 1, &amp;#34;abcd&amp;#34;: 2, &amp;#34;Foo&amp;#34;: 3}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;keys_unsorted&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;abc&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;abcd&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;Foo&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;aaa&amp;#34;, &amp;#34;bbb&amp;#34;, &amp;#34;ccc&amp;#34;]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;keys&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> 0, 1, 2&lt;span class="o">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="haskey">has(key)&lt;/h3>
&lt;p>返回输入的json对象是否有给定的key,或者数组存在指定的索引,有返回true,没有返回false&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[{&amp;#34;foo&amp;#34;:123, &amp;#34;abc&amp;#34;:456}, {&amp;#34;cde&amp;#34;:789, &amp;#34;fgh&amp;#34;:111}]&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;map(has(&amp;#34;foo&amp;#34;))&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> true, &lt;span class="nb">false&lt;/span> &lt;span class="o">]&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[[0,1], [&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;]]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;map(has(2))&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> false, &lt;span class="nb">true&lt;/span> &lt;span class="o">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="in">in&lt;/h3>
&lt;p>检查输入的键是否在对象中,或者输入的索引存在数组中,有返回true,没有返回false,本质上是反过来的has&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[&amp;#34;foo&amp;#34;, &amp;#34;123&amp;#34;]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[]|in({&amp;#34;foo&amp;#34;:123})&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="nb">true&lt;/span>
&lt;span class="nb">false&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[2, 3]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[]|in([&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;])&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="nb">true&lt;/span>
&lt;span class="nb">false&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="path">path&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#TODO&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="del">del&lt;/h3>
&lt;p>del用来删除json 对象的键和值&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#删除一个键值对&lt;/span>
&lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;aaa&amp;#34;: 111, &amp;#34;bbb&amp;#34;: 222, &amp;#34;ccc&amp;#34;:33}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;del(.aaa)&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;bbb&amp;#34;&lt;/span>: 222, &lt;span class="s2">&amp;#34;ccc&amp;#34;&lt;/span>: 33&lt;span class="o">}&lt;/span>
&lt;span class="c1">#删除多个键值对&lt;/span>
&lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;aaa&amp;#34;: 111, &amp;#34;bbb&amp;#34;: 222, &amp;#34;ccc&amp;#34;:33}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;del(.[&amp;#34;aaa&amp;#34;, &amp;#34;bbb&amp;#34;])&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;ccc&amp;#34;&lt;/span>: 33&lt;span class="o">}&lt;/span>
&lt;span class="c1">#根据下标删除数组元素&lt;/span>
&lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[111, 222, 33]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;del(.[1,2])&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> 111&lt;span class="o">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="to_entries-from_entries-with_entries">to_entries, from_entries, with_entries&lt;/h3>
&lt;ul>
&lt;li>to_entries 把json对象转成键-值对数值&lt;/li>
&lt;li>from_entries 键-值对数组转成json对象&lt;/li>
&lt;li>with_entries 是 to_entries | map(foo) | from_entries 的缩写&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;aa&amp;#34;:11, &amp;#34;bb&amp;#34;:22}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;to_entries&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;key&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;aa&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;value&amp;#34;&lt;/span>: &lt;span class="m">11&lt;/span> &lt;span class="o">}&lt;/span>, &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;key&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;bb&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;value&amp;#34;&lt;/span>: &lt;span class="m">22&lt;/span> &lt;span class="o">}]&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[{&amp;#34;key&amp;#34; : &amp;#34;aa&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;11&amp;#34;}, {&amp;#34;key&amp;#34;:&amp;#34;bb&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;22&amp;#34;}]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;from_entries&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;aa&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;11&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;bb&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;22&amp;#34;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">#修改key名&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;a&amp;#34;: 1, &amp;#34;b&amp;#34;: 2}&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;with_entries(.key |= &amp;#34;student_&amp;#34; + .)&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;student_a&amp;#34;&lt;/span>: 1, &lt;span class="s2">&amp;#34;student_b&amp;#34;&lt;/span>: 2&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="select">select&lt;/h3>
&lt;p>select 是过滤器,里面可以写表达式&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#选择数组里面的偶数&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="o">[&lt;/span>1,2,3,4,5,6&lt;span class="o">]&lt;/span>&lt;span class="p">|&lt;/span>jq &lt;span class="s1">&amp;#39;map(select(.%2 == 0))&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">[&lt;/span>
2,
4,
&lt;span class="m">6&lt;/span>
&lt;span class="o">]&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[{&amp;#34;id&amp;#34;: &amp;#34;first&amp;#34;, &amp;#34;val&amp;#34;: 1}, {&amp;#34;id&amp;#34;: &amp;#34;second&amp;#34;, &amp;#34;val&amp;#34;: 2}]&amp;#39;&lt;/span>&lt;span class="p">|&lt;/span> jq &lt;span class="s1">&amp;#39;.[]|select(.id==&amp;#34;first&amp;#34;)&amp;#39;&lt;/span>
&lt;span class="c1">#输出&lt;/span>
&lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;id&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;first&amp;#34;&lt;/span>,
&lt;span class="s2">&amp;#34;val&amp;#34;&lt;/span>: &lt;span class="m">1&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="实例">实例&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;ID&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;Name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;ltptest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;Owner&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;ltptest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;DpReplicaNum&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;MpReplicaNum&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;Status&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;Capacity&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;RwDpCnt&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;MpCnt&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;DpCnt&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;AvailSpaceAllocated&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">3000&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;Tokens&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;bHRwdGVzdCMxIzE1NzY4MjU1MzY=&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;TokenType&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;Value&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;bHRwdGVzdCMxIzE1NzY4MjU1MzY=&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;VolName&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;ltptest&amp;#34;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="nt">&amp;#34;bHRwdGVzdCMyIzE1NzY4MjU1MzY=&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;TokenType&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;Value&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;bHRwdGVzdCMyIzE1NzY4MjU1MzY=&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;VolName&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;ltptest&amp;#34;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ jq &lt;span class="s1">&amp;#39;.Tokens | .[] | select( .TokenType == 2) | .Value&amp;#39;&lt;/span>
&lt;span class="s2">&amp;#34;bHRwdGVzdCMyIzE1NzY4MjU1MzY=&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="c1"># 获取 docker image下载量&lt;/span>
$ curl &lt;span class="s2">&amp;#34;https://hub.docker.com/v2/repositories/chubaofs/&amp;#34;&lt;/span> 2&amp;gt;/dev/null &lt;span class="p">|&lt;/span> &lt;span class="se">\&amp;gt;&lt;/span>
jq &lt;span class="s1">&amp;#39;reduce (.results | .[] | .pull_count ) as $item (0; .+$item) &amp;#39;&lt;/span>
&lt;span class="c1"># strftime&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[ { &amp;#34;CreateTime&amp;#34;: 1629968504 }, { &amp;#34;CreateTime&amp;#34;: 130675857 } ]&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> jq &lt;span class="s1">&amp;#39;.[].CreateTime |= strftime(&amp;#34;%Y-%m-%d_%H:%M:%S&amp;#34;)&amp;#39;&lt;/span>
&lt;span class="c1"># 计算百分比及格式化dataSize&lt;/span>
&lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;[ { &amp;#34;UseSize&amp;#34;: 1629968504, &amp;#34;TotalSize&amp;#34;: 10222023 }, { &amp;#34;UsedSize&amp;#34;: 130675857, &amp;#34;TotalSize&amp;#34;: 2132 } ]&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span>jq &lt;span class="s1">&amp;#39;[
&lt;/span>&lt;span class="s1"> .[] | . + { Ratio: (.UsedSize/.TotalSize | .*100 | floor | ./100 ) } |
&lt;/span>&lt;span class="s1"> (
&lt;/span>&lt;span class="s1"> [&amp;#34;B&amp;#34;, &amp;#34;KB&amp;#34;, &amp;#34;MB&amp;#34;, &amp;#34;GB&amp;#34;, &amp;#34;TB&amp;#34;, &amp;#34;PB&amp;#34;, &amp;#34;ZB&amp;#34;] as $unit |
&lt;/span>&lt;span class="s1"> .TotalSize |= ( . as $size |
&lt;/span>&lt;span class="s1"> ($size | [until(.&amp;lt;1024; ./1024)] | .[0] | .*100 | floor | ./100 | tostring) +
&lt;/span>&lt;span class="s1"> &amp;#34;_&amp;#34; +
&lt;/span>&lt;span class="s1"> ($size | log10 | ./3 | floor as $l | $unit[$l] )
&lt;/span>&lt;span class="s1"> )
&lt;/span>&lt;span class="s1"> )
&lt;/span>&lt;span class="s1"> ] &amp;#39;&lt;/span>
&amp;gt;
&lt;span class="o">[&lt;/span>
&lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;UsedSize&amp;#34;&lt;/span>: 1629968504,
&lt;span class="s2">&amp;#34;TotalSize&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;9.74MB&amp;#34;&lt;/span>,
&lt;span class="s2">&amp;#34;Ratio&amp;#34;&lt;/span>: &lt;span class="m">0&lt;/span>
&lt;span class="o">}&lt;/span>,
&lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;UsedSize&amp;#34;&lt;/span>: 130675857,
&lt;span class="s2">&amp;#34;TotalSize&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;2.08KB&amp;#34;&lt;/span>,
&lt;span class="s2">&amp;#34;Ratio&amp;#34;&lt;/span>: &lt;span class="m">0&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">]&lt;/span>
&lt;span class="c1">## 更新对象属性数组中的某一属性值&lt;/span>
$ &lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;Replicas&amp;#34;:[ { &amp;#34;ReportTime&amp;#34;: 1629968504 }, { &amp;#34;ReportTime&amp;#34;: 130675857 } ]}&amp;#39;&lt;/span> &lt;span class="p">|&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> jq -r &lt;span class="s1">&amp;#39;.Replicas[] |= (.ReportTime |= strftime(&amp;#34;%Y-%m-%dT%H:%M:%S&amp;#34;))&amp;#39;&lt;/span>
&amp;gt;
&lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;Replicas&amp;#34;&lt;/span>: &lt;span class="o">[&lt;/span>
&lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;ReportTime&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;2021-08-26T09:01:44&amp;#34;&lt;/span>
&lt;span class="o">}&lt;/span>,
&lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;ReportTime&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;1974-02-21T10:50:57&amp;#34;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">]&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://gist.github.com/olih/f7437fb6962fb3ee9fe95bda8d2c8fa4">https://gist.github.com/olih/f7437fb6962fb3ee9fe95bda8d2c8fa4&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://stedolan.github.io/jq/">jq&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>MySQL 锁</title><link>https://justice.bj.cn/post/30.architech/mysql/mysql%E9%94%81/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/mysql/mysql%E9%94%81/</guid><description>&lt;h1 id="mysql-锁">MySQL 锁&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>mysql中的锁是用于保证并发事务访问一致性的一种机制。&lt;/p>
&lt;h2 id="分类">分类&lt;/h2>
&lt;p>按对资源的访问类型可分为：&lt;/p>
&lt;ul>
&lt;li>共享锁（读锁）：其他事务可以读，但不能写。&lt;/li>
&lt;li>排他锁（写锁） ：其他事务不能读取，也不能写。&lt;/li>
&lt;/ul>
&lt;p>按对资源的锁定粒度可分为：&lt;/p>
&lt;ul>
&lt;li>表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。&lt;/li>
&lt;li>行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。&lt;/li>
&lt;li>页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般&lt;/li>
&lt;/ul>
&lt;p>MySQL 不同的存储引擎支持不同的锁机制，所有的存储引擎都以自己的方式显现了锁机制，服务器层完全不了解存储引擎中的锁实现：&lt;/p>
&lt;ul>
&lt;li>MyISAM 和 MEMORY 存储引擎采用的是表级锁（table-level locking）&lt;/li>
&lt;li>BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁&lt;/li>
&lt;li>InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。&lt;/li>
&lt;/ul>
&lt;p>MySQL中锁的种类很多，有常见的表锁和行锁，也有新加入的Metadata Lock等等,表锁是对一整张表加锁，虽然可分为读锁和写锁，但毕竟是锁住整张表，会导致并发能力下降，一般是做ddl处理时使用。&lt;/p>
&lt;p>行锁则是锁住数据行，这种加锁方法比较复杂，但是由于只锁住有限的数据，对于其它数据不加限制，所以并发能力强，MySQL一般都是用行锁来处理并发事务。这里主要讨论的也就是行锁。&lt;/p>
&lt;p>默认情况下，表锁和行锁都是自动获得的， 不需要额外的命令。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>表锁&lt;/th>
&lt;th>页锁&lt;/th>
&lt;th>行锁&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>MyISAM&lt;/td>
&lt;td>√&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BDB&lt;/td>
&lt;td>√&lt;/td>
&lt;td>√&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>InnoDB&lt;/td>
&lt;td>√&lt;/td>
&lt;td>&lt;/td>
&lt;td>√&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="innodb存储引擎的锁的算法有三种">InnoDB存储引擎的锁的算法有三种&lt;/h2>
&lt;p>1.&lt;strong>Record lock&lt;/strong>：单个行记录上的锁&lt;/p>
&lt;p>2.&lt;strong>Gap lock&lt;/strong>：间隙锁，锁定一个范围，不包括记录本身&lt;/p>
&lt;p>3.&lt;strong>Next-key lock&lt;/strong>：record+gap 锁定一个范围，包含记录本身&lt;/p>
&lt;h2 id="myisam-表锁">&lt;strong>MyISAM 表锁&lt;/strong>&lt;/h2>
&lt;h2 id="myisam表级锁模式">&lt;strong>MyISAM表级锁模式：&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；&lt;/li>
&lt;li>表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；&lt;/li>
&lt;/ul>
&lt;p>MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。&lt;/p>
&lt;p>默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。 （This ensures that updates to a table are not “starved” even when there is heavy SELECT activity for the table. However, if there are many updates for a table, SELECT statements wait until there are no more updates.）。&lt;/p>
&lt;p>这也正是 MyISAM 表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。同时，一些需要长时间运行的查询操作，也会使写线程“饿死” ，应用中应尽量避免出现长时间运行的查询操作（在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解” ，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行）。&lt;/p>
&lt;p>可以设置改变读锁和写锁的优先级：&lt;/p>
&lt;ul>
&lt;li>通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。&lt;/li>
&lt;li>通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。&lt;/li>
&lt;li>通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。&lt;/li>
&lt;li>给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。&lt;/li>
&lt;/ul>
&lt;h2 id="myisam加表锁方法">&lt;strong>MyISAM加表锁方法：&lt;/strong>&lt;/h2>
&lt;p>MyISAM 在执行查询语句（SELECT）前，会自动给涉及的表加读锁，在执行更新操作&lt;br>
（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。&lt;/p>
&lt;p>在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。&lt;/p>
&lt;p>MyISAM存储引擎支持并发插入，以减少给定表的读和写操作之间的争用：&lt;/p>
&lt;p>如果MyISAM表在数据文件中间没有空闲块，则行始终插入数据文件的末尾。 在这种情况下，你可以自由混合并发使用MyISAM表的INSERT和SELECT语句而不需要加锁——你可以在其他线程进行读操作的时候，同时将行插入到MyISAM表中。 文件中间的空闲块可能是从表格中间删除或更新的行而产生的。 如果文件中间有空闲快，则并发插入会被禁用，但是当所有空闲块都填充有新数据时，它又会自动重新启用。 要控制此行为，可以使用MySQL的concurrent_insert系统变量。&lt;/p>
&lt;p>如果你使用LOCK TABLES显式获取表锁，则可以请求READ LOCAL锁而不是READ锁，以便在锁定表时，其他会话可以使用并发插入。&lt;/p>
&lt;ul>
&lt;li>当concurrent_insert设置为0时，不允许并发插入。&lt;/li>
&lt;li>当concurrent_insert设置为1时，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个线程读表的同时，另一个线程从表尾插入记录。这也是MySQL的默认设置。&lt;/li>
&lt;li>当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。&lt;/li>
&lt;/ul>
&lt;h2 id="查询表级锁争用情况">&lt;strong>查询表级锁争用情况：&lt;/strong>&lt;/h2>
&lt;p>可以通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁的争夺，如果 Table_locks_waited 的值比较高，则说明存在着较严重的表级锁争用情况：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="n">mysql&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SHOW&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">LIKE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;Table%&amp;#39;&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="c1">-----------------------+---------+
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Variable_name&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Value&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="c1">-----------------------+---------+
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Table_locks_immediate&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">1151552&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Table_locks_waited&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">15324&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="c1">-----------------------+---------+
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="innodb行级锁和表级锁">&lt;strong>InnoDB行级锁和表级锁&lt;/strong>&lt;/h2>
&lt;h2 id="innodb锁模式">&lt;strong>InnoDB锁模式：&lt;/strong>&lt;/h2>
&lt;p>InnoDB 实现了以下两种类型的&lt;strong>行锁&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。&lt;/li>
&lt;li>排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。&lt;/li>
&lt;/ul>
&lt;p>为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是&lt;strong>表锁&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。&lt;/li>
&lt;li>意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>锁模式的兼容情况：&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-37761612ead11ddc3762a4c20ddab3f3_720w.jpg" alt="">&lt;/p>
&lt;p>（如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务； 反之， 如果两者不兼容，该事务就要等待锁释放。）&lt;/p>
&lt;h2 id="innodb加锁方法">&lt;strong>InnoDB加锁方法：&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>意向锁是 InnoDB 自动加的， 不需用户干预。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB&lt;br>
会自动给涉及数据集加排他锁（X)；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于普通 SELECT 语句，InnoDB 不会加任何锁；&lt;br>
事务可以通过以下语句显式给记录集加共享锁或排他锁：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>共享锁（S）：SELECT * FROM table_name WHERE &amp;hellip; LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>排他锁（X)：SELECT * FROM table_name WHERE &amp;hellip; FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>隐式锁定：&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>InnoDB在事务执行过程中，使用两阶段锁协议：&lt;/p>
&lt;p>随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁；&lt;/p>
&lt;p>锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在&lt;strong>同一时刻&lt;/strong>被释放。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>显式锁定 ：&lt;/strong>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">select ... lock in share mode //共享锁
select ... for update //排他锁
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>select for update：&lt;/strong>&lt;/p>
&lt;p>在执行这个 select 查询语句的时候，会将对应的索引访问条目进行上排他锁（X 锁），也就是说这个语句对应的锁就相当于update带来的效果。&lt;/p>
&lt;p>select *** for update 的使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到 for update 子句。&lt;/p>
&lt;p>**select lock in share mode ：**in share mode 子句的作用就是将查找到的数据加上一个 share 锁，这个就是表示其他的事务只能对这些数据进行简单的select 操作，并不能够进行 DML 操作。select *** lock in share mode 使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据 使用了 in share mode 的方式上了 S 锁。&lt;/p>
&lt;p>&lt;strong>性能影响：&lt;/strong>&lt;br>
select for update 语句，相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。&lt;br>
select lock in share mode 语句是一个给查找的数据上一个共享锁（S 锁）的功能，它允许其他的事务也对该数据上S锁，但是不能够允许对该数据进行修改。如果不及时的commit 或者rollback 也可能会造成大量的事务等待。&lt;/p>
&lt;p>&lt;strong>for update 和 lock in share mode 的区别：&lt;/strong>&lt;/p>
&lt;p>前一个上的是排他锁（X 锁），一旦一个事务获取了这个锁，其他的事务是没法在这些数据上执行 for update ；后一个是共享锁，多个事务可以同时的对相同数据执行 lock in share mode。&lt;/p>
&lt;h2 id="innodb-行锁实现方式">&lt;strong>InnoDB 行锁实现方式：&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！&lt;/li>
&lt;li>不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。&lt;/li>
&lt;li>只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，&lt;br>
别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。（更多阅读：&lt;a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s/h4B84UmzAUJ81iBY_FXNOg">MySQL索引总结&lt;/a>）&lt;/li>
&lt;li>由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。&lt;/li>
&lt;/ul>
&lt;h2 id="innodb的间隙锁">&lt;strong>InnoDB的间隙锁：&lt;/strong>&lt;/h2>
&lt;p>当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。&lt;/p>
&lt;p>很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。&lt;/p>
&lt;p>&lt;strong>InnoDB使用间隙锁的目的：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>防止幻读，以满足相关隔离级别的要求；&lt;/li>
&lt;li>满足恢复和复制的需要：&lt;/li>
&lt;/ol>
&lt;p>MySQL 通过 BINLOG 录入执行成功的 INSERT、UPDATE、DELETE 等更新数据的 SQL 语句，并由此实现 MySQL 数据库的恢复和主从复制。MySQL 的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点：&lt;/p>
&lt;p>一是 MySQL 的恢复是 SQL 语句级的，也就是重新执行 BINLOG 中的 SQL 语句。&lt;/p>
&lt;p>二是 MySQL 的 Binlog 是按照事务提交的先后顺序记录的， 恢复也是按这个顺序进行的。&lt;/p>
&lt;p>由此可见，MySQL 的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。&lt;/p>
&lt;h2 id="innodb-在不同隔离级别下的一致性读及锁的差异">&lt;strong>InnoDB 在不同隔离级别下的一致性读及锁的差异：&lt;/strong>&lt;/h2>
&lt;p>锁和多版本数据（MVCC）是 InnoDB 实现一致性读和 ISO/ANSI SQL92 隔离级别的手段。&lt;/p>
&lt;p>因此，在不同的隔离级别下，InnoDB 处理 SQL 时采用的一致性读策略和需要的锁是不同的：&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-c83c6459f8dc93a5f157fe1e3080088d_720w.jpg" alt="">&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-568951f4cdfeb9416042627a7b94c4ac_720w.jpg" alt="">&lt;/p>
&lt;p>对于许多 SQL，隔离级别越高，InnoDB 给记录集加的锁就越严格（尤其是使用范围条件的时候），产生锁冲突的可能性也就越高，从而对并发性事务处理性能的 影响也就越大。&lt;/p>
&lt;p>因此， 我们在应用中， 应该尽量使用较低的隔离级别， 以减少锁争用的机率。实际上，通过优化事务逻辑，大部分应用使用 Read Commited 隔离级别就足够了。对于一些确实需要更高隔离级别的事务， 可以通过在程序中执行 SET SESSION TRANSACTION ISOLATION&lt;/p>
&lt;p>LEVEL REPEATABLE READ 或 SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE 动态改变隔离级别的方式满足需求。&lt;/p>
&lt;h2 id="获取-innodb-行锁争用情况">&lt;strong>获取 InnoDB 行锁争用情况：&lt;/strong>&lt;/h2>
&lt;p>可以通过检查 InnoDB_row_lock 状态变量来分析系统上的行锁的争夺情况：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">mysql&amp;gt; show status like &amp;#39;innodb_row_lock%&amp;#39;;
+-------------------------------+-------+
| Variable_name | Value |
+-------------------------------+-------+
| InnoDB_row_lock_current_waits | 0 |
| InnoDB_row_lock_time | 0 |
| InnoDB_row_lock_time_avg | 0 |
| InnoDB_row_lock_time_max | 0 |
| InnoDB_row_lock_waits | 0 |
+-------------------------------+-------+
5 rows in set (0.01 sec)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="lock-tables-和-unlock-tables">&lt;strong>LOCK TABLES 和 UNLOCK TABLES&lt;/strong>&lt;/h2>
&lt;p>Mysql也支持lock tables和unlock tables，这都是在服务器层（MySQL Server层）实现的，和存储引擎无关，它们有自己的用途，并不能替代事务处理。 （除了禁用了autocommint后可以使用，其他情况不建议使用）：&lt;/p>
&lt;ul>
&lt;li>LOCK TABLES 可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。&lt;/li>
&lt;li>UNLOCK TABLES 可以释放当前线程获得的任何锁定。当前线程执行另一个 LOCK TABLES 时，&lt;br>
或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁&lt;/li>
&lt;/ul>
&lt;h2 id="lock-tables语法">&lt;strong>LOCK TABLES语法：&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>在用 LOCK TABLES 对 InnoDB 表加锁时要注意，要将 AUTOCOMMIT 设为 0，否则MySQL 不会给表加锁；&lt;/li>
&lt;li>事务结束前，不要用 UNLOCK TABLES 释放表锁，因为 UNLOCK TABLES会隐含地提交事务；&lt;/li>
&lt;li>COMMIT 或 ROLLBACK 并不能释放用 LOCK TABLES 加的表级锁，必须用UNLOCK TABLES 释放表锁。&lt;/li>
&lt;/ul>
&lt;p>正确的方式见如下语句：&lt;br>
例如，如果需要写表 t1 并从表 t 读，可以按如下做：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="k">SET&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">AUTOCOMMIT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">LOCK&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TABLES&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">t1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">WRITE&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">t2&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">READ&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">...;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="k">do&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">something&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">with&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">tables&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">t1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">and&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">t2&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">here&lt;/span>&lt;span class="p">];&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">COMMIT&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="n">UNLOCK&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TABLES&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="使用lock-tables的场景">&lt;strong>使用LOCK TABLES的场景：&lt;/strong>&lt;/h2>
&lt;p>给表显示加表级锁（InnoDB表和MyISAM都可以），一般是为了在一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。（与MyISAM默认的表锁行为类似）&lt;/p>
&lt;p>在用 LOCK TABLES 给表显式加表锁时，必须同时取得所有涉及到表的锁，并且 MySQL 不支持锁升级。也就是说，在执行 LOCK TABLES 后，只能访问显式加锁的这些表，不能访问未加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。&lt;/p>
&lt;p>其实，在MyISAM自动加锁（表锁）的情况下也大致如此，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。&lt;/p>
&lt;p>例如，有一个订单表 orders，其中记录有各订单的总金额 total，同时还有一个 订单明细表 order_detail，其中记录有各订单每一产品的金额小计 subtotal，假设我们需要检 查这两个表的金额合计是否相符，可能就需要执行如下两条 SQL：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">Select sum(total) from orders;
Select sum(subtotal) from order_detail;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这时，如果不先给两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中，&lt;br>
order_detail 表可能已经发生了改变。因此，正确的方法应该是：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">Lock tables orders read local, order_detail read local;
Select sum(total) from orders;
Select sum(subtotal) from order_detail;
Unlock tables;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>（在 LOCK TABLES 时加了“local”选项，其作用就是允许当你持有表的读锁时，其他用户可以在满足 MyISAM 表并发插入条件的情况下，在表尾并发插入记录（MyISAM 存储引擎支持“并发插入”））&lt;/p>
&lt;h2 id="悲观锁乐观锁">悲观锁/乐观锁&lt;/h2>
&lt;p>数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>乐观锁(Optimistic Lock)&lt;/strong>：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。&lt;/li>
&lt;/ul>
&lt;p>乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。,一般会使用版本号机制或CAS算法实现。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>悲观锁(Pessimistic Lock)&lt;/strong>：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。&lt;/li>
&lt;/ul>
&lt;p>悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。使用数据库中的锁机制&lt;/p>
&lt;h3 id="两种锁的使用场景">&lt;strong>两种锁的使用场景&lt;/strong>&lt;/h3>
&lt;p>从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。&lt;/p>
&lt;p>但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行Retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。&lt;/p>
&lt;h2 id="死锁">死锁&lt;/h2>
&lt;p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。&lt;/p>
&lt;h3 id="死锁的解决方法">死锁的解决方法&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>  如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果业务处理不好可以用分布式事务锁或者使用乐观锁;&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/29150809">https://zhuanlan.zhihu.com/p/29150809&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>MySQL事务</title><link>https://justice.bj.cn/post/30.architech/mysql/mysql%E4%BA%8B%E5%8A%A1/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/mysql/mysql%E4%BA%8B%E5%8A%A1/</guid><description>&lt;h1 id="mysql事务">MySQL事务&lt;/h1>
&lt;h2 id="定义">定义&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>数据库事务是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>事务的使用是数据库管理系统区别文件系统的重要特征之一。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据库事务指的是一组数据操作，事务内的操作要么就是全部成功，要么就是全部失败，什么都不做，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>InnoDB 引擎支持事务，MyISAM 引擎是不支持事务。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="事务acid">事务ACID&lt;/h2>
&lt;p>原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability），人们习惯称之为 ACID 特性。下面我逐一对其进行解释。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>原子性&lt;/strong> （Atomicity）&lt;/p>
&lt;p>事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。例如，如果一个事务需要新增 100 条记录，但是在新增了 10 条记录之后就失败了，那么数据库将回滚对这 10 条新增的记录。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>一致性&lt;/strong> （Consistency）&lt;/p>
&lt;p>指事务将数据库从一种状态转变为另一种一致的的状态。事务开始前和结束后，数据库的完整性约束没有被破坏。例如工号带有唯一属性，如果经过一个修改工号的事务后，工号变的非唯一了，则表明一致性遭到了破坏。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>隔离性&lt;/strong> （Isolation）&lt;/p>
&lt;p>要求每个读写事务的对象对其他事务的操作对象能互相分离，即该事务提交前对其他事务不可见。 也可以理解为多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。这指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。例如一个用户在更新自己的个人信息的同时，是不能看到系统管理员也在更新该用户的个人信息（此时更新事务还未提交）。&lt;/p>
&lt;p>注：MySQL 通过锁机制来保证事务的隔离性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>持久性&lt;/strong> （Durability）&lt;/p>
&lt;p>事务一旦提交，则其结果就是永久性的。即使发生宕机的故障，数据库也能将数据恢复，也就是说事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。这只是从事务本身的角度来保证，排除 RDBMS（关系型数据库管理系统，例如 Oracle、MySQL 等）本身发生的故障。&lt;/p>
&lt;p>注：MySQL 使用 &lt;code>redo log&lt;/code> 来保证事务的持久性。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>并发控制
（1）DBS（数据库系统）一个明显的特点是多个用户共享数据库资源，尤其是多个用户可以同时存取相同数据。&lt;/p>
&lt;p>串行控制：如果事务是顺序执行的，即一个事务完成之后，再开始另一事务。
并行控制：如果DBMS可以同时接受多个事务，并且这些事务在时间上可以重叠执行。
（2）并发控制概述&lt;/p>
&lt;p>事务是并发控制的基本单位，保证事务ACID的特性是事务处理的重要任务，而并发操作有可能会破坏其ACID特性。&lt;/p>
&lt;p>DBMS并发控制机制的责任：对并发操作进行正确调度，保证事务的隔离更一般，确保数据库的一致性。&lt;/p>
&lt;h3 id="数据的不一致性">数据的不一致性&lt;/h3>
&lt;p>如果没有锁定且多个用户同时访问一个数据库，则当他们的事务同时使用相同的数据时可能会发生问题。由于并发操作带来的数据不一致性包括：丢失数据更新、读“脏”数据（脏读）、不可重复读。&lt;/p>
&lt;p>（1）更新丢失
两个事务都同时更新一行数据，一个事务对数据的更新把另一个事务对数据的更新覆盖了。这是因为系统没有执行任何的锁操作，因此并发并没有被隔离开来。&lt;/p>
&lt;p>（2）脏读
一个事务读取到了另一事务未提交的数据操作结果。&lt;/p>
&lt;p>（3）不可重复读
不可重复读（Non-repeatable Reads）：一个事务对同一行数据重复读取两次，但是却得到了不同的结果。&lt;/p>
&lt;p>包括以下情况：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>虚读：事务T1读取某一数据后，事务T2对其做了修改，当事务T1再次读取该数据时得到与前一次不同的值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>幻读：事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据或者缺少了第一次查询中出现的数据。这是因为在两次查询过程中有另外一个事务插入数据造成的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>不可重复读和幻读的区别：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>不可重复读重点在于update和delete，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>幻读的重点在于insert。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。&lt;/p>
&lt;h2 id="事务隔离级别">事务隔离级别&lt;/h2>
&lt;p>为了避免上面出现的几种情况，在标准SQL规范中，定义了4个事务隔离级别，不同的隔离级别对事务的处理不同。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>读未提交（Read Uncommitted）&lt;/strong>：在并发事务A,B中，事务A能读取到事务B的未提交修改操作数据；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>读提交（Read Committed）&lt;/strong>：在并发事务A,B中，事务A只能读取到事务B的已提交的数据；读提交解决了脏读的问题，但是无法解决可重复读、幻读。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>可重复读取（Repeatable Read）：处理更新丢失、脏读和不可重复读取。读取数据的事务将会禁止写事务，但允许读事务，写事务则禁止任何其他事务。可通过“共享读锁”和“排他写锁”实现。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>序列化（Serializable）：提供严格的事务隔离。要求失去序列化执行，事务只能一个接一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。&lt;/p>
&lt;p>隔离级别越高，越能保证数据的完整性和统一性，但是对并发性能的影响也越大。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed。它能够避免脏读，而且具有较好的并发性能。尽管它会导致不可重复读、幻读和第二类丢失更新这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="隔离级别">隔离级别&lt;/h2>
&lt;p>SQL 标准定义的四种隔离级别被 ANSI（美国国家标准学会）和 ISO/IEC（国际标准）采用，每种级别对事务的处理能力会有不同程度的影响。&lt;/p>
&lt;p>mysql 有四级事务隔离级别 每个级别都有字符或数字编号&lt;/p>
&lt;blockquote>
&lt;p>读未提交 READ-UNCOMMITTED | 0：存在脏读，不可重复读，幻读的问题&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>读已提交 READ-COMMITTED | 1：解决脏读的问题，存在不可重复读，幻读的问题&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>可重复读 REPEATABLE-READ | 2：解决脏读，不可重复读的问题，存在幻读的问题，默认隔离级别，使用 MMVC机制 实现可重复读&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>序列化 SERIALIZABLE | 3：解决脏读，不可重复读，幻读，可保证事务安全，但完全串行执行，性能最低&lt;/p>
&lt;/blockquote>
&lt;p>幻读会在 RU / RC / RR 级别下出现，SERIALIZABLE 则杜绝了幻读，但 RU / RC 下还会存在脏读，不可重复读，故我们就以 RR 级别来研究幻读，排除其他干扰。&lt;/p>
&lt;h5 id="各个隔离级别下产生的一些问题">各个隔离级别下产生的一些问题&lt;/h5>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>隔离级别&lt;/strong>&lt;/th>
&lt;th>&lt;strong>脏读&lt;/strong>&lt;/th>
&lt;th>&lt;strong>不可重复读&lt;/strong>&lt;/th>
&lt;th>&lt;strong>幻读&lt;/strong>&lt;/th>
&lt;th>实现方式&lt;/th>
&lt;th>性能&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>读未提交(RU)&lt;/td>
&lt;td>O&lt;/td>
&lt;td>O&lt;/td>
&lt;td>O&lt;/td>
&lt;td>未加锁&lt;/td>
&lt;td>最好&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>读提交(RC)&lt;/td>
&lt;td>x&lt;/td>
&lt;td>O&lt;/td>
&lt;td>O&lt;/td>
&lt;td>读不加锁，写入、修改和删除加锁&lt;/td>
&lt;td>&lt;/td>
&lt;td>Oracle默认隔离级别&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>可重复读(RR)&lt;/td>
&lt;td>x&lt;/td>
&lt;td>x&lt;/td>
&lt;td>O&lt;/td>
&lt;td>MVCC&lt;/td>
&lt;td>&lt;/td>
&lt;td>InnoDB默认隔离级别&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>串行化(Serialser)&lt;/td>
&lt;td>x&lt;/td>
&lt;td>x&lt;/td>
&lt;td>x&lt;/td>
&lt;td>读加共享锁，写加排它锁&lt;/td>
&lt;td>最差&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>在MVCC并发控制中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read)。快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。&lt;/p>
&lt;h3 id="nextkey锁">NextKey锁&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>MySQL 通过行锁+间隙锁的方式 解决了RR级别下解决了幻读的问题;&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h4 id="快照读vs当前读">快照读VS当前读&lt;/h4>
&lt;p>在一个支持MVCC并发控制的系统中，哪些读操作是快照读？哪些操作又是当前读呢？以MySQL InnoDB为例：&lt;/p>
&lt;p>快照读：简单的select操作，属于快照读，不加锁。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>当前读：特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">lock&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">in&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">share&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">mode&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">for&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">update&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">insert&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">into&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">values&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="err">…&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">update&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">set&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">delete&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>所有以上的语句，都属于当前读，读取记录的最新版本。并且，读取之后，还需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，除了第一条语句，对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。&lt;/p>
&lt;h3 id="serializable">Serializable&lt;/h3>
&lt;p>这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差。如果你的业务并发的特别少或者没有并发，同时又要求数据及时可靠的话，可以使用这种模式。&lt;/p>
&lt;p>这里要吐槽一句，不要看到select就说不会加锁了，在Serializable这个级别，还是会加锁的！&lt;/p>
&lt;h3 id="mvcc在mysql的innodb中的实现">MVCC在MySQL的InnoDB中的实现&lt;/h3>
&lt;p>在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。 在可重读Repeatable reads事务隔离级别下：&lt;/p>
&lt;ul>
&lt;li>SELECT时，读取创建版本号&amp;lt;=当前事务版本号，删除版本号为空或&amp;gt;当前事务版本号。&lt;/li>
&lt;li>INSERT时，保存当前事务版本号为行的创建版本号&lt;/li>
&lt;li>DELETE时，保存当前事务版本号为行的删除版本号&lt;/li>
&lt;li>UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行&lt;/li>
&lt;/ul>
&lt;p>通过MVCC，虽然每行记录都需要额外的存储空间，更多的行检查工作以及一些额外的维护工作，但可以减少锁的使用，大多数读操作都不用加锁，读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，也只锁住必要行。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://developer.ibm.com/zh/articles/os-mysql-transaction-isolation-levels-and-locks/">MySQL 事务隔离级别和锁 – IBM Developer&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://tech.meituan.com/2014/08/20/innodb-lock.html">Innodb中的事务隔离级别和锁的关系 - 美团技术团队&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Protobuf</title><link>https://justice.bj.cn/post/30.architech/protobuf/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/protobuf/</guid><description>&lt;h1 id="protobuf">Protobuf&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Protobuf 是 Google 整的一个序列化/反序列化框架，性能不算很好不过用的人比较多，各个语言的实现也比较全，其中 golang 的版本是 google 官方维护的 &lt;a href="https://github.com/golang/protobuf">golang/protobuf&lt;/a>，但由于比较保守，对各种新 feature request 不太感兴趣，所以社区广泛使用的是一个 fork 的版本 &lt;a href="https://github.com/gogo/protobuf">gogo/protobuf&lt;/a>，gogo 版本不仅在性能上做了很多优化，而且提供了很多 &lt;a href="https://github.com/gogo/protobuf/blob/master/extensions.md">extensions&lt;/a>，可以让生成的代码更符合 go 开发的习惯。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-protobuf" data-lang="protobuf">&lt;span class="n">syntax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;proto3&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="kd">message&lt;/span> &lt;span class="nc">Person&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">required&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">required&lt;/span> &lt;span class="kt">int32&lt;/span> &lt;span class="n">id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="n">email&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="kd">enum&lt;/span> &lt;span class="n">PhoneType&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="n">MOBILE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="n">HOME&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="n">WORK&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="kd">message&lt;/span> &lt;span class="nc">PhoneNumber&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">required&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="n">number&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="n">PhoneType&lt;/span> &lt;span class="n">type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="k">default&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">HOME&lt;/span>&lt;span class="p">];&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">repeated&lt;/span> &lt;span class="n">PhoneNumber&lt;/span> &lt;span class="n">phone&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="语法">语法&lt;/h2>
&lt;h3 id="修饰符">修饰符&lt;/h3>
&lt;ul>
&lt;li>required : 　不可以增加或删除的字段，必须初始化；&lt;/li>
&lt;li>optional : 　 可选字段，可删除，可以不初始化；&lt;/li>
&lt;li>repeated : 　可重复字段， 对应到java文件里，生成的是List。&lt;/li>
&lt;/ul>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://colobu.com/2019/10/03/protobuf-ultimate-tutorial-in-go/">Protobuf 终极教程&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Raft算法</title><link>https://justice.bj.cn/post/31.distribute/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/raft%E7%AE%97%E6%B3%95/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/31.distribute/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/raft%E7%AE%97%E6%B3%95/</guid><description>&lt;h1 id="raft算法">Raft算法&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;code>Raft&lt;/code>算法是2013年斯坦福大学的Diego Ongaro、John Ousterhout 两人发布的一致性算法，论文：《In Search of an Understandable Consensus Algorithm》；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>与&lt;code>Paxos&lt;/code>相比，Raft 易理解、易实现；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Raft 和 Paxos 一样, 只要保证超过半数的节点正常就能够提供服务；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="基本思想">基本思想&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Raft将整个时间划分为一个个的小周期, 称为&lt;strong>任期&lt;/strong>(&lt;code>Term&lt;/code>)；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个任期又分为&lt;code>选举&lt;/code>和选举后&lt;code>正常操作&lt;/code>两个阶段；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>选举&lt;/code>阶段为每个周期开始的阶段，目的是通过投票选出一个&lt;code>Leader&lt;/code>;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一个Term周期内只能有一个合法的&lt;code>Leader&lt;/code>;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>成功选举出&lt;code>Leader&lt;/code>后，进入&lt;code>正常操作&lt;/code>阶段；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>选举阶段，整个Raft集群不处理外界客户端的请求；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>正常操作阶段，只有&lt;code>Leader&lt;/code>节点能正常接收并处理客户端请求，其他节点如果接收客户端请求，只能缓存或转发给&lt;code>Leader&lt;/code>，由&lt;code>Leader&lt;/code>进行处理；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Leader&lt;/code>接收到客户端请求后，先将请求追加到本地日志中，然后将请求发送给各个&lt;code>Follower&lt;/code>节点；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Follower&lt;/code>接收到请求后，将请求写入本地日志，并给&lt;code>Leader&lt;/code>发送响应；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Leader&lt;/code>收到多数&lt;code>Follower&lt;/code>写入成功响应后，给客户端发送响应，告知状态机执行后结果；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/12-20-57-24-image-20190523192955386.png" alt="image-20190523192955386">&lt;/p>
&lt;h2 id="关键概念">关键概念&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Log&lt;/strong>(日志)：&lt;/li>
&lt;li>&lt;strong>Election&lt;/strong>(选举)：Raft 的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为 Follower 某个节点定时器触发选举后 Term 递增，状态由 Follower 转为 Candidate，向其他节点发起 RequestVote RPC 请求&lt;/li>
&lt;li>&lt;strong>Term&lt;/strong>(任期)：在 Raft 中使用了一个可以理解为周期（第几届、任期）的概念，用 Term 作为一个周期，每个 Term 都是一个连续递增的编号，每一轮选举都是一个 Term 周期，在一个 Term 中只能产生一个 Leader&lt;/li>
&lt;li>&lt;strong>Index&lt;/strong>(日志序号)：&lt;/li>
&lt;/ul>
&lt;h3 id="角色">角色&lt;/h3>
&lt;p>基本的Raft 集群的节点分为以下三种角色：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Candidate&lt;/strong>(候选者)：负责发起选举，发起投票及接收投票。Raft 刚启动时由一个节点从 Follower 转为 Candidate 发起选举，选举出 Leader 后从 Candidate 转为 Leader 状态；&lt;/li>
&lt;li>&lt;strong>Leader&lt;/strong>(领导者)：负责日志的同步管理，处理来自客户端的请求，与 Follower 保持这 heartBeat 的联系；&lt;/li>
&lt;li>&lt;strong>Follower&lt;/strong>(跟随者)：负责响应来自 Leader 或者 Candidate 的请求；&lt;/li>
&lt;/ul>
&lt;p>改进Raft集群另外提供如下几种角色：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Learner&lt;/strong>(学习者)：只读节点，不参与选举投票及日志复制过程，只被动复制 follower 日志；&lt;/li>
&lt;li>&lt;strong>PreCandidate&lt;/strong>(预选者)：&lt;/li>
&lt;/ul>
&lt;h3 id="状态机">状态机&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">graph LR
Follower(Follower)
Candidate(Candidae)
Leader(Leader)
PreCandidate(PreCandidate)
S((START)) --&amp;gt; Follower
Follower -- elect timeout --&amp;gt; Candidate
Follower -- high term --&amp;gt; Follower
Candidate --elect timeout--&amp;gt; Candidate
Candidate --quorum --&amp;gt; Leader
Candidate --high term/hb Event--&amp;gt; Follower
Leader --high term--&amp;gt; Follower
Follower -- elect_timeout preVote --&amp;gt; PreCandidate
PreCandidate --elect quorum--&amp;gt; Candidate
PreCandidate --elect timeout--&amp;gt; PreCandidate
PreCandidate --high term--&amp;gt; Follower
Candidate --elect timeout prevote--&amp;gt; PreCandidate
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/12-20-55-36-fb8549c8d081a00433750711486cd9844ecf6559.png" alt="image-20190523141929145">&lt;/p>
&lt;ul>
&lt;li>所有节点初始状态都是 Follower 角色；&lt;/li>
&lt;li>选举计时器超时，转换为 Candidate 进行选举&lt;/li>
&lt;li>Candidate 收到大多数节点的选票则转换为 Leader；发现 Leader 或者收到更高任期的请求则转换为 Follower&lt;/li>
&lt;li>Leader 在收到更高任期的请求后转换为 Follower&lt;/li>
&lt;/ul>
&lt;h3 id="计时器">计时器&lt;/h3>
&lt;p>raft 定义了两种计时器：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>选举计时器&lt;/strong>：Candidate 节点在进行选举时，如果在一个选举计时器周期内，任然没有获取多数投票，将重新发起选举。 默认值是 1000ms，最大值 50000ms。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>心跳计时器&lt;/strong>：Follower 节点在一个心跳计时器周期内没有收到 Leader 的心跳消息，该 Follower 将会转为 Candidate 状态，发起选举。默认值 100ms，&lt;/p>
&lt;p>选举定时必须要大于 5 倍心跳定时，建议是 10 倍关系。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="关键数据结构">关键数据结构&lt;/h3>
&lt;ul>
&lt;li>Entry&lt;/li>
&lt;li>Message&lt;/li>
&lt;li>Peer&lt;/li>
&lt;li>Snapshot：&lt;/li>
&lt;li>HardState：持久化状态；&lt;/li>
&lt;li>SoftState: 内存状态；&lt;/li>
&lt;li>需要持久化的状态：
&lt;ul>
&lt;li>currentTerm: 当前任期；&lt;/li>
&lt;li>votedFor：投给票的节点 ID；&lt;/li>
&lt;li>log[]：日志序列&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>内存中的状态：
&lt;ul>
&lt;li>commitIndex：&lt;/li>
&lt;li>lastApplied：&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>leader 内存状态：
&lt;ul>
&lt;li>nextIndex[]：&lt;/li>
&lt;li>matchIndex[]：&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/12-20-57-38-image-20190523190540129.png" alt="image-20190523190540129">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>firstLogIndex：标识当前日志序列的起始位置，如果日志不做压缩处理，也就是没有快照模块的话，那么 firstLogIndex 就是零值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>lastLogIndex：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>commitIndex：表示当前已经提交的日志，也就是成功同步到 majority 的日志位置的最大值&lt;/p>
&lt;/li>
&lt;li>
&lt;p>applyIndex：是已经 apply 到状态机的日志索引，它的值必须小于等于 commitIndex，因为只有已经提交的日志才可以 apply 到状态机&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="快照">快照&lt;/h2>
&lt;p>Raft日志会一直增长&lt;/p>
&lt;h2 id="算法流程">算法流程&lt;/h2>
&lt;p>Raft 算法流程分为以下几个步骤：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>启动&lt;/strong>：系统启动时处理流程；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>选举&lt;/strong>：；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>日志复制&lt;/strong>：当选举成功产生 Leader 后，系统进入日志复制阶段，Leader 持续将收到的客户端日志按顺序复制到 Follower：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>变更&lt;/strong>：&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/09/04-10-58-18-raft-alg.gif" alt="">&lt;/p>
&lt;h3 id="启动">启动&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>启动时，所有节点(Node)均为&lt;code>Follower&lt;/code>状态，任期&lt;code>term&lt;/code>置为 1；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果&lt;code>Follower&lt;/code>节点在&lt;code>选举超时时间&lt;/code>内未收到其他节点的 append/hearbeat/snapshot 消息，则状态变为&lt;code>Candidate&lt;/code>，进入选举状态；&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="选举">选举&lt;/h3>
&lt;p>Raft算法被分为一个个任期(term)，每个term分为两个阶段：选举阶段和当选后日志复制阶段。&lt;/p>
&lt;ol>
&lt;li>&lt;code>Candidate&lt;/code>节点先给自己投一票，然后给其他节点发送&lt;code>拉票请求&lt;/code>；&lt;/li>
&lt;li>&lt;code>Leader&lt;/code>,&lt;code>Candidate&lt;/code>节点将忽略其他节点的&lt;code>拉票请求&lt;/code>;&lt;/li>
&lt;li>&lt;code>Follower&lt;/code>节点收到&lt;code>拉票请求&lt;/code>后，按如下规则处理：
&lt;ol>
&lt;li>已为其他节点投过票，忽略拉票节点当前&lt;code>拉票请求&lt;/code>；&lt;/li>
&lt;li>&lt;code>拉票请求&lt;/code>中的&lt;code>term&lt;/code>或&lt;code>index&lt;/code>小于自身，忽略请求；&lt;/li>
&lt;li>否则, 该节点发送&lt;code>投票消息&lt;/code>给&lt;code>拉票节点&lt;/code>；&lt;/li>
&lt;li>同一任期内(term), 按收到请求顺序投票给至多一个候选人，&lt;/li>
&lt;li>该候选人的 log 至少要和自己一样新；&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;code>Candidate&lt;/code>节点收到&lt;code>投票消息&lt;/code>后：
&lt;ol>
&lt;li>计算获得票数，如果票数达到多数赞成票（&amp;gt;一半投票者），则自身当选为&lt;code>Leader&lt;/code>，转为领导人状态, 同时向其他节点发送&lt;code>心跳消息&lt;/code>, 并将缓存的&lt;code>客户端请求&lt;/code>立即执行；&lt;/li>
&lt;li>如果收到其他节点的 Leader 心跳包，且该心跳包的任期要&amp;gt;=自身节点，则表明该其他节点已成功当选为 leader，自身节点将转为&lt;code>Follower&lt;/code>状态；&lt;/li>
&lt;li>否则，选举计数器超时，表明该选举周期内没有任何节点当选，接下来将&lt;code>term&lt;/code>加 1 后，重新进行选举；&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h3 id="日志复制">日志复制&lt;/h3>
&lt;p>每个&lt;strong>term&lt;/strong>在选举成功后，进入日志复制阶段。日志复制阶段中&lt;code>Leader&lt;/code>接收外部&lt;code>Client&lt;/code>的请求，将请求日志复制到各&lt;code>Follower&lt;/code>的过程。日志复制的流程如下：&lt;/p>
&lt;ol>
&lt;li>&lt;code>Leader&lt;/code>接收&lt;code>Client&lt;/code>消息；&lt;/li>
&lt;li>&lt;code>Leader&lt;/code>将消息增加上(index, term)作为&lt;code>Log&lt;/code>，将&lt;code>Log&lt;/code>追加到日志存储中;&lt;/li>
&lt;li>&lt;code>Leader&lt;/code>通过&lt;code>AppendEntries&lt;/code> RPC调用将&lt;code>Log&lt;/code>复制到所有&lt;code>Follower&lt;/code>；&lt;/li>
&lt;li>&lt;code>Follower&lt;/code>收到&lt;code>AppendEntries&lt;/code> RPC，记录Log并返回ACK给&lt;code>Leader&lt;/code>;&lt;/li>
&lt;li>&lt;code>Leader&lt;/code> 收到大多数 &lt;code>Follower&lt;/code> 节点的Ack，则通过&lt;code>状态机&lt;/code>执行消息，并结果返回给 client；&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/09/07-18-13-28-2021-09-07-18-13-23-image.png" alt="">&lt;/p>
&lt;h3 id="配置改变">配置改变&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>配置变更包括节点数量的改变，配置参数的变更等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>最简单的方式是：停止集群、改变成员、启动集群。这种方式在执行时会导致集群整体不可用；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Raft集群成员配置作为一个特殊日志从 leader 节点同步到其它节点去；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Raft 使用一种两阶段方法平滑切换集群成员配置来避免遇到前一节描述的问题，具体流程如下：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="安全性">安全性&lt;/h2>
&lt;p>Raft 增加了如下两条限制以保证安全性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>拥有最新的已提交的 log entry 的 Follower 才有资格成为 Leader。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Leader 只能推进 commit index 来提交当前 term 的已经复制到大多数服务器上的日志，旧 term 日志的提交要等到提交当前 term 的日志来间接提交（log index 小于 commit index 的日志被间接提交）。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="日志压缩">日志压缩&lt;/h3>
&lt;p>在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响可用性。Raft 采用对整个系统进行 snapshot 来解决，snapshot 之前的日志都可以丢弃。&lt;/p>
&lt;p>每个副本独立的对自己的系统状态进行 snapshot，并且只能对已经提交的日志记录进行 snapshot。&lt;/p>
&lt;p>当 Leader 要发给某个日志落后太多的 Follower 的 log entry 被丢弃，Leader 会将 snapshot 发给 Follower。或者当新加进一台机器时，也会发送 snapshot 给它。发送 snapshot 使用 InstalledSnapshot RPC（RPC 细节参见八、Raft 算法总结）。&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/07-09-28-51-2021-10-07-09-28-04-image.png" alt="">&lt;/p>
&lt;h3 id="成员变更">成员变更&lt;/h3>
&lt;p>成员变更是在集群运行过程中副本发生变化，如增加/减少副本数、节点替换等。&lt;/p>
&lt;p>因为各个服务器提交成员变更日志的时刻可能不同，造成各个服务器从旧成员配置（Cold）切换到新成员配置（Cnew）的时刻不同。成员变更不能影响服务的可用性，但是成员变更过程的某一时刻，可能出现在 Cold 和 Cnew 中同时存在两个不相交的多数派，进而可能选出两个 Leader，形成不同的决议，破坏安全性。&lt;/p>
&lt;p>为了解决这一问题，Raft 提出了两阶段的成员变更方法。&lt;/p>
&lt;p>集群先从旧成员配置 Cold 切换到一个过渡成员配置，称为共同一致（joint consensus），共同一致是旧成员配置 Cold 和新成员配置 Cnew 的组合 Cold U Cnew，一旦共同一致 Cold U Cnew 被提交，系统再切换到新成员配置 Cnew。&lt;/p>
&lt;h2 id="实现要点">实现要点&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Batch and Pipeline&lt;/p>
&lt;/li>
&lt;li>
&lt;p>并行 Append Log&lt;/p>
&lt;/li>
&lt;li>
&lt;p>异步 Apply log&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Snapshot&lt;/p>
&lt;/li>
&lt;li>
&lt;p>异步 Lease Read&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ReadIndex&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="预投票prevote">预投票（PreVote）&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>问题：当一个 Follower 节点（A）与其他节点网络隔离时，由于心跳超时，将会变成候选人并发起选举，这时会递增 Term。由于网络隔离，其选举将无法成功，于是会持续选举，导致 Term 不断增大。当网络恢复后，该 A 节点会把其 Term 发送给其他节点，由于该 Term 很大概率大于其他节点 Term，从而引发其他节点进入选举流程。但此时，由于 A 节点的被隔离很久，日志不可能为最新的，所以其不会成为 Leader，导致集群一直在选举。Raft 论文中提出了&lt;strong>PreVote&lt;/strong>算法来解决该问题。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>主要思想：在发起正式投票前，先进行预投票(pre-vote)，预投票时自身 term 不变，但投票 tern+1。确认自己能获得集群大多数节点的投票时，才将自己的 term+1，然后正式进行投票。。由此就可以避免在网络分区的时孤立节点的 term 持续增大，导致后续选举的反复。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>预投票是一个典型的 2PC 事务，&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>为此，需要增加一个新的 PreCandidate 状态。&lt;/p>
&lt;h3 id="read">Read&lt;/h3>
&lt;p>为保证 Read 操作的一致性，最简单的方法是将 Read 也走一遍 raft log，这样性能将很差。&lt;/p>
&lt;p>因为 leader 节点能保证已经 committed 的 log 是最新的 log，所以可以直接从 leader 读取，为此需保证 leader 的有效性，有两种方式：&lt;/p>
&lt;h4 id="readindex-read">&lt;strong>ReadIndex&lt;/strong> Read&lt;/h4>
&lt;ol>
&lt;li>Leader 将当前自己的 commit index 记录到一个 local 变量 ReadIndex 里面。&lt;/li>
&lt;li>向其他节点发起一次 heartbeat，如果大多数节点返回了对应的 heartbeat response，那么 leader 就能够确定现在自己仍然是 leader。&lt;/li>
&lt;li>Leader 等待自己的状态机执行，直到 apply index 超过了 ReadIndex，这样就能够安全的提供 linearizable read 了。&lt;/li>
&lt;li>Leader 执行 read 请求，将结果返回给 client。&lt;/li>
&lt;/ol>
&lt;p>注意：&lt;/p>
&lt;p>leader 刚通过选举成为 leader 的时候， commit index 并不能够保证是当前整个系统最新的 commit index，此时首先提交一个 no-op 的 entry，保证 leader 的 commit index 成为最新的。&lt;/p>
&lt;p>&lt;a href="https://jin-yang.github.io/post/golang-raft-etcd-sourcode-consistent-reading.html">https://jin-yang.github.io/post/golang-raft-etcd-sourcode-consistent-reading.html&lt;/a>&lt;/p>
&lt;h4 id="lease-read">Lease Read&lt;/h4>
&lt;p>虽然 ReadIndex 比原来的 Raft log read 快了很多，但毕竟还是有 Heartbeat 的开销，在 Raft 论文里面，提到了一种通过 clock + heartbeat 的 lease read 优化方法。&lt;/p>
&lt;p>也就是 leader 发送 heartbeat 的时候，会首先记录一个时间点 start，当系统大部分节点都回复了 heartbeat response，那么我们就可以认为 leader 的 lease 有效期可以到 &lt;code>start + election timeout / clock drift bound &lt;/code>这个时间点。&lt;/p>
&lt;p>为什么能够这么认为呢？主要是在于 Raft 的选举机制，因为 follower 会在至少 election timeout 的时间之后，才会重新发生选举，所以下一个 leader 选出来的时间一定可以保证大于 &lt;code>start + election timeout / clock drift bound&lt;/code>。&lt;/p>
&lt;p>虽然采用 lease 的做法很高效，但仍然会面临风险问题，也就是我们有了一个预设的前提，各个服务器的 CPU clock 的时间是准的，即使有误差，也会在一个非常小的 bound 范围里面，如果各个服务器之间 clock 走的频率不一样，有些太快，有些太慢，这套 lease 机制就可能出问题。&lt;/p>
&lt;h3 id="follower-read">Follower Read&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>先去 Leader 查询最新的 committed index；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>然后拿着 committed Index 去 Follower read，从而保证能从 Follower 中读到最新的数据；&lt;/p>
&lt;p>当前 etcd 就实现了 Follower read&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="幽灵复现">幽灵复现&lt;/h3>
&lt;ol>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/47025699">https://zhuanlan.zhihu.com/p/47025699&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/47117804">线性一致性和 Raft&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/35697913">Raft 的 PreVote 实现机制&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/50455478">Etcd 之 Lease read&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://juejin.im/post/5af066f1f265da0b715634b9">Raft 协议精解&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247484499&amp;amp;idx=1&amp;amp;sn=79acb9b4b2f8baa3296f2288c4a0a45b&amp;amp;scene=0#wechat_redirect">TiKV 源码解析系列 - Lease Read&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.csdn.net/solotzg/article/details/80669924">Raft TLA+形式化验证&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.wangjunfeng.com/post/raft/">分布式系统一致性协议 Raft 理解 - Jefferywang 的烂笔头&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zinglix.xyz/2020/06/25/raft/">「图解 Raft」让一致性算法变得更简单 - ZingLix Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md">raft-zh_cn/raft-zh_cn.md at master · maemual/raft-zh_cn · GitHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/lUbVBVzvNVxhgbcHQBbkkQ">条分缕析 Raft 算法&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cnblogs.com/mindwind/p/5231986.html">Raft 为什么是更易理解的分布式一致性算法 - mindwind - 博客园&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/125573685">全面理解Raft协议&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://juejin.cn/post/6902274909959880711">Raft 协议实战系列（五）—— 集群成员变更与日志压缩&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/114221938">浅谈分布式存储之raft&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://segmentfault.com/a/1190000022248118">https://segmentfault.com/a/1190000022248118&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>买卖股票的最佳时机 II</title><link>https://justice.bj.cn/post/leetcode/doc/122.%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-ii/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/leetcode/doc/122.%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-ii/</guid><description>&lt;h1 id="买卖股票的最佳时机-iihttpsleetcode-cncomproblemsbest-time-to-buy-and-sell-stock-iidescription-httpsleetcode-cncomproblemsbest-time-to-buy-and-sell-stock-iidescription">&lt;a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/description/" title="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/description/">买卖股票的最佳时机 II&lt;/a>&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Category&lt;/th>
&lt;th>Difficulty&lt;/th>
&lt;th>Likes&lt;/th>
&lt;th>Dislikes&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>algorithms&lt;/td>
&lt;td>Easy (57.53%)&lt;/td>
&lt;td>613&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Tags&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://leetcode.com/tag/array" title="https://leetcode.com/tag/array">&lt;code>array&lt;/code>&lt;/a> | &lt;a href="https://leetcode.com/tag/greedy" title="https://leetcode.com/tag/greedy">&lt;code>greedy&lt;/code>&lt;/a>&lt;/p>
&lt;p>&lt;strong>Companies&lt;/strong>&lt;/p>
&lt;p>&lt;code>bloomberg&lt;/code>&lt;/p>
&lt;p>给定一个数组，它的第 &lt;em>i&lt;/em> 个元素是一支给定股票第 &lt;em>i&lt;/em> 天的价格。&lt;/p>
&lt;p>设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。&lt;/p>
&lt;p>**注意：**你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。&lt;/p>
&lt;p>&lt;strong>示例 1:&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">输入: [7,1,5,3,6,4]
输出: 7
解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。
  随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>示例 2:&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">输入: [1,2,3,4,5]
输出: 4
解释: 在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。
  注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。
  因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>示例 3:&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">输入: [7,6,4,3,1]
输出: 0
解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;hr>
&lt;p>&lt;a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/comments/" title="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/comments/">Discussion&lt;/a> | &lt;a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/solution/" title="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/solution/">Solution&lt;/a>&lt;/p>
&lt;h2 id="解法">解法&lt;/h2>
&lt;h3 id="贪心法">贪心法&lt;/h3>
&lt;h2 id="代码">代码&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">Solution&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">maxProfit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">prices&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">max_profit&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">prices&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">prices&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">prices&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;span class="n">max_profit&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">prices&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">prices&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">max_profit&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>十道海量数据处理面试题</title><link>https://justice.bj.cn/post/30.architech/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%9D%A2%E8%AF%95%E9%A2%98/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%9D%A2%E8%AF%95%E9%A2%98/</guid><description>&lt;h1 id="十道海量数据处理面试题">十道海量数据处理面试题&lt;/h1>
&lt;h3 id="1海量日志数据提取出某日访问百度次数最多的那个ip">1、海量日志数据，提取出某日访问百度次数最多的那个IP。&lt;/h3>
&lt;p>　　当时给出的方案是：IP的数目还是有限的，最多2^32个，所以可以考虑使用hash将ip直接存入内存，然后进行统计。&lt;/p>
&lt;p>　　再详细介绍下此方案：首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。&lt;/p>
&lt;h3 id="2搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来每个查询串的长度为1-255字节">2、搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。**&lt;/h3>
&lt;p>　　假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。&lt;/p>
&lt;p>　　典型的Top K算法，还是在这篇文章里头有所阐述。 文中，给出的最终算法是：第一步、先对这批海量数据预处理，在O（N）的时间内用Hash表完成排序；然后，第二步、借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。 即，借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比所以，我们最终的时间复杂度是：O（N） + N'*O（logK），（N为1000万，N’为300万）。ok，更多，详情，请参考原文。&lt;/p>
&lt;p>　　或者：采用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。&lt;/p>
&lt;p>&lt;strong>3、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。&lt;/strong>&lt;/p>
&lt;p>　　方案：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,&amp;hellip;x4999）中。这样每个文件大概是200k左右。&lt;/p>
&lt;p>　　如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。 对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。&lt;/p>
&lt;p>&lt;strong>4、有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。&lt;/strong>&lt;/p>
&lt;p>　　还是典型的TOP K算法，解决方案如下： 方案1： 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件（记为）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。 找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件（记为）。&lt;/p>
&lt;p>　　对这10个文件进行归并排序（内排序与外排序相结合）。&lt;/p>
&lt;p>　　方案2： 一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树/hash_map等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并排序就可以了。&lt;/p>
&lt;p>　　方案3： 与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。&lt;/p>
&lt;p>&lt;strong>5、 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？&lt;/strong>&lt;/p>
&lt;p>　　方案1：可以估计每个文件安的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。&lt;/p>
&lt;p>　　遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,&amp;hellip;,a999）中。这样每个小文件的大约为300M。&lt;/p>
&lt;p>　　遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,&amp;hellip;,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0,a1vsb1,&amp;hellip;,a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。&lt;/p>
&lt;p>　　求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。&lt;/p>
&lt;p>　　方案2：如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。&lt;/p>
&lt;p>&lt;strong>6、在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。&lt;/strong>&lt;/p>
&lt;p>　　方案1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。&lt;/p>
&lt;p>　　方案2：也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。&lt;/p>
&lt;p>&lt;strong>7、腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？&lt;/strong>&lt;/p>
&lt;p>　　与上第6题类似，我的第一反应时快速排序+二分查找。以下是其它更好的方法： **方案1：**oo，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。&lt;/p>
&lt;p>　　dizengrong： **方案2：**这个问题在《编程珠玑》里有很好的描述，大家可以参考下面的思路，探讨一下：又因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；这里我们把40亿个数中的每一个用32位的二进制来表示假设这40亿个数开始放在一个文件中。&lt;/p>
&lt;p>　　然后将这40亿个数分成两类: 1.最高位为0 2.最高位为1 并将这两类分别写入到两个文件中，其中一个文件中数的个数&amp;lt;=20亿，而另一个&amp;gt;=20亿（这相当于折半了）；与要查找的数的最高位比较并接着进入相应的文件再查找&lt;/p>
&lt;p>再然后把这个文件为又分成两类: 1.次最高位为0 2.次最高位为1&lt;/p>
&lt;p>　　并将这两类分别写入到两个文件中，其中一个文件中数的个数&amp;lt;=10亿，而另一个&amp;gt;=10亿（这相当于折半了）； 与要查找的数的次最高位比较并接着进入相应的文件再查找。 &amp;hellip;&amp;hellip;. 以此类推，就可以找到了,而且时间复杂度为O(logn)，方案2完。&lt;/p>
&lt;p>**附：**这里，再简单介绍下，位图方法： 使用位图法判断整形数组是否存在重复 判断集合中存在重复是常见编程任务之一，当集合中数据量比较大时我们通常希望少进行几次扫描，这时双重循环法就不可取了。&lt;/p>
&lt;p>　　位图法比较适合于这种情况，它的做法是按照集合中最大元素max创建一个长度为max+1的新数组，然后再次扫描原数组，遇到几就给新数组的第几位置上1，如遇到5就给新数组的第六个元素置1，这样下次再遇到5想置位时发现新数组的第六个元素已经是1了，这说明这次的数据肯定和以前的数据存在着重复。这种给新数组初始化时置零其后置一的做法类似于位图的处理方法故称位图法。它的运算次数最坏的情况为2N。如果已知数组的最大值即能事先给新数组定长的话效率还能提高一倍。&lt;/p>
&lt;p>&lt;strong>8、怎么在海量数据中找出重复次数最多的一个？&lt;/strong>&lt;/p>
&lt;p>方案1：先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。然后找出上一步求出的数据中重复次数最多的一个就是所求（具体参考前面的题）。&lt;/p>
&lt;p>&lt;strong>9、上千万或上亿数据（有重复），统计其中出现次数最多的钱N个数据。&lt;/strong>&lt;/p>
&lt;p>　　方案1：上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map/搜索二叉树/红黑树等来进行统计次数。然后就是取出前N个出现次数最多的数据了，可以用第2题提到的堆机制完成。&lt;/p>
&lt;p>&lt;strong>10、一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。&lt;/strong>&lt;/p>
&lt;p>　　方案1：这题是考虑时间效率。用trie树统计每个词出现的次数，时间复杂度是O(n&lt;em>le)（le表示单词的平准长度）。然后是找出出现最频繁的前10个词，可以用堆来实现，前面的题中已经讲到了，时间复杂度是O(n&lt;/em>lg10)。所以总的时间复杂度，是O(n&lt;em>le)与O(n&lt;/em>lg10)中较大的哪一个。&lt;/p>
&lt;p>&lt;strong>附、100w个数中找出最大的100个数。&lt;/strong>&lt;/p>
&lt;p>　　方案1：在前面的题中，我们已经提到了，用一个含100个元素的最小堆完成。复杂度为O(100w*lg100)。&lt;/p>
&lt;p>　　方案2：采用快速排序的思想，每次分割之后只考虑比轴大的一部分，知道比轴大的一部分在比100多的时候，采用传统排序算法排序，取前100个。复杂度为O(100w*100)。&lt;/p>
&lt;p>　　方案3：采用局部淘汰法。选取前100个元素，并排序，记为序列L。然后一次扫描剩余的元素x，与排好序的100个元素中最小的元素比，如果比这个最小的要大，那么把这个最小的元素删除，并把x利用插入排序的思想，插入到序列L中。依次循环，知道扫描了所有的元素。复杂度为O(100w*100)。&lt;/p>
&lt;p>&lt;strong>二、十个海量数据处理方法大总结&lt;/strong>&lt;/p>
&lt;p>　　ok，看了上面这么多的面试题，是否有点头晕。是的，需要一个总结。接下来，本文将简单总结下一些处理海量数据问题的常见方法。&lt;/p>
&lt;p>　对海量数据的处理方法进行了一个一般性的总结，当然这些方法可能并不能完全覆盖所有的问题，但是这样的一些方法也基本可以处理绝大多数遇到的问题。下面的一些问题基本直接来源于公司的面试笔试题目，方法不一定最优，如果你有更好的处理方法，欢迎讨论。&lt;/p>
&lt;p>&lt;strong>1.Bloom filter&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 可以用来实现数据字典，进行数据的判重，或者集合求交集&lt;/p>
&lt;p>&lt;strong>基本原理及要点：&lt;/strong>&lt;/p>
&lt;p>　　对于原理来说很简单，位数组+k个独立hash函数。将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在，很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。&lt;/p>
&lt;p>　　还有一个比较重要的问题，如何根据输入元素个数n，确定位数组m的大小及hash函数个数。当hash函数个数k=(ln2)&lt;em>(m/n)时错误率最小。在错误率不大于E的情况下，m至少要等于n&lt;/em>lg(1/E)才能表示任意n个元素的集合。但m还应该更大些，因为还要保证bit数组里至少一半为0，则m应该&amp;gt;=nlg(1/E)*lge 大概就是nlg(1/E)1.44倍(lg表示以2为底的对数)。&lt;/p>
&lt;p>　　举个例子我们假设错误率为0.01，则此时m应大概是n的13倍。这样k大概是8个。&lt;/p>
&lt;p>　　注意这里m与n的单位不同，m是bit为单位，而n则是以元素个数为单位(准确的说是不同元素的个数)。通常单个元素的长度都是有很多bit的。所以使用bloom filter内存上通常都是节省的。&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong>&lt;/p>
&lt;p>　　Bloom filter将集合中的元素映射到位数组中，用k（k为哈希函数个数）个映射位是否全1表示元素在不在这个集合中。Counting bloom filter（CBF）将位数组中的每一位扩展为一个counter，从而支持了元素的删除操作。Spectral Bloom Filter（SBF）将其与集合元素的出现次数关联。SBF采用counter中的最小值来近似表示元素的出现频率。&lt;/p>
&lt;p>　　问题实例：给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？&lt;/p>
&lt;p>　　根据这个问题我们来计算下内存的占用，4G=2^32大概是40亿*8大概是340亿，n=50亿，如果按出错率0.01算需要的大概是650亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。&lt;/p>
&lt;p>&lt;strong>2.Hashing&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 快速查找，删除的基本数据结构，通常需要总数据量可以放入内存&lt;/p>
&lt;p>&lt;strong>基本原理及要点：&lt;/strong>&lt;/p>
&lt;p>　　hash函数选择，针对字符串，整数，排列，具体相应的hash方法。&lt;/p>
&lt;p>　　碰撞处理，一种是open hashing，也称为拉链法；另一种就是closed hashing，也称开地址法，opened addressing。&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong>&lt;/p>
&lt;p>　　d-left hashing中的d是多个的意思，我们先简化这个问题，看一看2-left hashing。2-left hashing指的是将一个哈希表分成长度相等的两半，分别叫做T1和T2，给T1和T2分别配备一个哈希函数，h1和h2。在存储一个新的key时，同时用两个哈希函数进行计算，得出两个地址h1[key]和h2[key]。这时需要检查T1中的h1[key]位置和T2中的h2[key]位置，哪一个位置已经存储的（有碰撞的）key比较多，然后将新key存储在负载少的位置。如果两边一样多，比如两个位置都为空或者都存储了一个key，就把新key存储在左边的T1子表中，2-left也由此而来。在查找一个key时，必须进行两次hash，同时查找两个位置。&lt;/p>
&lt;p>&lt;strong>问题实例：&lt;/strong>&lt;/p>
&lt;p>　　1).海量日志数据，提取出某日访问百度次数最多的那个IP。&lt;/p>
&lt;p>　　IP的数目还是有限的，最多2^32个，所以可以考虑使用hash将ip直接存入内存，然后进行统计。&lt;/p>
&lt;p>&lt;strong>3.bit-map&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下&lt;/p>
&lt;p>　　基本原理及要点：使用bit数组来表示某些元素是否存在，比如8位电话号码&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong> bloom filter可以看做是对bit-map的扩展&lt;/p>
&lt;p>&lt;strong>问题实例：&lt;/strong>&lt;/p>
&lt;p>　　1)已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。&lt;/p>
&lt;p>　　8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。&lt;/p>
&lt;p>　　2)2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。&lt;/p>
&lt;p>　　将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map。&lt;/p>
&lt;p>&lt;strong>4.堆&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 海量数据前n大，并且n比较小，堆可以放入内存&lt;/p>
&lt;p>　　基本原理及要点：最大堆求前n小，最小堆求前n大。方法，比如求前n小，我们比较当前元素与最大堆里的最大元素，如果它小于最大元素，则应该替换那个最大元素。这样最后得到的n个元素就是最小的n个。适合大数据量，求前n小，n的大小比较小的情况，这样可以扫描一遍即可得到所有的前n元素，效率很高。&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong> 双堆，一个最大堆与一个最小堆结合，可以用来维护中位数。&lt;/p>
&lt;p>&lt;strong>问题实例：&lt;/strong>&lt;/p>
&lt;p>　　1)100w个数中找最大的前100个数。&lt;/p>
&lt;p>　　用一个100个元素大小的最小堆即可。&lt;/p>
&lt;p>　　五、双层桶划分&amp;mdash;-其实本质上就是【分而治之】的思想，重在分的技巧上！&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 第k大，中位数，不重复或重复的数字&lt;/p>
&lt;p>　　基本原理及要点：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。可以通过多次缩小，双层只是一个例子。&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong>&lt;/p>
&lt;p>&lt;strong>问题实例：&lt;/strong>&lt;/p>
&lt;p>&lt;strong>1).2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。&lt;/strong>&lt;/p>
&lt;p>　　有点像鸽巢原理，整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。&lt;/p>
&lt;p>&lt;strong>2).5亿个int找它们的中位数。&lt;/strong>&lt;/p>
&lt;p>　　这个例子比上面那个更明显。首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。&lt;/p>
&lt;p>　　实际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成2^24个区域，然后确定区域的第几大数，在将该区域分成2^20个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有2^20，就可以直接利用direct addr table进行统计了。&lt;/p>
&lt;p>&lt;strong>6.数据库索引&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 大数据量的增删改查&lt;/p>
&lt;p>&lt;strong>基本原理及要点：&lt;/strong> 利用数据的设计实现方法，对海量数据的增删改查进行处理。&lt;/p>
&lt;p>&lt;strong>7.倒排索引(Inverted index)&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 搜索引擎，关键字查询&lt;/p>
&lt;p>&lt;strong>基本原理及要点：&lt;/strong> 为何叫倒排索引？一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。&lt;/p>
&lt;p>　以英文为例，下面是要被索引的文本： T0 = &amp;ldquo;it is what it is&amp;rdquo; T1 = &amp;ldquo;what is it&amp;rdquo; T2 = &amp;ldquo;it is a banana&amp;rdquo;&lt;/p>
&lt;p>我们就能得到下面的反向文件索引：&lt;/p>
&lt;p>&amp;ldquo;a&amp;rdquo;: {2} &amp;ldquo;banana&amp;rdquo;: {2} &amp;ldquo;is&amp;rdquo;: {0, 1, 2} &amp;ldquo;it&amp;rdquo;: {0, 1, 2} &amp;ldquo;what&amp;rdquo;: {0, 1}&lt;/p>
&lt;p>　检索的条件&amp;quot;what&amp;quot;,&amp;ldquo;is&amp;quot;和&amp;quot;it&amp;quot;将对应集合的交集。&lt;/p>
&lt;p>　　正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档，很容易看到这个反向的关系。&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong>&lt;/p>
&lt;p>　　问题实例：文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索。&lt;/p>
&lt;p>&lt;strong>8.外排序&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围：&lt;/strong> 大数据的排序，去重&lt;/p>
&lt;p>&lt;strong>基本原理及要点：&lt;/strong> 外排序的归并方法，置换选择败者树原理，最优归并树&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong>&lt;/p>
&lt;p>&lt;strong>问题实例：&lt;/strong>&lt;/p>
&lt;p>　　1).有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词。&lt;/p>
&lt;p>　　这个数据具有很明显的特点，词的大小为16个字节，但是内存只有1m做hash有些不够，所以可以用来排序。内存可以当输入缓冲区使用。&lt;/p>
&lt;p>&lt;strong>9.trie树&lt;/strong>&lt;/p>
&lt;p>&lt;strong>适用范围&lt;/strong>： 数据量大，重复多，但是数据种类小可以放入内存&lt;/p>
&lt;p>&lt;strong>基本原理及要点：&lt;/strong> 实现方式，节点孩子的表示方式&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong> 压缩实现。&lt;/p>
&lt;p>&lt;strong>问题实例：&lt;/strong>&lt;/p>
&lt;p>　　1).有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。&lt;/p>
&lt;p>　　2).1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？&lt;/p>
&lt;p>　　3).寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。&lt;/p>
&lt;p>&lt;strong>10.分布式处理 mapreduce&lt;/strong>&lt;/p>
&lt;p>**适用范围：**数据量大，但是数据种类小可以放入内存&lt;/p>
&lt;p>**基本原理及要点：**将数据交给不同的机器去处理，数据划分，结果归约。&lt;/p>
&lt;p>&lt;strong>扩展：&lt;/strong>&lt;/p>
&lt;p>&lt;strong>问题实例：&lt;/strong>&lt;/p>
&lt;p>　　1).The canonical example application of MapReduce is a process to count the appearances ofeach different word in a set of documents:&lt;/p>
&lt;p>　　2).海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。&lt;/p>
&lt;p>　　3).一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)？&lt;/p>
&lt;h2 id="经典问题分析">经典问题分析&lt;/h2>
&lt;p>上千万or亿数据（有重复），统计其中出现次数最多的前N个数据,分两种情况：可一次读入内存，不可一次读入。　&lt;/p>
&lt;ul>
&lt;li>可用思路：trie树+堆，数据库索引，划分子集分别统计，hash，分布式计算，近似统计，外排序&lt;/li>
&lt;/ul>
&lt;p>　　所谓的是否能一次读入内存，实际上应该指去除重复后的数据量。如果去重后数据可以放入内存，我们可以为数据建立字典，比如通过 map，hashmap，trie，然后直接进行统计即可。当然在更新每条数据的出现次数的时候，我们可以利用一个堆来维护出现次数最多的前N个数据，当然这样导致维护次数增加，不如完全统计后在求前N大效率高。&lt;/p>
&lt;p>　　如果数据无法放入内存。一方面我们可以考虑上面的字典方法能否被改进以适应这种情形，可以做的改变就是将字典存放到硬盘上，而不是内存，这可以参考数据库的存储方法。&lt;/p>
&lt;p>　　当然还有更好的方法，就是可以采用分布式计算，基本上就是map-reduce过程，首先可以根据数据值或者把数据hash(md5)后的值，将数据按照范围划分到不同的机子，最好可以让数据划分后可以一次读入内存，这样不同的机子负责处理各种的数值范围，实际上就是map。得到结果后，各个机子只需拿出各自的出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是reduce过程。&lt;/p>
&lt;p>　　实际上可能想直接将数据均分到不同的机子上进行处理，这样是无法得到正确的解的。因为一个数据可能被均分到不同的机子上，而另一个则可能完全聚集到一个机子上，同时还可能存在具有相同数目的数据。比如我们要找出现次数最多的前100个，我们将1000万的数据分布到10台机器上，找到每台出现次数最多的前 100个，归并之后这样不能保证找到真正的第100个，因为比如出现次数最多的第100个可能有1万个，但是它被分到了10台机子，这样在每台上只有1千个，假设这些机子排名在1000个之前的那些都是单独分布在一台机子上的，比如有1001个，这样本来具有1万个的这个就会被淘汰，即使我们让每台机子选出出现次数最多的1000个再归并，仍然会出错，因为可能存在大量个数为1001个的发生聚集。因此不能将数据随便均分到不同机子上，而是要根据hash 后的值将它们映射到不同的机子上处理，让不同的机器处理一个数值范围。&lt;/p>
&lt;p>　 而外排序的方法会消耗大量的IO，效率不会很高。而上面的分布式方法，也可以用于单机版本，也就是将总的数据根据值的范围，划分成多个不同的子文件，然后逐个处理。处理完毕之后再对这些单词的及其出现频率进行一个归并。实际上就可以利用一个外排序的归并过程。&lt;/p>
&lt;p>　 另外还可以考虑近似计算，也就是我们可以通过结合自然语言属性，只将那些真正实际中出现最多的那些词作为一个字典，使得这个规模可以放入内存。&lt;/p></description></item><item><title>可视化Go内存管理</title><link>https://justice.bj.cn/post/14.language/golang/go%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/go%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid><description>&lt;h1 id="可视化go内存管理">可视化Go内存管理&lt;/h1>
&lt;p>这篇文章基于Go 1.13的默认官方实现，有些概念细节可能会在Go的未来版本中发生变化&lt;/p>
&lt;h2 id="go内部内存结构">Go内部内存结构&lt;/h2>
&lt;p>首先，让我们看看Go内部的内存结构是什么样子的。&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-44-10-2020-03-10-19-07-25-image.png" alt="">&lt;/p>
&lt;p>Go运行时将Goroutines（G）调度到逻辑处理器（P）上执行。每个P都有一台逻辑机器（M）。在这篇文章中，我们将使用P、M和G。如果您不熟悉Go调度程序，请先阅读 &lt;strong>《Go调度程序：Ms，Ps和Gs》&lt;/strong> 。&lt;/p>
&lt;h2 id="goroutine调度原理">Goroutine调度原理&lt;/h2>
&lt;p>每个Go程序进程都由操作系统（OS）分配了一些虚拟内存，这是该进程可以访问的全部内存。在这个虚拟内存中实际正在使用的内存称为Resident Set（驻留内存)。该空间由内部内存结构管理，如下所示：&lt;/p>
&lt;p>Go内部内存结构原理图&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-44-18-2020-03-10-19-08-20-image.png" alt="">&lt;/p>
&lt;p>Go将内存划分和分组为页(page)，&lt;/p>
&lt;p>这与我们在前几章中看到的 &lt;strong>JVM&lt;/strong> 和 &lt;strong>V8&lt;/strong> 的内存结构完全不同。如您所见，这里没有分代内存。Go的内存分配器是基于 &lt;strong>TCMalloc&lt;/strong> （Thread Cache Malloc）实现的。&lt;/p>
&lt;p>让我们看看Go独特的内存构造是什么样子的：&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-44-25-2020-03-10-19-09-10-image.png" alt="">&lt;/p>
&lt;h3 id="页堆page-heapmheap">页堆page heap（mheap）&lt;/h3>
&lt;p>这里是Go存储动态数据（在编译时无法计算大小的任何数据）的地方。它是最大的内存块，也是进行垃圾收集（GC）的地方。&lt;/p>
&lt;p>驻留内存(resident set)被划分为每个大小为8KB的页，并由一个全局 &lt;strong>mheap对象&lt;/strong> 管理。&lt;/p>
&lt;p>大对象（大小&amp;gt; 32kb的对象）直接从mheap分配。这些大对象申请请求是以获取中央锁(central lock)为代价的，因此在任何给定时间点只能满足一个P的请求。&lt;/p>
&lt;p>mheap通过将页归类为不同结构进行管理的：&lt;/p>
&lt;ul>
&lt;li>mspan：mspan是mheap中管理的内存页的最基本结构。这是一个双向链接列表，其中包含起始页面的地址，span size class和span中的页面数量。像TCMalloc一样，Go将内存页按大小分为67个不同类别，大小从8字节到32KB&lt;/li>
&lt;/ul>
&lt;h2 id="mspan结构">mspan结构&lt;/h2>
&lt;p>每个span存在两个，一个span用于带指针的对象（scan class），一个用于无指针的对象（noscan class）。这在GC期间有帮助，因为noscan类查找活动对象时无需遍历span。&lt;/p>
&lt;ul>
&lt;li>mcentral：mcentral将相同大小级别的span归类在一起。每个mcentral包含两个mspanList：empty：双向span链表，包括没有空闲对象的span或缓存mcache中的span。当此处的span被释放时，它将被移至non-empty span链表。non-empty：有空闲对象的span双向链表。当从mcentral请求新的span，mcentral将从该链表中获取span并将其移入empty span链表。&lt;/li>
&lt;/ul>
&lt;p>如果mcentral没有可用的span，它将向mheap请求新页。&lt;/p>
&lt;ul>
&lt;li>arena：堆在已分配的虚拟内存中根据需要增长和缩小。当需要更多内存时，mheap从虚拟内存中以每块64MB（对于64位体系结构）为单位获取新内存， 这块内存被称为 &lt;strong>arena&lt;/strong> 。这块内存也会被划分页并映射到span。&lt;/li>
&lt;li>mcache：这是一个非常有趣的构造。mcache是提供给P（逻辑处理器）的高速缓存，用于存储小对象（对象大小&amp;lt;= 32Kb）。尽管这类似于线程堆栈，但它是堆的一部分，用于动态数据。所有类大小的mcache包含scan和noscan类型mspan。Goroutine可以从mcache没有任何锁的情况下获取内存，因为一次P只能有一个锁G。因此，这更有效。mcache从mcentral需要时请求新的span。&lt;/li>
&lt;/ul>
&lt;h3 id="栈">栈&lt;/h3>
&lt;p>这是栈存储区，每个Goroutine（G）有一个栈。在这里存储了静态数据，包括函数栈帧，静态结构，原生类型值和指向动态结构的指针。这与分配给每个P的mcache不是一回事。&lt;/p>
&lt;h2 id="go内存使用栈与堆">Go内存使用（栈与堆）&lt;/h2>
&lt;p>现在我们已经清楚了内存的组织方式，现在让我们看看程序执行时Go是如何使用Stack和Heap的。&lt;/p>
&lt;p>我们使用下面的这个Go程序，代码没有针对正确性进行优化，因此可以忽略诸如不必要的中间变量之类的问题，因此，重点是可视化栈和堆内存的使用情况。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go"> &lt;span class="kn">package&lt;/span> &lt;span class="nx">main&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="s">&amp;#34;fmt&amp;#34;&lt;/span>
&lt;span class="kd">type&lt;/span> &lt;span class="nx">Employee&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">name&lt;/span> &lt;span class="kt">string&lt;/span>
&lt;span class="nx">salary&lt;/span> &lt;span class="kt">int&lt;/span>
&lt;span class="nx">sales&lt;/span> &lt;span class="kt">int&lt;/span>
&lt;span class="nx">bonus&lt;/span> &lt;span class="kt">int&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kd">const&lt;/span> &lt;span class="nx">BONUS_PERCENTAGE&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="mi">10&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">getBonusPercentage&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">salary&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">percentage&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">salary&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="nx">BONUS_PERCENTAGE&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">100&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nx">percentage&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">findEmployeeBonus&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">salary&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">noOfSales&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">bonusPercentage&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nf">getBonusPercentage&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">salary&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nx">bonus&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">bonusPercentage&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="nx">noOfSales&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nx">bonus&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="kd">var&lt;/span> &lt;span class="nx">john&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">Employee&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="s">&amp;#34;John&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5000&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="nx">john&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">bonus&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nf">findEmployeeBonus&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">john&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">salary&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">john&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">sales&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nx">fmt&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Println&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">john&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">bonus&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>与许多垃圾回收语言相比，Go的一个主要区别是许多对象直接在程序栈上分配。Go编译器使用一种称为 &lt;strong>“逃逸分析”&lt;/strong> 的过程来查找其生命周期在编译时已知的对象，并将它们分配在栈上，而不是在垃圾回收的堆内存中。在编译过程中，Go进行了逃逸分析，以确定哪些可以放入栈（静态数据），哪些需要放入堆（动态数据）。我们可以通过运行带有 -gcflags &amp;lsquo;-m&amp;rsquo; 标志的go build命令来查看分析的细节。对于上面的代码，它将输出如下内容：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash"> ❯ go build -gcflags &lt;span class="s1">&amp;#39;-m&amp;#39;&lt;/span> gc.go
&lt;span class="c1"># command-line-arguments&lt;/span>
temp/gc.go:14:6: can inline getBonusPercentage
temp/gc.go:19:6: can inline findEmployeeBonus
temp/gc.go:20:39: inlining call to getBonusPercentage
temp/gc.go:27:32: inlining call to findEmployeeBonus
temp/gc.go:27:32: inlining call to getBonusPercentage
temp/gc.go:28:13: inlining call to fmt.Println
temp/gc.go:28:18: john.bonus escapes to heap
temp/gc.go:28:13: io.Writer&lt;span class="o">(&lt;/span>os.Stdout&lt;span class="o">)&lt;/span> escapes to heap
temp/gc.go:28:13: main &lt;span class="o">[]&lt;/span>interface &lt;span class="o">{}&lt;/span> literal does not escape
&amp;lt;autogenerated&amp;gt;:1: os.&lt;span class="o">(&lt;/span>*File&lt;span class="o">)&lt;/span>.close .this does not escape
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可视化程序执行过程中栈和堆的使用&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-44-35-8f0714db-666d-40bb-bbdb-a97874896ef0.gif" alt="">&lt;/p>
&lt;p>正如你看到的：&lt;/p>
&lt;ul>
&lt;li>main函数被保存栈中的“main栈帧”中&lt;/li>
&lt;li>每个函数调用都作为一个栈帧块被添加到堆中&lt;/li>
&lt;li>包括参数和返回值在内的所有静态变量都保存在函数的栈帧块内&lt;/li>
&lt;li>无论类型如何，所有静态值都直接存储在栈中。这也适用于全局范畴&lt;/li>
&lt;li>所有动态类型都在堆上创建，并且被栈上的指针所引用。小于32Kb的对象由P的mcache分配。这同样适用于全局范畴&lt;/li>
&lt;li>具有静态数据的结构体保留在栈上，直到在该位置将任何动态值添加到该结构中为止。该结构被移到堆上。&lt;/li>
&lt;li>从当前函数调用的函数被推入堆顶部&lt;/li>
&lt;li>当函数返回时，其栈帧将从栈中删除&lt;/li>
&lt;li>一旦主过程(main)完成，堆上的对象将不再具有来自Stack的指针的引用，并成为孤立对象&lt;/li>
&lt;/ul>
&lt;p>栈是由操作系统自动管理的，而不是Go本身。因此，我们不必担心栈。另一方面，堆并不是由操作系统自动管理的，并且由于其具有最大的内存空间并保存动态数据，因此它可能会成倍增长，从而导致我们的程序随着时间耗尽内存。随着时间的流逝，它也变得支离破碎，使应用程序变慢。解决这些问题是垃圾收集的初衷。&lt;/p>
&lt;h2 id="go内存管理">Go内存管理&lt;/h2>
&lt;p>Go的内存管理包括在需要内存时自动分配内存，在不再需要内存时进行垃圾回收。这是由标准库完成的(译注：应该是运行时完成的)。与C/C++不同，开发人员不必处理它，并且Go进行的基础管理得到了高效的优化。&lt;/p>
&lt;h3 id="内存分配">内存分配&lt;/h3>
&lt;p>许多采用垃圾收集的编程语言都使用分代内存结构来使收集高效，同时进行压缩以减少碎片。正如我们前面所看到的，Go在这里采用了不同的方法，Go在构造内存方面有很大的不同。Go使用线程本地缓存(thread local cache)来加速小对象分配，并维护着scan/noscan的span来加速GC。这种结构以及整个过程避免了碎片，从而在GC期间无需做紧缩处理。&lt;/p>
&lt;p>Go根据对象的大小决定对象的分配过程，分为三类：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Tiny（size &amp;lt;16B）：使用mcache的微小分配器分配大小小于16个字节的对象。这是高效的，并且在单个16字节块上可完成多个微小分配。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Small（尺寸16B〜32KB）：大小在16个字节和32k字节之间的对象被分配在G运行所在的P的mcache的对应的mspan size class上。在微小型和小型对象分配中，如果mspan的列表为空，分配器将从mheap获取大量的页面用于mspan。如果mheap为空或没有足够大的页面满足分配请求，那么它将从操作系统中分配一组新的页（至少1MB）。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/03/10-19-13-29-96c13703-d760-41f6-9399-c54d5d678bef.gif?token=AARMIEQA4P4BEYPQMJ4O2OS6M53JU" alt="">&lt;/p>
&lt;ul>
&lt;li>大对象（大小&amp;gt; 32KB）：大于32 KB的对象直接分配在mheap的相应大小类上(size class)。如果mheap为空或没有足够大的页面满足分配请求，则它将从操作系统中分配一组新的页（至少1MB）。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-44-41-a744f6f0-831f-4897-9955-b21eb4e06e42.gif" alt="">&lt;/p>
&lt;p>大对象分配&lt;/p>
&lt;h2 id="垃圾收集gc">垃圾收集(GC)&lt;/h2>
&lt;p>Go通过垃圾回收机制管理堆内存。简单来说，它释放了孤儿对象(orphan object)使用的内存，从而为创建新对象的分配腾出了空间。&lt;/p>
&lt;p>从Go 1.12版本开始，Go使用了非分代的、并发的、基于三色标记和清除的垃圾回收器。收集过程大致如下所示：&lt;/p>
&lt;p>当完成一定百分比（GC百分比）的堆分配，GC过程就开始了。收集器将在不同工作阶段执行不同的工作：&lt;/p>
&lt;ul>
&lt;li>标记设置（mark setup, stw）：GC启动时，收集器将打开写屏障(write barrier)，以便可以在下一个并发阶段维护数据完整性。此步骤需要非常小的暂停(stw)，因此每个正在运行的Goroutine都会暂停以启用此功能，然后继续。&lt;/li>
&lt;li>标记（并发执行的）：打开写屏障后，实际的标记过程将并行启动，这个过程将使用可用CPU能力的25%。对应的P将保留，直到该标记过程完成。这个过程是使用专用的Goroutines完成的。在这个过程中，GC标记了堆中的活动对象(被任何活动的Goroutine的栈中引用的）。当采集花费更长的时间时，该过程可以从应用程序中征用活动的Goroutine来辅助标记过程。这称为 &lt;strong>Mark Assist&lt;/strong> 。&lt;/li>
&lt;li>标记终止（stw）：标记一旦完成，每个活动的Goroutine都会暂停，写入屏障将关闭，清理任务将开始执行。GC还会在此处计算下一个GC目标。完成此操作后，保留的P的会释放回应用程序。&lt;/li>
&lt;li>清除（并发）：当完成收集并尝试分配后，清除过程开始将未标记为活动的对象回收。清除的内存量与分配的内存量是同步的(即回收后的内存马上可以被再分配了)。&lt;/li>
&lt;/ul>
&lt;p>让我们在一个Goroutine中看看这个过程。为了简洁起见，将对象的数量保持较小。&lt;/p>
&lt;ul>
&lt;li>标记过程选择GC root并将其着色为黑色，并以深度优先的树状方式遍历该该根节点里面的指针，将遇到的每个对象都标记为灰色&lt;/li>
&lt;li>当它到达noscan span中的某个对象或某个对象不再有指针时，它完成了这个根节点的标记操作并选取下一个GC root对象&lt;/li>
&lt;li>当扫描完所有GC root节点之后，它将选取灰色对象，并以类似方式继续遍历其指针&lt;/li>
&lt;li>如果在打开写屏障时，指向对象的指针发生任何变化，则该对象将变为灰色，以便GC对其进行重新扫描&lt;/li>
&lt;li>当不再有灰色对象留下时，标记过程完成，并且写屏障被关闭&lt;/li>
&lt;li>当分配开始时(因为写屏障关闭了)，清除过程也会同步进行&lt;/li>
&lt;/ul>
&lt;p>我们看到这里有一些停止世界(stop)的过程，但是通常这个过程非常快，在大多数情况下可以忽略不计。对象的着色在span的gcmarkBits属性中进行。&lt;/p></description></item><item><title>快速排序</title><link>https://justice.bj.cn/post/13.algorithm/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/13.algorithm/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</guid><description>&lt;h1 id="快速排序">快速排序&lt;/h1>
&lt;h2 id="基本思想">基本思想&lt;/h2>
&lt;p>选择一个基准，将整个未排序序列按基准分为大小两个部分，递归进行，直到整个序列有序为止。&lt;/p>
&lt;h3 id="时间复杂度">时间复杂度&lt;/h3>
&lt;ul>
&lt;li>Avg: $O(nlogn)$&lt;/li>
&lt;li>Max: O(n^2)&lt;/li>
&lt;li>Min: O(n)&lt;/li>
&lt;/ul>
&lt;h3 id="空间复杂度">空间复杂度&lt;/h3>
&lt;ul>
&lt;li>code&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="cm">/*
&lt;/span>&lt;span class="cm">* 快速排序
&lt;/span>&lt;span class="cm">*/&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">sort_quick&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">list&lt;/span>&lt;span class="p">[],&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">low&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">high&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">low&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="n">high&lt;/span> &lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">l&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">low&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">h&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">high&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">flag&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">low&lt;/span>&lt;span class="p">];&lt;/span> &lt;span class="c1">//选择首节点为基准
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">do&lt;/span>&lt;span class="p">{&lt;/span>
&lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">while&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">flag&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">h&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="o">--&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">flag&lt;/span>&lt;span class="p">){&lt;/span>
&lt;span class="n">swap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">]);&lt;/span>
&lt;span class="n">l&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">while&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">flag&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">l&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">flag&lt;/span>&lt;span class="p">){&lt;/span>
&lt;span class="n">swap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">]);&lt;/span>
&lt;span class="n">h&lt;/span>&lt;span class="o">--&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>&lt;span class="k">while&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="n">low&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="n">sort_quick&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">low&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">l&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">high&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="n">sort_quick&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">list&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">h&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">high&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>排序算法总结</title><link>https://justice.bj.cn/post/13.algorithm/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/13.algorithm/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</guid><description>&lt;h1 id="排序算法总结">排序算法总结&lt;/h1>
&lt;h2 id="概述">概述&lt;/h2>
&lt;p>排序是最基础算法之一。&lt;/p>
&lt;h3 id="分类">分类&lt;/h3>
&lt;p>十种常见排序算法可以分为两大类：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>比较类排序&lt;/strong>：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破$O(nlogn)$，因此也称为非线性时间比较类排序。&lt;/li>
&lt;li>&lt;strong>非比较类排序&lt;/strong>：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较类排序。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-32-59-849589-20190306165258970-1789860540.png" alt="">&lt;/p>
&lt;h3 id="复杂度">复杂度&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>排序方法&lt;/th>
&lt;th>时间复杂度(Avg)&lt;/th>
&lt;th>时间复杂度(Max)&lt;/th>
&lt;th>时间复杂度(Min)&lt;/th>
&lt;th>空间复杂度&lt;/th>
&lt;th>稳定性&lt;/th>
&lt;th>分类&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>冒泡排序&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n)$&lt;/td>
&lt;td>$O(1)$&lt;/td>
&lt;td>稳定&lt;/td>
&lt;td>比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>插入排序&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n)$&lt;/td>
&lt;td>$O(1)$&lt;/td>
&lt;td>稳定&lt;/td>
&lt;td>比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>选择排序&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(1)$&lt;/td>
&lt;td>不稳定&lt;/td>
&lt;td>比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>希尔排序&lt;/td>
&lt;td>$O(n^{1.3})$&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n)$&lt;/td>
&lt;td>$O(1)$&lt;/td>
&lt;td>不稳定&lt;/td>
&lt;td>比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>归并排序&lt;/td>
&lt;td>$O(nlog{{_2}{n}})$&lt;/td>
&lt;td>$O(nlog{{_2}{n}})$&lt;/td>
&lt;td>$O(nlog{{_2}{n}})$&lt;/td>
&lt;td>$O(n)$&lt;/td>
&lt;td>稳定&lt;/td>
&lt;td>比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>堆排序&lt;/td>
&lt;td>$O(n{log_2}n)$&lt;/td>
&lt;td>$O(nlog{{_2}{n}})$&lt;/td>
&lt;td>$O(nlog{{_2}{n}})$&lt;/td>
&lt;td>$O(1)$&lt;/td>
&lt;td>不稳定&lt;/td>
&lt;td>比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>快速排序&lt;/td>
&lt;td>$O(n{log_2}n)$&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(nlog_2n)$&lt;/td>
&lt;td>$O(nlog_2n)$&lt;/td>
&lt;td>不稳定&lt;/td>
&lt;td>比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>基数排序&lt;/td>
&lt;td>$O(n*k)$&lt;/td>
&lt;td>$O(n*k)$&lt;/td>
&lt;td>$O(n*k)$&lt;/td>
&lt;td>$O(n+k)$&lt;/td>
&lt;td>稳定&lt;/td>
&lt;td>非比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计数排序&lt;/td>
&lt;td>$O(n+k)$&lt;/td>
&lt;td>$O(n+k)$&lt;/td>
&lt;td>$O(n+k)$&lt;/td>
&lt;td>$O(n+k)$&lt;/td>
&lt;td>稳定&lt;/td>
&lt;td>非比较&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>桶排序&lt;/td>
&lt;td>$O(n+k)$&lt;/td>
&lt;td>$O(n^2)$&lt;/td>
&lt;td>$O(n)$&lt;/td>
&lt;td>$O(n+k)$&lt;/td>
&lt;td>稳定&lt;/td>
&lt;td>非比较&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="相关概念">相关概念&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>稳定性&lt;/strong>：如果 a 原本在 b 前面，而 a=b，排序之后 a 仍然在 b 的前面，则为稳定排序，否则未不稳定。&lt;/li>
&lt;li>&lt;strong>时间复杂度&lt;/strong>：对排序数据的总的操作次数。反映当 n 变化时，操作次数呈现什么规律。&lt;/li>
&lt;li>&lt;strong>空间复杂度&lt;/strong>： 是指算法在计算机内执行时所需存储空间的度量，它也是数据规模 n 的函数。&lt;/li>
&lt;/ul>
&lt;h2 id="基础比较排序算法">基础比较排序算法&lt;/h2>
&lt;h3 id="冒泡排序bubble-sort">冒泡排序（Bubble Sort）&lt;/h3>
&lt;p>冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。&lt;/p>
&lt;h4 id="算法描述">算法描述&lt;/h4>
&lt;ul>
&lt;li>比较相邻的元素。如果第一个比第二个大，就交换它们两个；&lt;/li>
&lt;li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；&lt;/li>
&lt;li>针对所有的元素重复以上的步骤，除了最后一个；&lt;/li>
&lt;li>重复步骤 1~3，直到排序完成。&lt;/li>
&lt;/ul>
&lt;h4 id="动图演示">动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-33-20-849589-20171015223238449-2146169197.png" alt="">&lt;/p>
&lt;h4 id="实现">实现&lt;/h4>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="双向冒泡排序">双向冒泡排序（）&lt;/h3>
&lt;p>双向冒泡排序（Bidirectional Bubble Sort），又叫鸡尾酒排序。这是冒泡排序的一种变体。不同之处在于，冒泡排序是从低到高比较序列里的每个元素，而鸡尾酒排序从两个方向（低到高、高到低）来回排序，效率更高。&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-33-32-640" alt="">&lt;/p>
&lt;h3 id="选择排序selection-sort">选择排序（Selection Sort）&lt;/h3>
&lt;p>选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。&lt;/p>
&lt;h4 id="描述">描述&lt;/h4>
&lt;p>n 个记录的直接选择排序可经过 n-1 趟直接选择排序得到有序结果。具体算法描述如下：&lt;/p>
&lt;ul>
&lt;li>初始状态：无序区为 R[1..n]，有序区为空；&lt;/li>
&lt;li>第 i 趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为 R[1..i-1]和 R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第 1 个记录 R 交换，使 R[1..i]和 R[i+1..n)分别变为记录个数增加 1 个的新有序区和记录个数减少 1 个的新无序区；&lt;/li>
&lt;li>n-1 趟结束，数组有序化了。&lt;/li>
&lt;/ul>
&lt;h4 id="动图演示-1">动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-34-51-849589-20171015224719590-1433219824.png" alt="">&lt;/p>
&lt;h4 id="实现-1">实现&lt;/h4>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="算法分析">算法分析&lt;/h4>
&lt;p>表现最稳定的排序算法之一，因为无论什么数据进去都是$O(^2)$的时间复杂度，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。&lt;/p>
&lt;h3 id="插入排序insertion-sort">插入排序（Insertion Sort）&lt;/h3>
&lt;p>插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。&lt;/p>
&lt;h4 id="算法描述-1">算法描述&lt;/h4>
&lt;p>一般来说，插入排序都采用 in-place 在数组上实现。具体算法描述如下：&lt;/p>
&lt;ul>
&lt;li>从第一个元素开始，该元素可以认为已经被排序；&lt;/li>
&lt;li>取出下一个元素，在已经排序的元素序列中从后向前扫描；&lt;/li>
&lt;li>如果该元素（已排序）大于新元素，将该元素移到下一位置；&lt;/li>
&lt;li>重复步骤 3，直到找到已排序的元素小于或者等于新元素的位置；&lt;/li>
&lt;li>将新元素插入到该位置后；&lt;/li>
&lt;li>重复步骤 2~5。&lt;/li>
&lt;/ul>
&lt;h4 id="动图演示-2">动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-34-32-849589-20171015225645277-1151100000.png" alt="">&lt;/p>
&lt;h4 id="代码实现">代码实现&lt;/h4>
&lt;h4 id="算法分析-1">算法分析&lt;/h4>
&lt;p>插入排序在实现上，通常采用 in-place 排序（即只需用到 O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。&lt;/p>
&lt;h2 id="高级比较排序算法">高级比较排序算法&lt;/h2>
&lt;h3 id="希尔排序shell-sort">希尔排序（Shell Sort）&lt;/h3>
&lt;p>1959 年 Shell 发明，第一个突破$O(n^2)$的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫&lt;strong>缩小增量排序&lt;/strong>。&lt;/p>
&lt;h4 id="算法描述-2">算法描述&lt;/h4>
&lt;p>先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：&lt;/p>
&lt;ul>
&lt;li>选择一个增量序列 t1，t2，…，tk，其中 ti&amp;gt;tj，tk=1；&lt;/li>
&lt;li>按增量序列个数 k，对序列进行 k 趟排序；&lt;/li>
&lt;li>每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。&lt;/li>
&lt;/ul>
&lt;h4 id="动图演示-3">动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-34-40-849589-20180331170017421-364506073.png" alt="">&lt;/p>
&lt;h4 id="代码实现-1">代码实现&lt;/h4>
&lt;h4 id="算法分析-2">算法分析&lt;/h4>
&lt;p>希尔排序的核心在于间隔序列的设定。既可以提前设定好间隔序列，也可以动态的定义间隔序列。动态定义间隔序列的算法是《算法（第 4 版）》的合著者 Robert Sedgewick 提出的。&lt;/p>
&lt;h3 id="归并排序merge-sort">归并排序（Merge Sort）&lt;/h3>
&lt;p>归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为 2-路归并。&lt;/p>
&lt;h4 id="算法描述-3">算法描述&lt;/h4>
&lt;ul>
&lt;li>把长度为 n 的输入序列分成两个长度为 n/2 的子序列；&lt;/li>
&lt;li>对这两个子序列分别采用归并排序；&lt;/li>
&lt;li>将两个排序好的子序列合并成一个最终的排序序列。&lt;/li>
&lt;/ul>
&lt;h4 id="动图演示-4">动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-34-22-849589-20171015230557043-37375010.png" alt="">&lt;/p>
&lt;h4 id="代码实现-2">代码实现&lt;/h4>
&lt;h4 id="算法分析-3">算法分析&lt;/h4>
&lt;p>归并排序是一种稳定的排序方法。和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 O(nlogn）的时间复杂度。代价是需要额外的内存空间。&lt;/p>
&lt;h3 id="快速排序quick-sort">快速排序（Quick Sort）&lt;/h3>
&lt;p>快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。&lt;/p>
&lt;h4 id="算法描述-4">算法描述&lt;/h4>
&lt;p>快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：&lt;/p>
&lt;ul>
&lt;li>从数列中挑出一个元素，称为 “基准”（pivot）；&lt;/li>
&lt;li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；&lt;/li>
&lt;li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。&lt;/li>
&lt;/ul>
&lt;h4 id="62-动图演示">6.2 动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-33-40-849589-20171015230936371-1413523412.png" alt="">&lt;/p>
&lt;h4 id="代码实现-3">代码实现&lt;/h4>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="堆排序heap-sort">堆排序（Heap Sort）&lt;/h3>
&lt;p>堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。&lt;/p>
&lt;h4 id="算法描述-5">算法描述&lt;/h4>
&lt;ul>
&lt;li>将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；&lt;/li>
&lt;li>将堆顶元素 R[1]与最后一个元素 R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足 R[1,2…n-1]&amp;lt;=R[n]；&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h4 id="72-动图演示">7.2 动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-34-14-849589-20171015231308699-356134237.png" alt="loading-ag-1822">&lt;/p>
&lt;h4 id="代码实现-4">代码实现&lt;/h4>
&lt;h2 id="非比较排序">非比较排序&lt;/h2>
&lt;h3 id="计数排序counting-sort">计数排序（Counting Sort）&lt;/h3>
&lt;p>计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。&lt;/p>
&lt;h4 id="算法描述-6">算法描述&lt;/h4>
&lt;ul>
&lt;li>找出待排序的数组中最大和最小的元素；&lt;/li>
&lt;li>统计数组中每个值为 i 的元素出现的次数，存入数组 C 的第 i 项；&lt;/li>
&lt;li>对所有的计数累加（从 C 中的第一个元素开始，每一项和前一项相加）；&lt;/li>
&lt;li>反向填充目标数组：将每个元素 i 放在新数组的第 C(i)项，每放一个元素就将 C(i)减去 1。&lt;/li>
&lt;/ul>
&lt;h4 id="动图演示-5">动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-33-57-849589-20171015231740840-6968181.png" alt="">&lt;/p>
&lt;h4 id="代码实现-5">代码实现&lt;/h4>
&lt;h4 id="算法分析-4">算法分析&lt;/h4>
&lt;p>计数排序是一个稳定的排序算法。当输入的元素是 n 个 0 到 k 之间的整数时，时间复杂度是 O(n+k)，空间复杂度也是 O(n+k)，其排序速度快于任何比较排序算法。当 k 不是很大并且序列比较集中时，计数排序是一个很有效的排序算法。&lt;/p>
&lt;h3 id="桶排序bucket-sort">桶排序（Bucket Sort）&lt;/h3>
&lt;p>桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。&lt;/p>
&lt;h4 id="算法描述-7">算法描述&lt;/h4>
&lt;ul>
&lt;li>设置一个定量的数组当作空桶；&lt;/li>
&lt;li>遍历输入数据，并且把数据一个一个放到对应的桶里去；&lt;/li>
&lt;li>对每个不是空的桶进行排序；&lt;/li>
&lt;li>从不是空的桶里把排好序的数据拼接起来。&lt;/li>
&lt;/ul>
&lt;h4 id="图片演示">图片演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-33-48-849589-20171015232107090-1920702011.png" alt="">&lt;/p>
&lt;h4 id="代码实现-6">代码实现&lt;/h4>
&lt;h4 id="算法分析-5">算法分析&lt;/h4>
&lt;p>桶排序最好情况下使用线性时间 O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为 O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。&lt;/p>
&lt;h3 id="基数排序radix-sort">基数排序（Radix Sort）&lt;/h3>
&lt;p>基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。&lt;/p>
&lt;h4 id="算法描述-8">算法描述&lt;/h4>
&lt;ul>
&lt;li>取得数组中的最大数，并取得位数；&lt;/li>
&lt;li>arr 为原始数组，从最低位开始取每个位组成 radix 数组；&lt;/li>
&lt;li>对 radix 进行计数排序（利用计数排序适用于小范围数的特点）；&lt;/li>
&lt;/ul>
&lt;h4 id="动图演示-6">动图演示&lt;/h4>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-32-46-849589-20171015232453668-1397662527.png" alt="">&lt;/p>
&lt;h4 id="代码实现-7">代码实现&lt;/h4>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="算法分析-6">算法分析&lt;/h4>
&lt;p>基数排序基于分别排序，分别收集，所以是稳定的。但基数排序的性能比桶排序要略差，每一次关键字的桶分配都需要 O(n)的时间复杂度，而且分配之后得到新的关键字序列又需要 O(n)的时间复杂度。假如待排数据可以分为 d 个关键字，则基数排序的时间复杂度将是 O(d*2n) ，当然 d 要远远小于 n，因此基本上还是线性级别的。&lt;/p>
&lt;p>基数排序的空间复杂度为 O(n+k)，其中 k 为桶的数量。一般来说 n&amp;raquo;k，因此额外空间需要大概 n 个左右。&lt;/p></description></item><item><title>Golang基础</title><link>https://justice.bj.cn/post/14.language/golang/golang%E5%9F%BA%E7%A1%80/</link><pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/golang%E5%9F%BA%E7%A1%80/</guid><description>&lt;h1 id="golang基础">Golang基础&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;h2 id="初始化">初始化&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/22-13-51-07-image-20190412160342216.png" alt="image-20190412160342216">&lt;/p>
&lt;p>规则：&lt;/p>
&lt;ul>
&lt;li>每个package 只会被初始化一次；&lt;/li>
&lt;li>同一个 package，不同文件是按照文件名的顺序来初始化；&lt;/li>
&lt;li>不能循环 import , 例如：A import B ,然后又 B import A；&lt;/li>
&lt;li>任何 package , 都可以存在一个以上的 init() , 执行顺序由上而下；&lt;/li>
&lt;li>main() 只能存在于 package main；&lt;/li>
&lt;li>属于 package main 的文件 , 都将会初始化；&lt;/li>
&lt;/ul>
&lt;h2 id="变量">变量&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>golang变量声明即初始化；&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">//声明
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">var&lt;/span> &lt;span class="nx">v&lt;/span> &lt;span class="nx">VAR_TYPE&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="基础语法">基础语法&lt;/h2>
&lt;h3 id="类型别名">类型别名&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>类型别名是go 1.9中增加的语法，用于给已有类型设置一个另外的名称；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>语法：&lt;code>type TypeAllias = OldType&lt;/code>;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>类型别名除了名称和原类型不同外，其他完全一样，可以直接用在原类型用的所有属性，无须转换；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>类型别名不允许循环定义；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>大写字母开头的别名支持导出；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// 类型别名
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">type&lt;/span> &lt;span class="nx">identifier&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">Type&lt;/span>
&lt;span class="c1">// 类型定义
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">type&lt;/span> &lt;span class="nx">newType&lt;/span> &lt;span class="nx">Type&lt;/span>
&lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">type&lt;/span> &lt;span class="kt">byte&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kt">uint8&lt;/span> &lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">type&lt;/span> &lt;span class="kt">rune&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kt">int32&lt;/span> &lt;span class="c1">//
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="类型嵌入">类型嵌入&lt;/h3>
&lt;p>golang中的类型不支持继承，但提供了嵌合机制；&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">type&lt;/span> &lt;span class="nx">Wheel&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">Size&lt;/span> &lt;span class="kt">int&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kd">type&lt;/span> &lt;span class="nx">Engine&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">Power&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="c1">// 功率
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">Type&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="c1">// 类型
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="kd">type&lt;/span> &lt;span class="nx">Car&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">Wheel&lt;/span>
&lt;span class="nx">Engine&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">c&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">Car&lt;/span>&lt;span class="p">{&lt;/span>
&lt;span class="nx">Wheel&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nx">Wheel&lt;/span>&lt;span class="p">{&lt;/span>
&lt;span class="nx">Size&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="nx">Engine&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nx">Engine&lt;/span>&lt;span class="p">{&lt;/span>
&lt;span class="nx">Type&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s">&amp;#34;1.4T&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nx">Power&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">143&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="nx">fmt&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;%+v\n&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">c&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="基本数据结构">基本数据结构&lt;/h2>
&lt;h3 id="数组array">数组(array)&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// 初始化
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">var&lt;/span> &lt;span class="nx">arr1&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">int&lt;/span>
&lt;span class="nx">arr2&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="nx">arr3&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="nx">arr4&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="c1">//指针数组
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">arr5&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">new&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">new&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">)}&lt;/span>
&lt;span class="o">*&lt;/span>&lt;span class="nx">arr5&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="mi">10&lt;/span>
&lt;span class="c1">//数组复制: 元素个数和类型相同时才能复制
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">//多维数组
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">var&lt;/span> &lt;span class="nx">arr10&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">int&lt;/span>
&lt;span class="nx">arr10&lt;/span> &lt;span class="o">:=&lt;/span>
&lt;span class="nx">array&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">{{&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">},&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">},&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">},&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">}}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="切片slice">切片(slice)&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">//初始化
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">var&lt;/span> &lt;span class="nx">slice1&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="c1">//nil slice
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">slice2&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="nx">slice3&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">{}&lt;/span> &lt;span class="c1">//空切片
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">slice4&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nb">make&lt;/span>&lt;span class="p">([]&lt;/span>&lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="映射map">映射(map)&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="nx">dict1&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nb">make&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kd">map&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="kt">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nx">dict2&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="kd">map&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="kt">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="kt">string&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="s">&amp;#34;Red&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;Yellow&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;Blue&amp;#34;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="gc">gc&lt;/h3>
&lt;h3 id="goroutine">goroutine&lt;/h3>
&lt;h3 id="channel">channel&lt;/h3>
&lt;h3 id="interface">Interface&lt;/h3>
&lt;h3 id="sync">sync&lt;/h3>
&lt;ul>
&lt;li>WaitGroup&lt;/li>
&lt;/ul>
&lt;h3 id="defer">defer&lt;/h3>
&lt;p>defer 是后进先出。&lt;/p>
&lt;p>panic 需要等defer 结束后才会向上传递。 出现panic恐慌时候，会先按照defer的后入先出的顺序执行，最后才会执行panic。&lt;/p>
&lt;h3 id="关键字">关键字&lt;/h3>
&lt;ul>
&lt;li>defer&lt;/li>
&lt;/ul>
&lt;h3 id="值语义和引用语义">值语义和引用语义&lt;/h3>
&lt;p>Go语言中的大多数类型都基于值语义，包括：&lt;/p>
&lt;ul>
&lt;li>基本类型，如byte、int、bool、float32、string等；&lt;/li>
&lt;li>复合类型，如arry、struct、pointer等；&lt;/li>
&lt;/ul>
&lt;h3 id="字符类型">字符类型&lt;/h3>
&lt;p>golang中有两种字符类型：&lt;/p>
&lt;ul>
&lt;li>byte：uint8 类型， 代表一个&lt;a href="http://c.biancheng.net/c/ascii/">ASCII&lt;/a> 字符;&lt;/li>
&lt;li>rune： int32 类型，代表一个unicode字符；&lt;/li>
&lt;/ul>
&lt;h2 id="注意事项">注意事项&lt;/h2>
&lt;ol>
&lt;li>for-range 的k,v变量在整个遍历过程中共用，不能直接进行引用传递。&lt;/li>
&lt;li>&lt;/li>
&lt;/ol>
&lt;h2 id="包管理">包管理&lt;/h2>
&lt;h3 id="gopath">GOPATH&lt;/h3>
&lt;h3 id="go-mod">go-mod&lt;/h3>
&lt;h3 id="闭包">闭包&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Go语言支持闭包；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Go语言能通过escape analyze识别出变量的作用域，自动将变量在堆上分配；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>返回闭包时并不是单纯返回一个函数，而是返回了一个结构体，记录下函数返回地址和引用的环境中的变量地址；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">func&lt;/span> &lt;span class="nf">f&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">i&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kd">func&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="kd">func&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">i&lt;/span>&lt;span class="o">++&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nx">i&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://www.jianshu.com/p/2904efc7f1a8">图解golang内存分配&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://colobu.com/2017/06/26/learn-go-type-aliases/">了解 Go 1.9 的类型别名&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>全面介绍数砖开发 Delta Lake 的第一篇论文</title><link>https://justice.bj.cn/post/30.architech/deltalake/</link><pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/deltalake/</guid><description>&lt;h1 id="全面介绍数砖开发-delta-lake-的第一篇论文">全面介绍数砖开发 Delta Lake 的第一篇论文&lt;/h1>
&lt;h2 id="摘要">摘要&lt;/h2>
&lt;p>云对象存储如Amazon S3，作为目前最大且最节约成本的存储系统，用于实现数据仓库和数据湖的存储非常具有吸引力。但由于其实现的本质是键值存储，保证ACID事务性和高性能具有很大的挑战：元数据操作，比如list对象是很昂贵的操作；一致性保证也受限。&lt;/p>
&lt;p>在本论文中，我们向大家介绍Delta Lake，一个由Databricks开源的基于云对象存储的ACID表存储层技术。Delta Lake通过使用压缩至Apache Parquent格式的事务性日志来提供ACID，Time Travel以及海量数据集的高性能元数据操作（比如快速搜索查询相关的上亿个表分区）。同时Delta Lake也提供一些高阶的特性，比如自动数据布局优化，upsert，缓存以及审计日志等。Delta Lake表可以通过Apache Spark， Hive， Presto， Redshift等系统访问。Delta Lake目前已被上千个Databriks用户使用，每天处理exabytes级数据，最大的应用实例管理EB级数据集以及上亿对象。&lt;/p>
&lt;h3 id="1引言">1.引言&lt;/h3>
&lt;p>云对象存储如Amazon S3以及Azure Blob存储已成为最大且最广泛使用的存储系统，为上百万用户存储EB级数据。除了云服务传统的优点，如按需付费，规模效益，专业的管理等，云对象存储特别具有吸引力的原因是允许用户对存储和计算资源进行分离；举例来说，用户可以存储PB数据，但是仅运行一个集群执行几个小时的查询。&lt;/p>
&lt;p>因此，目前许多组织使用云存储来管理数据仓库以及数据湖上的大型结构化数据。主流的开源大数据系统，包括Apache Spark， Hive以及Presto支持Apache Parquet，ORC格式云对象存储的读写。商业服务包括AWS Athena， Google BigQuery和Redshift Spectrum 查询也支持以上这些系统及这些文件格式。&lt;/p>
&lt;p>不幸的是，尽管许多系统支持云对象的读写，实现高性能及可变的表存储非常有挑战，同时也使得在其上构建数仓很困难。与分布式文件系统如HDFS， 或者DBMS的定制存储引擎不同，大多数云存储对象都仅仅只是键值存储，并没有跨键的一致性保证。它们的性能特点也与分布式文件系统非常不同因此需要获得特殊的关注。&lt;/p>
&lt;p>在云存储对象中存储关系型数据最常见的方式是使用列存储格式，比如Parquet和ORC，每张表都被存储为一系列对象（parquet或者ORC文件）的集合，通过某些列做分区。这种方式在对象文件的数量适中时，扫描文件的性能尚可接受。但对于更复杂的扫描工作，正确性以及性能都将受到挑战。首先，多对象的更新并不是原子的，查询之间没有隔离：举例来说，如果一个查询需要更新表中的多个对象（比如从表的所有parquet文件中删除某个用户的相关记录），由于是逐个object更新，因此读客户端将会看到部分更新。另外，写回滚也很困难：如果一个更新失败，那么表将处于被污染的状态。第二，对于有上百万对象的大表，元数据操作非常昂贵。比如，parquet文件中footer包含了min/max等统计信息在查询时用来帮助跳过读文件。在HDFS上读footer信息只需要几毫秒，云对象存储的延迟非常高使得跳过读操作甚至比实际的查询花费时间还要长。&lt;/p>
&lt;p>从我们与云客户工作的经验来看，这些一致性以及性能方面的问题对企业的数据团队产生了很大的挑战。大多数的企业数据是持续更新的，所以需要原子写的解决方案；多数涉及到用户信息的数据需要表范围的更新以满足GDPR这样的合规要求。即使是内部的数据也需要更新操作来修正错误数据以及集成延迟到达的记录。有趣的是，在Databricks提供云服务最初的几年，我们收到的客户服务支持升级中，约有一半都是由于云存储策略导致的数据损毁，一致性以及性能等方面的问题。(比如，取消更新任务失败造成的影响，或者改进读取上万个对象的查询性能)。&lt;/p>
&lt;p>为了解决这些挑战，我们设计了Delta Lake，基于云存储对象的ACID表存储层。Delta Lake从2017年开始服务于客户，并于2019年开源。Delta Lake的核心概念很简单：我们使用存储在云对象中的预写日志，以ACID的方式维护了哪些对象属于Delta table这样的信息。对象本身写在parquet文件中，使已经能够处理Parquet格式的引擎可以方便地开发相应的connectors。这样的设计可以让客户端以串行的方式一次更新多个对象，替换一些列对象的子集，同时保持与读写parquet文件本身相同的高并发读写性能。日志包含了为每一个数据文件维护的元数据，如min/max 统计信息。相比“对象存储中的文件”这样的方式，元数据搜索相关数据文件速度有了数量级的提升。 最关键的是，我们设计Delta Lake使所有元数据都在底层对象存储中，并且事务是通过针对对象存储的乐观并发协议实现的（具体细节因云厂商而异）。这意味着不需要单独的服务来维护Delta table的状态；用户只需要在运行查询时启动服务器，享受存储计算扩展分离带来的好处。&lt;/p>
&lt;p>基于这样的事务性设计，我们能够加入在传统云数据湖上无法提供的解决用户痛点的特性，包括：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Time travel：允许用户查询具体时间点的数据快照或者回滚错误的数据更新。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Upsert，delete以及merge操作：高效重写相关对象实现对存储数据的更新以及合规工作流（比如GDPR）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>高效的流I/O：流作业以低延迟将小对象写入表中，然后以事务形式将它们合并到大对象中来提高查询性能。支持快速“tail”读取表中新加入数据，因此作业可以将Delta表作为一个消息队列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>缓存：由于Delta表中的对象以及日志是不可变的，集群节点可以安全地将他们缓存在本地存储中。我们在Databricks云服务中利用这个特性为Delta表实现透明的SSD缓存。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据布局优化：我们的云服务包括一个特性，能够在不影响查询的情况下，自动优化表中对象的大小，以及数据记录的聚类（clustering）（将记录存储成Zorder实现多维度的本地化）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Schema演进：当表的schema变化时，允许在不重写parquet文件的情况下读取旧的parquet文件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>日志审计：基于事务日志的审计功能。&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;p>这些特性改进了数据在云对象存储上的可管理性和性能，并且结合了数仓和数据湖的关键特性创造了“湖仓”的典范：直接在廉价的对象存储上使用标准的DBMS管理功能。事实上，我们发现很多Databricks的客户希望使用Delta Lake简化他们整体的数据架构，替换之前分离的数据湖，数仓，以及流存储系统，用Delta表来为所有用例提供适用的功能。表格1展示了一个例子，数据管道包括对象存储，消息队列以及为两个不同商业智能服务的数仓（每一个使用独立的计算资源），替换为只包含云存储对象上的Delta表，使用Delta的流I/O以及性能特性来执行ETL和BI。这种新的管道只用到了廉价的对象存储并产生了更少数量的数据备份，在存储和运维方面降低了成本。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/0yBD9iarX0nvHAHdS1bjNgoKNYeovO77csdibuLB2ez2OshfIKyibpR8tzHh2OnfENrEKw7MdGzo5yibpQ3eXnsv9w/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1" alt="">&lt;/p>
&lt;p>图1: 使用3个存储系统实现的数据pipeline(1个消息队列, 1个对象存储 和 1个数据仓库), 或者使用 Delta Lake去同时实现流和表存储. Delta Lake的实现使得不需要维护多份copy，只需要使用最便宜的对象存储.&lt;/p>
&lt;p>Delta Lake目前被大多数Databricks的大客户采用，每天处理exabyte数据（约占我们整体工作需求的一半），其他云厂商如Google Cloud，Alibaba，Tencent，Fivetran，Informatica，Qlik，Talend以及其他产品也支持Delta Lake。在Databricks的客户中，Delta Lake的使用用例非常多样化，从传统的ETL和数仓的工作流，到生物信息学，实时网络安全分析（每天处理数百TB流事件数据），GDPR合规性以及用于机器学习的数据管理（管理数以百万计的图像作为Delta表中的记录而不是S3对象，以获取ACID并提高性能）。我们将在Section 5具体讨论这些使用用例。&lt;/p>
&lt;p>有趣的是，Delta Lake将Databricks的云存储相关支持问题比例从一半降为接近于零。Detla Lake为大多数客户改善了负载性能，在某些极端用例下，使用Delta Lake的数据布局以及快速访问统计信息对高维数据集（比如网络安全和生物信息学等场景）查询，甚至可以获得100倍的速度提升。开源的Delta Lake项目包含了Apache Spark（流批）， Hive， Presto，AWS Athena，Redshift以及Snowflake的连接器，能够运行在多种云对象存储或者HDFS之上。在本文中，我们将展示Delta Lake的设计初衷，设计理念，用户使用案例以及推动设计的性能测试。&lt;/p>
&lt;h3 id="2动机云对象存储的特点及挑战">2.动机：云对象存储的特点及挑战&lt;/h3>
&lt;p>&lt;strong>2.1 对象存储API&lt;/strong>&lt;/p>
&lt;p>云对象存储，比如Amazon S3，Azure Blob存储，Google云存储，以及OpenStack Swift，都提供了简单但容易扩展的键值存储接口。这些系统允许用户创建桶，每个桶存储多个对象，每个对象都是一个二进制blob，大小可到几TB（比如，在S3上对象最大为5TB），每个对象都由一个字符串作为key来标识。通常的方式是将文件系统的路径作为云对象存储的key。但云对象存储不能像文件系统那样，提供廉价的对“文件”或者对象的重命名操作。云对象存储提供元数据API，比如S3的List操作，根据给定的起始键，列出在某个桶中按键的字典序排序的所有对象。这使得通过发起一个LIST请求，给定一个代表目录前缀的key（比如 warehouse/table1/）有效地列出目录下的所有对象成为可能。但很可惜的是，元数据的API操作通常很昂贵，比如S3的LIST调用每次只能返回1000个key，每次调用花费几十至上百毫秒，所以当以顺序的方式列出一个有数百万对象的数据集可能需要好几分钟。&lt;/p>
&lt;p>读取对象时，云对象存储支持字节范围的请求，读取某个大对象的某字节范围（比如，从10000字节到20000字节）通常是高效的。这样就可以利用对常用值进行聚类的存储格式。&lt;/p>
&lt;p>更新对象通常需要重写整个对象。这些更新需要是原子的，以使读对整个新版本对象或者老版本对象可见。有些系统也支持对象的追加写。&lt;/p>
&lt;p>一些云厂商也在blob存储上实现了分布式文件系统接口，比如Azure的ADLS Gen2与Hadoop的HDFS具有相似的语义（比如目录的原子rename）。然而，Delta Lake解决的许多问题，如小文件问题，对多个目录的原子更新问题即使在分布式系统中也依然存在。事实上，有很多用户是在HDFS上使用Delta Lake。&lt;/p>
&lt;h2 id="heading">&lt;/h2>
&lt;p>&lt;strong>2.2 一致性属性&lt;/strong>&lt;/p>
&lt;p>如引言中所述，大多数云对象存储对单个key提供最终一致性保证，对跨key不提供一致性保证， 这对包含多对象的数据集管理提出了挑战。特别是当客户端提交了新的对象，其他客户端不能够保证在LIST或者读操作中立即看到这个对象。类似地，对现有对象的更新对其他客户端也不能够立即可见。更严重的是，有些对象存储系统，即使同一客户端执行了写操作也不能够立即读到新对象。&lt;/p>
&lt;p>精确的一致性模型因不同的云厂商而异，且相当复杂。举个具体的例子，Amazon S3提供了写后读的一致性，S3的客户端在PUT操作后可以通过GET返回这个对象的内容。一个例外是：如果客户端在PUT之前对不存在的Key先调用了GET，那么后续的GET操作可能由于S3的逆向缓存机制在一段时间内读不到这个对象。S3的LIST操作是最终一致的，这意味着在PUT之后LIST操作可能无法返回新的对象。其他的云对象存储提供更强的一致性保证，但在跨key的情况下仍然无法提供原子性操作。&lt;/p>
&lt;h2 id="heading-1">&lt;/h2>
&lt;p>&lt;strong>2.3 性能特点&lt;/strong>&lt;/p>
&lt;p>根据我们的经验，通过对象存储实现高吞吐量需要在大型顺序I / O和并行性之间取得平衡。&lt;/p>
&lt;p>对于读取，如前所述，最小粒度的操作是读取连续字节范围。每个读取操作通常会有至少5–10 ms的延迟，然后以大约50–100 MB / s的速度读取数据，因此，一个操作需要读取至少数百KB，才能达到顺序读取的峰值吞吐量的一半；读取数MB才能以接近峰值吞吐量。此外，在典型的VM配置上，应用程序需要并行运行多个读取以最大化吞吐量。例如，在AWS上最常用于分析的VM类型具有至少10 Gbps的网络带宽，因此它们需要并行运行8-10次读取才能充分利用此带宽。&lt;/p>
&lt;p>LIST操作也需要高并行度才能快速列出大数量的对象。比如S3的LIST操作每个请求只能返回1000个对象，耗时十到数百毫秒，因此客户端对大桶或者目录进行list时需要并行发出上百个LIST请求。在针对云上Apache Spark的优化运行时中，除了在Spark集群的driver节点中并行执行线程外，有时我们还会在worker节点上并行执行LIST操作以使它们更快地运行。在Delta Lake中，可用对象的元数据（包括它们的名称和数据统计信息）是存储在Delta日志中的，但我们还是会并行从该日志中读取数据。&lt;/p>
&lt;p>如2.1节所述，写操作通常要求必须重写整个对象（或者追加），这意味着如果一张表期望得到点更新，那么对象文件必须小一些，这与大量读对文件大小的要求是矛盾的。一种替代方案是使用日志结构的存储格式。&lt;/p>
&lt;p>表存储的含义。对于分析型工作负载，对象存储的性能特征引出的三点考虑：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>将需要经常访问的数据就近连续存储，这通常要求选择列存储格式。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使对象较大，但不能过大。大对象增加了更新数据的成本（例如，删除某个用户的所有数据），因为需要全部重写。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>避免使用LIST操作，并在可能的情况下按字典顺序的键范围发送请求。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="heading-2">&lt;/h2>
&lt;p>&lt;strong>2.4 现有的表存储方法&lt;/strong>&lt;/p>
&lt;p>基于对象存储的特征，目前主要有三种方法在对象存储之上管理表格数据集。我们将简述这些方法及其面临的挑战。&lt;/p>
&lt;p>**1.**目录文件 目前开源大数据技术栈以及云服务支持的最通用的方式是将表存储为对象集合，通常采用列存，比如Parquet。作为一种改进，可以基于一个或多个属性将记录“分区”到目录中。例如，对于具有日期字段的表，我们可以为每个日期创建一个单独的对象目录，例如，mytable / date = 2020-01-01 / obj1 以及mytable / date = 2020-01-01 / obj2用于记录从1月1日的数据，mytable / date = 2020-01-02 / obj1，1月2日的数据，依此类推，然后根据该字段将传入的数据拆分为多个对象。这样的分区减少了LIST操作以及仅访问几个分区的查询读操作的成本。&lt;/p>
&lt;p>这种方式具有吸引力是因为整个表仅由一些对象组成，可以通过许多工具访问 而无需运行任何其他数据存储或系统。这种方式起源于HDFS之上的Apache Hive，并且与Parquet，Hive和文件系统上的其他大数据软件配合使用。&lt;/p>
&lt;p>如引言中所述，这种方式的挑战是 “一堆文件”在云对象存储上有性能和一致性方面的问题。客户遇到的最常见挑战是：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>跨多个对象没有原子性：任何需要写入或更新多个对象的事务都可能导致其他客户端只可见部分写入。此外，如果事务失败，数据将处于损坏状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>最终一致性：即使事务成功，客户端也有可能只看到部分更新对象。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>性能差：查找与查询相关对象时的LIST操作很昂贵，即使它们被键划分到分区目录中。此外，访问存储在Parquet或ORC文件中的对象统计信息很昂贵，因为它需要对每个文件的统计信息进行额外的高延迟读取。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>没有管理功能：对象存储没有实现数据仓库中常用的标准工具，例如表版本控制或审核日志。&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>2.&lt;/strong> 自定义存储引擎. 为云构建的“闭源”存储引擎，例如Snowake数据仓库[23]，可以通过在单独的，高度一致的服务中管理元数据来绕过云对象存储的许多一致性挑战。这种服务保存着哪些对象构成了表这样的事实。在这些引擎中，可以将云对象存储视为笨拙的块设备，并且可以使用标准技术在云对象上实现有效的元数据存储，搜索，更新等。但是，此方法需要运行一个高可用性服务来管理元数据，这可能很昂贵，在使用外部计算引擎查询数据时可能会增加成本，而且有可能将用户锁定在某个特定厂商。&lt;/p>
&lt;p>这种方式的挑战：尽管这种从头开始的“闭源”设计是有好处的，但使用这种方法遇到的一些具体挑战是：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>所有对表的I / O操作都需要连接元数据服务联系，增加资源成本并降低性能和可用性。例如，当用Spark访问Snow ﬂake数据集时，使用Snow ﬂake的Spark连接器通过Snow service的服务读取数据，与直接从云对象存储中读取数据相比降低了性能。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>与重用现有开放格式（例如Parquet）的方法相比，开发现有计算引擎的连接器需要更多的工作量。根据我们的经验，数据团队希望在数据上使用多种计算引擎（例如Spark，TensorFlow，PyTorch等），因此使连接器易于实现非常重要。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>专有的元数据服务将用户与特定厂商绑定，相比之下，基于直接访问云存储的方式使用户总是能够使用各种技术访问他们的数据。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/0yBD9iarX0nvHAHdS1bjNgoKNYeovO77ccXk5wDSjPN79YnOF0OkCyGKWsyJic6EJ9JbwBIj9AmcqMR7IG7edwLw/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1" alt="">&lt;/p>
&lt;p>图2:一个Delta table的对象layout案例&lt;/p>
&lt;p>Apache Hive ACID 使用Hive Metastore（一种事务性关系型数据库，例如MySQL）跟踪每张表相关的更新，更新以多个文件的形式存储在表的元数据信息中，一般为ORC格式。但是，这种方法受限于metastore的性能，根据我们的经验，它可能成为具有数百万个对象的表的瓶颈。&lt;/p>
&lt;p>**3.**在对象存储中保存元数据 Delta Lake的方法是将事务日志和元数据直接存储在云对象存储中，并在对象存储操作上使用一组协议来实现可序列化。。表中的数据以Parquet格式存储，只要实现一个最基本的连接器去发现要读取的对象集，就可以使用任何已经支持Parquet的软件访问数据。尽管我们认为Delta Lake是第一个使用该设计的系统（从2016年开始），但现在另外两个软件Apache Hudi 和Apache Iceberg 也支持这种方式。Delta Lake提供了一系列这些系统不支持的独特功能，例如Z序聚类，缓存和后台优化。我们将在第8节中详细讨论这些系统之间的异同。&lt;/p>
&lt;h1 id="heading-3">&lt;/h1>
&lt;ol start="3">
&lt;li>DELTA LAKE存储格式及访问协议&lt;/li>
&lt;/ol>
&lt;p>Delta Lake表是云对象存储或文件系统上的一个目录，其中包含具有表内容的数据对象和事务操作日志（包含检查点）。客户端使用我们根据云对象存储的特性量身定制的乐观并发控制协议来更新这些数据结构。在本节中，我们描述了Delta Lake的存储格式以及访问协议。我们还描述了Delta Lake的事务隔离级别，包括序列化（serializable）和快照（snapshot）隔离级别。&lt;/p>
&lt;h2 id="heading-4">&lt;/h2>
&lt;p>&lt;strong>3.1 存储格式&lt;/strong>&lt;/p>
&lt;p>图2展示了Delta Table的存储格式。每个表都存储在一个文件系统目录中（本例中是mytable）或者在对象存储中以相同目录作为key前缀的一些对象。&lt;/p>
&lt;h3 id="heading-5">&lt;/h3>
&lt;p>3.1.1 数据对象&lt;/p>
&lt;p>表的内容存储在Apache Parquet对象中，可以使用Hive的分区命名规范将其组织到目录中。&lt;/p>
&lt;p>例如在图2中，该表按日期列分区，因此对于每个日期，数据对象位于单独的目录中。我们选择Parquet作为我们的数据格式，因为Parquet面向列，提供多种压缩更新，支持半结构化数据的嵌套数据类型，并且已经在许多引擎中实现了高性能。基于现有的开放文件格式，还使Delta Lake可以持续利用Parquet库最新发布的更新并简化其他引擎的连接器开发（第4.8节）。其他开放文件格式，例如ORC [12]，也可以类似地工作，但是Parquet在Spark中拥有的支持最为成熟。&lt;/p>
&lt;p>每个数据对象在Delta中拥有唯一名字，通常是由writer生成的GUID。哪些对象是表的哪的版本是由事务日志决定的。&lt;/p>
&lt;h3 id="heading-6">&lt;/h3>
&lt;p>3.1.2 日志&lt;/p>
&lt;p>日志存储在表的_delta_log子目录中。它包含一系列以零填充的递增数字作为ID的JSON对象用于存储日志记录，并包含对某些特定日志对象的检查点，这些检查点将检查点之前的日志合并为Parquet格式。如3.2节中讨论的，一些简单的访问协议（取决于每个对象存储中可用的原子操作）用于创建新的日志条目或检查点，并使客户端在此基础上支持事务。&lt;/p>
&lt;p>每个日志记录对象（比如000003.json）包含了在前一个版本的表基础上进行的操作数组，以产生下一个版本。可用的操作包括：&lt;/p>
&lt;p>更改元数据 metaData操作更改表的当前元数据。表的第一个版本必须包含metaData操作。后续的metaData操作将完全覆盖表的当前元数据。元数据是一种数据结构，其中包含模式，分区列名称（如示例中的日期），数据文件的存储格式（通常为Parquet，但提供了可扩展性）以及其他配置选项，例如将表标记为仅追加。&lt;/p>
&lt;p>添加或删除文件   添加和删除操作用于通过添加或删除单个数据对象来修改表中的数据。因此，客户可以搜索日志以查找所有尚未删除的已添加对象，以确定组成表的对象集。&lt;/p>
&lt;p>数据对象的添加记录还可以包括数据统计信息，例如总记录条数以及每列的最小/最大值和空计数。当表中已存在的路径遇到添加操作时，最新版本的统计信息将替换任何先前版本的统计信息。这样可以在新版Delta Lake中“升级”旧表使其具有更多统计信息。&lt;/p>
&lt;p>删除操作包括表明删除发生时间的时间戳。在用户指定的保留时间阈值之后，数据对象会被进行惰性延迟物理删除。此延迟使并发的读取器可以继续对过期的数据快照执行操作。删除操作应作为墓碑保留在日志和所有日志检查点中，直到数据对象被删除为止。&lt;/p>
&lt;p>可以将添加或删除操作上的dataChange标志设置为false，以指示当与同一日志记录对象中的其他操作结合使用时，此添加或删除操作仅对现有数据重新排列或添加统计信息。例如，跟踪事务日志的流查询可以使用此标志来跳过不会影响其结果的操作，例如在早期数据文件中更改排序顺序。&lt;/p>
&lt;p>协议演进 协议操作用于增加Delta协议的版本号，在读取或写入给定表时需要此版本号。我们使用此操作向存储格式添加新功能，同时指出哪些客户端仍然兼容。&lt;/p>
&lt;p>添加来源信息 每个日志记录对象还可以在commitInfo操作中包括来源信息，例如，记录执行操作的用户。&lt;/p>
&lt;p>更新应用事务ID。Delta Lake为应用程序提供了一种将应用程序的数据包括在日志记录中的方法，这对于实现端到端事务性应用很有用。例如，写入Delta表的流处理系统需要知道先前已经提交了哪些写入，才能实现“精确一次性”的语义：如果流作业崩溃，则需要知道其哪些写入先前已写入表中，以便它可以从输入流中的正确偏移处开始重播后续写入。为了支持该用例，Delta Lake允许应用程序在其日志记录对象中写入带有appId和版本字段的自定义txn操作，这样该日志对象就可以用来跟踪应用程序特定的信息，例如本示例中输入流的对应偏移量。将此信息与相应的Delta添加和删除操作放置在相同的日志记录中（原子地插入到日志中），应用程序可以确保Delta Lake以原子方式添加新数据并存储其版本字段。每个应用程序可以简单地随机生成其appId来获得唯一的ID。我们在Spark Structured Streaming的Delta Lake connector中中使用此特性。&lt;/p>
&lt;h3 id="heading-7">&lt;/h3>
&lt;p>3.1.3日志检查点&lt;/p>
&lt;p>出于性能考虑，有必要定期将日志压缩到检查点中。检查点存储了直到特定日志记录ID的所有非冗余操作，以Parquet格式存储在表的日志中。某些冗余的操作是可以删除的。这些操作包括：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>对同一数据对象先执行添加操作，然后执行删除操作。可以删除添加项，因为数据对象不再是表的一部分。根据表的数据retention配置，应将删除操作保留为墓碑具体来说，客户端使用在删除操作中的时间戳来决定何时从存储中删除对象。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>同一对象的多个添加项可以被最后一个替换，因为新添加项只能添加统计信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>来自同一appId的多个txn操作可以被最新的替换，因为最新的txn操作包含其最新版本字段&lt;/p>
&lt;/li>
&lt;li>
&lt;p>changeMetadata以及协议操作可以进行合并操作以仅保留最新的元数据。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>检查点过程的最终结果是一个Parquet文件，其中包含仍在表中的每个对象的添加记录，需要保留直到retention period到期的对象删除记录，以及如txn，协议和changeMetadata等操作的少量记录。这种面向列的文件对于查询表的元数据以及基于数据统计信息查找哪些对象可能包含与选择性查询相关的数据来说是非常理想的存储格式。根据我们的经验，使用Delta Lake检查点查找对象集几乎总是比使用LIST操作和读取对象存储上的Parquet文件的Footer要快得多。&lt;/p>
&lt;p>任何客户端都可以尝试创建至指定日志记录ID的检查点，如果成功，则应将其写为对应ID的.parquet文件。例如，000003.parquet将代表直到并包括000003.json记录的检查点。默认情况下，我们的客户端每10个事务会写入一个检查点。&lt;/p>
&lt;p>最后，访问Delta Lake表的客户端需要高效地找到最后一个检查点（以及检查点之后的日志），而不需要列出_delta_log目录中的所有对象。检查点writer将会把最新的检查点ID写入_delta_log / _last_checkpoint文件中，前提是写入的检查点ID比该文件中当前的ID更大。请注意，由于云对象存储库最终的一致性问题，即使_last_checkpoint文件不是最新的也没有关系，因为客户端仍会在该文件中的ID之后搜索新的检查点。&lt;/p>
&lt;h2 id="heading-8">&lt;/h2>
&lt;p>&lt;strong>3.2 访问协议&lt;/strong>&lt;/p>
&lt;p>Delta Lake的访问协议是为了让用户能依托“对象存储”的接口实现“序列化”级别事务，尽管大部分公有云的“对象存储”只提供“最终一致性”保障。这个选择关键在于需要有一个“日志记录”对象，例如000003.json，此“日志对象”会作为客户端读取数据表的某个版本时使用的核心数据结构。读取了这个“日志对象”的内容，用户就能够从“对象存储”中定位到本张数据表中其他对象，完成后续对数据表中数据的查询，当然由于“对象存储”最终一致性，读取时可能数据对象还不可见，客户端可能需要等一个delay的小段时间。对于“写入”事务，用户需要一种机制去保障只有一个用户能创建下一个“日志记录”(比如，000003.json),这种机制可以理解为一种类似“乐观锁”的控制能力。&lt;/p>
&lt;h3 id="heading-9">&lt;/h3>
&lt;p>3.2.1 读表操作&lt;/p>
&lt;p>我们先描述Delta table的read-only读事务。读事务会安全的读到数据表的某个版本。Read-only的读事务有5个步骤：&lt;/p>
&lt;p>1.在table的log目录读取_last_checkpoint 对象，如果对象存在，读取最近一次的checkpoint ID&lt;/p>
&lt;p>2.在对象存储table的log目录中执行一次LIST操作，如果“最近一次checkpoint ID”存在，则以此ID做start key；如果它不存在，则找到最新的.parquet文件以及其后面的所有.json文件。这个操作提供了数据表从最近一次“快照”去恢复整张表所有状态所需要的所有文件清单。（需注意：因为对象存储是最终一致性语义，这个LIST操作返回的文件清单可能不连续，比如清单中有000004.json和000006.json但是没有000005.json . 这个问题Delta Lake有考虑到，客户端可以使用从表中读取的最大的ID，这里是000006.json，等待所有确实的对象可见后再完成计算）&lt;/p>
&lt;p>3.使用“快照”(如果存在)和后续的“日志记录”去重新组成数据表的状态（即，包含add records，没有相关remove records的数据对象）和这些数据对象的统计信息。Delta数据格式被涉及可以并行读取：比如，在使用Spark读取delta格式时，可以使用Spark job去并行读取.parquet的快照文件和.json的”日志记录“。&lt;/p>
&lt;p>4.使用统计信息去定位读事务的query相关的数据对象集合。&lt;/p>
&lt;p>5.可以在启动的spark cluster或其他计算集群中，并行的读取这些相关数据对象。 需注意，因为对象存储的最终一致性，一些worker节点可能读不到driver在制定执行计划后下发任务的相关数据文件，目前的设计是如果worker读不到，就等一段时间然后retry。&lt;/p>
&lt;p>我们注意到这个访问协议的每一步中都有相关的设计去规避对象存储的最终一致性。比如，客户端可能会读取到一个过期的_last_checkpoint文件，仍然可以用它的内容，通过LIST命令去定位新的“日志记录”文件清单，生产最新版本的数据表状态。这个_last_checkpoint文件主要是提供一个最新的快照ID，帮助减少LIST操作的开销。同样的，客户端能容忍在LIST最近对象清单时的不一致（比如，日志记录ID之间的gap），也能容忍在读取日志记录中的数据对象时，还不可见，通过等一等的方式去规避。&lt;/p>
&lt;h3 id="heading-10">&lt;/h3>
&lt;p>3.2.2 写事务&lt;/p>
&lt;p>一个写入数据的事务处理，一般会涉及最多5个步骤，具体有几步取决与事务中的具体操作：&lt;/p>
&lt;p>1.找到一个最近的日志记录ID，比如r，使用读事务协议的1-2步（比如，从最近的一次checkpoint ID开始往前找）.事务会读取表数据的第r个版本（按需），然后尝试去写一个r+1版本的日志记录文件。&lt;/p>
&lt;p>2.读取表数据的r版本数据，如果需要，使用读事务相同的步骤（比如，合并最新的checkpoint .parquet 和 较新的所有.json 日志记录文件，生成数据表的最新状态，然后读取数据表相关的数据对象清单）&lt;/p>
&lt;p>3.写入事务相关的数据对象到正确的数据表路径，使用GUID生成对象名。这一步可以并行化。最后这些数据对象会被最新的日志记录对象所引用。&lt;/p>
&lt;p>4.尝试去写本次写事务的日志记录到r+1版本的.json日志记录对象中，如果没有其他客户端在尝试写入这个对象（乐观锁）。这一步需要是原子的（atomic），我们稍后会探讨在不同的对象存储中如何实现原子性。如果这一步失败了，事务是要重试的；这取决于事务query的语义，在一定情况下客户端还是可以在重试中复用step3产生的数据对象们，然后把这些数据对象们写入到重试事务产生的新的.log日志记录对象中。&lt;/p>
&lt;p>5.此步可选。为r+1版本的日志记录对象，写一个新的.parquet 快照对象.(最佳实践中，默认每10条日志记录会做一次快照) 然后，在写事务完成后，更新_last_checkpoint文件内容，指向r+1的快照。&lt;/p>
&lt;p>需注意到第5步中，写一个新的.parquet 快照对象，更新_last_checkpoint文件内容，只会影响性能，如果在这一步客户端失败了并不会损害到数据完整性。比如，在生成快照对象时失败了，或者在更新_last_checkpoint文件内容时失败了，其他客户端仍然可以使用老一些的快照去读取数据表的内容。在第4步成功后，事务就算原子性的提交完成了。&lt;/p>
&lt;p>原子性的添加日志记录。在写事务协议中很明显的，步骤4，创建r+1版本的.json日志记录对象需要原子性：只能有一个客户端能成功的创建此日志记录。不幸的事，不是所有的大规模对象存储系统有put-if-absent类似的原子操作，我们针对不同的对象存储做了不同的实现去达到原子性的效果：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Google Cloud Storage 和 Azure Blob Store 都支持原子性的put-if-absent操作，所以直接使用即可&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在类似HDFS的分布式文件系统，我们使用原子的rename操作去rename临时文件到最终位置（如果最终位置文件已存在就fail）.Azure Data Lake Storage [18]也提供了文件系统API中的原子rename操作，所以我们直接使用这些系统的这些方法。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Amazon S3并没有提供原子性的“put if absent” 或者 “rename” 操作。在Databricks的部署服务中，我们使用了一个单独的轻量级协调服务去保证针对一个指定ID的日志记录，只能有一个客户端能够做添加操作。这个服务只有在写事务时才需要（读事务和非数据相关操作不涉及），所以它的load是相对较低的。在开源的Apache Spark的Delta Lake connector上，我们能保证同一个Spark driver程序（SparkContext object）的进程内部能利用in-memory的状态，在事务之间保证拿到不同的日志记录ID，即用户可以在一个单独的spark集群内针对一张Delta table做并发的操作。我们仍然提供了一个API接口，留给用户足够的自由度去实现一个自己日志存储实现类，从而达成事务操作的独立、强一致性。（LogStore）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="heading-11">&lt;/h3>
&lt;p>&lt;strong>3.3  关于隔离级别&lt;/strong>&lt;/p>
&lt;p>在遵循了Delta Lake的并发控制协议后，所有写事务都是线性化隔离级别（serializable）的，也使得事务的日志记录ID的线性增长。这遵循了写事务的提交协议，即每个日志记录ID只有一个写事务能使用。读事务是能达到snapshot isolation或者serializability的。在3.2.1节中描述的读协议只会读取数据表的一个快照，所以客户端使用这个协议就能达成snapshot isolation，但是客户端如果想达到线性化（serializable）的读取，可以发出一个“读after写”的事务，假装mock一次写事务然后再读，来达到线性化。在最佳实践中，Delta Lake 的connector实现了在内存中将每一张已访问过的表的最近“日志记录”ID做cache起来，这样客户端能“读自己所写”，即使客户端使用了snapshot isolation的读能力，也能在多次读操作时读到单调递增的数据表版本。更重要的是，Delta Lake目前只支持单表事务。基于“日志记录”的协议设计，在未来是可以被扩展到管理多张表上去的。&lt;/p>
&lt;h3 id="heading-12">&lt;/h3>
&lt;p>&lt;strong>3.4 事务频率&lt;/strong>&lt;/p>
&lt;p>Delta Lake的写事务频率受限于在写新的日志记录时，需要执行put-if-absent操作的延迟（描述与3.2.2章节）。在任何基于乐观锁的并发控制协议中，高频率的写事务都会导致事务commit失败。实际上，对象存储的写入延迟能达到上百毫秒ms，这严重限制了写事务的tps（transactions per second）。但是我们发现对于Delta Lake应用的并发来说这个并发率也够了，即使是一个相对高并行的streaming流式数据任务（打比方 Spark Streaming jobs），负责把数据导入到云存储，也可以把很多数据对象放在一个写事务当中批量提交。如果在未来，更高频的tps成为需求，我们相信去定制开发一个LogStore服务去负责事务日志管理（类似于Databricks在AWS针对S3存储做的commit服务），是能够提供更快的事务提交能力的（比如把事务日志先存储在低延迟的DBMS上，然后再异步写入对象存储）。当然，snapshot isolation隔离级别的读事务是没有竞争的，他们只需要去读对象存储中的对象即可，所以读事务的并发读是很高的，完全不受限的。&lt;/p>
&lt;h3 id="4delta中的高级功能">4.DELTA中的高级功能&lt;/h3>
&lt;p>Delta Lake的事务设计允许很多更宽范围的高阶数据管理功能，这和很多传统的分析型DBMS提供的便利能力类似。在本章，我们会探讨一些更广泛被使用的特性，以及客户的case或者说客户的痛点。&lt;/p>
&lt;h3 id="heading-13">&lt;/h3>
&lt;p>&lt;strong>4.1 时间穿梭和回滚&lt;/strong>&lt;/p>
&lt;p>数据工程师的pipeline经常会出逻辑错误，比如有时会把脏数据从外部系统导入到大数据系统中。在传统的数据湖设计方案中，很难去通过给单表做增加对象来实现undo更新语义。更多时候，一些工作比如机器学习训练是需要去针对老版本的数据做重新训练的（比如在同一份数据集上去对比 新/老的两种训练算法的效果）。在Delta Lake技术诞生前，这些问题都给Databricks的用户造成过很大的挑战，需要他们去设计很复杂的数据pipeline纠错辅助工具，或者将数据冗余多份。而有了Delta Lake后，基于它底层数据对象和事务日志的不可修改性，使得读取数据过去的历史快照变得很直接和容易，这是一个经典的MVCC实现。客户端只需要一个老的日志记录ID就能读到数据的历史版本。为了更好的帮用户实现Time travel，Delta Lake允许用户去做每张表级别的数据retention inverval配置，而且支持在sql中使用 timestamp 或者commit_id等隐藏字段等语义去帮助读取历史快照版本。客户端也能通过Delta Lake提供的API，在一次读/写操作后，获取到当下使用的commit ID日志记录。比如，我们在开源的MLflow项目中在每次ML训练任务中，使用这个API去自动记录数据表版本号，作为每次训练的元数据。用户会发现在修复数据pipeline的错误时，time travel功能会特别有用。比如，在需要修复一些用户数据时，有效的undo一个更新操作可以通过在数据表的快照上执行一条MERGE语句的SQL达成目标：&lt;/p>
&lt;p>MERGE INTO mytable target USING mytable TIMESTAMP AS OF  source ON source.userId = target.userId WHEN MATCHED THEN UPDATE SET *&lt;/p>
&lt;p>我们还开发了一个CLONE命令，它能够在数据表当下的一份快照上创建一个 copy-onwrite的新版本快照。&lt;/p>
&lt;h3 id="heading-14">&lt;/h3>
&lt;p>&lt;strong>4.2 有效的更新，删除和合并&lt;/strong>&lt;/p>
&lt;p>在企业中很多分析型的数据是需要持续更新的。比如根据GDPR[27]的数据隐私合规要求，企业需要能够有能力按要求删除一个用户相关的所有数据。即使不涉及个人隐私的数据，在某些场景下也有更新需求，比如上游数据pipeline的错误导致数据损坏就需要update去修复数据，再比如延迟到达的数据（late-arriving）也会导致需要对老数据进行更新等等。然后，一些聚合数据集也需要不断的更新聚合结果数据集（比如由数据分析时发出的针对一张表的sum query需要根据时间不断重新计算聚合值）。在传统的数据湖存储格式中，比如在S3上直接将Parquet文件放入目录下，很难在同时有并发读取的请求时去执行更新操作。即使要做，更新任务也要执行的非常小心，因为如果在更新时发生任务fail了，会留下一些“部分更新”的数据碎片。在Delta Lake中，所有这些操作都可以以事务进行运行（同时成功同时失败），在Delta log里记录（增加 or 删除）这些相关的被update的数据对象。Delta Lake支持标准的 SQL UPSERT，DELETE和MERGE语法。&lt;/p>
&lt;h3 id="heading-15">&lt;/h3>
&lt;p>&lt;strong>4.3 流式的数据导入和消费&lt;/strong>&lt;/p>
&lt;p>很多数据团队期望能使用streaming数据pipeline来实时的将数据进行ETL或者聚合操作，但基于传统的云存储是很难做到的。这些数据团队会使用一些独立的流式消息队列，比如Apache Kafka 或者 AWS Kinesis，在处理不好数据流时容易产生数据冗余，同时也给数据团队带来了很多额外的运维管理复杂度。我们在Delta Lake的设计中使用“日志记录”文件去记录事务追加的提交记录，用户可以把此日志记录当作一个message queue来看待，producer写入，consumer消费。有了递增的“日志记录”文件，用户就不需要额外再部署一套单独的消息队列服务了。这个能力由三个场景推演而来：&lt;/p>
&lt;p>写合并. 一个最简化的数据湖就是由一组对象文件组成，这使得写入数据很容易（写新的数据对象即可），但是在 写和读 的性能之间很难找到一个很好的平衡点。如果写入方想要快速的通过写小文件的方式达到快速写入数据的目的，在读取方最终会因为“过多的小文件读”和过多的“元数据”操作而变慢。相反，Delta Lake允许用户去跑一个后台Daemon来以事务的方式达成合并小文件的目标，且不影响读取方。如在3.1.2章描述，在做compact操作时将dataChange flag设置为false，如果已经读了小文件，可以让流streaming的消费者忽略这些compaction操作生成的数据文件。通过写小文件，使下游Streaming应用更快消费到新数据（延迟低，性能略差）。而其他普通的基于老版本数据的查询仍然可以很快。&lt;/p>
&lt;p>Exactly-Once 流式写入 . 写入方在日志记录对象中可以使用txn action type字段，用它来跟踪写入指定表的所有相关数据对象，从而达到“exactly-oncce”写入。总的来说，流式处理系统在写入（更新）外部存储时是需要一些机制去保证写入的幂等性的，需要幂等去避免duplicate数据写入，比如在发生写入错误后job重试时。在复写数据时，如果为每个记录设置一个唯一键（unique key），是能达到幂等效果的。或者说，将所有需要写入的记录放在一个“last version written” 事务记录里，一起成功或者一起失败。Delta Lake使用后一种模式让每个spark应用在每次事务中维护一个（appId，version）元组。比如在Spark Structured Streamingg 的Delta Lake connector中，我们用这个feature支持了所有流式计算语义的exactly-once写入（append, aggregation, upsert ）.&lt;/p>
&lt;p>有效的Log Tailing.  把Delta Lake表当作message queue的终极目标是要能让consumer能有效的找到“增量新写入”. 幸运的是，.json的日志存储格式是一系列按字典序自增ID的日志对象，这就让consumer的增量消费变的容易了：一个消费者可以在对象存储以last log ID为startkey，跑个简单的LIST操作，就能把增量新写入的数据对象找出来了。在日志记录内容中每一条的dataChange flag会允许流式streaming消费者决定是否跳过compact 或者重新整理过的数据，是否直接读新的数据文件（可能是新的小文件）.流式计算应用也能通过自己上一次成功处理完成的last record ID点位，完成stop或者restart操作 。&lt;/p>
&lt;p>将这三个feature合起来，我们发现很多用户真的可以用Delta Lake，一个搭建在对象存储上的数据格式，去实现消息队列的语义，从而完成“秒级延迟”的流式计算pipeline。而不是依赖于一个独立的消息队列服务，比如kafka。&lt;/p>
&lt;h3 id="heading-16">&lt;/h3>
&lt;p>&lt;strong>4.4 数据布局优化&lt;/strong>&lt;/p>
&lt;p>数据layout在分析类系统中对查询性能有很大的影响，特别是在很多分析query都有高度的挑剔复杂度时。因为Delta Lake支持以事务的方式去更新一张数据表，它就必须要能够支持在不影响并发的其他操作的情况下做layout的优化。比如，一个后台Daemon进程会把数据对象做compact，在这些数据对象内部重新排序，甚至去更新这些数据的统计指标、索引信息等等，且要在不影响其他客户端的前提下。我们基于事务这个优势，实现了一些数据layout优化的特性：&lt;/p>
&lt;p>OPTIMIZE Command. 用户可以针对一张表手动触发OPTIMIZE命令，这个命令可以在不影响进行中(on-going)事务的前提下进行小文件的合并，同时重新计算缺少的文件统计信息。默认情况下，这个操作的目标是把文件重新规整为每个文件1GB大小，这个值是我们的经验值，当然用户可以按自定义设置这个参数。&lt;/p>
&lt;p>Z-Ordering by Multiple Attributes.  很多数据集上跑的query都有很高的选择度，query会有很多条件。比如，一个网络安全的数据集，它的数据包含有网络中 (sourceIp, destIp, time) 这样一个三元组，在这三个维度（属性）都会有很多查询使用。如果使用Apache Hive的简单按照path/directory做分区的办法，只能在数据写入时按一部分维度（属性）做分区，但是要使用多个维度（属性）创建分区，分区数会暴涨，这在hive里是极力避免的。&lt;/p>
&lt;p>Delta Lake支持在数据表中按照一些给定的维度（属性）去重新整理记录，使用Z-order[35]技术，在指定的多个维度（属性）上都能达到相对较高的数据本地性。在指定的多维度空间上去计算Z-order曲线还是很容易计算出来的，这个技术的目标是在“经常会涉及到多个维度的查询场景”下，都能达到较好的性能，而不是偏向于某一个维度（在Section 6 的测试中有表现）。用户可以在每张表上设置自己需要的Z-order维度集合，然后跑一个OPTIMIZE命令，就可以达到把数据按Z-order整理好的目的了，用户还可以随时调整Z-order策略。Z-order技术使用了数据统计学技术，能让查询过滤更多的数据，减少读IO开销。在最佳实践中，Z-order技术的目标就是让所有的数据对象，在用户指定的几个维度下，都有一个相对小的值范围，在查询时能保证过滤掉更多的数据对象。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/0yBD9iarX0nvHAHdS1bjNgoKNYeovO77cnnkjrJxqDSsO6gXVkgw1Uic0TfDwsiclHXqfdMulXZKb11PBeVx2g9BA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1" alt="">&lt;/p>
&lt;p>图3:DESCRIBE HISTORY输出了在一张Delta标上每一次的update。&lt;/p>
&lt;p>自动优化. 在Databricks的云服务上，用户可以给一张表设置AUTO OPTIMIZE 属性，从而可以自动的去compact新写入的数据对象。&lt;/p>
&lt;p>总的来说，Delta Lake的设计也允许在数据表做update时，能够维护index和高计算消耗的统计信息。我们在这个点上开发了不少新feature。&lt;/p>
&lt;h3 id="heading-17">&lt;/h3>
&lt;p>&lt;strong>4.5 缓存&lt;/strong>&lt;/p>
&lt;p>很多云用户都会为不同的业务，跑不同的常驻的计算集群，有时候也会根据业务的负载动态伸缩集群规模。在这些集群中，使用本地磁盘将经常访问的数据做caching是一种加速query的很好的机会。比如，AWS i3机型为每个core提供一个237GB的NVME SSD，价格比同等的m5（general-purpose）实例贵个50%。在Databricks，我们在集群针对Delta Lake的数据搞了一层透明的cache处理，这个特性可以帮助访问数据&amp;amp;元数据是都提速。Caching是安全的，这是因为在Delta Lake中，data文件，log文件，checkpoint文件等等一旦写入，都是immutable不可修改的。我们在第6章会看到，使用了cache后，读性能显著的增长了。&lt;/p>
&lt;h3 id="heading-18">&lt;/h3>
&lt;p>&lt;strong>4.6 审计日志&lt;/strong>&lt;/p>
&lt;p>Delta Lake的事务日志也可以被用作审计日志，基于日志中的commitinfo记录。在Databricks，我们开发了一个“锁”机制，去防止用户在spark集群使用UDF去直接访问云对象存储，这保证了只有使用runtime引擎才能向日志记录写入commitinfo记录，从而保证了事务日志的不可变性，也就达到了可审计的目标。用户可以使用 DESCRIBE HISTORY命令去看Delta Lake表的历史版本，如Figure3图所示。在开源版本的Delta Lake中Commit information日志也是可见的。审计日志是企业级数据应用合规要求中，在数据安全要求里越来越重要的强制性要求。&lt;/p>
&lt;h3 id="heading-19">&lt;/h3>
&lt;p>&lt;strong>4.7 Schema 演变和增强&lt;/strong>&lt;/p>
&lt;p>数据源经过长时期的迭代后，通常都会有schema变更的需求，，但是这也带来了挑战，老的数据文件（old Parquet files）可能会有“过期的/错误的”schema。Delta Lake可以以事务的方式完成schema变更，如果需要甚至还可以按照最新的schema去更新底层的数据的对象（比如删除一个用户不再需要的字段）。把每次的schema变更记录保存在事务日志中并维护一个历史，可以不重写老的Paruqet数据文件（当然只能在add column 加列时）。同等重要的是，Delta的客户端要保证新写入的数据是能符合表的schema的。在有Delta Lake这种写入时check schema的机制之前，将Parquet文件写入一个directory经常会有把schema搞错的事情发生，有了这个简单的check机制就能很好的trace到问题，因为在发生schema错误时会抛出错误。&lt;/p>
&lt;h3 id="heading-20">&lt;/h3>
&lt;p>&lt;strong>4.8 Connectors to Query and ETL Engines&lt;/strong>&lt;/p>
&lt;p>Delta Lake在Spark SQL和Structured Streaming通过使用Apache Spark的data source API，提供了全能力的connector。更进一步，它目前和很多系统都提供了“只读”的集成：Apache Hive, Presto, AWS Athena, AWS Redshift, and Snowflake，用户使用这些系统都能去查询Delta table了，跑普通查询甚至用Delta table数据和其他数据源的数据做join也可以。最后，一些ETL和CDC（Change Data Capture）的工具包括Fivetran, Informatica, Qlik and Talend 都是可以写入Delta Lake的 [33, 26]。一些查询引擎的整合使用了特殊的机制，比如Hive里的symbolic links ，会生成叫symlink的manifest文件。一个symlink manifest文件本质上是一个 text file，它包含了“对象存储 or 文件系统”在对应path/directory下可见的文件列表。很多Hive兼容（Hive-compatible）的系统是能够识别这个manifest files的，通常文件叫“_symlink_format_manifest”，当去读一张表对应数据时，可以先去找目录下的这个文件，然后把文件内容里的所有paths作为本张表的数据对象清单。在Delta Lake的上下文中， manifest files的作用就是为读取方提供了一个表的静态快照（包含表的file lists）。要生成一张表的manifest files ，用户需要跑一个简单的SQL指令。然后就可以把数据作为外部表load到Presto, Athena, Redshift or Snowflake等等引擎了。在其他case里，比如Apache Hive，开源社区也有人为Hive设计了一个Delta Lake的connector。&lt;/p>
&lt;h3 id="5delta-lake-use-cases">5.DELTA LAKE USE CASES&lt;/h3>
&lt;p>Delta Lake目前被Databricks中几千个活跃用户所使用，每天使用它处理EB级的数据量，和开源社区里的其他组织一样。这些use cases跨越了很广阔的数据源和应用。Delta Lake的数据源包括：企业级的OLTP系统的Change Data Capture (CDC) logs, 应用logs, 时间序列data, 图数据, 为BI分析用的数据表格的聚合数据, 图片，machine learning（ML）的特征数据等等。在这些数据上跑的应用包括：SQL（最常见的应用类型）， BI（business intelligence） ， streaming（流计算），data science（数据科学），machine learning（机器学习） and graph analytics（图计算）。Delta Lake对大多数使用Parquet、ORC等存储格式的数据应用来说，是一个很好的补充。&lt;/p>
&lt;p>在这些use cases里，我们发现用户会使用Delta Lake来简化他们的企业级数据架构，使用云对象存储，在上面搭建“lakehouse”湖仓一体系统，同时达成数据湖和事务的能力。比如，想象一个从多数据源load数据的典型数据pipeline：从OLTP数据出来的CDC logs和设备产生的sensor data，将两个数据进行一些的ETL然后产生一些服务于数仓和数据科学家的衍生数据表（图1所示）。传统的实现需要集成很多组件，比如使用message queue（Apache Kafka）去承载实时计算的结果；使用一种数据湖存储作为长期存储；再使用一种数据仓库技术（比如Redshift）来为用户提供高速的Analytical分析类查询服务，数仓引擎可能会使用索引技术和告诉的本地磁盘（SSD）。在这些系统中都需要duplicate data，等于同一份数据多了多份拷贝，另外一个挑战是在这些系统中保证数据的一致性。而有了Delta Lake之后，上述的多种存储系统都可以被简单的“单一”云对象存储所取代即可，在上面利用好Delta Lake的ACID事务能力，streaming I/O能力 和 caching能力，这样就能得到同等的性能同时剔除数据架构上的复杂度。虽然Delta Lake不能代替上述系统的所有能力，也不能在所有场景都work的非常好（比如毫秒级的实时系统），但在大多数场景还是能满足需求的。在4.8章我们也介绍了，Delta目前和其他一些查询系统也已经有了connector集成，在后续章节我们会更详细的说一些use case。&lt;/p>
&lt;h3 id="heading-21">&lt;/h3>
&lt;p>&lt;strong>5.1 Data Engineering and ETL&lt;/strong>&lt;/p>
&lt;p>很多组织都在将ETL/ELT和数据仓库搬到云上，来减轻管理维护负担，另一边，更多的组织在将自己的业务数据（OLTP系统的交易数据）和其他数据源（web访问或IOT物联网系统）打通从而给下游的其他数据应用赋能，比如机器学习应用。这些应用都需要一个可靠且容易维护的数据工程化以及/ETL能力去处理这些数据。当这些组织将工作搬到云上后，他们都倾向于使用“云对象存储”作为数据的落地存储，这能带来存储开销的缩减，然后从这些原始数据经过计算加工，将加工后数据再导入到“更优的数仓系统”（比如拥有本地SSD存储）。Delta Lake的ACID事务能力，对UPSERT/MERGE的支持，以及time travel等特性是能够让这些公司直接基于对象存储就能“架设”数据仓库的，比如提供数据仓库常见的rollback，time travel，审计日志等能力。更多的好处是，使用Delta Lake后，避免了使用多种存储，避免了复杂数据链路的维护工作。最后，Delta Lake也同时支持SQL和Spark 编程API去写程序，让创建data pipeline更容易了。我们看到，在跨越不同行业比如（金融服务业、healthcare以及media行业）时，数据处理或者ML机器学习类的工作都在技术上都是差不多的，一旦这些公司的最基本的ETL pipeline和数据完成后，这些组织还可以进一步使用这些数据去充分挖掘价值（比如使用PySpark写一些数据科学分析）。可以在云上再开一个独立的计算集群即可，新集群也可以访问底层同一份数据，底层的基于Delta Lake的存储是共享的。还有一些组织将一部分的pipeline改为流式query（使用Spark Structured Streaming的Streaming SQL）。这些都可以通过新的云虚机（VM）来简单的跑起来，同时访问相同的底层数据。&lt;/p>
&lt;h3 id="heading-22">&lt;/h3>
&lt;p>&lt;strong>5.2 Data Warehousing and BI&lt;/strong>&lt;/p>
&lt;p>传统的数据仓库系统会使用有效的工具将ETL/ELT的功能结9合起来，来满足交互式的查询能力&lt;/p>
&lt;p>比如BI（business intelligence）。支持这些需求的核心技术能力就是使用高效的存储格式（列式存储格式），数据的访问优化比如clustering和indexing，更快的存储介质，和更可靠的查询引擎。Delta Lake能够依托云对象存储直接支撑所有的这些特性，比如列式存储、数据layout优化、min-max统计、SSD caching，所有这些都是依托了它基于事务的ACID设计。之后，为我们还发现很多Delta Lake的用户会基于他们的LakeHouse数据集去跑adhoc query和BI需求，有的直接跑SQL，也有的使用Tableau这样的BI软件。基于这些use case都是常见需求，DataBricks开发了一个新的向量化的专门为BI需求服务的执行引擎，就好像对Spark runtime的优化一样。像其他ETL的case一样，BI直接查询Delta Lake的好处是能给分析师提供更新鲜的新数据，因为数据不再需要被load到另外一个独立的数据仓库系统了。&lt;/p>
&lt;h3 id="heading-23">&lt;/h3>
&lt;p>&lt;strong>5.3 合规 &amp;amp; 重新生成数据&lt;/strong>&lt;/p>
&lt;p>传统数据湖存储格式设计初就是为了不可变数据的，但现在越来越多的国家对数据有了合规要求，比如欧盟的GDPR[27],结合业界的最佳实战来看，对企业而言，需要大家有有效的方法去delete或者correct个人用户的隐私数据。我们看到不少组织将云上的数据集转向使用Delta Lake，就是为了使用它的高效 UPSERT，MERGE 和 DELETE 能力。用户还可以使用审计日志（section4.6）功能去做数据治理。Delta Lake的time travel能力对于需要重新使用老数据的数据科学分析和机器学习场景也非常有用。我们把MLflow和Delta Lake做了整合，MLflow是一个开源的模型管理平台，也是Databricks主导的，它能够自动的记录哪个模型使用了哪个版本的数据集进行了什么训练，这样能够方便开发人员重新跑过去的训练。&lt;/p>
&lt;p>&lt;strong>5.4 Specialized Use Cases&lt;/strong>&lt;/p>
&lt;p>5.4.1 Computer System Event Data&lt;/p>
&lt;p>我们见过的使用Delta Lake的一个最大的单场景需求是“安全信息事件管理平台（SIEM）”，来自一家大型的科技公司。这家公司将一大堆的计算机系统事件记录了下来，包含：TCP和UPD的网络流，认证请求，SSH登陆日志，等等，把这些数据都导入到一张大的Delta Lake表中，数据量有PB级。很多的ETL、SQL、图分析作业 以及 机器学习任务都会使用这个数据源，按照一定的已知行为pattern去搜索一些入侵的证据（比如，怀疑一个用户的登陆事件，或者有人从一些服务器上导出了大量的数据）。这些任务中很多是流式计算任务，都是为了尽可能缩小发现问题的时间。更多的是，超过100个分析师会查询这张表数据，直接用这张Delta Lake table去调查怀疑的告警，或者去设计新的自动化监控任务。这个信息安全的case真的很有意思，因为它很容易就自动的收集了大规模的数据（每天上百TB数据），因为这些数据是需要保留很久的，它将被用来作为法庭上分析新发现的入侵方式（有时在事实发生几个月后才定义出来），因为这些数据需要按很多维度被查询。比如，如果一个分析师发现了某个服务器曾经被攻破过，她可能需要去查查在网络里从这个sourceIP地址出去的数据（看看哪些机器可能从这里被攻击了），以这台机器为destination 的IP地址（看看攻击是从哪些源头来到这台机器），需要按时间，按其他一些维度（比如，攻击者拿到的员工的access token）。为PB级的数据集维护重量级的索引结构会是一件很重的事情，所以这个组织使用了Delta Lake的ZORDER BY特性去重新组织Parquet数据对象，从而提供跨越多个维度的聚类。因为法律要求类的查询伴随的这些维度都会经常组合出现（比如，在百万级别数据中找寻1个IP address），Z-ordering 和Delta Lake本身的min/max统计合在一起，能显著的降低每个query要读取的数据对象个数。Delta Lake的 AUTO OPTIMIZE功能， time travel 和 ACID transactions也在保证数据准确性，在百级别工程师协同访问数据等方面，发挥了重要作用。&lt;/p>
&lt;h3 id="heading-24">&lt;/h3>
&lt;p>5.4.2 Bioinformatics&lt;/p>
&lt;p>生物信息是另一个我们发现Delta Lake被重度使用的领域，它被用来管理机器产生的数据。这里有很多数据源，包括DNA序列，RNA序列，电子医疗记录，还有医学设备的时间序列数据，这些数据让生物医药公司能够收集到关于病人和疾病更细节的信息。这些数据源一般会用来和公共数据集做join，比如和UI Biobank[44],他拥有序列信息和500,000个体的医疗记录。虽然传统的生物信息工具也使用过定制的数据格式，比如SAM，BAM ，VCF[34, 24]，很多组织现在都开始将数据使用数据湖存储格式比如Parquet。大数据基因组学项目[37] 先行使用了这个方法。Delta Lake更进一步的加强了生物信息的工作能力，通过帮助开启全多维分析查询（使用Z-ordering），ACID事务，和高效的UPSERT 和 MERGE。在一些case里，使用这些特性和直接使用Parquet相比快了100x倍。在2019年，Databricks和Regeneron 发布了Glow[28],一个开源的基因组学数据工具集，它使用Delta Lake作为存储。&lt;/p>
&lt;h3 id="heading-25">&lt;/h3>
&lt;p>5.4.3 Media Datasets for Machine Learning&lt;/p>
&lt;p>另一个我们看到很令人惊喜的应用是使用Delta Lake去管理多媒体数据集，比如从website上传的一批图片，用作后续的machine learning。虽然图片和其他媒体文件已经用高效的二进制格式编码好了，管理好这些百万级的对象，在对象存储中也是很有挑战的，因为每个对象只有区区几个kb大小。对象存储的LIST操作会跑上几分钟，很难并发的快速读到足够的对象，然后喂给基于GPU上跑的机器学习任务。我们看到很多组织也将这种媒体文件以二进制的记录存储在Delta table里，然后使用Delta做高速的推理查询，流式处理，和ACID事务。比如，头部的电子商务公司以及旅游公司就使用这种办法去管理用户上传的百万级别的图片。&lt;/p>
&lt;h3 id="6-性能实验">6. 性能实验&lt;/h3>
&lt;p>在这一章，我们通过一些性能实验来表现Delta Lake的特性。我们首先，(1) 分析有很大规模数量对象 or 分区的开源大数据系统的问题，带着问题去看Delta Lake使用中心化的checkpoint去做metadata和统计信息的技术设计。（2）再分析在一张大表中，当查询条件多样化时 Z-ordering的性能问题。&lt;/p>
&lt;p>最后我们还把Delta 的性能和 原生Parquet在TPC-DS数据集上做了对比，在写入场景并没有发现有明显的overhead增加。&lt;/p>
&lt;h3 id="heading-26">&lt;/h3>
&lt;p>&lt;strong>6.1 多对象or分区的影响&lt;/strong>&lt;/p>
&lt;p>Delta Lake的很多设计初心都是为了解决云对象存储的 listing和reading 对象的高延迟。这个延迟会让加载一张几千个数据文件的表 or 创建一个Hive风格的有几千个partition的表 变的很重。小文件常常会给HDFS造成问题，但是在性能这块HDFS还是要好过云对象存储的。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/0yBD9iarX0nvHAHdS1bjNgoKNYeovO77ch4lzVzSRTDnia3twCwibvlLQSSrPia8bPZdkxdO1JgfLtE5P8W5p4cXzg/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1" alt="">&lt;/p>
&lt;p>图4: 在查询有大量分区时不同系统的性能表现。未使用Delta的系统查询1million分区时太慢了，结果就没有列出来。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/0yBD9iarX0nvHAHdS1bjNgoKNYeovO77cv3eTgnE1ytiahkef1o0T2Td1WiaCn83nV516Keyqde50RAoocu1yY0MA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1" alt="">&lt;/p>
&lt;p>图5:在拥有100个对象的表中，使用4个字段“全局排序”或“zorder”能过滤掉的Parquet文件比例&lt;/p>
&lt;p>去评估海量数据对象的影响，我们使用Databricks服务，在AWS创建了16-node AWS clusters of i3.2xlarge VMs (where each VM has 8 vCPUs, 61 GB RAM and 1.9 TB SSD storage)  ，还有托管的Apache Hive和Presto。然后我们创建一张33,000,000行的数据表，但是给他分配1000到1,000,000个分区，用这种方式去衡量大规模分区时metadata的overhead，然后在这些记录上跑一个简单的sum query。我们使用Databricks Runtime提供的Spark集群去跑，也用其他的引擎比如Hive 和 Presto ，另一边底层的存储格式同时对比Delta Lake和原生Parquet。&lt;/p>
&lt;p>如图4所示，使用Delta Lake的Databricks Runtime组合在性能上有显著的性能优势，即使在没有SSD做cache的情况下。Hive使用了近一个小时才能找到1张表里的10,000个分区，1万个分区是个挺正常的数量，在给一张hive表按时间（天）分区的同时只要再来一个其他分区键就很容易达到这个规模了。Presto在读100,000分区是用了1个小时还要多。而Databricks Runtime引擎用了差不多450秒完成了100,000分区的listing操作，这很大程度上是因为我们优化了基于对象存储的LIST请求，我们把它并行化了，用spark cluster分布式的执行。&lt;/p>
&lt;p>但是，在1个million分区这个量级，Delta Lake使用了108秒，如果使用了cache on SSD去把日志记录log做cache，可以把时间压缩到只要17秒。百万级别的hive分区看上去好像不现实，但在真实世界里，PB级别的表里真的有甚至上亿级别的数据对象的，在这种数据集上跑LIST操作是很重很重的。&lt;/p>
&lt;h3 id="heading-27">&lt;/h3>
&lt;p>&lt;strong>6.2 Impact of Z-Ordering&lt;/strong>&lt;/p>
&lt;p>要解析Z-Ordering，我们就要评估在访问一张表的数据时能跳过的数据百分比，我们针对这一指标，在使用Z-ordering 和 在数据表只根据一列做partition 或者 sort 来做对比。我们先根据Section5.4.1章节的use case里，基于信息安全数据集的灵感生成一份数据，有4个fields：sourceIP，sourcePort，destIP和destPort ，这几个维度能代表一个网络流量。我们选择32-bit的IP地址和16-bit的端口统一进行随机生成，然后我们把这张数据表存储为100个Parquet对象。然后，我们根据一些query去看能跳过多少对象，这些query的条件中包含一些维度（比如 SELECT SUM(col) WHERE sourceIP = &amp;ldquo;127.0.0.1&amp;rdquo;）。&lt;/p>
&lt;p>图5展示了结果，使用了(1)一个全局排序（特别的，按这个顺序 sourceIP, sourcePort, destIP and destPort ） 和 （2）使用这4个field做Z-ordering。在全局排序下，按照source IP搜索结果是能有效的跳过很多数据的，因为可以使用Parquet对象中source IP列的 min/max统计信息（大多数query只需要读这100个Paruqet对象中的1个），但按其他filed查询是则就没有效率了，因为每个文件都包含了很多记录，这些文件里关于其他列的min/max值范围太大了，甚至逼近整张表的min/max，达不到很好的过滤效果。相反，使用这4列做一个Z-ordering，不论按哪个field去查询，都能至少过滤掉43%的Parquet数据对象，平均能过滤率能达到54%（和简单的排序比平局是25%）。&lt;/p>
&lt;p>如果有些表的数据对象比1000个更多，那Z-order就能带来更大的整体提升了。比如，在一个500TB的网络流量数据集上要按多个维度查询，按上述办法做Z-ordering后，我们在查询时能过滤掉数据表里的93%的数据对象。&lt;/p>
&lt;p>&lt;img src="https://mmbiz.qpic.cn/mmbiz_png/0yBD9iarX0nvHAHdS1bjNgoKNYeovO77cmWs46PmXwRcF2v4OhQWg6CibbnW13Wwea4o86Ep323ibQc8cXVcxChOg/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1" alt="">&lt;/p>
&lt;p>图6 ：使用不同查询引擎 +底层存储格式，在TPC-DS压力测试下的表现&lt;/p>
&lt;h3 id="heading-28">&lt;/h3>
&lt;p>&lt;strong>6.3 TPC-DS 性能测试&lt;/strong>&lt;/p>
&lt;p>要给Delta Lake在DBMS关系模型来一轮全面的性能基准测试，我们使用了TPC-DS数据集，在Databricks Runtime上来跑（分别以Delta Lake格式和原生Parquet格式存储），然后再交叉使用原生Spark和Presto来测试。每对组合都使用1个master和8个worker，跑在（ i3.2xlarge AWS VMs, which have 8 vCPUs ）机器上。我们使用TPC-DS在S3存储生成1TB的标准数据集，事实表按代理日key日期列做分区。图6展示了在不同配置下3种组合的平均耗时。我们看到Databricks Runtime和Delta Lake的组合性能是最好的。。（此处有benchmarket 的嫌疑）在这个实验中，Delta Lake在处理大规模分区的优势没有很明显的体现，这是因为整张表太小了，Delta Lake确实也在原生Parquet上做了一些加速，主要是针对benchmark中的大query做加速。Databricks Runtime的执行计划优化会比第三方的Spark服务做的更好一些（大多数基于Apache Spark2.4).&lt;/p>
&lt;h3 id="heading-29">&lt;/h3>
&lt;p>&lt;strong>6.4 写入性能&lt;/strong>&lt;/p>
&lt;p>我们同样使用Delta Lake和原生Parquet这两种格式，通过分别加载一个大的数据集，来对比Delta的统计信息是否显著的增加了写入的开销。图7分别展示了几种组合加载数据的Load时间。（Databricks, Delta Databricks, Parquet 3rd-Party Spark ， 数据集为400 GB TPC-DS store_sales table），硬件资源为（one i3.2xlarge master and eight i3.2xlarge workers ）。可以看到spark在写入Delta Lake的速度和Parquet没有差太多，这表明统计信息的收集并不会在写入数据时增加明显的overhead。&lt;/p>
&lt;p>（评：在较大的数据集上，overhead相对小，但是在小数据集，overhead就相对大了。overhead是根据query的基准SLA的一个相对值）&lt;/p>
&lt;h3 id="7-探讨--局限">7. 探讨 &amp;amp; 局限&lt;/h3>
&lt;p>从我们的经验看，Delta Lake展现出他能依托云对象存储来实现企业级数据处理所要求的ACID事务能力，能支持大规模的流式处理，批处理，和交互式查询工作负载。Delta Lake的设计是很有吸引力的，因为他在使用云存储时并不需要一个很重的中间件层服务，这也让他能够很容易被一些支持Parquet的查询引擎所直接使用。Delta Lake的ACID能力带来了很强大的管理能力和性能提升，但说实话，目前的设计还是有很多局限的，这也是未来工作的方向。&lt;/p>
&lt;p>首先，Delta Lake目前只支持单表的序列化级别的事务，因为每张表都有它自己的事务日志。如果有跨表的事务日志将能打破这个局限，但这可能会显著的增加并发乐观锁的竞争（在给日志记录文件做append时）。在高TPS的事务场景下，一个coordinator是可以承接事务log写入的，这样能解决事务直接读写对象存储。&lt;/p>
&lt;p>然后，在流式工作负载下，Delta Lake受限于云对象存储的latency。比如，使用对象存储的API很难达到ms级的流式延迟要求。另外一边看，我们发现大企业的用户一般都跑并行的任务，在使用Delta Lake去提供秒级的服务延迟在大多数场景下也是能够接受的。&lt;/p>
&lt;p>第三，Delta Lake目前不支持二级索引（只有数据对象级别的min/max统计），我们已经开始着手开发一个基于Bloom filter的index了。Delta 的ACID事务能力，允许我们以事务的方式更新这些索引。&lt;/p>
&lt;h3 id="8-相关工作">8. 相关工作&lt;/h3>
&lt;p>很多学术界的研究和工业界的项目都在思考使用云环境去做数据管理系统。比如，Branter，在基于S3开发OLTP数据库；在最终一致性的KVstore上去实现因果一致性；AWS Aruora 是一个商业的OLTP DBMS系统，它拥有存储计算分离的架构；Google BigQuery ，AWS Redshift Spectrum [39] 和 Snowflake [23] 都是OLAP的DBMS系统，他们都做到了存储计算分离，单独的计算集群都可以访问共享的云对象存储上的数据。其他一些项目，在考虑怎样自动的让DBMS引擎适应弹性、多租户的工作负载。&lt;/p>
&lt;p>Delta Lake参考了这些工作的vision，借助了广泛的云基础设施，但是有一些不同的目标。特别的看，很多云上的DBMS系统需要一个中间件层服务去桥接client端和storage层。（比如Aurora 和 Redshift都有一个frontend server来处理client端连接），这种方式增加了运维的负担（这个frontend节点需要一直保持running），需要考虑扩展性、可用性、在大规模写入数据时可能会造成问题。相反，Delta Lake允许多客户端仅仅依靠云对象存储就能独立的协调工作，不需要再依赖一个单独的服务了（当然在3.2.2章说到，在使用AWS S3时会依赖一个轻量级的日志记录存储服务），这种设计解放了用户的运维压力，同时还保证了弹性扩容读/写的能力。还有，这套架构的HA能力是和底层云对象存储的可用性相同的，在发生灾难事故时，没有什么组件需要重启 or 特殊对待。当然，这个设计能这么从容灵活，也是因为Delta Lake的目标场景天然特性：是OLAP场景，TPS很低频，但事务涉及的数据量很大，因此很适合这种乐观锁的设计。&lt;/p>
&lt;p>最接近Delta Lake设计和初衷的系统是 Apache Hudi[8] 和 Apache Iceberg[10],这两者都定义了数据格式，也都基于云对象存储实现了事务语义。这些系统没有能提供Delta Lake的所有能力，比如，其他两个系统都没有提供数据layout优化的特性（Z-Order），也没有提供把数据湖表当作streaming input 源的能力（Delta Lake的日志记录），也没有基于本地SSD做caching的Databricks runtime服务。&lt;/p>
&lt;p>还有，Hudi同时只能有一个write（类似悲观锁）。&lt;/p>
&lt;p>这些项目都和现在popular的计算引擎有结合，比如Spark 和 Presto，但都缺乏和商业数据仓库组件的connector（Redshift 和 Snowflake）【这个点应该动态发展的去看，有失偏颇】，而在Delta 我们实现了Manifest file以及一些商用的ETL tools。&lt;/p>
&lt;p>Apache Hive ACID[32] 也基于“对象存储”/“分布式文件系统”实现了事务能力，但它要依靠Hive metastore区去track每张表的状态。这会在有几百万分区的时候成为瓶颈（把底层mysql替换成兼容mysql协议的分布式NewSQL即可，比如tidb），也增加了用户的运维负担。Hive ACID 也没法做到 time travel。低延迟的基于HDFS的存储、比如HBase、Kudu，都可以在把数据写入HDFS前将很多small write做合并，但都需要一层独立的分布式文件系统或分布式服务层。在合并高性能的OLTP和OLAP负载之间还是有一条很长的距离的，这个领域也有被称为HTAP系统。这些提供通常会有一个单独的为OLTP优化的写入存储，然后有一个为OLAP优化的长期存储。在我们的实际工作中，我们非常想基于对象存储开发一个支持高TPS的并发协议，但不使用一个独立的外部存储系统。&lt;/p>
&lt;h3 id="9结论">9.结论&lt;/h3>
&lt;p>我们已经介绍了Delta Lake，一个在云对象存储上搭建的ACID的数据表存储层服务，它给数据仓库带来了很多DBMS-like系统的性能和管理数据的feature，但并没有带来太多overhead。&lt;/p>
&lt;p>它只是一种存储格式+一些客户端访问协议，这简化了维护成本，天生的highly available，也让客户端可以以 直接、高带宽的方式访问云对象存储。目前Delta Lake已经被几千家公司所使用，每天处理EB级（成千上万PB）的数据，被用来取代更复杂的基于很多数据系统柔和而成的复杂架构数仓。&lt;/p>
&lt;p>最后，Delta Lake是开源的，基于Apache 2 license at  https://delta.io.&lt;/p>
&lt;p>本文翻译自：https://databricks.com/wp-content/uploads/2020/08/p975-armbrust.pdf&lt;/p></description></item><item><title>Golang 调试</title><link>https://justice.bj.cn/post/14.language/golang/golang%E8%B0%83%E8%AF%95/</link><pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/golang%E8%B0%83%E8%AF%95/</guid><description>&lt;h1 id="golang-调试">Golang 调试&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Golang程序的调试工具包括gdb调试、go pprof性能调试工具及go gc分析工具。熟练掌握这些工具的基本用法对golang的程序开发及调试分析拥有很大的帮助。&lt;/p>
&lt;h2 id="gdb单步调试工具">GDB：单步调试工具&lt;/h2>
&lt;p>gdb可以用来作为golang的调试工具。&lt;/p>
&lt;h3 id="gdb用法">Gdb用法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#编译时，打开相关编译变量， -gcflags是给go编译器的参数，gc是go compile的意思。-N是不要优化代码，-l 是禁止内联代码。&lt;/span>
$ go build -gcflags &lt;span class="s2">&amp;#34;-N -l&amp;#34;&lt;/span> test.go
&lt;span class="c1"># 运行gdb&lt;/span>
$ gdb &lt;span class="nb">test&lt;/span>
&lt;span class="o">(&lt;/span>gdb&lt;span class="o">)&lt;/span> info files &lt;span class="c1">#查看文件&lt;/span>
&lt;span class="o">(&lt;/span>gdb&lt;span class="o">)&lt;/span> l main.main &lt;span class="c1"># list&lt;/span>
&lt;span class="o">(&lt;/span>gdb&lt;span class="o">)&lt;/span> b &lt;span class="m">10&lt;/span> &lt;span class="c1"># breakpoint 10，第10行设置断点&lt;/span>
&lt;span class="o">(&lt;/span>gdb&lt;span class="o">)&lt;/span> r &lt;span class="c1"># run&lt;/span>
&lt;span class="o">(&lt;/span>gdb&lt;span class="o">)&lt;/span> s &lt;span class="c1"># step, 单&lt;/span>
&lt;span class="o">(&lt;/span>gdb&lt;span class="o">)&lt;/span> p *b &lt;span class="c1"># print *b&lt;/span>
&lt;span class="o">(&lt;/span>gdb&lt;span class="o">)&lt;/span> n &lt;span class="c1"># next&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>gdb对golang的调试功能支持不完善，delve&lt;/p>
&lt;h2 id="pprof">PProf&lt;/h2>
&lt;p>pprof是go tool自带的性能调试工具，看用于对pprof采样数据进行分析。&lt;/p>
&lt;h3 id="获取采样数据">获取采样数据&lt;/h3>
&lt;p>要使用pprof，需要先生成采样数据，有两种使用方式可以产生pprof数据：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>通过引入&lt;code>runtime/pprof&lt;/code>包，并手动调用&lt;code>rutime.StartCPUProfile, runtimeStopCPUProfile&lt;/code>等API来获取采样数据；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过引入&lt;code>import _ &amp;quot;net/http/prprof&amp;quot;&lt;/code>方式在线使用;&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kn">import&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="c1">// 引入net/http/pprof包，该包自动注册 handler到 http server
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">_&lt;/span> &lt;span class="s">&amp;#34;net/http/pprof&amp;#34;&lt;/span> &lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">GOMAXPROCS&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">// 限制 CPU 使用数，避免过载
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">SetMutexProfileFraction&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">// 开启对锁调用的跟踪
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">SetBlockProfileRate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">// 开启对阻塞操作的跟踪
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="k">go&lt;/span> &lt;span class="kd">func&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// 启动一个 http server，以提供pprof http服务端口，服务默认在/debug/pprof下
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">http&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">ListenAndServe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;:6060&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">nil&lt;/span>&lt;span class="p">);&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">nil&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">log&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Fatal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">err&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="nx">os&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Exit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}()&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="pprof用法">pprof用法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1"># 浏览器&lt;/span>
$ curl &lt;span class="s1">&amp;#39;http://127.0.0.1:6060/debug/pprof/goroutine&amp;#39;&lt;/span> &amp;gt; /tmp/goroutine.dbg
$ go tool pprof -http&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;:8081&amp;#34;&lt;/span> /tmp/goroutine.dbg
&lt;span class="c1"># 函数调用cpu耗时&lt;/span>
$ go tool pprof http://localhost:6060/debug/pprof/profile
&lt;span class="c1"># 内存&lt;/span>
$ go tool pprof -sample_index&lt;span class="o">=&lt;/span>alloc_space &lt;span class="s2">&amp;#34;http://localhost:6060/debug/pprof/heap?gc=1&amp;amp;seconds=60&amp;#34;&lt;/span>
&lt;span class="c1"># 已分配的堆内存&lt;/span>
$ go tool pprof http://localhost:6060/debug/pprof/allocs
&lt;span class="c1"># goroutine&lt;/span>
$ go tool pprof http://localhost:6060/debug/pprof/goroutine
$ curl &lt;span class="s1">&amp;#39;http://localhost:6060/debug/goroutine?debug=1&amp;#39;&lt;/span> &amp;gt; ~/tmp/gopprof.txt
&lt;span class="c1"># 阻塞&lt;/span>
$ go tool pprof http://localhost:6060/debug/pprof/block
&lt;span class="c1"># 锁 &lt;/span>
$ go tool pprof http://localhost:6060/debug/pprof/mutex
&lt;span class="o">(&lt;/span>pprof&lt;span class="o">)&lt;/span> top &lt;span class="c1"># 查看top 前的指标&lt;/span>
&lt;span class="o">(&lt;/span>pprof&lt;span class="o">)&lt;/span> list &amp;lt;&amp;gt; &lt;span class="c1"># 查看指标对象所在源码，需设置源码目录为编译时目录&lt;/span>
&lt;span class="o">(&lt;/span>pprof&lt;span class="o">)&lt;/span> web --nodefraction&lt;span class="o">=&lt;/span>0.1 &lt;span class="o">[&lt;/span>metanode.NewInode&lt;span class="o">]&lt;/span> &lt;span class="c1"># 生成svg，在浏览其中图形化展示指标&lt;/span>
&lt;span class="o">(&lt;/span>pprof&lt;span class="o">)&lt;/span> traces &lt;span class="c1">#&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="go-tool-trace">go tool trace&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ curl &lt;span class="s1">&amp;#39;http://localhost:6060/debug/pprof/trace?seconds=5&amp;#39;&lt;/span> &amp;gt; ~/tmp/gotrace.out
$ go tool trace -http&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;:8081&amp;#34;&lt;/span> ~/tmp/gotrace.out
$ go tool trace ~/tmp/gotrace.out
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="godebuggc调试">GODEBUG：GC调试&lt;/h2>
&lt;p>GODEBUG 开启 debug 模式后，可做内存 trace 和调度器的 trace&lt;/p>
&lt;p>GODEBUG 还支持设置以下变量:&lt;/p>
&lt;ul>
&lt;li>GOGC： 改变堆增长方式 —— 设置初始的 GC 目标百分比。当新分配内存，与上一次采集后剩余的实时数据的比例达到这个百分比时，才会触发一次 GC。默认值是 GOGC=100。设置 &lt;code>GOGC=off&lt;/code> 则完全禁用垃圾收集器。&lt;/li>
&lt;li>schedtrace：设置 &lt;code>schedtrace=X&lt;/code> ,每 X 毫秒打印一次调度器状态 —— 包括调度器、处理器、线程和 goroutine&lt;/li>
&lt;/ul>
&lt;h3 id="用法">用法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1"># 输出gc&lt;/span>
$ &lt;span class="nv">GODEBUG&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">gctrace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span> go run example.go
$ &lt;span class="nv">GODEBUG&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">gctrace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span> ./go-pprof-practice &lt;span class="p">|&lt;/span> grep gc
&lt;span class="c1"># 手动触发gc&lt;/span>
$ curl -X GET &lt;span class="s2">&amp;#34;http://localhost:6060/debug/pprof/heap?gc=1&amp;#34;&lt;/span>
&lt;span class="c1"># 查看调度&lt;/span>
$ &lt;span class="nv">GODEBUG&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">schedtrace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">1000&lt;/span> ./awesomeProject
&lt;span class="c1"># 查看调度详情&lt;/span>
$ &lt;span class="nv">GODEBUG&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">scheddetail&lt;/span>&lt;span class="o">=&lt;/span>1,schedtrace&lt;span class="o">=&lt;/span>&lt;span class="m">1000&lt;/span> ./awesomeProject
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>gctrace格式&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-&amp;gt;#-&amp;gt;# MB, # MB goal, # P
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>gc#&lt;/code>：GC 执行次数的编号，每次叠加。&lt;/li>
&lt;li>&lt;code>@#s&lt;/code>：自程序启动后到当前的具体秒数。&lt;/li>
&lt;li>&lt;code>#%&lt;/code>：自程序启动以来在GC中花费的时间百分比。&lt;/li>
&lt;li>&lt;code>#+...+#&lt;/code>：GC 的标记工作共使用的 CPU 时间占总 CPU 时间的百分比。&lt;/li>
&lt;li>&lt;code>#-&amp;gt;#-&amp;gt;# MB&lt;/code>：分别表示 GC 启动时, GC 结束时, GC 活动时的堆大小.&lt;/li>
&lt;li>&lt;code>#MB goal&lt;/code>：下一次触发 GC 的内存占用阈值。&lt;/li>
&lt;li>&lt;code>#P&lt;/code>：当前使用的处理器 P 的数量。&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;p>golang调度器追踪&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ GOMAXPROCS=2 GODEBUG=schedtrace=1000 ./example
SCHED 0ms: gomaxprocs=2 idleprocs=1 threads=2 spinningthreads=0 idlethreads=0 runqueue=0 [0 0]
SCHED 1002ms: gomaxprocs=2 idleprocs=0 threads=4 spinningthreads=1 idlethreads=1 runqueue=0 [0 4]
SCHED 2002ms: gomaxprocs=2 idleprocs=0 threads=4 spinningthreads=0 idlethreads=1 runqueue=0 [4 4]
$ GOMAXPROCS=2 GODEBUG=schedtrace=1000,scheddetail=1 ./example
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>第2秒：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">2002ms : This is the trace for the 2 second mark.
gomaxprocs=2 : 2 processors are configured for this program.
threads=4 : 4 threads exist. 2 for processors and 2 for the runtime.
idlethreads=1 : 1 idle thread (3 threads running).
idleprocs=0 : 0 processors are idle (2 processors busy).
runqueue=0 : All runnable goroutines have been moved to a local run queue.
[4 4] : 4 goroutines are waiting inside each local run queue.
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>输出项&lt;/th>
&lt;th>意义&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1009ms&lt;/td>
&lt;td>自从程序开始的毫秒数&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gomaxprocs=1&lt;/td>
&lt;td>配置的处理器数(逻辑的processor，也就是Go模型中的P,会通过操作系统的线程绑定到一个物理处理器上)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>threads=3&lt;/td>
&lt;td>运行期管理的线程数，目前三个线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>idlethreads=1&lt;/td>
&lt;td>空闲的线程数,当前一个线程空闲，两个忙&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>idleprocs=0&lt;/td>
&lt;td>空闲的处理器数,当前0个空闲&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>runqueue=0&lt;/td>
&lt;td>在全局的run队列中的goroutine数，目前所有的goroutine都被移动到本地run队列&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[9]&lt;/td>
&lt;td>本地run队列中的goroutine数，目前9个goroutine在本地run队列中等待&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="堆栈track">堆栈track&lt;/h2>
&lt;p>golang程序panic后，会打印出panic时的内存堆栈信息以便于问题 分析，输出如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">1    panic: runtime error: invalid memory address or nil pointer dereference
2    [signal SIGSEGV: segmentation violation code=0x1 addr=0x30 pc=0x751ba4]
3    goroutine 58 [running]:
4    github.com/joeshaw/example.UpdateResponse(0xad3c60, 0xc420257300, 0xc4201f4200, 0x16, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
5 /go/src/github.com/joeshaw/example/resp.go:108 +0x144
6    github.com/joeshaw/example.PrefetchLoop(0xacfd60, 0xc420395480, 0x13a52453c000, 0xad3c60, 0xc420257300)
7 /go/src/github.com/joeshaw/example/resp.go:82 +0xc00
8     created by main.runServer
9 /go/src/github.com/joeshaw/example/cmd/server/server.go:100 +0x7e0
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>
&lt;p>第1行 ：panic错误提示消息，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>第2行：引发panic的UNIX信号 ，&lt;/p>
&lt;ul>
&lt;li>
&lt;p>code: UNIX &lt;code>siginfo.si_code&lt;/code>, &lt;code>0x1&lt;/code>为&lt;code>SEGV_MAPERR&lt;/code>(“address not mapped to object”) in Linux’s &lt;code>siginfo.h&lt;/code> file.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>addr: &lt;code>siginfo.si_addr&lt;/code>，030: invalid memory address, 无效内存地址;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>pc: 程序计数器, 代表panic时，程序当前运行的地址；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>第3行：panic时，goroutine 58 的状态&lt;/p>
&lt;/li>
&lt;li>
&lt;p>第4-9行: gorutine panic时的stack frame&lt;/p>
&lt;ul>
&lt;li>
&lt;p>第4行： UpdateResponse函数调用参数&lt;/p>
&lt;/li>
&lt;li>
&lt;p>第5行：所在文件行数；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>stack track函数参数遵守如下规则：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>每个参数 按函数原型参数列表从左到右按内存布局按word逐一展开，不是和原型参数个数一一对应；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果是method，receiver为最左边开始 展开；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>返回值在参数展开后展开，多返回值也按左到右顺序逐一展开；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>内建类型(int, rune,byte)按word逐个输出，不足一个word的 ，将合并成一个word；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>指针类型：输出指针地址；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>string类型：输出两个：指针地址，string长度；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>slice：输出三个 ：地址, 长度，容量；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>struct：按stuct字段顺序逐个展开；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>interface: 2个： 类型，数据指针；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>参数都未被使用或者只是在 &lt;code>fmt.Print()&lt;/code> 中未作修改使用，用&lt;code>func(...)&lt;/code>代替，内联的函数也只显示&amp;hellip; ；&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;p>golang stack track 中函数调用各种类型参数的对应的数量：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>类型名称&lt;/th>
&lt;th>参数域数量&lt;/th>
&lt;th>参数域说明&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>string&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;code>指针&lt;/code> &lt;code>长度&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>slice&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&lt;code>指针&lt;/code> &lt;code>长度&lt;/code> &lt;code>容量&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>map&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;code>指针&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>chan&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;code>指针&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>interface&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;code>类型指针&lt;/code> &lt;code>值指针&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>pointer&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;code>指针&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>func&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;code>指针&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>nil&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;code>0x0&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://guidao.github.io/go_debug.html">https://guidao.github.io/go_debug.html&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://cizixs.com/2017/09/11/profiling-golang-program/">https://cizixs.com/2017/09/11/profiling-golang-program/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.wolfogre.com/posts/go-ppof-practice/">golang pprof 实战 | Wolfogre's Blog&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://segmentfault.com/a/1190000020255157">https://segmentfault.com/a/1190000020255157&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/Brby6D7d1szUIBjcD_8kfg">https://mp.weixin.qq.com/s/Brby6D7d1szUIBjcD_8kfg&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/go-delve/delve">GitHub - go-delve/delve: Delve is a debugger for the Go programming language.&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://golang.org/doc/gdb">Debugging Go Code with GDB - The Go Programming Language&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://tonybai.com/2020/12/10/a-kind-of-thinking-about-how-to-trace-function-call-chain/">Go函数调用链跟踪的一种实现思路 | Tony Bai&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://tonybai.com/2019/04/04/notes-about-fixing-a-go-panic-problem/">记一次go panic问题的解决过程 | Tony Bai&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.orztu.com/post/golang-trace/">https://www.orztu.com/post/golang-trace/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://studygolang.com/articles/18792">Go 语言的 Stack Trace - Go语言中文网 - Golang中文社区&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://segmentfault.com/a/1190000040612732">https://segmentfault.com/a/1190000040612732&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://colobu.com/2016/04/19/Scheduler-Tracing-In-Go/">Go 调度器跟踪&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://segmentfault.com/a/1190000019736288">https://segmentfault.com/a/1190000019736288&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/google/pprof/blob/master/doc/README.md#interpreting-the-callgraph">pprof/README.md at master · google/pprof · GitHub&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.jb51.net/article/137597.htm">golang中定时器cpu使用率高的现象详析_Golang_脚本之家&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://swsmile.info/post/golang-trace/">https://swsmile.info/post/golang-trace/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://juejin.cn/post/6844903887757901831">Golang 大杀器之跟踪剖析 trace - 掘金&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/95056679">https://zhuanlan.zhihu.com/p/95056679&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.cnblogs.com/-lee/p/12718025.html">Golang 性能测试 (3) 跟踪刨析 golang trace - 搬砖程序员带你飞 - 博客园&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item></channel></rss>