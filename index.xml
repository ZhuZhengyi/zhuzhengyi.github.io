<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Justice的小站</title><link>https://justice.bj.cn/</link><description>Recent content on Justice的小站</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 22 May 2022 09:42:16 +0800</lastBuildDate><atom:link href="https://justice.bj.cn/index.xml" rel="self" type="application/rss+xml"/><item><title>Justice's Blog</title><link>https://justice.bj.cn/homepage/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/about/</guid><description>&lt;h2 id="self-introduction">Self Introduction&lt;/h2>
&lt;p>Cras ex dui, tristique a libero eget, consectetur semper ligula. Nunc augue arcu, malesuada a nisi et, molestie finibus metus. Sed lacus odio, ultricies a nisl vitae, sollicitudin tempor ipsum. Vivamus quis feugiat arcu. Sed mi nunc, efficitur quis tellus vitae, posuere mattis metus. Phasellus in mattis dui. Nullam blandit, augue non ullamcorper dapibus, lacus dui molestie massa, in iaculis purus lectus eu lectus. Duis hendrerit lacinia tellus, sit amet feugiat dolor placerat id. Aenean ac velit massa. Vivamus feugiat dui at magna viverra, ut dictum nunc rutrum. Duis eget sapien finibus, lobortis orci id, vestibulum tellus. Maecenas lobortis urna libero, quis fermentum lectus lobortis nec. Nullam laoreet volutpat libero, ac mattis magna ullamcorper quis. Duis eget ipsum eu nisi mattis cursus et vitae turpis.&lt;/p>
&lt;p>Aliquam pretium diam eget leo feugiat finibus. Donec malesuada commodo ipsum. Aenean a massa in lacus venenatis vestibulum. Duis vel sem quis elit iaculis consectetur et quis dolor. Morbi eu ipsum hendrerit, malesuada ante sed, dapibus est. Suspendisse feugiat nulla ut gravida convallis. Phasellus id massa posuere, rhoncus justo ut, porttitor dolor. Nulla ultrices malesuada egestas. Nunc fermentum tincidunt sem ac vulputate. Donec mollis sollicitudin justo eget varius. Donec ornare velit et felis blandit, id molestie sapien lobortis. Morbi eget tristique justo. Mauris posuere, nibh eu laoreet ultricies, ligula erat iaculis sapien, vel dapibus lacus libero ut diam. Etiam viverra ante felis, et scelerisque nunc pellentesque vitae. Praesent feugiat dictum molestie.&lt;/p>
&lt;h2 id="details">Details&lt;/h2>
&lt;p>Nunc pellentesque vitae:&lt;/p>
&lt;ul>
&lt;li>Morbi accumsan nibh efficitur diam molestie, non dignissim diam facilisis.&lt;/li>
&lt;li>Donec dignissim leo in mollis faucibus.&lt;/li>
&lt;li>Donec blandit lacus a pellentesque fermentum.&lt;/li>
&lt;/ul>
&lt;p>Donec mollis sollicitudin:&lt;/p>
&lt;ul>
&lt;li>Nunc dictum purus ornare purus consectetur, eu pellentesque massa ullamcorper.&lt;/li>
&lt;li>Aliquam eu leo vitae justo aliquam tincidunt.&lt;/li>
&lt;li>Fusce non massa id augue interdum feugiat sed et nulla.&lt;/li>
&lt;li>Vivamus molestie augue in tristique laoreet.&lt;/li>
&lt;/ul></description></item><item><title>Pages</title><link>https://justice.bj.cn/homepage/pages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/pages/</guid><description/></item><item><title>Experiences</title><link>https://justice.bj.cn/homepage/experiences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/experiences/</guid><description/></item><item><title>Vintage</title><link>https://justice.bj.cn/homepage/vintage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/vintage/</guid><description/></item><item><title>Blank</title><link>https://justice.bj.cn/homepage/blank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/blank/</guid><description>
&lt;div style="text-align:center">
&lt;p>Write anything you like here!&lt;/p>
&lt;/div></description></item><item><title>jzice-nvim</title><link>https://justice.bj.cn/post/70.tool/jzice-nvim/</link><pubDate>Sun, 22 May 2022 09:42:16 +0800</pubDate><guid>https://justice.bj.cn/post/70.tool/jzice-nvim/</guid><description>&lt;h1 id="jzice-nvim">jzice-nvim&lt;/h1>
&lt;h2 id="info">Info&lt;/h2>
&lt;p>Neovim lua config in one file.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/05/22-09-37-56-0814c4b860a52b0174fee92e0b62de8f7b770953.png" alt="pic1">&lt;/p>
&lt;h2 id="require">Require&lt;/h2>
&lt;ul>
&lt;li>neovim &amp;gt; 0.7.0&lt;/li>
&lt;li>git&lt;/li>
&lt;li>rg&lt;/li>
&lt;/ul>
&lt;h2 id="feature">Feature&lt;/h2>
&lt;ul>
&lt;li>plugin manager: packer&lt;/li>
&lt;li>theme: molokai&lt;/li>
&lt;li>ui: startiy + nvim-tree + symbols-outline + lualine(statusline)&lt;/li>
&lt;li>lspconfig + lsp-installer + nvim-cmp&lt;/li>
&lt;li>telescope + anyjump + lspsaga&lt;/li>
&lt;li>hop + vim-eft&lt;/li>
&lt;li>nvim-autopairs&lt;/li>
&lt;li>nvim-notify&lt;/li>
&lt;li>vim-fugitive+lazygit + gitsigns&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">1. `curl &amp;#39;https://raw.githubusercontent.com/jzice/jzice-nvim/main/lua/jzice-nvim/init.lua&amp;#39; &amp;gt; ~/.config/nvim/init.lua`
2. start nvim first to install packer auto
3. restart nvim +PackerSync
4. restart nvim
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="config">config&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-lua" data-lang="lua">&lt;span class="n">require&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;jzice-nvim&amp;#39;&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="n">setup&lt;/span>&lt;span class="p">({&lt;/span>
&lt;span class="n">theme&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;molokai&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">settings&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">--...&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="n">packer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">git&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">default_url_format&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;https://github.com/%s&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="p">})&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="plugin-list">Plugin list&lt;/h2>
&lt;ul>
&lt;li>any-jump.vim&lt;/li>
&lt;li>bufdelete.nvim&lt;/li>
&lt;li>bufferline.nvim&lt;/li>
&lt;li>cmp-buffer&lt;/li>
&lt;li>cmp-cmdline&lt;/li>
&lt;li>cmp-nvim-lsp&lt;/li>
&lt;li>cmp-nvim-lsp-signature-help&lt;/li>
&lt;li>cmp-path&lt;/li>
&lt;li>cmp-under-comparator&lt;/li>
&lt;li>cmp-vsnip&lt;/li>
&lt;li>cmp_luasnip&lt;/li>
&lt;li>Comment.nvim&lt;/li>
&lt;li>DrawIt&lt;/li>
&lt;li>friendly-snippets&lt;/li>
&lt;li>gist-vim&lt;/li>
&lt;li>git-blame.nvim&lt;/li>
&lt;li>gitsigns.nvim&lt;/li>
&lt;li>GoldenView.Vim&lt;/li>
&lt;li>goyo.vim (not loaded)&lt;/li>
&lt;li>hop.nvim&lt;/li>
&lt;li>indent-blankline.nvim&lt;/li>
&lt;li>lazygit.nvim&lt;/li>
&lt;li>leetcode.vim&lt;/li>
&lt;li>limelight.vim&lt;/li>
&lt;li>lsp_signature.nvim&lt;/li>
&lt;li>lspkind.nvim&lt;/li>
&lt;li>lspsaga.nvim&lt;/li>
&lt;li>lualine.nvim&lt;/li>
&lt;li>LuaSnip&lt;/li>
&lt;li>neoformat&lt;/li>
&lt;li>NrrwRgn&lt;/li>
&lt;li>nvim-autopairs&lt;/li>
&lt;li>nvim-cmp&lt;/li>
&lt;li>nvim-dap&lt;/li>
&lt;li>nvim-dap-go&lt;/li>
&lt;li>nvim-dap-python&lt;/li>
&lt;li>nvim-dap-ui&lt;/li>
&lt;li>nvim-dap-virtual-text&lt;/li>
&lt;li>nvim-lightbulb&lt;/li>
&lt;li>nvim-lsp-installer&lt;/li>
&lt;li>nvim-lsp-notify&lt;/li>
&lt;li>nvim-lspconfig&lt;/li>
&lt;li>nvim-notify&lt;/li>
&lt;li>nvim-tree.lua&lt;/li>
&lt;li>nvim-treesitter&lt;/li>
&lt;li>nvim-ts-context-commentstring&lt;/li>
&lt;li>nvim-ts-rainbow&lt;/li>
&lt;li>nvim-web-devicons&lt;/li>
&lt;li>orgmode&lt;/li>
&lt;li>packer.nvim (not loaded)&lt;/li>
&lt;li>plenary.nvim&lt;/li>
&lt;li>salt-vim (not loaded)&lt;/li>
&lt;li>symbols-outline.nvim&lt;/li>
&lt;li>telescope-symbols.nvim&lt;/li>
&lt;li>telescope.nvim&lt;/li>
&lt;li>todo-comments.nvim&lt;/li>
&lt;li>undotree&lt;/li>
&lt;li>vim-arsync&lt;/li>
&lt;li>vim-better-default&lt;/li>
&lt;li>vim-choosewin&lt;/li>
&lt;li>vim-colorschemes&lt;/li>
&lt;li>vim-dispatch&lt;/li>
&lt;li>vim-easy-align&lt;/li>
&lt;li>vim-eft&lt;/li>
&lt;li>vim-expand-region&lt;/li>
&lt;li>vim-floaterm&lt;/li>
&lt;li>vim-fugitive&lt;/li>
&lt;li>vim-hardtime&lt;/li>
&lt;li>Vim-Jinja2-Syntax&lt;/li>
&lt;li>vim-matchup&lt;/li>
&lt;li>vim-repeat&lt;/li>
&lt;li>vim-rooter&lt;/li>
&lt;li>vim-startify&lt;/li>
&lt;li>vim-surround&lt;/li>
&lt;li>vim-translator&lt;/li>
&lt;li>vim-visual-multi&lt;/li>
&lt;li>vim-vsnip&lt;/li>
&lt;li>vim-zenroom2&lt;/li>
&lt;li>VimVLanguage&lt;/li>
&lt;li>vimwiki&lt;/li>
&lt;li>vista.vim&lt;/li>
&lt;li>which-key.nvim&lt;/li>
&lt;/ul></description></item><item><title>Accumulo</title><link>https://justice.bj.cn/post/30.architech/accumulo/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/accumulo/</guid><description>&lt;h1 id="accumulo">Accumulo&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>&lt;strong>Apache Accumulo&lt;/strong> 由 NSA 开源一个可靠、可伸缩、高性能的排序分布式的 Key-Value 数据库。基于单元访问控制以及可定制的服务器端处理。Accumulo 使用 Google BigTable 设计思路，基于 Apache Hadoop、Zookeeper 和 Thrift 构建。它与 HBase 很像，但也有不少创新点，比如基于 cell 的访问控制，称为 iterator 的服务器端编程机制，可以在整个流程中对各种函数编码。Accumulo 设有自动负载平衡和分区，数据压缩和细粒度的安全标签。&lt;/p>
&lt;h2 id="特性">特性&lt;/h2>
&lt;ul>
&lt;li>BigTable 的复制品，也是跑在 Hadoop 的上层；&lt;/li>
&lt;li>单元级安全保证；&lt;/li>
&lt;li>允许使用比内存容量更大的数据列；&lt;/li>
&lt;li>通过 C++ 的 STL 可保持数据从 JAVA 环境的内存映射出来；&lt;/li>
&lt;li>使用 Hadoop 的 Map/reduce 模型；&lt;/li>
&lt;li>支持在服务器端编程；&lt;/li>
&lt;li>支持 multi-volume；&lt;/li>
&lt;/ul>
&lt;h2 id="和-hbase-对比">和 HBase 对比&lt;/h2>
&lt;ul>
&lt;li>安全性方面都支持 cell 级别的安全控制；&lt;/li>
&lt;li>hbase 使用 coprocessor，accumulo 使用的 iterator 来提供服务端定制功能；&lt;/li>
&lt;li>hbase 可跨数据中心复制，对灾难的恢复支持更好；&lt;/li>
&lt;li>一致性模型：hbase 使用的日志复制，accumulo 使用的 mvcc；&lt;/li>
&lt;li>accumulo 可支持附加索引，hbase 只支持 row key 索引；&lt;/li>
&lt;li>accumulo 的 cf 不用事先制定，hbase 需要事先制定；&lt;/li>
&lt;li>accumulo 支持 locality group，hbase 不支持；&lt;/li>
&lt;li>accumulo 支持多 cf，hbase 的 cf 尽量少；&lt;/li>
&lt;/ul>
&lt;h2 id="bigtable-vs-accumulo-vs-hbase">BigTable vs Accumulo vs HBase&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Bigtable&lt;/th>
&lt;th style="text-align:left">Accumulo&lt;/th>
&lt;th style="text-align:left">Hbase&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">Tablet&lt;/td>
&lt;td style="text-align:left">Tablet&lt;/td>
&lt;td style="text-align:left">Region&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Tablet Server&lt;/td>
&lt;td style="text-align:left">Tablet Server&lt;/td>
&lt;td style="text-align:left">Region Server&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Minor Compaction&lt;/td>
&lt;td style="text-align:left">Minor Compaction&lt;/td>
&lt;td style="text-align:left">Flush&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Merging Compaction&lt;/td>
&lt;td style="text-align:left">Major Compaction&lt;/td>
&lt;td style="text-align:left">Minor Compaction&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Major Compaction&lt;/td>
&lt;td style="text-align:left">(Full) Majro Compaction&lt;/td>
&lt;td style="text-align:left">Major Compaction&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Commit Log&lt;/td>
&lt;td style="text-align:left">WAL&lt;/td>
&lt;td style="text-align:left">WAL&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">GFS&lt;/td>
&lt;td style="text-align:left">HDFS&lt;/td>
&lt;td style="text-align:left">HDFS&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">MemTable&lt;/td>
&lt;td style="text-align:left">MemTable&lt;/td>
&lt;td style="text-align:left">MemStore&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">SSTable&lt;/td>
&lt;td style="text-align:left">RFile&lt;/td>
&lt;td style="text-align:left">HFile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Chubby&lt;/td>
&lt;td style="text-align:left">ZooKeeper&lt;/td>
&lt;td style="text-align:left">ZooKeeper&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">MapReduce&lt;/td>
&lt;td style="text-align:left">Hadoop MapReduce&lt;/td>
&lt;td style="text-align:left">Hadoop MapReduce&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="应用生态">应用生态&lt;/h2>
&lt;p>Accumulo 最早由 NSA 2007 年开始开发，于 2011 年 9 月提交 Apache 基金会成为开源项目，Accumulo 数据库系统是 NSA 架构的核心（PRISM 棱镜项目的核心），大多数 NSA 的关键分析应用都运行在 Accumulo 上。NSA 开发 Accumulo 的工程师 2012 年离开 NSA，创办了基于 accumulo 的网络安全软件公司 Sqrrl，并于 2017 年 12 月被 Amazon 收购。&lt;/p>
&lt;p>Accumulo 基于 Hadoop 生态，是 bigtable 的一种安全增加实现，因此很适合用于政府及大公司的大规模数据分析中。到 2014 年，已经有几十家不同类型的美国企业安装了 Accumulo 技术系统，其中，美国 20 强企业中已有 3 家安装，50 强企业中有 5 家安装，还有不少企业已表示对此有兴趣。国内公司使用的 accumulo 较少；&lt;/p>
&lt;p>Accumulo 和 hbase 的重合度较高，彼此基本可以相互替代。想较于 hbase，其社区活跃度较低，文档较少，github： stark:384, fork:205 (hbase: star:2K, fork 1.5K )；&lt;/p>
&lt;h2 id="使用场景">使用场景&lt;/h2>
&lt;p>Accumulo 源于 NSA，因此很适用用于构建安全、实时的大数据应用系统，包括[^1]：&lt;/p>
&lt;ul>
&lt;li>实时检测分析；&lt;/li>
&lt;li>图数据；&lt;/li>
&lt;li>物联网应用；&lt;/li>
&lt;li>Sessionization；&lt;/li>
&lt;/ul>
&lt;h2 id="典型应用">典型应用&lt;/h2>
&lt;ul>
&lt;li>Sqrrl 威胁追踪平台：基于 accumulo 的可靠、安全、 多租户、 近实时数据分析系统，支持机构对几十 PB 级的数据分析，被很多美国政府和军方机构使用。&lt;/li>
&lt;li>Apache Fluo： Twitter  &lt;a href="https://research.google.com/pubs/pub36726.html">Google Percolator&lt;/a>的开源实现，允许用户对存储在  &lt;a href="https://www.oschina.net/p/accumulo">Apache Accumulo&lt;/a>  中的大型数据集进行增量更新，而无需重新处理所有的数据。与批处理和流处理框架不同的是，Fluo 提供了更低的延迟，并且可以在极大的数据集上运行。在将新数据与现有数据相结合时，与批处理框架（例如 Spark，MapReduce）相比，Fluo 可明显减少延迟。其增量更新是使用事务实现的，允许数千个更新同时发生而不会破坏数据。&lt;/li>
&lt;/ul>
&lt;h2 id="架构">架构&lt;/h2>
&lt;p>一个典型的 Accumulo 系统包括一套 ZK 系统，多个 client，多个 TabletServers，一台 master 服务器，一个或多个 gc 收集进程，若干 monitor 进程，一个或多个 Tracer 进程。底层数据存储于 hadoop 的 hdfs 中。&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-38-45-image-20180626155114401.png" alt="image-20180626155114401">&lt;/p>
&lt;p>组件包括：&lt;/p>
&lt;ul>
&lt;li>Client：Accumulo includes a client library that is linked to every application. The client library contains logic for finding servers managing a particular tablet, and communicating with TabletServers to write and retrieve key-value pairs.&lt;/li>
&lt;li>zookeeper：检测进程的存活、任务的协调、灾备和配置的存储；&lt;/li>
&lt;li>Master：主服务，主要保存元数据的存储，分区分配，动态迁移及表操作；&lt;/li>
&lt;li>Tablet Server：提供数据读写的入口；&lt;/li>
&lt;li>Garbage Collector：对 RFile 进行合并清理；&lt;/li>
&lt;li>Tracer：追踪组件。支持分布式时间 API；&lt;/li>
&lt;li>Monitor：提供实例状态健康监控信息；&lt;/li>
&lt;li>hdfs：用于数据存储；&lt;/li>
&lt;/ul>
&lt;h2 id="数据模型data-model">数据模型(Data Model)&lt;/h2>
&lt;p>Accumulo 提供比简单键值存储更丰富的数据模型，但不是完全关系数据库。数据表示为键值对，其中键和值由以下元素组成：&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-38-52-image-20180625120614505.png" alt="image-20180625120614505">&lt;/p>
&lt;p>Key 和 Value 的所有元素都以字节数组表示，除了 Timestamp，它是一个 Long。 Accumulo 按照元素排序键，按字典顺序升序排列。时间戳按降序排列，以便相同 Key 的更高版本首先出现在顺序扫描中。表格由一组排序的键值对组成。&lt;/p>
&lt;h2 id="数据管理">数据管理&lt;/h2>
&lt;p>Accumulo 数据存储在表中，划分成多个 tablet。tablet 基于行边界进行划分，一行的所有列数据都在同一个 tablet 中。Master 将 tablet 分配到一个 Tablet Sever 中。&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-38-59-image-20180625122144641.png" alt="image-20180625122144641">&lt;/p>
&lt;h2 id="相关图数据库">相关图数据库&lt;/h2>
&lt;h3 id="gaffer">Gaffer&lt;/h3>
&lt;ul>
&lt;li>Gaffer 是一个图形数据库框架。&lt;/li>
&lt;li>它允许在节点和边上存储包含丰富属性的非常大的图。有多种存储选项可供选择，包括 Accumulo，Hbase 和 Parquet。（Gaffer is a graph database framework. It allows the storage of very large graphs containing rich properties on the nodes and edges. Several storage options are available, including Accumulo, Hbase and Parquet.）&lt;/li>
&lt;li>最新版本：1.5.2（2018-6-7），社区活跃度较高（github：start 1419，fork：302）&lt;/li>
&lt;li>&lt;a href="https://github.com/gchq/Gaffer">https://github.com/gchq/Gaffer&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>特性&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>巨大节点/边上的快速查询；&lt;/li>
&lt;li>快速持续摄取数据；&lt;/li>
&lt;li>边和节点上存储任意 Java 对象；&lt;/li>
&lt;li>内在提供的自动，可配置的聚合统计属性（比如：count，histograms，sketches）&lt;/li>
&lt;li>丰富的时间汇总、数据过滤和转换功能；&lt;/li>
&lt;li>良好的数据访问控制；&lt;/li>
&lt;li>查询支持 hook ；&lt;/li>
&lt;li>自动、基于规则的数据删除（用于过期数据删除）；&lt;/li>
&lt;li>使用 spark 提供更快速、灵活的数据分析；&lt;/li>
&lt;li>REST API&lt;/li>
&lt;/ul>
&lt;h3 id="graphulo">Graphulo&lt;/h3>
&lt;ul>
&lt;li>MIT 开源项目；&lt;/li>
&lt;li>Apache Accumulo 数据库的 Java 库工具，用来支持数据库内的图算法分析；&lt;/li>
&lt;li>提供服务器端稀疏矩阵数学原语，支持更高级别的图算法和分析。&lt;/li>
&lt;li>&lt;a href="https://github.com/Accla/graphulo/">https://github.com/Accla/graphulo/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="lumify">lumify&lt;/h3>
&lt;ul>
&lt;li>基于 accumulo 的开源大数据集成、分析、可视化平台；&lt;/li>
&lt;li>&lt;a href="http://www.altamiracorp.com/index.php/lumify/">http://www.altamiracorp.com/index.php/lumify/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="accumulograph">AccumuloGraph&lt;/h3>
&lt;p>以[Apache Accumulo]作为后端的 TinkerPop 图数据库 Blueprints Api 的实现，最新版本 0.2.1，已停更；&lt;/p>
&lt;h2 id="关键流程">关键流程&lt;/h2>
&lt;h3 id="写流程">写流程&lt;/h3>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-39-05-image-20180626144601503.png" alt="image-20180626144601503">&lt;/p>
&lt;ol>
&lt;li>写 Memory Map；&lt;/li>
&lt;li>写 WAL;&lt;/li>
&lt;li>写返回；&lt;/li>
&lt;/ol>
&lt;h3 id="读流程">读流程&lt;/h3>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-39-13-image-20180626144644956.png" alt="image-20180626144644956">&lt;/p>
&lt;h2 id="性能对比accumulo-vs-hbase">性能对比（Accumulo vs HBase）&lt;/h2>
&lt;p>&lt;a href="http://accumulosummit.com/2015/program/talks/hdfs-short-circuit-local-read-performance-benchmarking-with-apache-accumulo-and-apache-hbase/">HDFS Short Circuit Local Read Performance Benchmarking with Apache Accumulo and Apache HBase（2015 accumulo summit ）&lt;/a>&lt;/p>
&lt;h3 id="吞吐量">吞吐量&lt;/h3>
&lt;ul>
&lt;li>读&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-39-18-image-20180627182851723.png" alt="image-20180627182851723">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>写&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-39-24-299541F8-59F2-48CC-9FAA-427A09F9274D.jpeg" alt="299541F8-59F2-48CC-9FAA-427A09F9274D">&lt;/p>
&lt;p>accumulo 支持 bigtable 的 locality group 特性，读写性能受 column 的数量影响较小，hbase 在列较少时读写性能优于 accumulo，但当列增大时，读写性能均有下降&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="延迟">延迟&lt;/h3>
&lt;ul>
&lt;li>accumulo&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-39-30-image-20180627175550283.png" alt="image-20180627175550283">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>hbase&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-39-37-image-20180627175718775.png" alt="image-20180627175718775">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="快速入门">快速入门&lt;/h2>
&lt;h3 id="安装">安装&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ wget http://mirrors.shu.edu.cn/apache/accumulo/1.9.1/accumulo-1.9.1-bin.tar.gz
$ &lt;span class="nb">cd&lt;/span> /export/servers/
$ tar xf accumulo-1.9.1-bin.tar.gz
$ &lt;span class="nb">cd&lt;/span> accumulo-1.9.1
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="配置">配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ bin/bootstrap_config.sh
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>The agency needed a scalable, secure database with which to store and analyze the never-ending stream of data it collects as part of its mandate “&lt;a href="http://www.fas.org/irp/congress/1999_hr/99-07-01mcnamara.htm">to understand the secret communications of our foreign adversaries&lt;/a>.1” BigTable was the best database it could find to meet its requirements, but even it lacked cell-level security. As such, engineers at the NSA developed and natively incorporated cell-level security capabilities into its reverse-engineered version of BigTable, and Accumulo was born.&lt;/li>
&lt;li>&lt;a href="http://bigdata-guide.blogspot.com/2014/01/hbase-versus-cassandra-versus-accumulo.html">http://bigdata-guide.blogspot.com/2014/01/hbase-versus-cassandra-versus-accumulo.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/apache/accumulo-wikisearch">https://github.com/apache/accumulo-wikisearch&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.pdl.cmu.edu/SDI/2013/slides/big_graph_nsa_rd_2013_56002v1.pdf">http://www.pdl.cmu.edu/SDI/2013/slides/big_graph_nsa_rd_2013_56002v1.pdf&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://quabase.sei.cmu.edu/mediawiki/index.php/Accumulo_Data_Model_Features">https://quabase.sei.cmu.edu/mediawiki/index.php/Accumulo_Data_Model_Features&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://quabase.sei.cmu.edu/mediawiki/index.php/Accumulo">https://quabase.sei.cmu.edu/mediawiki/index.php/Accumulo&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://arstechnica.com/information-technology/2013/06/what-the-nsa-can-do-with-big-data/2/">https://arstechnica.com/information-technology/2013/06/what-the-nsa-can-do-with-big-data/2/&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://accumulosummit.com/2015/program/talks/hdfs-short-circuit-local-read-performance-benchmarking-with-apache-accumulo-and-apache-hbase/">http://accumulosummit.com/2015/program/talks/hdfs-short-circuit-local-read-performance-benchmarking-with-apache-accumulo-and-apache-hbase/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.tencent.com/developer/article/1063206">https://cloud.tencent.com/developer/article/1063206&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gigaom.com/2013/06/07/under-the-covers-of-the-nsas-big-data-effort/">https://gigaom.com/2013/06/07/under-the-covers-of-the-nsas-big-data-effort/&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.cena.com.cn/ia/20140919/56653.html">http://www.cena.com.cn/ia/20140919/56653.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.cbdio.com/BigData/2016-09/01/content_5199203.htm">http://www.cbdio.com/BigData/2016-09/01/content_5199203.htm&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.openfoundry.org/tw/foss-news/8453-nas-proposes-security-nosql-database-accumulo?tmpl=component&amp;amp;print=1&amp;amp;layout=default&amp;amp;page=">NSA 向 Apache 提交安全的 NoSQL 資料庫&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.ippon.tech/use-cassandra-mongodb-hbase-accumulo-mysql/">https://blog.ippon.tech/use-cassandra-mongodb-hbase-accumulo-mysql/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cloudera.com/products/open-source/apache-hadoop/apache-accumulo.htmlh">https://www.cloudera.com/products/open-source/apache-hadoop/apache-accumulo.htmlh&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://wikibon.org/blog/breaking-analysis-accumulo-why-the-world-needs-another-nosql-database/">http://wikibon.org/blog/breaking-analysis-accumulo-why-the-world-needs-another-nosql-database/&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Alluxio</title><link>https://justice.bj.cn/post/30.architech/alluxio/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/alluxio/</guid><description>&lt;h1 id="alluxio">Alluxio&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Alluxio是一个开源的基于内存的分布式存储系统, 为计算框架和存储系统构建了桥梁，使应用程序能够通过一个公共接口连接到许多存储系统。 项目源自 UC Berkeley 的 &lt;a href="https://amplab.cs.berkeley.edu/software/">AMPLab&lt;/a>（见&lt;a href="https://www.alluxio.org/resources/white-papers">论文&lt;/a>）&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-47-16-image-20190515093053597.png" alt="image-20190515093053597">&lt;/p>
&lt;h2 id="特点">特点&lt;/h2>
&lt;ul>
&lt;li>分布式共享缓存&lt;/li>
&lt;li>可插拔存储&lt;/li>
&lt;li>存储分层&lt;/li>
&lt;li>统一命名空间&lt;/li>
&lt;li>Hadoop兼容&lt;/li>
&lt;li>多种回收策略&lt;/li>
&lt;li>支持fuse&lt;/li>
&lt;li>支持kv&lt;/li>
&lt;/ul>
&lt;h2 id="架构">架构&lt;/h2>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-47-09-image-20190515113141895.png" alt="image-20190515113141895">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>master&lt;/strong>：负责监控各个Worker以及管理全局的文件系统元数据，比如文件系统树等&lt;/li>
&lt;li>&lt;strong>worker&lt;/strong>：负责管理本节点数据存储服务（本地的MEM、SSD和HDD）&lt;/li>
&lt;li>&lt;strong>client&lt;/strong>：向用户和应用提供访问接口，以及向Master和Worker发送请求&lt;/li>
&lt;li>&lt;strong>ufs&lt;/strong>：定期备份数据&lt;/li>
&lt;/ul>
&lt;h2 id="ha">HA&lt;/h2>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-47-01-image-20190515160825686.png" alt="image-20190515160825686">&lt;/p>
&lt;h2 id="使用场景">使用场景&lt;/h2>
&lt;ul>
&lt;li>分层存储：提供MEM-SSD-HDD 分层存储；&lt;/li>
&lt;li>多存储系统聚合：Alluxio支持不同的底层存储，并提供统一的接口。例如GlusterFS、(secure) HDFS、NFS、Amazon S3、AliyunOSS、OpenStack Swift、Google Cloud Storage。&lt;/li>
&lt;li>Hadoop生态缓存加速：alluxio能和hadoop很好兼容，直接替换hdfs接口，为hadoop生态提供缓存加速功能（具体加速效果和具体业务有关）；&lt;/li>
&lt;li>计算层需要反复访问远程（比如在云端，或跨机房）的数据；&lt;/li>
&lt;li>计算层需要同时访问多个独立的持久化数据源（比如同时访问S3和HDFS中的数据）；&lt;/li>
&lt;li>多个独立的大数据应用（比如不同的Spark Job）需要高速有效的共享数据；&lt;/li>
&lt;li>当计算层有着较为严重的内存资源、以及JVM GC压力，或者较高的任务失败率时，Alluxio作为输入输出数据的Off heap存储可以极大缓解这一压力，并使计算消耗的时间和资源更可控可预测。&lt;/li>
&lt;/ul>
&lt;h2 id="配置">配置&lt;/h2>
&lt;ul>
&lt;li>分层存储&lt;/li>
&lt;/ul>
&lt;p>$ALLUXIO_HOME/conf/alluxio-site.conf&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">alluxio.worker.tieredstore.levels&lt;span class="o">=&lt;/span>&lt;span class="m">2&lt;/span>
alluxio.worker.tieredstore.level0.alias&lt;span class="o">=&lt;/span>MEM
alluxio.worker.tieredstore.level0.dirs.path&lt;span class="o">=&lt;/span>/mnt/ramdisk
alluxio.worker.tieredstore.level0.dirs.quota&lt;span class="o">=&lt;/span>100GB
alluxio.worker.tieredstore.level0.watermark.high.ratio&lt;span class="o">=&lt;/span>0.9
alluxio.worker.tieredstore.level0.watermark.low.ratio&lt;span class="o">=&lt;/span>0.7
alluxio.worker.tieredstore.level1.alias&lt;span class="o">=&lt;/span>HDD
alluxio.worker.tieredstore.level1.dirs.path&lt;span class="o">=&lt;/span>/mnt/hdd1,/mnt/hdd2,/mnt/hdd3
alluxio.worker.tieredstore.level1.dirs.quota&lt;span class="o">=&lt;/span>2TB,5TB,500GB
alluxio.worker.tieredstore.level1.watermark.high.ratio&lt;span class="o">=&lt;/span>0.9
alluxio.worker.tieredstore.level1.watermark.low.ratio&lt;span class="o">=&lt;/span>0.7
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="数据读写">数据读写&lt;/h2>
&lt;h3 id="读">读&lt;/h3>
&lt;ul>
&lt;li>缓存命中
&lt;ul>
&lt;li>本地缓存命中：一旦客户端发现访问的数据在本地存在，则会直接通过一种“短路读”的方式，直接访问本地文件系统进行访问，从而绕开TCP网络传输过程。&lt;/li>
&lt;li>远程缓存命中：直接读取远程节点上的缓存，同时为了以后潜在的读取访问操作，将远程缓存进行一个拷贝在发起请求的worker节点上。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缓存非命中：worker会读取底层文件系统，然后加到内存里，方便下次缓存的命中。
&lt;ul>
&lt;li>Partial Caching：&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="写">写&lt;/h3>
&lt;ul>
&lt;li>不持久化：直接更新到内存，可能因为机器crash导致数据丢失。&lt;/li>
&lt;li>持久化
&lt;ul>
&lt;li>同步持久化&lt;/li>
&lt;li>异步持久化&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://blog.csdn.net/Androidlushangderen/article/details/81142285">https://blog.csdn.net/Androidlushangderen/article/details/81142285&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Anna</title><link>https://justice.bj.cn/post/30.architech/anna/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/anna/</guid><description>&lt;h1 id="anna">Anna&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Anna是伯克利 RISE 实验室推出了KV存储数据库，提供了惊人的存取速度、超强的伸缩性和史无前例的一致性保证。anna基于无协调 actor 模型，每个 actor 对应一个线程，对任何一个共享状态都有自己的一份私有拷贝，并通过异步广播将更新通知给其他 actor。在多核服务器上，这种模型比传统的共享内存模型的性能要高出一个数量级。&lt;/p>
&lt;h2 id="特点">特点&lt;/h2>
&lt;p>&lt;a href="http://db.cs.berkeley.edu/jmh/papers/anna_ieee18.pdf">Anna&lt;/a> 的key和节点的分布也是一致性哈希。采用 &lt;a href="http://publicatio.bibl.u-szeged.hu/1529/1/gossip11.pdf">gossip&lt;/a> 算法来处理actor的容灾和扩缩容。按文中的意思似乎数据分片的同步也采用的是 &lt;a href="http://publicatio.bibl.u-szeged.hu/1529/1/gossip11.pdf">gossip&lt;/a> 。不过在这一点上 &lt;a href="http://publicatio.bibl.u-szeged.hu/1529/1/gossip11.pdf">gossip&lt;/a> 对分布式系统的局部分片扩容天生是比 &lt;a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos&lt;/a> 和 &lt;a href="https://raft.github.io/">Raft&lt;/a> 要好很多。&lt;/p>
&lt;h2 id="架构">架构&lt;/h2>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-47-31-image-20190528100256465.png" alt="image-20190528100256465">&lt;/p>
&lt;p>Anna 服务器由一系列独立的线程组成，每个线程运行无协调的 actor。每个线程对应一个 CPU 核心，线程数量不超过 CPU 的总核数。客户端代理负责将远程请求分发给 actor，每个 actor 都有一个私有的哈希表，这些哈希表存放在共享内存中。线程间的变更通过内存广播进行交换，而服务器间的变更则通过 protobuf 进行交换。&lt;/p>
&lt;p>这种线程和 CPU 核心一对一的模型避免了上下文切换开销。actor 之间不共享键值状态，通过一致性哈希对键空间进行分区，并使用多主复制机制在 actor 之间复制数据分区，而且复制系数是可配置的。actor 基于时间戳将键的更新通知给其他 actor 副本，每个 actor 有自己的私有状态，这个状态保存在一个叫作“格子”的数据结构中，确保在消息发生延迟、重排或重复时仍然能够保证一致性。&lt;/p>
&lt;h2 id="性能测评">性能测评&lt;/h2>
&lt;ul>
&lt;li>Anna 与 TBB、Masstree 和 Ideal&lt;/li>
&lt;li>Anna 与Redis&lt;/li>
&lt;li>Anna 与 Cassandra&lt;/li>
&lt;/ul>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/3WmGpZkEuSz-ox_2CPCsqg">https://mp.weixin.qq.com/s/3WmGpZkEuSz-ox_2CPCsqg&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/ucbrise/anna">https://github.com/ucbrise/anna&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://juejin.im/entry/5aaa708b51882555627d04b4">https://juejin.im/entry/5aaa708b51882555627d04b4&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://db.cs.berkeley.edu/jmh/papers/anna_ieee18.pdf">http://db.cs.berkeley.edu/jmh/papers/anna_ieee18.pdf&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>apache arrow</title><link>https://justice.bj.cn/post/30.architech/arrow/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/arrow/</guid><description>&lt;h2 id="apache-arrow">apache arrow&lt;/h2>
&lt;h3 id="简介">简介&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Apache Arrow 是一种基于内存的列式数据格式；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为了解决系统到系统之间的数据传输问题，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>2016 年 2 月 Arrow 被提升为 Apache 的顶级项目。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>和protobuf相比，protobuf主要是序列化structured data，有很多的键值对和非常深的nested structure。arrow序列化的对象主要还是表格状数据。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="主要技术">主要技术&lt;/h3>
&lt;ul>
&lt;li>适配器模式&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-48-18-image-20190513185116005.png" alt="image-20190513185116005">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>列式存储&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-09-48-27-image-20190513185147232.png" alt="image-20190513185147232">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>SIMD&lt;/p>
&lt;p>即单指令流多数据流（SingleInstruction Multiple Data），是一种采用一个控制器来控制多个处理器，同时对一组数据（又称“数据向量”）中的每一个分别执行相同的操作从而实现空间上的并行性的技术。在微处理器中，单指令流多数据流技术则是一个控制器控制多个平行的处理微元。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>对于 Apache Arrow 的期望：&lt;/p>
&lt;ul>
&lt;li>列式存储：大数据系统几乎都是列式存储的，类似于 Apache Parquet 这样的列式数据存储技术自从诞生起就是大家的期望。&lt;/li>
&lt;li>内存式：SAP HANA 是第一个利用内存加速分析流程的组件，随着 Apache Spark 的出现，进一步提升了利用内存加速流程的技术可能性落地。&lt;/li>
&lt;li>复杂数据和动态模式：当我们通过继承和内部数据结构呈现数据的时候，一开始有点麻烦，后来就有了 JSON 和基于文档的数据库。&lt;/li>
&lt;/ul>
&lt;p>Arrow 的列式存储有着 O(1) 的随机访问速度，并且可以进行高效的 Cache，同时还允许 SIMD 指令的优化。由于很多大数据系统都是在 JVM 上运行的，Arrow 对于 Python 和 R 的社区来说显得格外重要。&lt;/p>
&lt;p>Apache Arrow 是基于 Apache Drill 中的 Value Vector 来实现的，而使用 Value Vector 可以减少运算时重复访问数据带来的成本。&lt;/p>
&lt;h2 id="内存表示">内存表示&lt;/h2>
&lt;p>arrow在内存中表示数据的最基本单元是array，它代表了一连串长度已知、类型相同的数据。而多个长度相同、类型相同或者不同的array就可以用来表示结果集（或者一部分的结果集）。举一个简单的例子：一个如下图所示的结果集（或者table）&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">+------+------+
| C1 | C2 | [
|------+------| DoubleArray: [ 1.11, 2.22, 3.33],
| 1.11 | foo | -&amp;gt; StringArray: [ foo, bar, NULL]
| 2.22 | bar | ]
| 3.33 | NULL |
+------+------+
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>就可以表示成一个大小为2的有序集合，集合中的array（DoubleArray 和 StringArray）长度为3。arrow限制了array的最大长度，当结果集（或者表）的大小超过了array的最大长度，就需要把结果集水平切分成多个有序集合。&lt;/p>
&lt;h2 id="arrow-flight">Arrow Flight&lt;/h2>
&lt;p>近段时间Arrow最大的变化就是添加了Flight，一个通用C/S架构的高性能数据传输框架。Flight基于gRPC开发，从最开始重点就是优化Arrow格式数据。&lt;/p>
&lt;p>Flight的具体细节请看&lt;a href="https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/">官方文档&lt;/a>。这里只介绍它的优势：&lt;/p>
&lt;ul>
&lt;li>无序列化/反序列化：Flight会直接将内存中的Arrow发送，不进行任何序列化/反序列化操作&lt;/li>
&lt;li>批处理：Flight对record batch的操作无需访问具体的列、记录或者元素&lt;/li>
&lt;li>高并发：Flight的吞吐量只收到客户端和服务端的吞吐量以及网络的限制&lt;/li>
&lt;li>网络利用率高：Flight使用基于HTTP/2的gRPC，不仅是快&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.dremio.com/is-time-to-replace-odbc-jdbc/">官方给出的数据&lt;/a>是Flight的传输大约是标准ODBC的20-50倍。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://www.infoq.cn/article/apache-arrow">聊聊 Apache Arrow&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/339132159">Apache Arrow简介&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.tencent.com/developer/article/1902699">Apache Arrow - 大数据在数据湖后的下一个风向标 - 云+社区 - 腾讯云&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.aliyun.com/article/397187">Apache Arrow 内存数据-阿里云开发者社区&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.liuhaihua.cn/archives/698599.html">http://www.liuhaihua.cn/archives/698599.html&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Apache Avro</title><link>https://justice.bj.cn/post/30.architech/avro/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/avro/</guid><description>&lt;h1 id="apache-avro">Apache Avro&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Avro是Hadoop的一个数据序列化系统;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>由Hadoop的创始人Doug Cutting（也是Lucene，Nutch等项目的创始人）开发，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>设计用于支持大批量数据交换的应用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>基于scheme的序列化；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>支持二进制和json两种编码方式；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>支持多种语言；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Avro数据以模式来读和写(文件或是网络)，并且写入的数据都不需要加入其它标识，这样序列化时速度快且结果内容少;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>可排序&lt;/strong>。一种语言支持的Avro程序在序列化数据后，可由其它语言的Avro程序对未反序列化的数据排序。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="主要特点">主要特点&lt;/h2>
&lt;ul>
&lt;li>支持二进制序列化方式，可以便捷，快速地处理大量数据；&lt;/li>
&lt;li>动态语言友好，Avro提供的机制使动态语言可以方便地处理Avro数据&lt;/li>
&lt;/ul>
&lt;h2 id="与protobuf区别">与protobuf区别&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Property&lt;/th>
&lt;th>avro&lt;/th>
&lt;th>thrift/protobuf&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Dynamic schema&lt;/td>
&lt;td>是的&lt;/td>
&lt;td>不&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Built into Hadoop&lt;/td>
&lt;td>是的&lt;/td>
&lt;td>不&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Schema in JSON&lt;/td>
&lt;td>是的&lt;/td>
&lt;td>不&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>No need to compile&lt;/td>
&lt;td>是的&lt;/td>
&lt;td>不&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>No need to declare IDs&lt;/td>
&lt;td>是的&lt;/td>
&lt;td>不&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bleeding edge&lt;/td>
&lt;td>是的&lt;/td>
&lt;td>不&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Avro为了便于MapReduce的处理定义了一种&lt;strong>容器文件格式&lt;/strong>(Container File Format)。&lt;/p>
&lt;ol>
&lt;li>文件中只能有一种模式，所有需要存入这个文件的对象都需要按照这种模式以二进制编码的形式写入。&lt;/li>
&lt;li>对象在文件中以块(Block)来组织，并且这些对象都是可以被压缩的。&lt;/li>
&lt;li>块和块之间会存在同步标记符(Synchronization Marker)，以便MapReduce方便地切割文件用于处理。&lt;/li>
&lt;/ol>
&lt;p>下图是根据文档描述画出的文件结构图（将Avro对象序列化到文件的操作）：&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/03/17-14-37-32-2022-03-17-14-37-27-image.png" alt="">&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://developer.huawei.com/consumer/cn/forum/topic/0201763297717170935?fid=0101592429757310384">华为开发者论坛&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.cnblogs.com/wqbin/p/11228188.html">Avro从入门到入土 - wqbin - 博客园&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.gingerdoc.com/avro/avro_quick_guide">AVRO - 快速指南 - Gingerdoc 姜知笔记&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Apache Hudi</title><link>https://justice.bj.cn/post/30.architech/hudi/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/hudi/</guid><description>&lt;h1 id="apache-hudi">Apache Hudi&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Hudi，全称是&lt;em>Hadoop Upsert Delete and Incremental&lt;/em>, 最初的设计目标：&lt;strong>在&lt;/strong>hadoop上实现update和delete操作；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Hudi通过&lt;code>COW&lt;/code>和&lt;code>MOR&lt;/code>两种方式在只能overwrite的文件系统上实现update操作；&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h2 id="cow表">COW表&lt;/h2>
&lt;ul>
&lt;li>cow, copy on write，COW表写的时候数据直接写入basefile,（parquet）不写log文件；&lt;/li>
&lt;/ul>
&lt;p>Upsert的过程整体分为3步（这里省略了很多不太重要的步骤）：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>根据partitionPath进行重新分区。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>根据recordKey确定哪些记录需要插入，哪些记录需要更新。对于需要更新的记录，还需要找到旧的记录所在的文件。（这个过程被称为tagging）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>把记录写入实际的文件。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/03/16-19-03-51-2022-03-16-19-03-47-image.png" alt="">&lt;/p>
&lt;h2 id="mor表">MOR表&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>merge on read，MOR表写数据时，记录首先会被快速的写进日志文件，稍后会使用时间轴上的压缩操作将其与基础文件合并。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MOR表在更新时只会把更新的那部分数据写入一个.log文件;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>因为.log文件不包含老数据，也不涉及tagging，又是顺序写入的，所以写入会非常快。而当客户端要读取数据时，会有两种选择：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>读取时动态地把.log文件和原始数据文件（称为base文件）进行merge&lt;/p>
&lt;/li>
&lt;li>
&lt;p>异步地把.log文件和base文件merge，如果merge还没完成，只能读到上个版本的数据;&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h2 id="index">Index&lt;/h2>
&lt;p>在upsert的工作原理中，我们提到了tagging过程中需要使用index确定每一条数据之前是否已经插入过, 这3种index分别是：&lt;strong>Bloom Index&lt;/strong>，&lt;strong>Simple Index&lt;/strong>和&lt;strong>HBase Index&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Bloom Index：实现原理是bloom filter。优点是效率高，缺点是bloom filter固有的假阳性问题，所以Hudi对bloom filter里存在的key，还需要回溯原文件再查找一遍。&lt;strong>Hudi默认使用的是Bloom Index&lt;/strong>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Simple Index：实现原理是把新数据和老数据进行join。优点是实现最简单，无需额外的资源。缺点是性能比较差。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>HBase Index：实现原理是把index存放在HBase里面。优点是性能最高，缺点是需要外部的系统，增加了运维压力。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="查询">&lt;strong>查询&lt;/strong>&lt;/h2>
&lt;p>鉴于这种灵活而全面的数据布局和丰富的时间线，Hudi能够支持三种不同的查询表方式，具体取决于表的类型。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>查询类型&lt;/th>
&lt;th>COW&lt;/th>
&lt;th>MOR&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>快照查询&lt;/td>
&lt;td>查询在给定表或表分区中所有文件片中的最新基本文件上执行，将查看到最新提交的记录。&lt;/td>
&lt;td>通过并到给定表或表分区中的所有文件切片中最新的基本文件及其日志文件合来执行查询，将看到最新的delta-commit操作写入的的记录。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>增量查询&lt;/td>
&lt;td>在给定的开始，结束即时时间范围内，对最新的基本文件执行查询（称为增量查询窗口），同时仅使用Hudi指定的列提取在此窗口中写入的记录。&lt;/td>
&lt;td>查询是在增量查询窗口中对最新的文件片执行的，具体取决于窗口本身，读取基本块或日志块中读取记录的组合。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>读优化查询&lt;/td>
&lt;td>和快照查询相同&lt;/td>
&lt;td>仅访问基本文件，提供给定文件片自上次执行压缩操作以来的数据。通常查询数据的最新程度的保证取决于压缩策略&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/03/17-10-12-49-2022-03-17-10-12-42-image.png" alt="">&lt;/p>
&lt;h3 id="读优化查询">&lt;strong>读优化查询&lt;/strong>&lt;/h3>
&lt;p>可查看给定的commit/compact即时操作的表的最新快照。仅将最新文件片的基本/列文件暴露给查询，并保证与非Hudi表相同的列查询性能。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>指标&lt;/th>
&lt;th>读优化查询&lt;/th>
&lt;th>快照查询&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>数据延迟&lt;/td>
&lt;td>高&lt;/td>
&lt;td>低&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>查询延迟&lt;/td>
&lt;td>低&lt;/td>
&lt;td>高&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/5LQH50gZkNulDMLlcKABeg">聊一聊Apache Hudi的原理（1）&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cnblogs.com/leesf456/p/12710118.html">Apache Hudi 设计与架构最强解读 - leesf - 博客园&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s?__biz=MzIyMzQ0NjA0MQ==&amp;amp;mid=2247485735&amp;amp;idx=1&amp;amp;sn=51915c05f158bdffa96f231a31bb1675&amp;amp;chksm=e81f5c51df68d5471097a8d12c62c83fe8cb0491da50f7d37fae6d831fed1506e14966832229&amp;amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIyMzQ0NjA0MQ==&amp;amp;mid=2247485735&amp;amp;idx=1&amp;amp;sn=51915c05f158bdffa96f231a31bb1675&amp;amp;chksm=e81f5c51df68d5471097a8d12c62c83fe8cb0491da50f7d37fae6d831fed1506e14966832229&amp;amp;scene=21#wechat_redirect&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Apache iceberg</title><link>https://justice.bj.cn/post/30.architech/iceberg/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/iceberg/</guid><description>&lt;h1 id="apache-iceberg">Apache iceberg&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Apache Iceberg 是一种用于跟踪超大规模表的新格式，是专门为对象存储（如S3）而设计的,&lt;/p>
&lt;p>由 Netflix 开发开源的，于 2018年11月16日进入 Apache 孵化器，是 Netflix 公司数据仓库基础&lt;/p>
&lt;h2 id="设计思想">设计思想&lt;/h2>
&lt;p>记录表在所有时间的所有文件，和 Delta Lake 或 Apache Hudi 一样，支持 snapshot，其是表在某个时刻的完整文件列表。每一次写操作都会生成一个新的快照。&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/13-10-02-37-2020-08-27-16-27-13-image.png" alt="">&lt;/p>
&lt;h2 id="好处">好处&lt;/h2>
&lt;ul>
&lt;li>所有的修改都是原子性的；&lt;/li>
&lt;li>没有耗时的文件系统操作；&lt;/li>
&lt;li>快照是索引好的，以便加速读取；&lt;/li>
&lt;li>CBO metrics 信息是可靠的；&lt;/li>
&lt;li>更新支持版本，支持物化视图。&lt;/li>
&lt;/ul></description></item><item><title>Apache Kylin</title><link>https://justice.bj.cn/post/30.architech/kylin/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/kylin/</guid><description>&lt;h1 id="apache-kylin">Apache Kylin&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Apache Kylin™是一个开源的分布式分析引擎，提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表。Apache Kylin采用“预计算”的模式，用户只需要提前定义好查询维度，Kylin将帮助我们进行计算，并将结果存储到HBase中，为海量数据的查询和分析提供亚秒级返回&lt;/p>
&lt;h2 id="特点">特点&lt;/h2>
&lt;h2 id="核心概念">核心概念&lt;/h2>
&lt;h2 id="参考">参考&lt;/h2>
&lt;p>&lt;a href="https://www.jianshu.com/p/6eadb77d091c">https://www.jianshu.com/p/6eadb77d091c&lt;/a>&lt;/p></description></item><item><title>Apache Phoenix</title><link>https://justice.bj.cn/post/30.architech/phoenix/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/phoenix/</guid><description>&lt;h1 id="apache-phoenix">Apache Phoenix&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Phoenix是构建在HBase上的一个SQL层，能让我们用标准的JDBC APIs而不是HBase客户端APIs来创建表，插入数据和对HBase数据进行查询。Phoenix完全使用Java编写，作为HBase内嵌的JDBC驱动。Phoenix查询引擎会将SQL查询转换为一个或多个HBase扫描，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。&lt;/p>
&lt;p>Phoenix通过以下方式使我们可以少写代码，并且性能比我们自己写代码更好：&lt;/p>
&lt;ul>
&lt;li>将SQL编译成原生的HBase scans。&lt;/li>
&lt;li>确定scan关键字的最佳开始和结束&lt;/li>
&lt;li>让scan并行执行&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h2 id="架构">架构&lt;/h2>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/12/25-09-35-33-2019-12-23-12-01-21-image.png" alt="">&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://www.jianshu.com/p/d862337247b1">Apache Phoenix介绍（SQL on HBase） - 简书&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>AWS常用概念</title><link>https://justice.bj.cn/post/30.architech/aws-s3/aws-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/30.architech/aws-s3/aws-%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</guid><description>&lt;h1 id="aws常用概念">AWS常用概念&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>每个&lt;strong>Region&lt;/strong>都是完全独立的。每个&lt;strong>Availability Zone&lt;/strong>都是隔离的，但是Region中的可用区通过低延迟链接连接。&lt;strong>Local Zone&lt;/strong>是一种AWS基础架构部署，可将所选服务放置在更接近最终用户的位置。&lt;strong>Local Zone&lt;/strong>是与您所在区域不同位置的区域的扩展。它为AWS基础架构提供了高带宽主干，非常适合对延迟敏感的应用程序，例如机器学习。下图说明了区域，可用区域和本地区域之间的关系。&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/21-08-59-25-2020-03-03-12-48-56-image.png" alt="">&lt;/p>
&lt;p>Amazon EC2资源是以下资源之一：全局，与Region，&lt;strong>Availability Zone&lt;/strong>或&lt;strong>Local Zone&lt;/strong>绑定&lt;/p>
&lt;h2 id="region">Region&lt;/h2>
&lt;p>每个Amazon EC2 &lt;strong>Region&lt;/strong>都旨在与其他Amazon EC2 &lt;strong>Region&lt;/strong>隔离。这样可以实现最大的容错能力和稳定性。&lt;/p>
&lt;p>当您查看您的资源时，您只会看到与您指定的区域相关联的资源。这是因为区域彼此隔离，并且我们不会自动在区域之间复制资源。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>B-Link-Tree</title><link>https://justice.bj.cn/post/12.data_struct/tree/b-link-tree/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/12.data_struct/tree/b-link-tree/</guid><description>&lt;h1 id="b-link-tree">B-Link-Tree&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>B-Link-Tree是B+ Tree的一个变种；优化了B+ Tree结构调整时的锁粒度，提升并发度，保持高并发下的性能稳定&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在中间节点增加字段link pointer，指向右兄弟节点，B-link Tree的名字也由此而来&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在每个节点内增加一个字段high key，在查询时如果目标值超过该节点的high key，就需要循着link pointer继续往后继节点查找&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="特点">特点&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>树结构调整时无需对全局或者局部子树加锁，进而有利于高并发下的性能稳定性；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个节点增加额外字段，link pointer和high key，但代价不大&lt;/p>
&lt;/li>
&lt;li>
&lt;p>查询时需要额外判断，如果查询找超过high key，需要额外通过link pointer查询其后继节点，在数据库应用中可能会产生一次额外的IO，从而造成单次查找性能的下降，但由于树结构调整是一个频率较低的动作，而且查询后继节点的操作也只会发生在子节点调整和父节点调整过程之间，一旦父节点调整完毕，就可以通过父节点的指针直接查询了而无需再通过子节点的后继指针查找。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="结构">结构&lt;/h2>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/01/10-14-25-15-2022-01-10-14-25-07-image.png" alt="">&lt;/p>
&lt;h2 id="节点分裂过程">节点分裂过程&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>B+ Tree在分裂时，为了保证一致性，需要使用全局锁住整棵树；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>B-Link-Tree在分裂时，执行一种自底向上的调整方法，每次只对当前调整节点加锁，当子节点调整完毕后再向上回溯调整父节点，直到所有调整完毕。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/01/10-14-28-05-2022-01-10-14-27-59-image.png" alt="">&lt;/p>
&lt;h2 id="应用">应用&lt;/h2>
&lt;ul>
&lt;li>在GreenPlum中就使用了B-link Tree来作为其存储引擎的索引。&lt;/li>
&lt;/ul>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/372830975">https://zhuanlan.zhihu.com/p/372830975&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.csd.uoc.gr/~hy460/pdf/p650-lehman.pdf">https://www.csd.uoc.gr/~hy460/pdf/p650-lehman.pdf&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://zhmin.github.io/posts/blink-tree/">B+Tree 的并发优化 BLink-Tree | 学习笔记&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>B-Tree, B+Tree, B*Tree</title><link>https://justice.bj.cn/post/12.data_struct/tree/b-tree/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/12.data_struct/tree/b-tree/</guid><description>&lt;h1 id="b-tree-btree-btree">B-Tree, B+Tree, B*Tree&lt;/h1>
&lt;h2 id="b-tree">B-Tree&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;code>B-Tree&lt;/code>(B树)又叫&lt;em>平衡多路查找树&lt;/em>(Balance Multiple Search Tree);&lt;/p>
&lt;/li>
&lt;li>
&lt;p>是一种平衡多叉树；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>m阶B-Tree的每个节点最多有m个子节点；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="特性">特性&lt;/h3>
&lt;p>一棵 m 阶 B 树 (m 叉树)的特性如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>每个Node最多含有 m -1个key；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Root节点key数：[1, m-1]；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>非Root节点key数：[m/2, m-1];&lt;/p>
&lt;/li>
&lt;li>
&lt;p>若Root结点不是叶子结点，则至少有 2 个孩子；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部接点或查询失败的接点，实际上这些结点不存在，指向这些结点的指针都为 null)；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个非终端结点中包含有 n 个关键字信息： (P1，K1，P2，K2，P3，&amp;hellip;&amp;hellip;，Kn，Pn+1)。其中：
       a)   Ki (i=1&amp;hellip;n)为关键字，且关键字按顺序升序排序 K(i-1)&amp;lt; Ki。 
       b)   Pi 为指向子树根的接点，且指针 P(i)指向子树种所有结点的关键字均小于 Ki，但都大于 K(i-1)。 
       c)   关键字的个数 n 必须满足： [ceil(m / 2)-1]&amp;lt;= n &amp;lt;= m-1。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/21-09-56-17-2020-04-21-13-16-05-image.png" alt="">&lt;/p>
&lt;h3 id="b-tree操作">B-Tree操作&lt;/h3>
&lt;p>来模拟下查找文件 29 的过程：&lt;/p>
&lt;p>(1) 根据根结点指针找到文件目录的根磁盘块 1，将其中的信息导入内存。【磁盘 IO 操作 1 次】&lt;/p>
&lt;p>(2) 此时内存中有两个文件名 17，35 和三个存储其他磁盘页面地址的数据。根据算法我们发现 17&amp;lt;29&amp;lt;35，因此我们找到指针 p2。&lt;/p>
&lt;p>(3) 根据 p2 指针，我们定位到磁盘块 3，并将其中的信息导入内存。【磁盘 IO 操作 2 次】&lt;/p>
&lt;p>(4) 此时内存中有两个文件名 26，30 和三个存储其他磁盘页面地址的数据。根据算法我们发现 26&amp;lt;29&amp;lt;30，因此我们找到指针 p2。&lt;/p>
&lt;p>(5) 根据 p2 指针，我们定位到磁盘块 8，并将其中的信息导入内存。【磁盘 IO 操作 3 次】&lt;/p>
&lt;p>(6) 此时内存中有两个文件名 28，29。根据算法我们查找到文件 29，并定位了该文件内存的磁盘地址。&lt;/p>
&lt;h2 id="btree">B+Tree&lt;/h2>
&lt;ul>
&lt;li>B+树是B-Tree的一种变种；&lt;/li>
&lt;/ul>
&lt;h3 id="特点">特点&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>B+&lt;strong>树的层级更少&lt;/strong>：相较于B树B+每个&lt;strong>非叶子&lt;/strong>节点存储的关键字数更多，树的层级更少所以查询数据更快；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>B+&lt;strong>树查询速度更稳定&lt;/strong>：B+所有关键字数据地址都存在&lt;strong>叶子&lt;/strong>节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>B+树天然具备排序功能：&lt;strong>B+树所有的&lt;/strong>叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>B+树全节点遍历更快：&lt;strong>B+树遍历整棵树只需要遍历所有的&lt;/strong>叶子节点即可，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>B树&lt;/strong>相对于&lt;strong>B+树&lt;/strong>的优点是：如果经常访问的数据离根节点很近，而&lt;strong>B树&lt;/strong>的&lt;strong>非叶子&lt;/strong>节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比&lt;strong>B+树&lt;/strong>快。&lt;/p>
&lt;p>&lt;code>B+树&lt;/code>通常用于数据库和操作系统的&lt;code>文件系统&lt;/code>中;&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/03/19-11-42-17-2022-03-19-11-42-14-image.png" alt="">&lt;/p>
&lt;h3 id="插入">插入&lt;/h3>
&lt;h3 id="删除">删除&lt;/h3>
&lt;h2 id="b-tree-1">B* Tree&lt;/h2>
&lt;p>B*树是B+树的变种，相对于B+树他们的不同之处如下：&lt;/p>
&lt;p>（1）首先是关键字个数限制问题，B+树初始化的关键字初始化个数是cei(m/2)，b&lt;em>树的初始化个数为（cei(2/3&lt;/em>m)）&lt;/p>
&lt;p>（2）B+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1/3的数据创建一个新的节点出来；&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2022/03/19-11-42-56-2022-03-19-11-42-52-image.png" alt="">&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.02.md">The-Art-Of-Programming-By-July/03.02.md at master · julycoding/The-Art-Of-Programming-By-July · GitHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/27700617">https://zhuanlan.zhihu.com/p/27700617&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/54102723">https://zhuanlan.zhihu.com/p/54102723&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://draveness.me/whys-the-design-mysql-b-plus-tree/">为什么 MySQL 使用 B+ 树 - 面向信仰编程&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ivanzz1001.github.io/records/post/data-structure/2018/06/16/ds-bplustree">B+树详解 | Ivanzz&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://segmentfault.com/a/1190000020416577">https://segmentfault.com/a/1190000020416577&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cnblogs.com/wade-luffy/p/6292784.html">B+树介绍 - wade&amp;amp;luffy - 博客园&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Bit/Byte</title><link>https://justice.bj.cn/post/12.data_struct/01.%E6%AF%94%E7%89%B9/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/12.data_struct/01.%E6%AF%94%E7%89%B9/</guid><description>&lt;h1 id="bitbyte">Bit/Byte&lt;/h1>
&lt;hr>
&lt;h2 id="series-">title: 比特/字节
description:
toc: true
authors: []
tags: []
categories: []
series: []&lt;/h2>
&lt;h1 id="bitbyte-1">Bit/Byte&lt;/h1>
&lt;h2 id="bit">bit&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>bit是内存中最小的数据单位，为一个数据位；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>8个bit组成一个byte。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="字符串相关算法">字符串相关算法&lt;/h2>
&lt;ul>
&lt;li>字符串匹配&lt;/li>
&lt;li>字符串转换&lt;/li>
&lt;li>公共前缀&lt;/li>
&lt;/ul></description></item><item><title>BlobStore</title><link>https://justice.bj.cn/post/40.storage/spdk/blobstore/</link><pubDate>Sat, 21 May 2022 21:27:53 +0800</pubDate><guid>https://justice.bj.cn/post/40.storage/spdk/blobstore/</guid><description>&lt;h1 id="blobstore">BlobStore&lt;/h1>
&lt;hr>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>SPDK bdev层类似于内核中的通用块设备层，是对底层不同类型设备（如NVMe bdev、Malloc bdev、AIO bdev等）的统一抽象管理。&lt;/p>
&lt;p>BlobStore是位于SPDK bdev之上，通过不同层级的抽象，实现对磁盘块(LBA)的管理，实现了对Blob的管理，包括Blob的分配、删除、读取、写入、元数据的管理等；&lt;/p>
&lt;p>BlobFS是在Blobstore的基础上进行封装的一个轻量级文件系统，用于提供部分对于文件操作的接口，并将对文件的操作转换为对Blob的操作，&lt;/p>
&lt;p>用于与用户态文件系统Blobstore Filesystem （BlobFS）集成，从而代替传统的文件系统，支持更上层的服务，如数据库MySQL、K-V存储引擎Rocksdb以及分布式存储系统Ceph、Cassandra等。&lt;/p>
&lt;hr>
&lt;h2 id="blobstore-1">BlobStore&lt;/h2>
&lt;h3 id="数据块管理">数据块管理&lt;/h3>
&lt;p>在blobstore中，将SSD中的块划分为多个抽象层：&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/09-10-54-17-2020-11-09-10-54-11-image.png" alt="">&lt;/p>
&lt;hr>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Logical Block&lt;/strong>：与块设备中所提供的逻辑块相对应，通常为512B或4KiB。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Page&lt;/strong>：由多个连续的Logical Block构成，通常一个page的大小为4KiB，因此一个Page由八个或一个Logical Block构成，取决于Logical Block的大小。&lt;/p>
&lt;ul>
&lt;li>在Blobstore中，Page是连续的，即从SSD的LBA 0开始，多个或一个块构成Page 0,接下来是Page 1，依次类推。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Cluster&lt;/strong>：由多个连续的Page构成，通常一个Cluster的大小默认为1MiB，因此一个Cluster由256个Page构成。&lt;/p>
&lt;ul>
&lt;li>Cluster与Page一样，是连续的，即从SSD的LBA 0开始的位置依次为Cluster 0到Cluster N。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Blob&lt;/strong>：Blobstore中主要的操作对象为Blob，与BlobFS中的文件相对应，提供read、write、create、delete等操作。&lt;/p>
&lt;ul>
&lt;li>一个Blob由多个Cluster构成，但构成Blob中的Cluster并不一定是连续的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="数据块管理-1">数据块管理&lt;/h2>
&lt;p>在Blobstore中，会将cluster 0作为一个特殊的cluster。&lt;/p>
&lt;p>该cluster用于存放Blobtore的所有信息以及元数据，对每个blob数据块的查找、分配都是依赖cluster 0中所记录的元数据所进行的。&lt;/p>
&lt;p>Cluster 0的结构如下：&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/09-10-54-53-2020-11-09-10-54-48-image.png" alt="">&lt;/p>
&lt;p>Cluster 0中的第一个page作为super block，Blobstore初始化后的一些基本信息都存放在super block中，例如cluster的大小、已使用page的起始位置、已使用page的个数、已使用cluster的起始位置、已使用cluster的个数、Blobstore的大小等信息。&lt;/p>
&lt;hr>
&lt;h3 id="元数据">元数据&lt;/h3>
&lt;p>Cluster 0中的其它page将组成元数据域（metadata region）。元数据域主要由以下几部分组成：&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/09-14-10-48-2020-11-09-14-10-36-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Metadata Page Allocation：用于记录所有元数据page的分配情况。在分配或释放元数据页后，将会对metadata page allocation中的数据做相应的修改。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cluster Allocation：用于记录所有cluster的分配情况。在分配新的cluster或释放cluster后会对cluster allocation中的数据做相应的修改。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Blob Id Allocation：用于记录blob id的分配情况。对于blobstore中的所有blob，都是通过唯一的标识符blob id将其对应起来。在元数据域中，将会在blob allocation中记录所有的blob id分配情况。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Metadata Pages Region：元数据页区域中存放着每个blob的元数据页。每个blob中所分配的cluster都会记录在该blob的元数据页中，在读写blob时，首先会通过blob id定位到该blob的元数据页，其次根据元数据页中所记录的信息，检索到对应的cluster。对于每个blob的元数据页，并不是连续的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>对于一个blob来说，metadata page记录了该blob的所有信息，数据存放于分配给该blob的cluster中。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>在创建blob时，首先会为其分配blob id以及metadata page，其次更新metadata region。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当对blob进行写入时，首先会为其分配cluster，其次更新该blob的metadata page，最后将数据写入，并持久化到磁盘中。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>为了实现对磁盘空间的动态分配管理，Blobstore中为每个blob分配的cluster并不是连续的。&lt;/p>
&lt;p>对于每个blob，通过相应的结构维护当前使用的cluster以及metadata page的信息：clusters与pages。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Cluster: 记录了当前该blob所有cluster的LBA起始地址，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>pages: 记录了当前该blob所有metadata page的LBA起始地址。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Blobstore实现了对磁盘空间分配的动态管理，并保证断电不丢失数据，具有persistent特性。&lt;/p>
&lt;p>Blobstore中的配置信息与数据信息均在super block与metadata region中管理，在重启后，若要保持persistent，可以通过Blobstore中所提供的load操作。&lt;/p>
&lt;p>&lt;strong>注意&lt;/strong>：&lt;/p>
&lt;blockquote>
&lt;p>Blob的persistent主要是针对NVMe这类bdev。对于Malloc bdev，由于其本身的性质，是无法保证Blob的persistent，需要重启后进行重新配置。&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;h2 id="blobfs">BlobFS&lt;/h2>
&lt;h3 id="blobfs-文件接口">BlobFS 文件接口&lt;/h3>
&lt;p>blobfs文件系统接口实现了基本的文件操作，&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>操作&lt;/th>
&lt;th>同步API&lt;/th>
&lt;th>异步API&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>打开文件&lt;/td>
&lt;td>spdk_fs_open_file&lt;/td>
&lt;td>spdk_fs_open_file_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>创建文件&lt;/td>
&lt;td>spdk_fs_create_file&lt;/td>
&lt;td>spdk_fs_create_file_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删除文件&lt;/td>
&lt;td>spdk_fs_delete_file&lt;/td>
&lt;td>spdk_fs_delete_file_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>重命名文件&lt;/td>
&lt;td>spdk_fs_rename_file&lt;/td>
&lt;td>spdk_fs_rename_file_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>文件状态&lt;/td>
&lt;td>spdk_fs_file_stat&lt;/td>
&lt;td>spdk_fs_file_stat_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>写&lt;/td>
&lt;td>spdk_file_write&lt;/td>
&lt;td>spdk_file_write_async/sspdkfile_writev_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>读&lt;/td>
&lt;td>spdk_file_read&lt;/td>
&lt;td>spdk_file_read_async/sspdkfile_readv_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>truncate&lt;/td>
&lt;td>spdk_file_truncate&lt;/td>
&lt;td>spdk_file_truncate_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>sync&lt;/td>
&lt;td>spdk_file_sync&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>关闭&lt;/td>
&lt;td>spdk_file_close&lt;/td>
&lt;td>spdk_file_close_async&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h3 id="缓存">缓存&lt;/h3>
&lt;p>为了提高文件的读取效率，BlobFS在内存中提供了cache buffer，由多层树结构组成，其结构如下所示：&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/09-10-58-02-2020-11-09-10-56-44-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>最底层Level 0叶子节点为buffer node，是用于存放数据的buffer。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Level 0以上的其它层中，均为tree node，用于构建树的索引结构。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在文件读写的时候，根据文件结构中的根节点以及读取位置的offset信息，在树结构中通过索引查找buffer node的位置，即从Level N，逐步定位到对应的Level 0的叶子节点。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="写">写&lt;/h3>
&lt;p>BlobFS目前用于支持上层的Rocksdb，在Rocksdb的抽象环境层中提供文件的接口，目前仅支持append类型的写操作。&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/09-10-57-32-2020-11-09-10-57-04-image.png" alt="">&lt;/p>
&lt;hr>
&lt;p>在进行文件写入：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>首先会根据文件当前的写入位置检查是否符合cache buffer写入需求，若满足，则直接将数据写入到cache buffer中，同时触发异步的flush操作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在flush的过程中，BlobFS触发Blob的写操作，将cache buffer中的数据，写入到文件对应blob的相应位置。若不满足cache buffer的写入需求，BlobFS则直接触发文件对应的blob的写操作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Blobstore首先为该blob分配cluster，根据计算得到的写入LBA信息，向SPDK bdev层发送异步的写请求，将数据写入，并更新相应的元数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于元数据的更新，出于性能考虑，当前对元数据的更新都在内存中操作，当用户使用强制同步或卸载Blobstore时，更新后的元数据信息才会同步到磁盘中。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>此外，blob结构中维护了两份可变信息（指cluster与metadata page）的元数据，分别为clean与active。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Clean中记录的是当前磁盘的元数据信息，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>而active中记录的是当前在内存中更新后的元数据信息。同步操作会将clean中记录的信息与active记录的信息相匹配。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="读流程">读流程&lt;/h3>
&lt;p>&lt;img src="https://raw.githubusercontent.com/ZhuZhengyi/notebook-images/master/2020/11/09-10-47-19-2020-11-04-09-45-33-image.png" alt="">&lt;/p>
&lt;hr>
&lt;p>在文件读写时：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>首先会进行read ahead操作，将一部分数据从磁盘预先读取到内存的buffer中；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>其后，根据cache buffer的大小，对文件的I/O进行切分，使每个I/O的最大长度不超过一个cache buffer的大小；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于拆分后的文件I/O，会根据其offset在cache buffer tree中查找相应的buffer；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>若存在，则直接从cache buffer中读取数据，进行memcpy；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>而对于没有缓存到cache buffer中的数据，将会对该文件的读取，转换到该文件对应的Blob进行读取。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对Blob读取时候，根据已打开的blob结构中记录的信息，可以获取该blob所有cluster的LBA起始位置，并根据读取位置的offset信息，计算相应的LBA地址。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>最后向SPDK bdev层发送异步的读请求，并等待I/O完成。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>BlobFS所提供的读操作为同步读，I/O完成后会在callback函数中，通过信号量通知BlobFS完成信号，至此文件读取结束。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="blobfs-fuse">BlobFS FUSE&lt;/h3>
&lt;p>BlobFS提供了一个FUSE插件，用于将SPDK BlobFS作为内核文件系统安装，以便进行检查或调试。FUSE插件需要fuse3，并在系统上检测到fuse3时自动构建。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">test/blobfs/fuse/fuse /usr/local/etc/spdk/rocksdb.conf Nvme0n1 /mnt/fuse
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="k">static&lt;/span> &lt;span class="k">struct&lt;/span> &lt;span class="n">fuse_operations&lt;/span> &lt;span class="n">spdk_fuse_oper&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">getattr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_getattr&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">readdir&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_readdir&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">mknod&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_mknod&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">unlink&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_unlink&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">truncate&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_truncate&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">utimens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_utimens&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">open&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_open&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">release&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_release&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">read&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_read&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">write&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_write&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">flush&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_flush&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">fsync&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_fsync&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">.&lt;/span>&lt;span class="n">rename&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fuse_rename&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">};&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="blobfs当前限制">BlobFS当前限制&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>现有BlobFS只在RocksDB上进行了测试，其他不同于RocksDB的文件系统使用场合可能会有问题，以后会进行更严格的测试；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>现在只支持同步操作API。异步API开发中，未经过严格测试，将于以后版本中完成；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>文件&lt;code>rename&lt;/code>API不是原子操作。将于未来版本修复；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当前不支持目录，只支持扁平的文件命名空间。文件名作为xattrs存储于blob中，文件名&lt;code>lookup&lt;/code>为&lt;code>O(n)&lt;/code>级。&lt;code>btree&lt;/code>版本目录支持实现将于未来版本支持；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当前&lt;code>write&lt;/code>操作仅支持append到文件末尾。任意位置写操作将在未来版本实现；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Blobstore实现对Blob管理，Blob类似与文件的概念，但又不完全等同于文件，Blob没有完全遵循文件的POSIX接口，因此避免与文件混淆，在SPDK中称之为Blob而不是File。&lt;/p>
&lt;p>Blobstore Filesystem （BlobFS）是基于Blobstore实现的轻量级文件系统，对Blobstore进行封装，提供一些文件的常用接口，如read、write、open、sync等，其目的在于作为文件系统支持更上层的应用，例如Rocksdb。但其本质仍然是Blobstore，因此命名为BlobFS。&lt;/p>
&lt;p>目前SPDK基于维护了Rocksdb的一个分支，该分支下的Rocksdb在环境抽象层主要通过BlobFS进行对接，I/O可以经由BlobFS绕过内核I/O栈。&lt;/p>
&lt;hr>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://spdk.io/doc/blobfs.html">SPDK: BlobFS (Blobstore Filesystem)&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.sdnlab.com/22880.html">https://www.sdnlab.com/22880.html&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.atzlinux.com/atzlinux/doc/os2atc2019/SPDK-bytedance-miaoyu.pdf">SPDK在字节跳动存储业务中的应⽤&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item></channel></rss>