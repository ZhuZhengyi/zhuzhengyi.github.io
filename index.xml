<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Justice的小站</title><link>https://justice.bj.cn/</link><description>Recent content on Justice的小站</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 10 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://justice.bj.cn/index.xml" rel="self" type="application/rss+xml"/><item><title>Justice's Blog</title><link>https://justice.bj.cn/homepage/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/about/</guid><description>&lt;h2 id="self-introduction">Self Introduction&lt;/h2>
&lt;p>Cras ex dui, tristique a libero eget, consectetur semper ligula. Nunc augue arcu, malesuada a nisi et, molestie finibus metus. Sed lacus odio, ultricies a nisl vitae, sollicitudin tempor ipsum. Vivamus quis feugiat arcu. Sed mi nunc, efficitur quis tellus vitae, posuere mattis metus. Phasellus in mattis dui. Nullam blandit, augue non ullamcorper dapibus, lacus dui molestie massa, in iaculis purus lectus eu lectus. Duis hendrerit lacinia tellus, sit amet feugiat dolor placerat id. Aenean ac velit massa. Vivamus feugiat dui at magna viverra, ut dictum nunc rutrum. Duis eget sapien finibus, lobortis orci id, vestibulum tellus. Maecenas lobortis urna libero, quis fermentum lectus lobortis nec. Nullam laoreet volutpat libero, ac mattis magna ullamcorper quis. Duis eget ipsum eu nisi mattis cursus et vitae turpis.&lt;/p>
&lt;p>Aliquam pretium diam eget leo feugiat finibus. Donec malesuada commodo ipsum. Aenean a massa in lacus venenatis vestibulum. Duis vel sem quis elit iaculis consectetur et quis dolor. Morbi eu ipsum hendrerit, malesuada ante sed, dapibus est. Suspendisse feugiat nulla ut gravida convallis. Phasellus id massa posuere, rhoncus justo ut, porttitor dolor. Nulla ultrices malesuada egestas. Nunc fermentum tincidunt sem ac vulputate. Donec mollis sollicitudin justo eget varius. Donec ornare velit et felis blandit, id molestie sapien lobortis. Morbi eget tristique justo. Mauris posuere, nibh eu laoreet ultricies, ligula erat iaculis sapien, vel dapibus lacus libero ut diam. Etiam viverra ante felis, et scelerisque nunc pellentesque vitae. Praesent feugiat dictum molestie.&lt;/p>
&lt;h2 id="details">Details&lt;/h2>
&lt;p>Nunc pellentesque vitae:&lt;/p>
&lt;ul>
&lt;li>Morbi accumsan nibh efficitur diam molestie, non dignissim diam facilisis.&lt;/li>
&lt;li>Donec dignissim leo in mollis faucibus.&lt;/li>
&lt;li>Donec blandit lacus a pellentesque fermentum.&lt;/li>
&lt;/ul>
&lt;p>Donec mollis sollicitudin:&lt;/p>
&lt;ul>
&lt;li>Nunc dictum purus ornare purus consectetur, eu pellentesque massa ullamcorper.&lt;/li>
&lt;li>Aliquam eu leo vitae justo aliquam tincidunt.&lt;/li>
&lt;li>Fusce non massa id augue interdum feugiat sed et nulla.&lt;/li>
&lt;li>Vivamus molestie augue in tristique laoreet.&lt;/li>
&lt;/ul></description></item><item><title>Pages</title><link>https://justice.bj.cn/homepage/pages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/pages/</guid><description/></item><item><title>Experiences</title><link>https://justice.bj.cn/homepage/experiences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/experiences/</guid><description/></item><item><title>Vintage</title><link>https://justice.bj.cn/homepage/vintage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/vintage/</guid><description/></item><item><title>Blank</title><link>https://justice.bj.cn/homepage/blank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/blank/</guid><description>
&lt;div style="text-align:center">
&lt;p>Write anything you like here!&lt;/p>
&lt;/div></description></item><item><title>Elasticsearch内核解析 - 查询篇</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E8%AF%BB%E6%B5%81%E7%A8%8B/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E8%AF%BB%E6%B5%81%E7%A8%8B/</guid><description>&lt;h1 id="elasticsearch内核解析---查询篇">Elasticsearch内核解析 - 查询篇&lt;/h1>
&lt;h2 id="读操作">读操作&lt;/h2>
&lt;p>实时性和《&lt;a href="https://zhuanlan.zhihu.com/p/34669354">Elasticsearch内核解析 - 写入篇&lt;/a>》中的“写操作”一样，对于搜索而言是近实时的，延迟在100ms以上，对于NoSQL则需要是实时的。&lt;/p>
&lt;p>一致性指的是写入成功后，下次读操作一定要能读取到最新的数据。对于搜索，这个要求会低一些，可以有一些延迟。但是对于NoSQL数据库，则一般要求最好是强一致性的。&lt;/p>
&lt;p>结果匹配上，NoSQL作为数据库，查询过程中只有符合不符合两种情况，而搜索里面还有是否相关，类似于NoSQL的结果只能是0或1，而搜索里面可能会有0.1，0.5，0.9等部分匹配或者更相关的情况。&lt;/p>
&lt;p>结果召回上，搜索一般只需要召回最满足条件的Top N结果即可，而NoSQL一般都需要返回满足条件的所有结果。&lt;/p>
&lt;p>搜索系统一般都是两阶段查询，第一个阶段查询到对应的Doc ID，也就是PK；第二阶段再通过Doc ID去查询完整文档，而NoSQL数据库一般是一阶段就返回结果。在Elasticsearch中两种都支持。&lt;/p>
&lt;p>目前NoSQL的查询，聚合、分析和统计等功能上都是要比搜索弱的。&lt;/p>
&lt;h2 id="lucene的读">Lucene的读&lt;/h2>
&lt;p>Elasticsearch使用了Lucene作为搜索引擎库，通过Lucene完成特定字段的搜索等功能，在Lucene中这个功能是通过IndexSearcher的下列接口实现的：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="n">TopDocs&lt;/span> &lt;span class="nf">search&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Query&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Document&lt;/span> &lt;span class="nf">doc&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">docID&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">count&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Query&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">......(&lt;/span>&lt;span class="n">其他&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>第一个search接口实现搜索功能，返回最满足Query的N个结果；第二个doc接口通过doc id查询Doc内容；第三个count接口通过Query获取到命中数。&lt;/p>
&lt;p>这三个功能是搜索中的最基本的三个功能点，对于大部分Elasticsearch中的查询都是比较复杂的，直接用这个接口是无法满足需求的，比如分布式问题。这些问题都留给了Elasticsearch解决，我们接下来看Elasticsearch中相关读功能的剖析。&lt;/p>
&lt;h2 id="elasticsearch的读">Elasticsearch的读&lt;/h2>
&lt;p>Elasticsearch中每个Shard都会有多个Replica，主要是为了保证数据可靠性，除此之外，还可以增加读能力，因为写的时候虽然要写大部分Replica Shard，但是查询的时候只需要查询Primary和Replica中的任何一个就可以了。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-1ad1351408bdf0ce7f76f251d6ef8bc4_720w.jpg" alt="">&lt;/p>
&lt;p>Search On Replicas&lt;/p>
&lt;p>在上图中，该Shard有1个Primary和2个Replica Node，当查询的时候，从三个节点中根据Request中的preference参数选择一个节点查询。preference可以设置_local，_primary，_replica以及其他选项。如果选择了primary，则每次查询都是直接查询Primary，可以保证每次查询都是最新的。如果设置了其他参数，那么可能会查询到R1或者R2，这时候就有可能查询不到最新的数据。&lt;/p>
&lt;blockquote>
&lt;p>上述代码逻辑在OperationRouting.Java的searchShards方法中。&lt;/p>
&lt;/blockquote>
&lt;p>接下来看一下，Elasticsearch中的查询是如何支持分布式的。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-737f6cb48ccf22c50c2e630433c6ad48_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中通过分区实现分布式，数据写入的时候根据_routing规则将数据写入某一个Shard中，这样就能将海量数据分布在多个Shard以及多台机器上，已达到分布式的目标。这样就导致了查询的时候，潜在数据会在当前index的所有的Shard中，所以Elasticsearch查询的时候需要查询所有Shard，同一个Shard的Primary和Replica选择一个即可，查询请求会分发给所有Shard，每个Shard中都是一个独立的查询引擎，比如需要返回Top 10的结果，那么每个Shard都会查询并且返回Top 10的结果，然后在Client Node里面会接收所有Shard的结果，然后通过优先级队列二次排序，选择出Top 10的结果返回给用户。&lt;/p>
&lt;p>这里有一个问题就是请求膨胀，用户的一个搜索请求在Elasticsearch内部会变成Shard个请求，这里有个优化点，虽然是Shard个请求，但是这个Shard个数不一定要是当前Index中的Shard个数，只要是当前查询相关的Shard即可，这个需要基于业务和请求内容优化，通过这种方式可以优化请求膨胀数。&lt;/p>
&lt;p>Elasticsearch中的查询主要分为两类，Get请求：通过ID查询特定Doc；Search请求：通过Query查询匹配Doc。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-1f4c1cf921049b841ae2612b4734cdb1_720w.jpg" alt="">&lt;/p>
&lt;blockquote>
&lt;p>上图中内存中的Segment是指刚Refresh Segment，但是还没持久化到磁盘的新Segment，而非从磁盘加载到内存中的Segment。&lt;/p>
&lt;/blockquote>
&lt;p>对于Search类请求，查询的时候是一起查询内存和磁盘上的Segment，最后将结果合并后返回。这种查询是近实时（Near Real Time）的，主要是由于内存中的Index数据需要一段时间后才会刷新为Segment。&lt;/p>
&lt;p>对于Get类请求，查询的时候是先查询内存中的TransLog，如果找到就立即返回，如果没找到再查询磁盘上的TransLog，如果还没有则再去查询磁盘上的Segment。这种查询是实时（Real Time）的。这种查询顺序可以保证查询到的Doc是最新版本的Doc，这个功能也是为了保证NoSQL场景下的实时性要求。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-c5455432442548d1f12c975684fc4a00_720w.jpg" alt="">&lt;/p>
&lt;p>多阶段查询&lt;/p>
&lt;p>所有的搜索系统一般都是两阶段查询，第一阶段查询到匹配的DocID，第二阶段再查询DocID对应的完整文档，这种在Elasticsearch中称为query_then_fetch，还有一种是一阶段查询的时候就返回完整Doc，在Elasticsearch中称作query_and_fetch，一般第二种适用于只需要查询一个Shard的请求。&lt;/p>
&lt;p>除了一阶段，两阶段外，还有一种三阶段查询的情况。搜索里面有一种算分逻辑是根据TF（Term Frequency）和DF（Document Frequency）计算基础分，但是Elasticsearch中查询的时候，是在每个Shard中独立查询的，每个Shard中的TF和DF也是独立的，虽然在写入的时候通过_routing保证Doc分布均匀，但是没法保证TF和DF均匀，那么就有会导致局部的TF和DF不准的情况出现，这个时候基于TF、DF的算分就不准。为了解决这个问题，Elasticsearch中引入了DFS查询，比如DFS_query_then_fetch，会先收集所有Shard中的TF和DF值，然后将这些值带入请求中，再次执行query_then_fetch，这样算分的时候TF和DF就是准确的，类似的有DFS_query_and_fetch。这种查询的优势是算分更加精准，但是效率会变差。另一种选择是用BM25代替TF/DF模型。&lt;/p>
&lt;p>在新版本Elasticsearch中，用户没法指定DFS_query_and_fetch和query_and_fetch，这两种只能被Elasticsearch系统改写。&lt;/p>
&lt;h2 id="elasticsearch查询流程">Elasticsearch查询流程&lt;/h2>
&lt;p>Elasticsearch中的大部分查询，以及核心功能都是Search类型查询，上面我们了解到查询分为一阶段，二阶段和三阶段，这里我们就以最常见的的二阶段查询为例来介绍查询流程。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-10acab5576a2359ca279331e81adc1e2_720w.jpg" alt="">&lt;/p>
&lt;p>查询流程&lt;/p>
&lt;p>&lt;strong>注册Action&lt;/strong>&lt;/p>
&lt;p>Elasticsearch中，查询和写操作一样都是在ActionModule.java中注册入口处理函数的。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">registerHandler.accept(new RestSearchAction(settings, restController));
......
actions.register(SearchAction.INSTANCE, TransportSearchAction.class);
......
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果请求是Rest请求，则会在RestSearchAction中解析请求，检查查询类型，不能设置为dfs_query_and_fetch或者query_and_fetch，这两个目前只能用于Elasticsearch中的优化场景，然后将请求发给后面的TransportSearchAction处理。然后构造SearchRequest，将请求发送给TransportSearchAction处理。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-02fdc9375a9d6af62ac6c2035b5a9730_720w.jpg" alt="">&lt;/p>
&lt;p>如果是第一阶段的Query Phase请求，则会调用SearchService的executeQueryPhase方法。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-be3a37c7fe08d4f1559b9eb0aaa8d37a_720w.jpg" alt="">&lt;/p>
&lt;p>如果是第二阶段的Fetch Phase请求，则会调用SearchService的executeFetchPhase方法。&lt;/p>
&lt;h2 id="client-node">&lt;strong>Client Node&lt;/strong>&lt;/h2>
&lt;p>Client Node 也包括了前面说过的Parse Request，这里就不再赘述了，接下来看一下其他的部分。&lt;/p>
&lt;p>&lt;strong>1. Get Remove Cluster Shard&lt;/strong>&lt;/p>
&lt;p>判断是否需要跨集群访问，如果需要，则获取到要访问的Shard列表。&lt;/p>
&lt;p>&lt;strong>2. Get Search Shard Iterator&lt;/strong>&lt;/p>
&lt;p>获取当前Cluster中要访问的Shard，和上一步中的Remove Cluster Shard合并，构建出最终要访问的完整Shard列表。&lt;/p>
&lt;p>这一步中，会根据Request请求中的参数从Primary Node和多个Replica Node中选择出一个要访问的Shard。&lt;/p>
&lt;p>&lt;strong>3. For Every Shard:Perform&lt;/strong>&lt;/p>
&lt;p>遍历每个Shard，对每个Shard执行后面逻辑。&lt;/p>
&lt;p>&lt;strong>4. Send Request To Query Shard&lt;/strong>&lt;/p>
&lt;p>将查询阶段请求发送给相应的Shard。&lt;/p>
&lt;p>&lt;strong>5. Merge Docs&lt;/strong>&lt;/p>
&lt;p>上一步将请求发送给多个Shard后，这一步就是异步等待返回结果，然后对结果合并。这里的合并策略是维护一个Top N大小的优先级队列，每当收到一个shard的返回，就把结果放入优先级队列做一次排序，直到所有的Shard都返回。&lt;/p>
&lt;p>翻页逻辑也是在这里，如果需要取Top 30~ Top 40的结果，这个的意思是所有Shard查询结果中的第30到40的结果，那么在每个Shard中无法确定最终的结果，每个Shard需要返回Top 40的结果给Client Node，然后Client Node中在merge docs的时候，计算出Top 40的结果，最后再去除掉Top 30，剩余的10个结果就是需要的Top 30~ Top 40的结果。&lt;/p>
&lt;p>上述翻页逻辑有一个明显的缺点就是每次Shard返回的数据中包括了已经翻过的历史结果，如果翻页很深，则在这里需要排序的Docs会很多，比如Shard有1000，取第9990到10000的结果，那么这次查询，Shard总共需要返回1000 * 10000，也就是一千万Doc，这种情况很容易导致OOM。&lt;/p>
&lt;p>另一种翻页方式是使用search_after，这种方式会更轻量级，如果每次只需要返回10条结构，则每个Shard只需要返回search_after之后的10个结果即可，返回的总数据量只是和Shard个数以及本次需要的个数有关，和历史已读取的个数无关。这种方式更安全一些，推荐使用这种。&lt;/p>
&lt;p>如果有aggregate，也会在这里做聚合，但是不同的aggregate类型的merge策略不一样，具体的可以在后面的aggregate文章中再介绍。&lt;/p>
&lt;p>&lt;strong>6. Send Request To Fetch Shard&lt;/strong>&lt;/p>
&lt;p>选出Top N个Doc ID后发送给这些Doc ID所在的Shard执行Fetch Phase，最后会返回Top N的Doc的内容。&lt;/p>
&lt;h2 id="query-phase">Query Phase&lt;/h2>
&lt;p>接下来我们看第一阶段查询的步骤：&lt;/p>
&lt;p>&lt;strong>1. Create Search Context&lt;/strong>&lt;/p>
&lt;p>创建Search Context，之后Search过程中的所有中间状态都会存在Context中，这些状态总共有50多个，具体可以查看DefaultSearchContext或者其他SearchContext的子类。&lt;/p>
&lt;p>&lt;strong>2. Parse Query&lt;/strong>&lt;/p>
&lt;p>解析Query的Source，将结果存入Search Context。这里会根据请求中Query类型的不同创建不同的Query对象，比如TermQuery、FuzzyQuery等，最终真正执行TermQuery、FuzzyQuery等语义的地方是在Lucene中。&lt;/p>
&lt;p>这里包括了dfsPhase、queryPhase和fetchPhase三个阶段的preProcess部分，只有queryPhase的preProcess中有执行逻辑，其他两个都是空逻辑，执行完preProcess后，所有需要的参数都会设置完成。&lt;/p>
&lt;p>由于Elasticsearch中有些请求之间是相互关联的，并非独立的，比如scroll请求，所以这里同时会设置Context的生命周期。&lt;/p>
&lt;p>同时会设置lowLevelCancellation是否打开，这个参数是集群级别配置，同时也能动态开关，打开后会在后面执行时做更多的检测，检测是否需要停止后续逻辑直接返回。&lt;/p>
&lt;p>&lt;strong>3. Get From Cache&lt;/strong>&lt;/p>
&lt;p>判断请求是否允许被Cache，如果允许，则检查Cache中是否已经有结果，如果有则直接读取Cache，如果没有则继续执行后续步骤，执行完后，再将结果加入Cache。&lt;/p>
&lt;p>&lt;strong>4. Add Collectors&lt;/strong>&lt;/p>
&lt;p>Collector主要目标是收集查询结果，实现排序，对自定义结果集过滤和收集等。这一步会增加多个Collectors，多个Collector组成一个List。&lt;/p>
&lt;ol>
&lt;li>FilteredCollector*：*先判断请求中是否有Post Filter，Post Filter用于Search，Agg等结束后再次对结果做Filter，希望Filter不影响Agg结果。如果有Post Filter则创建一个FilteredCollector，加入Collector List中。&lt;/li>
&lt;li>PluginInMultiCollector：判断请求中是否制定了自定义的一些Collector，如果有，则创建后加入Collector List。&lt;/li>
&lt;li>MinimumScoreCollector：判断请求中是否制定了最小分数阈值，如果指定了，则创建MinimumScoreCollector加入Collector List中，在后续收集结果时，会过滤掉得分小于最小分数的Doc。&lt;/li>
&lt;li>EarlyTerminatingCollector：判断请求中是否提前结束Doc的Seek，如果是则创建EarlyTerminatingCollector，加入Collector List中。在后续Seek和收集Doc的过程中，当Seek的Doc数达到Early Terminating后会停止Seek后续倒排链。&lt;/li>
&lt;li>CancellableCollector：判断当前操作是否可以被中断结束，比如是否已经超时等，如果是会抛出一个TaskCancelledException异常。该功能一般用来提前结束较长的查询请求，可以用来保护系统。&lt;/li>
&lt;li>EarlyTerminatingSortingCollector：如果Index是排序的，那么可以提前结束对倒排链的Seek，相当于在一个排序递减链表上返回最大的N个值，只需要直接返回前N个值就可以了。这个Collector会加到Collector List的头部。EarlyTerminatingSorting和EarlyTerminating的区别是，EarlyTerminatingSorting是一种对结果无损伤的优化，而EarlyTerminating是有损的，人为掐断执行的优化。&lt;/li>
&lt;li>TopDocsCollector：这个是最核心的Top N结果选择器，会加入到Collector List的头部。TopScoreDocCollector和TopFieldCollector都是TopDocsCollector的子类，TopScoreDocCollector会按照固定的方式算分，排序会按照分数+doc id的方式排列，如果多个doc的分数一样，先选择doc id小的文档。而TopFieldCollector则是根据用户指定的Field的值排序。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>5. lucene::search&lt;/strong>&lt;/p>
&lt;p>这一步会调用Lucene中IndexSearch的search接口，执行真正的搜索逻辑。每个Shard中会有多个Segment，每个Segment对应一个LeafReaderContext，这里会遍历每个Segment，到每个Segment中去Search结果，然后计算分数。&lt;/p>
&lt;p>搜索里面一般有两阶段算分，第一阶段是在这里算的，会对每个Seek到的Doc都计算分数，为了减少CPU消耗，一般是算一个基本分数。这一阶段完成后，会有个排序。然后在第二阶段，再对Top 的结果做一次二阶段算分，在二阶段算分的时候会考虑更多的因子。二阶段算分在后续操作中。&lt;/p>
&lt;p>具体请求，比如TermQuery、WildcardQuery的查询逻辑都在Lucene中，后面会有专门文章介绍。&lt;/p>
&lt;p>&lt;strong>6. rescore&lt;/strong>&lt;/p>
&lt;p>根据Request中是否包含rescore配置决定是否进行二阶段排序，如果有则执行二阶段算分逻辑，会考虑更多的算分因子。二阶段算分也是一种计算机中常见的多层设计，是一种资源消耗和效率的折中。&lt;/p>
&lt;p>Elasticsearch中支持配置多个Rescore，这些rescore逻辑会顺序遍历执行。每个rescore内部会先按照请求参数window选择出Top window的doc，然后对这些doc排序，排完后再合并回原有的Top 结果顺序中。&lt;/p>
&lt;p>&lt;strong>7. suggest::execute()&lt;/strong>&lt;/p>
&lt;p>如果有推荐请求，则在这里执行推荐请求。如果请求中只包含了推荐的部分，则很多地方可以优化。推荐不是今天的重点，这里就不介绍了，后面有机会再介绍。&lt;/p>
&lt;p>&lt;strong>8. aggregation::execute()&lt;/strong>&lt;/p>
&lt;p>如果含有聚合统计请求，则在这里执行。Elasticsearch中的aggregate的处理逻辑也类似于Search，通过多个Collector来实现。在Client Node中也需要对aggregation做合并。aggregate逻辑更复杂一些，就不在这里赘述了，后面有需要就再单独开文章介绍。&lt;/p>
&lt;p>上述逻辑都执行完成后，如果当前查询请求只需要查询一个Shard，那么会直接在当前Node执行Fetch Phase。&lt;/p>
&lt;h2 id="fetch-phase">Fetch Phase&lt;/h2>
&lt;p>Elasticsearch作为搜索系统时，或者任何搜索系统中，除了Query阶段外，还会有一个Fetch阶段，这个Fetch阶段在数据库类系统中是没有的，是搜索系统中额外增加的阶段。搜索系统中额外增加Fetch阶段的原因是搜索系统中数据分布导致的，在搜索中，数据通过routing分Shard的时候，只能根据一个主字段值来决定，但是查询的时候可能会根据其他非主字段查询，那么这个时候所有Shard中都可能会存在相同非主字段值的Doc，所以需要查询所有Shard才能不会出现结果遗漏。同时如果查询主字段，那么这个时候就能直接定位到Shard，就只需要查询特定Shard即可，这个时候就类似于数据库系统了。另外，数据库中的二级索引又是另外一种情况，但类似于查主字段的情况，这里就不多说了。&lt;/p>
&lt;p>基于上述原因，第一阶段查询的时候并不知道最终结果会在哪个Shard上，所以每个Shard中管都需要查询完整结果，比如需要Top 10，那么每个Shard都需要查询当前Shard的所有数据，找出当前Shard的Top 10，然后返回给Client Node。如果有100个Shard，那么就需要返回100 * 10 = 1000个结果，而Fetch Doc内容的操作比较耗费IO和CPU，如果在第一阶段就Fetch Doc，那么这个资源开销就会非常大。所以，一般是当Client Node选择出最终Top N的结果后，再对最终的Top N读取Doc内容。通过增加一点网络开销而避免大量IO和CPU操作，这个折中是非常划算的。&lt;/p>
&lt;p>Fetch阶段的目的是通过DocID获取到用户需要的完整Doc内容。这些内容包括了DocValues，Store，Source，Script和Highlight等，具体的功能点是在SearchModule中注册的，系统默认注册的有：&lt;/p>
&lt;ul>
&lt;li>ExplainFetchSubPhase&lt;/li>
&lt;li>DocValueFieldsFetchSubPhase&lt;/li>
&lt;li>ScriptFieldsFetchSubPhase&lt;/li>
&lt;li>FetchSourceSubPhase&lt;/li>
&lt;li>VersionFetchSubPhase&lt;/li>
&lt;li>MatchedQueriesFetchSubPhase&lt;/li>
&lt;li>HighlightPhase&lt;/li>
&lt;li>ParentFieldSubFetchPhase&lt;/li>
&lt;/ul>
&lt;p>除了系统默认的8种外，还有通过插件的形式注册自定义的功能，这些SubPhase中最重要的是Source和Highlight，Source是加载原文，Highlight是计算高亮显示的内容片断。&lt;/p>
&lt;p>上述多个SubPhase会针对每个Doc顺序执行，可能会产生多次的随机IO，这里会有一些优化方案，但是都是针对特定场景的，不具有通用性。&lt;/p>
&lt;p>Fetch Phase执行完后，整个查询流程就结束了。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Elasticsearch中的查询流程比较简单，更多的查询原理都在Lucene中，后续我们会有针对不同请求的Lucene原理介绍性文章。&lt;/p></description></item><item><title>Elasticsearch写流程</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</guid><description>&lt;h1 id="elasticsearch写流程">Elasticsearch写流程&lt;/h1>
&lt;h2 id="lucene的写操作及其问题">lucene的写操作及其问题&lt;/h2>
&lt;p>Elasticsearch底层使用Lucene来实现doc的读写操作，Lucene通过&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">addDocument&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">deleteDocuments&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">updateDocument&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>三个方法来实现文档的写入，更新和删除操作。但是存在如下问题&lt;/p>
&lt;ol>
&lt;li>&lt;strong>没有并发设计&lt;/strong>。 lucene只是一个搜索引擎库，并没有涉及到分布式相关的设计，因此要想使用Lucene来处理海量数据，并利用分布式的能力，就必须在其之上进行分布式的相关设计。&lt;/li>
&lt;li>&lt;strong>非实时&lt;/strong>。 将文件写入lucence后并不能立即被检索，需要等待lucene生成一个完整的segment才能被检索&lt;/li>
&lt;li>&lt;strong>数据存储不可靠&lt;/strong>。 写入lucene的数据不会立即被持久化到磁盘，如果服务器宕机，那存储在内存中的数据将会丢失&lt;/li>
&lt;li>&lt;strong>不支持部分更新&lt;/strong> 。lucene中提供的updateDocuments仅支持对文档的全量更新，对部分更新不支持&lt;/li>
&lt;/ol>
&lt;h2 id="2-elasticsearch的写入方案">2. Elasticsearch的写入方案&lt;/h2>
&lt;p>针对Lucene的问题，ES做了如下设计&lt;/p>
&lt;h3 id="21-分布式设计">2.1 分布式设计：&lt;/h3>
&lt;p>为了支持对海量数据的存储和查询，Elasticsearch引入分片的概念，一个索引被分成多个分片，每个分片可以有一个主分片和多个副本分片，每个分片副本都是一个具有完整功能的lucene实例。分片可以分配在不同的服务器上，同一个分片的不同副本不能分配在相同的服务器上。&lt;/p>
&lt;p>在进行写操作时，ES会根据传入的_routing参数（或mapping中设置的_routing, 如果参数和设置中都没有则默认使用_id), 按照公式 &lt;code>shard_num=hash(\routing)%num_primary_shards&lt;/code>,计算出文档要分配到的分片，在从集群元数据中找出对应主分片的位置，将请求路由到该分片进行文档写操作。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-8ce7b65ede7b511a2d6d02530ed501d6_720w.jpg" alt="">&lt;/p>
&lt;h3 id="22-近实时性-refresh操作">2.2 近实时性-refresh操作&lt;/h3>
&lt;p>当一个文档写入Lucene后是不能被立即查询到的，Elasticsearch提供了一个refresh操作，会定时地调用lucene的reopen(新版本为openIfChanged)为内存中新写入的数据生成一个新的segment，此时被处理的文档均可以被检索到。refresh操作的时间间隔由 &lt;code>refresh_interval&lt;/code>参数控制，默认为1s, 当然还可以在写入请求中带上refresh表示写入后立即refresh，另外还可以调用refresh API显式refresh。&lt;/p>
&lt;h3 id="23-数据存储可靠性">2.3 数据存储可靠性&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>引入translog&lt;/strong> 当一个文档写入Lucence后是存储在内存中的，即使执行了refresh操作仍然是在文件系统缓存中，如果此时服务器宕机，那么这部分数据将会丢失。为此ES增加了translog， 当进行文档写操作时会先将文档写入Lucene，然后写入一份到translog，写入translog是落盘的(如果对可靠性要求不是很高，也可以设置异步落盘，可以提高性能，由配置 &lt;code>index.translog.durability&lt;/code>和 &lt;code>index.translog.sync_interval&lt;/code>控制)，这样就可以防止服务器宕机后数据的丢失。由于translog是追加写入，因此性能要比随机写入要好。与传统的分布式系统不同，这里是先写入Lucene再写入translog，原因是写入Lucene可能会失败，为了减少写入失败回滚的复杂度，因此先写入Lucene.&lt;/li>
&lt;li>&lt;strong>flush操作&lt;/strong> 另外每30分钟或当translog达到一定大小(由 &lt;code>index.translog.flush_threshold_size&lt;/code>控制，默认512mb), ES会触发一次flush操作，此时ES会先执行refresh操作将buffer中的数据生成segment，然后调用lucene的commit方法将所有内存中的segment fsync到磁盘。此时lucene中的数据就完成了持久化，会清空translog中的数据(6.x版本为了实现sequenceIDs,不删除translog)&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-9418f89986e3a141b3acf83cf158885a_720w.jpg" alt="">&lt;/p>
&lt;ol>
&lt;li>&lt;strong>merge操作&lt;/strong> 由于refresh默认间隔为1s中，因此会产生大量的小segment，为此ES会运行一个任务检测当前磁盘中的segment，对符合条件的segment进行合并操作，减少lucene中的segment个数，提高查询速度，降低负载。不仅如此，merge过程也是文档删除和更新操作后，旧的doc真正被删除的时候。用户还可以手动调用_forcemerge API来主动触发merge，以减少集群的segment个数和清理已删除或更新的文档。&lt;/li>
&lt;li>&lt;strong>多副本机制&lt;/strong> 另外ES有多副本机制，一个分片的主副分片不能分片在同一个节点上，进一步保证数据的可靠性。&lt;/li>
&lt;/ol>
&lt;h3 id="24-部分更新">2.4 部分更新&lt;/h3>
&lt;p>lucene仅支持对文档的整体更新，ES为了支持局部更新，在Lucene的Store索引中存储了一个_source字段，该字段的key值是文档ID， 内容是文档的原文。当进行更新操作时先从_source中获取原文，与更新部分合并后，再调用lucene API进行全量更新， 对于写入了ES但是还没有refresh的文档，可以从translog中获取。另外为了防止读取文档过程后执行更新前有其他线程修改了文档，ES增加了版本机制，当执行更新操作时发现当前文档的版本与预期不符，则会重新获取文档再更新。&lt;/p>
&lt;h2 id="3-es的写入流程">3. ES的写入流程&lt;/h2>
&lt;p>ES的任意节点都可以作为协调节点(coordinating node)接受请求，当协调节点接受到请求后进行一系列处理，然后通过_routing字段找到对应的primary shard，并将请求转发给primary shard, primary shard完成写入后，将写入并发发送给各replica， raplica执行写入操作后返回给primary shard， primary shard再将请求返回给协调节点。大致流程如下图：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-b0b0c96aaeadfde4da0685dae4b9908f_720w.jpg" alt="">&lt;/p>
&lt;h3 id="31-coordinating节点">3.1 coordinating节点&lt;/h3>
&lt;p>ES中接收并转发请求的节点称为coordinating节点，ES中所有节点都可以接受并转发请求。当一个节点接受到写请求或更新请求后，会执行如下操作：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>ingest pipeline&lt;/strong> 查看该请求是否符合某个ingest pipeline的pattern, 如果符合则执行pipeline中的逻辑，一般是对文档进行各种预处理，如格式调整，增加字段等。如果当前节点没有ingest角色，则需要将请求转发给有ingest角色的节点执行。&lt;/li>
&lt;li>&lt;strong>自动创建索引&lt;/strong> 判断索引是否存在，如果开启了自动创建则自动创建，否则报错&lt;/li>
&lt;li>&lt;strong>设置routing&lt;/strong> 获取请求URL或mapping中的_routing，如果没有则使用_id, 如果没有指定_id则ES会自动生成一个全局唯一ID。该_routing字段用于决定文档分配在索引的哪个shard上。&lt;/li>
&lt;li>&lt;strong>构建BulkShardRequest&lt;/strong> 由于Bulk Request中包含多种(Index/Update/Delete)请求，这些请求分别需要到不同的shard上执行，因此协调节点，会将请求按照shard分开，同一个shard上的请求聚合到一起，构建BulkShardRequest&lt;/li>
&lt;li>&lt;strong>将请求发送给primary shard&lt;/strong> 因为当前执行的是写操作，因此只能在primary上完成，所以需要把请求路由到primary shard所在节点&lt;/li>
&lt;li>&lt;strong>等待primary shard返回&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>目前的Elasticsearch有两个明显的身份，一个是分布式搜索系统，另一个是分布式NoSQL数据库，对于这两种不同的身份，读写语义基本类似，但也有一点差异。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-aced78c779161b2a5baa366f63d86883_720w.jpg" alt="">&lt;/p>
&lt;h2 id="写操作">&lt;strong>写操作&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>实时性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>搜索系统的Index一般都是NRT（Near Real Time），近实时的，比如Elasticsearch中，Index的实时性是由refresh控制的，默认是1s，最快可到100ms，那么也就意味着Index doc成功后，需要等待一秒钟后才可以被搜索到。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NoSQL数据库的Write基本都是RT（Real Time），实时的，写入成功后，立即是可见的。Elasticsearch中的Index请求也能保证是实时的，因为Get请求会直接读内存中尚未Flush到存储介质的TransLog。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>可靠性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>搜索系统对可靠性要求都不高，一般数据的可靠性通过将原始数据存储在另一个存储系统来保证，当搜索系统的数据发生丢失时，再从其他存储系统导一份数据过来重新rebuild就可以了。在Elasticsearch中，通过设置TransLog的Flush频率可以控制可靠性，要么是按请求，每次请求都Flush；要么是按时间，每隔一段时间Flush一次。一般为了性能考虑，会设置为每隔5秒或者1分钟Flush一次，Flush间隔时间越长，可靠性就会越低。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NoSQL数据库作为一款数据库，必须要有很高的可靠性，数据可靠性是生命底线，决不能有闪失。如果把Elasticsearch当做NoSQL数据库，此时需要设置TransLog的Flush策略为每个请求都要Flush，这样才能保证当前Shard写入成功后，数据能尽量持久化下来。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>上面简单介绍了下NoSQL数据库和搜索系统的一些异同，我们会在后面有一篇文章，专门用来介绍Elasticsearch作为NoSQL数据库时的一些局限和特点。&lt;/p>
&lt;h2 id="读操作">读操作&lt;/h2>
&lt;p>下一篇《Elasticsearch内核解析 - 查询篇》中再详细介绍。&lt;/p>
&lt;p>上面大概对比了下搜索和NoSQL在写方面的特点，接下来，我们看一下Elasticsearch 6.0.0版本中写入流程都做了哪些事情，希望能对大家有用。&lt;/p>
&lt;h2 id="关键点">&lt;strong>关键点&lt;/strong>&lt;/h2>
&lt;p>在考虑或分析一个分布式系统的写操作时，一般需要从下面几个方面考虑：&lt;/p>
&lt;ul>
&lt;li>可靠性：或者是持久性，数据写入系统成功后，数据不会被回滚或丢失。&lt;/li>
&lt;li>一致性：数据写入成功后，再次查询时必须能保证读取到最新版本的数据，不能读取到旧数据。&lt;/li>
&lt;li>原子性：一个写入或者更新操作，要么完全成功，要么完全失败，不允许出现中间状态。&lt;/li>
&lt;li>隔离性：多个写入操作相互不影响。&lt;/li>
&lt;li>实时性：写入后是否可以立即被查询到。&lt;/li>
&lt;li>性能：写入性能，吞吐量到底怎么样。&lt;/li>
&lt;/ul>
&lt;p>Elasticsearch作为分布式系统，也需要在写入的时候满足上述的四个特点，我们在后面的写流程介绍中会涉及到上述四个方面。&lt;/p>
&lt;p>接下来,我们一层一层剖析Elasticsearch内部的写机制。&lt;/p>
&lt;h2 id="lucene的写">&lt;strong>Lucene的写&lt;/strong>&lt;/h2>
&lt;p>众所周知，Elasticsearch内部使用了Lucene完成索引创建和搜索功能，Lucene中写操作主要是通过IndexWriter类实现，IndexWriter提供三个接口：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">addDocument&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">updateDocuments&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">deleteDocuments&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>通过这三个接口可以完成单个文档的写入，更新和删除功能，包括了分词，倒排创建，正排创建等等所有搜索相关的流程。只要Doc通过IndesWriter写入后，后面就可以通过IndexSearcher搜索了，看起来功能已经完善了，但是仍然有一些问题没有解：&lt;/p>
&lt;ol>
&lt;li>上述操作是单机的，而不是我们需要的分布式。&lt;/li>
&lt;li>文档写入Lucene后并不是立即可查询的，需要生成完整的Segment后才可被搜索，如何保证实时性？&lt;/li>
&lt;li>Lucene生成的Segment是在内存中，如果机器宕机或掉电后，内存中的Segment会丢失，如何保证数据可靠性 ？&lt;/li>
&lt;li>Lucene不支持部分文档更新，但是这又是一个强需求，如何支持部分更新？&lt;/li>
&lt;/ol>
&lt;p>上述问题，在Lucene中是没有解决的，那么就需要Elasticsearch中解决上述问题。&lt;/p>
&lt;p>Elasticsearch在解决上述问题时，除了我们在上一篇《Elasticsearch数据模型简介》中介绍的几种系统字段外，在引擎架构上也引入了多重机制来解决问题。我们再来看Elasticsearch中的写机制。&lt;/p>
&lt;h2 id="elasticsearch的写">&lt;strong>Elasticsearch的写&lt;/strong>&lt;/h2>
&lt;p>Elasticsearch采用多Shard方式，通过配置routing规则将数据分成多个数据子集，每个数据子集提供独立的索引和搜索功能。当写入文档的时候，根据routing规则，将文档发送给特定Shard中建立索引。这样就能实现分布式了。&lt;/p>
&lt;p>此外，Elasticsearch整体架构上采用了一主多副的方式：&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-8203d235d8cfc14849012e6ea229fa89_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch一主多副&lt;/p>
&lt;p>每个Index由多个Shard组成，每个Shard有一个主节点和多个副本节点，副本个数可配。但每次写入的时候，写入请求会先根据_routing规则选择发给哪个Shard，Index Request中可以设置使用哪个Filed的值作为路由参数，如果没有设置，则使用Mapping中的配置，如果mapping中也没有配置，则使用_id作为路由参数，然后通过_routing的Hash值选择出Shard（在OperationRouting类中），最后从集群的Meta中找出出该Shard的Primary节点。&lt;/p>
&lt;p>请求接着会发送给Primary Shard，在Primary Shard上执行成功后，再从Primary Shard上将请求同时发送给多个Replica Shard，请求在多个Replica Shard上执行成功并返回给Primary Shard后，写入请求执行成功，返回结果给客户端。&lt;/p>
&lt;p>这种模式下，写入操作的延时就等于latency = Latency(Primary Write) + Max(Replicas Write)。只要有副本在，写入延时最小也是两次单Shard的写入时延总和，写入效率会较低，但是这样的好处也很明显，避免写入后，单机或磁盘故障导致数据丢失，在数据重要性和性能方面，一般都是优先选择数据，除非一些允许丢数据的特殊场景。&lt;/p>
&lt;p>采用多个副本后，避免了单机或磁盘故障发生时，对已经持久化后的数据造成损害，但是Elasticsearch里为了减少磁盘IO保证读写性能，一般是每隔一段时间（比如5分钟）才会把Lucene的Segment写入磁盘持久化，对于写入内存，但还未Flush到磁盘的Lucene数据，如果发生机器宕机或者掉电，那么内存中的数据也会丢失，这时候如何保证？&lt;/p>
&lt;p>对于这种问题，Elasticsearch学习了数据库中的处理方式：增加CommitLog模块，Elasticsearch中叫TransLog。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-20a780ddd33a74b37a81e18d3baf8983_720w.jpg" alt="">&lt;/p>
&lt;p>Refresh &amp;amp;&amp;amp; Flush&lt;/p>
&lt;p>在每一个Shard中，写入流程分为两部分，先写入Lucene，再写入TransLog。&lt;/p>
&lt;p>写入请求到达Shard后，先写Lucene文件，创建好索引，此时索引还在内存里面，接着去写TransLog，写完TransLog后，刷新TransLog数据到磁盘上，写磁盘成功后，请求返回给用户。这里有几个关键点，一是和数据库不同，数据库是先写CommitLog，然后再写内存，而Elasticsearch是先写内存，最后才写TransLog，一种可能的原因是Lucene的内存写入会有很复杂的逻辑，很容易失败，比如分词，字段长度超过限制等，比较重，为了避免TransLog中有大量无效记录，减少recover的复杂度和提高速度，所以就把写Lucene放在了最前面。二是写Lucene内存后，并不是可被搜索的，需要通过Refresh把内存的对象转成完整的Segment后，然后再次reopen后才能被搜索，一般这个时间设置为1秒钟，导致写入Elasticsearch的文档，最快要1秒钟才可被从搜索到，所以Elasticsearch在搜索方面是NRT（Near Real Time）近实时的系统。三是当Elasticsearch作为NoSQL数据库时，查询方式是GetById，这种查询可以直接从TransLog中查询，这时候就成了RT（Real Time）实时系统。四是每隔一段比较长的时间，比如30分钟后，Lucene会把内存中生成的新Segment刷新到磁盘上，刷新后索引文件已经持久化了，历史的TransLog就没用了，会清空掉旧的TransLog。&lt;/p>
&lt;p>上面介绍了Elasticsearch在写入时的两个关键模块，Replica和TransLog，接下来，我们看一下Update流程：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-e728bc042a75f8798925d708dc61b1ef_720w.jpg" alt="">&lt;/p>
&lt;p>Update&lt;/p>
&lt;p>Lucene中不支持部分字段的Update，所以需要在Elasticsearch中实现该功能，具体流程如下：&lt;/p>
&lt;ol>
&lt;li>收到Update请求后，从Segment或者TransLog中读取同id的完整Doc，记录版本号为V1。&lt;/li>
&lt;li>将版本V1的全量Doc和请求中的部分字段Doc合并为一个完整的Doc，同时更新内存中的VersionMap。获取到完整Doc后，Update请求就变成了Index请求。&lt;/li>
&lt;li>加锁。&lt;/li>
&lt;li>再次从versionMap中读取该id的最大版本号V2，如果versionMap中没有，则从Segment或者TransLog中读取，这里基本都会从versionMap中获取到。&lt;/li>
&lt;li>检查版本是否冲突(V1==V2)，如果冲突，则回退到开始的“Update doc”阶段，重新执行。如果不冲突，则执行最新的Add请求。&lt;/li>
&lt;li>在Index Doc阶段，首先将Version + 1得到V3，再将Doc加入到Lucene中去，Lucene中会先删同id下的已存在doc id，然后再增加新Doc。写入Lucene成功后，将当前V3更新到versionMap中。&lt;/li>
&lt;li>释放锁，部分更新的流程就结束了。&lt;/li>
&lt;/ol>
&lt;p>介绍完部分更新的流程后，大家应该从整体架构上对Elasticsearch的写入有了一个初步的映象，接下来我们详细剖析下写入的详细步骤。&lt;/p>
&lt;h2 id="elasticsearch写入请求类型">&lt;strong>Elasticsearch写入请求类型&lt;/strong>&lt;/h2>
&lt;p>Elasticsearch中的写入请求类型，主要包括下列几个：Index(Create)，Update，Delete和Bulk，其中前3个是单文档操作，后一个Bulk是多文档操作，其中Bulk中可以包括Index(Create)，Update和Delete。&lt;/p>
&lt;p>在6.0.0及其之后的版本中，前3个单文档操作的实现基本都和Bulk操作一致，甚至有些就是通过调用Bulk的接口实现的。估计接下来几个版本后，Index(Create)，Update，Delete都会被当做Bulk的一种特例化操作被处理。这样，代码和逻辑都会更清晰一些。&lt;/p>
&lt;p>下面，我们就以Bulk请求为例来介绍写入流程。&lt;/p>
&lt;h2 id="elasticsearch写入流程图">&lt;strong>Elasticsearch写入流程图&lt;/strong>&lt;/h2>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-4e32cd77e69ae4932665d110d6bf13a1_720w.jpg" alt="">&lt;/p>
&lt;p>写入流程图&lt;/p>
&lt;ul>
&lt;li>红色：Client Node。&lt;/li>
&lt;li>绿色：Primary Node。&lt;/li>
&lt;li>蓝色：Replica Node。&lt;/li>
&lt;/ul>
&lt;h2 id="注册action">&lt;strong>注册Action&lt;/strong>&lt;/h2>
&lt;p>在Elasticsearch中，所有action的入口处理方法都是注册在ActionModule.java中，比如Bulk Request有两个注册入口，分别是Rest和Transport入口：&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-7506f5d87f80ec63cbd2030b785441ec_720w.jpg" alt="">&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-ac3d0e6ee82d507d38110565d121febf_720w.jpg" alt="">&lt;/p>
&lt;p>如果请求是Rest请求，则会在RestBulkAction中Parse Request，构造出BulkRequest，然后发给后面的TransportAction处理。&lt;/p>
&lt;p>TransportShardBulkAction的基类TransportReplicationAction中注册了对Primary，Replica等的不同处理入口:&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-4ac69cd72079de47adfb2d81906579db_720w.jpg" alt="">&lt;/p>
&lt;p>这里对原始请求，Primary Node请求和Replica Node请求各自注册了一个handler处理入口。&lt;/p>
&lt;h2 id="client-node">&lt;strong>Client Node&lt;/strong>&lt;/h2>
&lt;p>Client Node 也包括了前面说过的Parse Request，这里就不再赘述了，接下来看一下其他的部分。&lt;/p>
&lt;p>&lt;strong>1. Ingest Pipeline&lt;/strong>&lt;/p>
&lt;p>在这一步可以对原始文档做一些处理，比如HTML解析，自定义的处理，具体处理逻辑可以通过插件来实现。在Elasticsearch中，由于Ingest Pipeline会比较耗费CPU等资源，可以设置专门的Ingest Node，专门用来处理Ingest Pipeline逻辑。&lt;/p>
&lt;p>如果当前Node不能执行Ingest Pipeline，则会将请求发给另一台可以执行Ingest Pipeline的Node。&lt;/p>
&lt;p>&lt;strong>2. Auto Create Index&lt;/strong>&lt;/p>
&lt;p>判断当前Index是否存在，如果不存在，则需要自动创建Index，这里需要和Master交互。也可以通过配置关闭自动创建Index的功能。&lt;/p>
&lt;p>&lt;strong>3. Set Routing&lt;/strong>&lt;/p>
&lt;p>设置路由条件，如果Request中指定了路由条件，则直接使用Request中的Routing，否则使用Mapping中配置的，如果Mapping中无配置，则使用默认的_id字段值。&lt;/p>
&lt;p>在这一步中，如果没有指定&lt;em>id字段，则会自动生成一个唯一的_id字段，目前使用的是UUID。&lt;/em>&lt;/p>
&lt;p>&lt;em>&lt;strong>4. Construct BulkShardRequest&lt;/strong>&lt;/em>&lt;/p>
&lt;p>&lt;em>由于Bulk Request中会包括多个(Index/Update/Delete)请求，这些请求根据routing可能会落在多个Shard上执行，这一步会按Shard挑拣Single Write Request，同一个Shard中的请求聚集在一起，构建BulkShardRequest，每个BulkShardRequest对应一个Shard。&lt;/em>&lt;/p>
&lt;p>&lt;em>&lt;strong>5. Send Request To Primary&lt;/strong>&lt;/em>&lt;/p>
&lt;p>&lt;em>这一步会将每一个BulkShardRequest请求发送给相应Shard的Primary Node。&lt;/em>&lt;/p>
&lt;h2 id="primary-node">&lt;strong>Primary Node&lt;/strong>&lt;/h2>
&lt;p>Primary 请求的入口是在PrimaryOperationTransportHandler的messageReceived，我们来看一下相关的逻辑流程。&lt;/p>
&lt;p>&lt;strong>1. Index or Update or Delete&lt;/strong>&lt;/p>
&lt;p>循环执行每个Single Write Request，对于每个Request，根据操作类型(&lt;em>CREATE/INDEX/UPDATE/DELETE&lt;/em>)选择不同的处理逻辑。&lt;/p>
&lt;p>其中，Create/Index是直接新增Doc，Delete是直接根据_id删除Doc，Update会稍微复杂些，我们下面就以Update为例来介绍。&lt;/p>
&lt;p>&lt;strong>2. Translate Update To Index or Delete&lt;/strong>&lt;/p>
&lt;p>这一步是Update操作的特有步骤，在这里，会将Update请求转换为Index或者Delete请求。首先，会通过GetRequest查询到已经存在的同_id Doc（如果有）的完整字段和值（依赖_source字段），然后和请求中的Doc合并。同时，这里会获取到读到的Doc版本号，记做V1。&lt;/p>
&lt;p>&lt;strong>3. Parse Doc&lt;/strong>&lt;/p>
&lt;p>这里会解析Doc中各个字段。生成ParsedDocument对象，同时会生成uid Term。在Elasticsearch中，_uid = type # _id，对用户，_Id可见，而Elasticsearch中存储的是_uid。这一部分生成的ParsedDocument中也有Elasticsearch的系统字段，大部分会根据当前内容填充，部分未知的会在后面继续填充ParsedDocument。&lt;/p>
&lt;p>&lt;strong>4. Update Mapping&lt;/strong>&lt;/p>
&lt;p>Elasticsearch中有个自动更新Mapping的功能，就在这一步生效。会先挑选出Mapping中未包含的新Field，然后判断是否运行自动更新Mapping，如果允许，则更新Mapping。&lt;/p>
&lt;p>&lt;strong>5. Get Sequence Id and Version&lt;/strong>&lt;/p>
&lt;p>由于当前是Primary Shard，则会从SequenceNumber Service获取一个sequenceID和Version。SequenceID在Shard级别每次递增1，SequenceID在写入Doc成功后，会用来初始化LocalCheckpoint。Version则是根据当前Doc的最大Version递增1。&lt;/p>
&lt;p>&lt;strong>6. Add Doc To Lucene&lt;/strong>&lt;/p>
&lt;p>这一步开始的时候会给特定_uid加锁，然后判断该_uid对应的Version是否等于之前Translate Update To Index步骤里获取到的Version，如果不相等，则说明刚才读取Doc后，该Doc发生了变化，出现了版本冲突，这时候会抛出一个VersionConflict的异常，该异常会在Primary Node最开始处捕获，重新从“Translate Update To Index or Delete”开始执行。&lt;/p>
&lt;p>如果Version相等，则继续执行，如果已经存在同id的Doc，则会调用Lucene的UpdateDocument(uid, doc)接口，先根据uid删除Doc，然后再Index新Doc。如果是首次写入，则直接调用Lucene的AddDocument接口完成Doc的Index，AddDocument也是通过UpdateDocument实现。&lt;/p>
&lt;p>这一步中有个问题是，如何保证Delete-Then-Add的原子性，怎么避免中间状态时被Refresh？答案是在开始Delete之前，会加一个Refresh Lock，禁止被Refresh，只有等Add完后释放了Refresh Lock后才能被Refresh，这样就保证了Delete-Then-Add的原子性。&lt;/p>
&lt;p>Lucene的UpdateDocument接口中就只是处理多个Field，会遍历每个Field逐个处理，处理顺序是invert index，store field，doc values，point dimension，后续会有文章专门介绍Lucene中的写入。&lt;/p>
&lt;p>&lt;strong>7. Write Translog&lt;/strong>&lt;/p>
&lt;p>写完Lucene的Segment后，会以keyvalue的形式写TransLog，Key是_id，Value是Doc内容。当查询的时候，如果请求是GetDocByID，则可以直接根据_id从TransLog中读取到，满足NoSQL场景下的实时性要去。&lt;/p>
&lt;p>需要注意的是，这里只是写入到内存的TransLog，是否Sync到磁盘的逻辑还在后面。&lt;/p>
&lt;p>这一步的最后，会标记当前SequenceID已经成功执行，接着会更新当前Shard的LocalCheckPoint。&lt;/p>
&lt;p>&lt;strong>8. Renew Bulk Request&lt;/strong>&lt;/p>
&lt;p>这里会重新构造Bulk Request，原因是前面已经将UpdateRequest翻译成了Index或Delete请求，则后续所有Replica中只需要执行Index或Delete请求就可以了，不需要再执行Update逻辑，一是保证Replica中逻辑更简单，性能更好，二是保证同一个请求在Primary和Replica中的执行结果一样。&lt;/p>
&lt;p>&lt;strong>9. Flush Translog&lt;/strong>&lt;/p>
&lt;p>这里会根据TransLog的策略，选择不同的执行方式，要么是立即Flush到磁盘，要么是等到以后再Flush。Flush的频率越高，可靠性越高，对写入性能影响越大。&lt;/p>
&lt;p>&lt;strong>10. Send Requests To Replicas&lt;/strong>&lt;/p>
&lt;p>这里会将刚才构造的新的Bulk Request并行发送给多个Replica，然后等待Replica的返回，这里需要等待所有Replica返回后（可能有成功，也有可能失败），Primary Node才会返回用户。如果某个Replica失败了，则Primary会给Master发送一个Remove Shard请求，要求Master将该Replica Shard从可用节点中移除。&lt;/p>
&lt;p>这里，同时会将SequenceID，PrimaryTerm，GlobalCheckPoint等传递给Replica。&lt;/p>
&lt;p>发送给Replica的请求中，Action Name等于原始ActionName + [R]，这里的R表示Replica。通过这个[R]的不同，可以找到处理Replica请求的Handler。&lt;/p>
&lt;p>&lt;strong>11. Receive Response From Replicas&lt;/strong>&lt;/p>
&lt;p>Replica中请求都处理完后，会更新Primary Node的LocalCheckPoint。&lt;/p>
&lt;h2 id="replica-node">&lt;strong>Replica Node&lt;/strong>&lt;/h2>
&lt;p>Replica 请求的入口是在ReplicaOperationTransportHandler的messageReceived，我们来看一下相关的逻辑流程。&lt;/p>
&lt;p>&lt;strong>1. Index or Delete&lt;/strong>&lt;/p>
&lt;p>根据请求类型是Index还是Delete，选择不同的执行逻辑。这里没有Update，是因为在Primary Node中已经将Update转换成了Index或Delete请求了。&lt;/p>
&lt;p>&lt;strong>2. Parse Doc&lt;/strong>&lt;/p>
&lt;p>&lt;strong>3. Update Mapping&lt;/strong>&lt;/p>
&lt;p>以上都和Primary Node中逻辑一致。&lt;/p>
&lt;p>&lt;strong>4. Get Sequence Id and Version&lt;/strong>&lt;/p>
&lt;p>Primary Node中会生成Sequence ID和Version，然后放入ReplicaRequest中，这里只需要从Request中获取到就行。&lt;/p>
&lt;p>&lt;strong>5. Add Doc To Lucene&lt;/strong>&lt;/p>
&lt;p>由于已经在Primary Node中将部分Update请求转换成了Index或Delete请求，这里只需要处理Index和Delete两种请求，不再需要处理Update请求了。比Primary Node会更简单一些。&lt;/p>
&lt;p>&lt;strong>6. Write Translog&lt;/strong>&lt;/p>
&lt;p>&lt;strong>7. Flush Translog&lt;/strong>&lt;/p>
&lt;p>以上都和Primary Node中逻辑一致。&lt;/p>
&lt;h2 id="最后">&lt;strong>最后&lt;/strong>&lt;/h2>
&lt;p>上面详细介绍了Elasticsearch的写入流程及其各个流程的工作机制，我们在这里再次总结下之前提出的分布式系统中的六大特性：&lt;/p>
&lt;ol>
&lt;li>可靠性：由于Lucene的设计中不考虑可靠性，在Elasticsearch中通过Replica和TransLog两套机制保证数据的可靠性。&lt;/li>
&lt;li>一致性：Lucene中的Flush锁只保证Update接口里面Delete和Add中间不会Flush，但是Add完成后仍然有可能立即发生Flush，导致Segment可读。这样就没法保证Primary和所有其他Replica可以同一时间Flush，就会出现查询不稳定的情况，这里只能实现最终一致性。&lt;/li>
&lt;li>原子性：Add和Delete都是直接调用Lucene的接口，是原子的。当部分更新时，使用Version和锁保证更新是原子的。&lt;/li>
&lt;li>隔离性：仍然采用Version和局部锁来保证更新的是特定版本的数据。&lt;/li>
&lt;li>实时性：使用定期Refresh Segment到内存，并且Reopen Segment方式保证搜索可以在较短时间（比如1秒）内被搜索到。通过将未刷新到磁盘数据记入TransLog，保证对未提交数据可以通过ID实时访问到。&lt;/li>
&lt;li>性能：性能是一个系统性工程，所有环节都要考虑对性能的影响，在Elasticsearch中，在很多地方的设计都考虑到了性能，一是不需要所有Replica都返回后才能返回给用户，只需要返回特定数目的就行；二是生成的Segment现在内存中提供服务，等一段时间后才刷新到磁盘，Segment在内存这段时间的可靠性由TransLog保证；三是TransLog可以配置为周期性的Flush，但这个会给可靠性带来伤害；四是每个线程持有一个Segment，多线程时相互不影响，相互独立，性能更好；五是系统的写入流程对版本依赖较重，读取频率较高，因此采用了versionMap，减少热点数据的多次磁盘IO开销。Lucene中针对性能做了大量的优化。后面我们也会有文章专门介绍Lucene中的优化思路。&lt;/li>
&lt;/ol></description></item><item><title>ElasticSearch基础</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/elasticsearch%E5%9F%BA%E7%A1%80/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/elasticsearch%E5%9F%BA%E7%A1%80/</guid><description>&lt;h1 id="elasticsearch基础">ElasticSearch基础&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Elasticsearch 是一个基于lucene的分布式可扩展的实时搜索和分析引擎。&lt;/p>
&lt;h2 id="特点">特点&lt;/h2>
&lt;ul>
&lt;li>分布式存储&lt;/li>
&lt;li>近实时检索&lt;/li>
&lt;/ul>
&lt;h2 id="核心概念">核心概念&lt;/h2>
&lt;ul>
&lt;li>索引(index)：&lt;/li>
&lt;li>分片(shard):&lt;/li>
&lt;li>分段(segment):&lt;/li>
&lt;li>Translog:&lt;/li>
&lt;/ul>
&lt;h3 id="写流程">写流程&lt;/h3>
&lt;h2 id="常用操作">常用操作&lt;/h2>
&lt;ul>
&lt;li>清空index数据&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1"># create index&lt;/span>
curl -X PUT http://192.168.0.10:20000/test6 --header &lt;span class="s2">&amp;#34;Content-Type: application/json&amp;#34;&lt;/span> -d index.json
cat index.json
&lt;span class="c1"># delete index&lt;/span>
curl -X DELETE http://192.168.0.10:20000/test6
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Elasticsearch数据模型</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid><description>&lt;h1 id="elasticsearch数据模型">Elasticsearch数据模型&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Elasticsearch是一个建立在全文搜索引擎库Apache Lucene 基础上的分布式搜索引擎，先来简单看一下Lucene中的一些数据模型：&lt;/p>
&lt;h2 id="lucene数据模型">Lucene数据模型&lt;/h2>
&lt;p>Lucene中包含了四种基本数据类型，分别是：&lt;/p>
&lt;ul>
&lt;li>Index：索引，由很多的Document组成。&lt;/li>
&lt;li>Document：由很多的Field组成，是Index和Search的最小单位。&lt;/li>
&lt;li>Field：由很多的Term组成，包括Field Name和Field Value。&lt;/li>
&lt;li>Term：由很多的字节组成，可以分词。&lt;/li>
&lt;/ul>
&lt;p>上述四种类型在Elasticsearch中同样存在，意思也一样。&lt;/p>
&lt;p>Lucene中存储的索引主要分为三种类型：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Invert Index：倒排索引，或者简称Index，通过Term可以查询到拥有该Term的文档。可以配置为是否分词，如果分词可以配置不同的分词器。索引存储的时候有多种存储类型，分别是：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DOCS：只存储DocID。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DOCS_AND_FREQS：存储DocID和词频（Term Freq）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DOCS_AND_FREQS_AND_POSITIONS：存储DocID、词频（Term Freq）和位置。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS：存储DocID、词频（Term Freq）、位置和偏移。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DocValues：正排索引，采用列式存储。通过DocID可以快速读取到该Doc的特定字段的值。由于是列式存储，性能会比较好。一般用于sort，agg等需要高频读取Doc字段值的场景。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Store：字段原始内容存储，同一篇文章的多个Field的Store会存储在一起，适用于一次读取少量且多个字段内存的场景，比如摘要等。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Lucene中提供索引和搜索的最小组织形式是Segment，Segment中按照索引类型不同，分成了Invert Index，Doc Values和Store这三大类（还有一些辅助类，这里省略），每一类里面都是按照Doc为最小单位存储。Invert Index中存储的Key是Term，Value是Doc ID的链表；Doc Value中Key 是Doc ID和Field Name，Value是Field Value；Store的Key是Doc ID，Value是Filed Name和Filed Value。&lt;/p>
&lt;p>由于Lucene中没有主键概念和更新逻辑，所有对Lucene的更新都是Append一个新Doc，类似于一个只能Append的队列，所有Doc都被同等对等，同样的处理方式。其中的Doc由众多Field组成，没有特殊Field，每个Field也都被同等对待，同样的处理方式。&lt;/p>
&lt;p>从上面介绍来看，Lucene只是提供了一个索引和查询的最基本的功能，距离一个完全可用的完整搜索引擎还有一些距离：&lt;/p>
&lt;h2 id="lucene的不足">Lucene的不足&lt;/h2>
&lt;ol>
&lt;li>Lucene是一个单机的搜索库，如何能以分布式形式支持海量数据?&lt;/li>
&lt;li>Lucene中没有更新，每次都是Append一个新文档，如何做部分字段的更新？&lt;/li>
&lt;li>Lucene中没有主键索引，如何处理同一个Doc的多次写入？&lt;/li>
&lt;li>在稀疏列数据中，如何判断某些文档是否存在特定字段？&lt;/li>
&lt;li>Lucene中生成完整Segment后，该Segment就不能再被更改，此时该Segment才能被搜索，这种情况下，如何做实时搜索？&lt;/li>
&lt;/ol>
&lt;p>上述几个问题，对于搜索而言都是至关重要的功能诉求，我们接下来看看Elasticsearch中是如何来解这些问题的。&lt;/p>
&lt;h2 id="elasticsearch怎么做">Elasticsearch怎么做&lt;/h2>
&lt;p>在Elasticsearch中，为了支持分布式，增加了一个系统字段_routing（路由），通过_routing将Doc分发到不同的Shard，不同的Shard可以位于不同的机器上，这样就能实现简单的分布式了。&lt;/p>
&lt;p>采用类似的方式，Elasticsearch增加了_id、_version、_source和_seq_no等等多个系统字段，通过这些Elasticsearch中特有的系统字段可以有效解决上述的几个问题，新增的系统字段主要是下列几个：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-02d4de08ebd1f37d1b99cc84728f1cf3_720w.jpg" alt="">&lt;/p>
&lt;p>下面我们逐个字段的剖析下上述系统字段的作用，先来看第一个_id字段：&lt;/p>
&lt;h2 id="1-_id">&lt;strong>1. _id&lt;/strong>&lt;/h2>
&lt;p>Doc的主键，在写入的时候，可以指定该Doc的ID值，如果不指定，则系统自动生成一个唯一的UUID值。&lt;/p>
&lt;p>Lucene中没有主键索引，要保证系统中同一个Doc不会重复，Elasticsearch引入了_id字段来实现主键。每次写入的时候都会先查询id，如果有，则说明已经有相同Doc存在了。&lt;/p>
&lt;p>通过_id值（ES内部转换成_uid）可以唯一在Elasticsearch中确定一个Doc。&lt;/p>
&lt;p>Elasticsearch中，_id只是一个用户级别的虚拟字段，在Elasticsearch中并不会映射到Lucene中，所以也就不会存储该字段的值。&lt;/p>
&lt;p>_id的值可以由_uid解析而来（_uid =type + &amp;lsquo;#&amp;rsquo; + id），Elasticsearch中会存储_uid。&lt;/p>
&lt;h2 id="2-_uid">&lt;strong>2. _uid&lt;/strong>&lt;/h2>
&lt;p>_uid的格式是：type + &amp;lsquo;#&amp;rsquo; + id。&lt;/p>
&lt;p>_uid会存储在Lucene中，在Lucene中的映射关系如下：dex下可能存在多个id值相同的Doc，而6.0.0之后只支持单Type，同Index下id值是唯一的。&lt;/p>
&lt;p>uid会存储在Lucene中，在Lucene中的映射关系如下：&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-b854f5d9505615613184bba5fe760088_720w.jpg" alt="">&lt;/p>
&lt;p>_uid 只是存储了倒排Index和原文store：倒排Index的目的是可以通过_id快速查询到文档；原文store用来在返回的Response里面填充完整的_id值。&lt;/p>
&lt;p>在Lucene中存储_uid，而不是_id的原因是，在6.0.0之前版本里面，_uid可以比_id表示更多的信息，比如Type。在6.0.0版本之后，同一个Index只能有一个Type，这时候Type就没多大意义了，后面Type应该会消失，那时候_id就会和_uid概念一样，到时候两者会合二为一，也能简化大家的理解。&lt;/p>
&lt;h2 id="3-_version">&lt;strong>3. _version&lt;/strong>&lt;/h2>
&lt;p>Elasticsearch中每个Doc都会有一个Version，该Version可以由用户指定，也可以由系统自动生成。如果是系统自动生成，那么每次Version都是递增1。&lt;/p>
&lt;p>_version是实时的，不受搜索的近实时性影响，原因是可以通过_uid从内存中versionMap或者TransLog中读取到。&lt;/p>
&lt;p>Version在Lucene中也是映射为一个特殊的Field存在。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-a529eeb14094626f3523a92e0dfdb299_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中Version字段的主要目的是通过doc_id读取Version，所以Version只要存储为DocValues就可以了，类似于KeyValue存储。&lt;/p>
&lt;p>Elasticsearch通过使用version来保证对文档的变更能以正确的顺序执行，避免乱序造成的数据丢失：&lt;/p>
&lt;ol>
&lt;li>首次写入Doc的时候，会为Doc分配一个初始的Version：V0，该值根据VersionType不同而不同。&lt;/li>
&lt;li>再次写入Doc的时候，如果Request中没有指定Version，则会先加锁，然后去读取该Doc的最大版本V1，然后将V1+1后的新版本写入Lucene中。&lt;/li>
&lt;li>再次写入Doc的时候，如果Request中指定了Version：V1，则继续会先加锁，然后去读该Doc的最大版本V2，判断V1==V2，如果不相等，则发生版本冲突。否则版本吻合，继续写入Lucene。&lt;/li>
&lt;li>当做部分更新的时候，会先通过GetRequest读取当前id的完整Doc和V1，接着和当前Request中的Doc合并为一个完整Doc。然后执行一些逻辑后，加锁，再次读取该Doc的最大版本号V2，判断V1==V2，如果不相等，则在刚才执行其他逻辑时被其他线程更改了当前文档，需要报错后重试。如果相等，则期间没有其他线程修改当前文档，继续写入Lucene中。这个过程就是一个典型的read-then-update事务。&lt;/li>
&lt;/ol>
&lt;h2 id="4-_source">&lt;strong>4. _source&lt;/strong>&lt;/h2>
&lt;p>Elasticsearch中有一个重要的概念是source，存储原始文档，也可以通过过滤设置只存储特定Field。&lt;/p>
&lt;p>Source在Lucene中也是映射为了一个特殊的Field存在：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-5faeffae9ed270c1030c83499287dfc7_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中_source字段的主要目的是通过doc_id读取该文档的原始内容，所以只需要存储Store即可。&lt;/p>
&lt;p>_source其实是名为_source的虚拟Store Field。&lt;/p>
&lt;p>Elasticsearch中使用_source字段可以实现以下功能：&lt;/p>
&lt;ul>
&lt;li>Update：部分更新时，需要从读取文档保存在_source字段中的原文，然后和请求中的部分字段合并为一个完整文档。如果没有_source，则不能完成部分字段的Update操作。&lt;/li>
&lt;li>Rebuild：最新的版本中新增了rebuild接口，可以通过Rebuild API完成索引重建，过程中不需要从其他系统导入全量数据，而是从当前文档的_source中读取。如果没有_source，则不能使用Rebuild API。&lt;/li>
&lt;li>Script：不管是Index还是Search的Script，都可能用到存储在Store中的原始内容，如果禁用了_source，则这部分功能不再可用。&lt;/li>
&lt;li>Summary：摘要信息也是来源于_source字段。&lt;/li>
&lt;/ul>
&lt;h2 id="5-_seq_no">&lt;strong>5. _seq_no&lt;/strong>&lt;/h2>
&lt;p>严格递增的顺序号，每个文档一个，Shard级别严格递增，保证后写入的Doc的_seq_no大于先写入的Doc的_seq_no。&lt;/p>
&lt;p>任何类型的写操作，包括index、create、update和Delete，都会生成一个_seq_no。&lt;/p>
&lt;p>_seq_no在Primary Node中由SequenceNumbersService生成，但其实真正产生这个值的是LocalCheckpointTracker，每次递增1：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="cm">/**
&lt;/span>&lt;span class="cm"> * The next available sequence number.
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">volatile&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">nextSeqNo&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm"> * Issue the next sequence number.
&lt;/span>&lt;span class="cm"> *
&lt;/span>&lt;span class="cm"> * @return the next assigned sequence number
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="kd">synchronized&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">generateSeqNo&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">nextSeqNo&lt;/span>&lt;span class="o">++;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>每个文档在使用Lucene的document操作接口之前，会获取到一个_seq_no，这个_seq_no会以系统保留Field的名义存储到Lucene中，文档写入Lucene成功后，会标记该seq_no为完成状态，这时候会使用当前seq_no更新local_checkpoint。&lt;/p>
&lt;p>checkpoint分为local_checkpoint和global_checkpoint，主要是用于保证有序性，以及减少Shard恢复时数据拷贝的数据拷贝量，更详细的介绍可以看这篇文章：&lt;a href="https://link.zhihu.com/?target=https%3A//www.elastic.co/blog/elasticsearch-sequence-ids-6-0">Sequence IDs: Coming Soon to an Elasticsearch Cluster Near You&lt;/a>。&lt;/p>
&lt;p>_seq_no在Lucene中的映射：&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-a90804c654226608954774a639768afd_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中_seq_no的作用有两个，一是通过doc_id查询到该文档的seq_no，二是通过seq_no范围查找相关文档，所以也就需要存储为Index和DocValues（或者Store）。由于是在冲突检测时才需要读取文档的_seq_no，而且此时只需要读取_seq_no，不需要其他字段，这时候存储为列式存储的DocValues比Store在性能上更好一些。&lt;/p>
&lt;p>_seq_no是严格递增的，写入Lucene的顺序也是递增的，所以DocValues存储类型可以设置为Sorted。&lt;/p>
&lt;p>另外，_seq_no的索引应该仅需要支持存储DocId就可以了，不需要FREQS、POSITIONS和分词。如果多存储了这些，对功能也没影响，就是多占了一点资源而已。&lt;/p>
&lt;h2 id="6-_primary_term">&lt;strong>6. _primary_term&lt;/strong>&lt;/h2>
&lt;p>_primary_term也和_seq_no一样是一个整数，每当Primary Shard发生重新分配时，比如重启，Primary选举等，_primary_term会递增1。&lt;/p>
&lt;p>_primary_term主要是用来恢复数据时处理当多个文档的_seq_no一样时的冲突，避免Primary Shard上的写入被覆盖。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-4a4184826fdd0a3d51001d3de3a57fb2_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中_primary_term只需要通过doc_id读取到即可，所以只需要保存为DocValues就可以了.&lt;/p>
&lt;h2 id="7-_routing">&lt;strong>7. _routing&lt;/strong>&lt;/h2>
&lt;p>路由规则，写入和查询的routing需要一致，否则会出现写入的文档没法被查到情况。&lt;/p>
&lt;p>在mapping中，或者Request中可以指定按某个字段路由。默认是按照_Id值路由。&lt;/p>
&lt;p>_routing在Lucene中映射为：&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-a401f30a09d5f75b4adf79150544f536_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中文档级别的_routing主要有两个目的，一是可以查询到使用某种_routing的文档有哪些，当发生_routing变化时，可以对历史_routing的文档重新读取再Index，这个需要倒排Index。另一个是查询到文档后，在Response里面展示该文档使用的_routing规则，这里需要存储为Store。&lt;/p>
&lt;h2 id="8-_field_names">&lt;strong>8. _field_names&lt;/strong>&lt;/h2>
&lt;p>该字段会索引某个Field的名称，用来判断某个Doc中是否存在某个Field，用于exists或者missing请求。&lt;/p>
&lt;p>_field_names在Lucene中的映射：&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-81d5dbc1f9e816879ad063b2fc1e9ba9_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中_field_names的目的是查询哪些Doc的这个Field是否存在，所以只需要倒排Index即可。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2></description></item><item><title>esrally for es on cfs</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/esrally/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/esrally/</guid><description>&lt;h1 id="esrally-for-es-on-cfs">esrally for es on cfs&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>esrally 是 elastic 官方开源的一款基于 python3 实现的针对 es 的压测工具，主要功能如下：&lt;/p>
&lt;ul>
&lt;li>自动创建、压测和销毁 es 集群&lt;/li>
&lt;li>可分 es 版本管理压测数据和方案&lt;/li>
&lt;li>完善的压测数据展示，支持不同压测之间的数据对比分析，也可以将数据存储到指定的es中进行二次分析&lt;/li>
&lt;li>支持收集 JVM 详细信息，比如内存、GC等数据来定位性能问题&lt;/li>
&lt;/ul>
&lt;h2 id="安装测试">安装测试&lt;/h2>
&lt;h3 id="测试环境">测试环境&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>节点类型&lt;/th>
&lt;th>节点数&lt;/th>
&lt;th>CPU&lt;/th>
&lt;th>内存&lt;/th>
&lt;th>存储&lt;/th>
&lt;th>网络&lt;/th>
&lt;th>备注&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>管理节点&lt;/td>
&lt;td>3&lt;/td>
&lt;td>32&lt;/td>
&lt;td>32 GB&lt;/td>
&lt;td>120 GB SSD&lt;/td>
&lt;td>10 Gb/s&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>元数据节点&lt;/td>
&lt;td>10&lt;/td>
&lt;td>32&lt;/td>
&lt;td>32 GB&lt;/td>
&lt;td>16 x 1TB SSD&lt;/td>
&lt;td>10 Gb/s&lt;/td>
&lt;td>混合部署&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据节点&lt;/td>
&lt;td>10&lt;/td>
&lt;td>32&lt;/td>
&lt;td>32 GB&lt;/td>
&lt;td>16 x 1TB SSD&lt;/td>
&lt;td>10 Gb/s&lt;/td>
&lt;td>混合部署&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="cfs配置">cfs配置&lt;/h3>
&lt;ul>
&lt;li>创建cfs vol&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="cp">#!/bin/sh
&lt;/span>&lt;span class="cp">&lt;/span>&lt;span class="c1"># ./create_vol.sh&lt;/span>
&lt;span class="nv">VolNames&lt;/span>&lt;span class="o">=&lt;/span>estest
&lt;span class="nv">leader&lt;/span>&lt;span class="o">=&lt;/span>10.194.139.42:8080 &lt;span class="c1">#cfs master leader节点的ip&lt;/span>
&lt;span class="nv">Capacity&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">1024&lt;/span> &lt;span class="c1">#unit GB&lt;/span>
&lt;span class="nv">Owner&lt;/span>&lt;span class="o">=&lt;/span>es01
&lt;span class="nv">DpCount&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">500&lt;/span>
&lt;span class="c1"># 创建vol&lt;/span>
curl &lt;span class="s2">&amp;#34;http://&lt;/span>&lt;span class="nv">$leader&lt;/span>&lt;span class="s2">/admin/createVol?name=&lt;/span>&lt;span class="nv">$VolName&lt;/span>&lt;span class="s2">&amp;amp;replicas=3&amp;amp;type=extent&amp;amp;capacity=&lt;/span>&lt;span class="nv">$Capacity&lt;/span>&lt;span class="s2">&amp;amp;owner=&lt;/span>&lt;span class="nv">$Owner&lt;/span>&lt;span class="s2">&amp;amp;followerRead=true&amp;#34;&lt;/span>
&lt;span class="c1"># 创建dp&lt;/span>
curl &lt;span class="s2">&amp;#34;http://&lt;/span>&lt;span class="nv">$leader&lt;/span>&lt;span class="s2">/dataPartition/create?count=&lt;/span>&lt;span class="nv">$DpCount&lt;/span>&lt;span class="s2">&amp;amp;name=&lt;/span>&lt;span class="nv">$VolName&lt;/span>&lt;span class="s2">&amp;amp;type=extent&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>
&lt;p>挂载cfs vol：&lt;/p>
&lt;p>在es运行节点运行cfs-client，挂载cfs vol到指定目录：&lt;code>/mnt/cfs&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">cd&lt;/span> &lt;span class="nv">$CFS_ROOT&lt;/span>
$ bin/cfs-client -c conf/cfs-client.json
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>cfs client 配置文件：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="err">//&lt;/span> &lt;span class="err">cfs-client.json&lt;/span>
&lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;mountPoint&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;/mnt/cfs&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;volName&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;estest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;owner&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;es01&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;masterAddr&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;10.194.139.42:8080,10.194.139.44:8080,10.194.139.45:8080&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;logDir&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;/export/Logs/cfs&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;warnLogDir&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;/export/Logs/cfs&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;logLevel&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;debug&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;consulAddr&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;http://cbconsul-cfs01.cbmonitor.svc.ht7.n.jd.local&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;exporterPort&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">9613&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;profPort&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;11094&amp;#34;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="es配置">es配置&lt;/h3>
&lt;p>修改es配置文件&lt;code>elasticsearch.yml&lt;/code>中配置项&lt;code>path.data&lt;/code>为cfs挂载目录:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="c"># elasticsearch.yml&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c">#...&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">path.data&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">/mnt/cfs/es/&amp;lt;HOST_NAME&amp;gt; &lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c">## HOST_NAME为节点主机名，如果节点运行多个es，每个es需配置不同的目录&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c">#...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="esrally">esrally&lt;/h3>
&lt;ul>
&lt;li>centos7&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ yum install -y python3 python3-devel
&lt;span class="c1"># install git&lt;/span>
$ yum install -y http://opensource.wandisco.com/centos/6/git/x86_64/wandisco-git-release-6-1.noarch.rpm
$ yum install -y git
$ pip3 install esrally
$ &lt;span class="nv">target_hosts&lt;/span>&lt;span class="o">=&lt;/span>10.194.132.2:20000,10.194.132.5:20000,10.194.132.71:20000,10.194.134.196:20000
$ esrally --track&lt;span class="o">=&lt;/span>pmc &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --target-hosts&lt;span class="o">=&lt;/span>&lt;span class="nv">$target_hosts&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --pipeline&lt;span class="o">=&lt;/span>benchmark-only
$ esrally --pipeline&lt;span class="o">=&lt;/span>benchmark-only &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --track&lt;span class="o">=&lt;/span>http_logs &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --target-hosts&lt;span class="o">=&lt;/span>&lt;span class="nv">$target_hosts&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --report-file&lt;span class="o">=&lt;/span>/tmp/report_http_logs.md
&lt;span class="c1"># 指定集群，运行测试，test-mode参数只会运行1000条文档 es集群必须处理green状态，否则会被禁止race&lt;/span>
&lt;span class="c1"># 去掉--offline --test-mode可以让其把相关文件夹创建，然后结束掉&lt;/span>
esrally --pipeline&lt;span class="o">=&lt;/span>benchmark-only --target-hosts&lt;span class="o">=&lt;/span>127.0.0.1:9200 --offline --test-mode --client-options&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;basic_auth_user:&amp;#39;elastic&amp;#39;,basic_auth_password:&amp;#39;your_password&amp;#39;&amp;#34;&lt;/span>
esrally race --track&lt;span class="o">=&lt;/span>geonames --challenge&lt;span class="o">=&lt;/span>append-no-conflicts --user-tag&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;car:1g&amp;#34;&lt;/span> --car&lt;span class="o">=&lt;/span>1gheap --pipeline&lt;span class="o">=&lt;/span>benchmark-only --target-hosts&lt;span class="o">=&lt;/span>127.0.0.1:9200 --offline --test-mode --client-options&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;basic_auth_user:&amp;#39;elastic&amp;#39;,basic_auth_password:&amp;#39;your_password&amp;#39;&amp;#34;&lt;/span>
esrally race --track&lt;span class="o">=&lt;/span>geonames --challenge&lt;span class="o">=&lt;/span>append-no-conflicts --user-tag&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;car:2g&amp;#34;&lt;/span> --car&lt;span class="o">=&lt;/span>2gheap --pipeline&lt;span class="o">=&lt;/span>benchmark-only --target-hosts&lt;span class="o">=&lt;/span>127.0.0.1:9200 --offline --test-mode --client-options&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;basic_auth_user:&amp;#39;elastic&amp;#39;,basic_auth_password:&amp;#39;your_password&amp;#39;&amp;#34;&lt;/span>
&lt;span class="c1"># 对比2次的测试结果，根据esrally list races显示的时间戳当参数值，如果报错就使用Race ID&lt;/span>
esrally compare --baseline&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;Race ID&amp;#39;&lt;/span> --contender&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;Race ID&amp;#39;&lt;/span>
&lt;span class="c1"># 修改集群的分片数和副本数&lt;/span>
vim /home/esrally/.rally/benchmarks/tracks/default/geonames/index.json
vim /home/esrally/.rally/benchmarks/tracks/default/geonames/challenges/default.json
&lt;span class="c1"># 常用命令&lt;/span>
esrally list tracks
esrally list cars
esrally list races
esrally list pipelines
$ esrally list races
$ esrally compare --baseline 30889a15-66d3-4336-b6cb-0304834d853a --contender 1d1d5a98-54cb-486d-8339-98fe72ff054c
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="测试结果">测试结果&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>metric&lt;/th>
&lt;th>local-r0&lt;/th>
&lt;th>local-r1&lt;/th>
&lt;th>local-r2&lt;/th>
&lt;th>cfs-r0&lt;/th>
&lt;th>cfs-r1&lt;/th>
&lt;th>cfs-r2&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Cumulative indexing time of primary&lt;br> shards&lt;/td>
&lt;td>48.1956&lt;/td>
&lt;td>50.1214&lt;/td>
&lt;td>53.6981&lt;/td>
&lt;td>61.514&lt;/td>
&lt;td>60.6874&lt;/td>
&lt;td>61.6843&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Cumulative merge time of primary shards&lt;/td>
&lt;td>19.3734&lt;/td>
&lt;td>19.759&lt;/td>
&lt;td>16.3446&lt;/td>
&lt;td>20.7753&lt;/td>
&lt;td>15.1702&lt;/td>
&lt;td>5.61673&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Cumulative refresh time of primary shard&lt;/td>
&lt;td>6.52128&lt;/td>
&lt;td>5.99413&lt;/td>
&lt;td>5.61948&lt;/td>
&lt;td>12.7984&lt;/td>
&lt;td>10.6824&lt;/td>
&lt;td>9.8606&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Cumulative flush time of primary shards&lt;/td>
&lt;td>0.00513&lt;/td>
&lt;td>0&lt;/td>
&lt;td>1.67E-05&lt;/td>
&lt;td>0.0028&lt;/td>
&lt;td>0.0147333&lt;/td>
&lt;td>0.03075&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-06-03-13-36-05-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>local-r0、local-r1, local-r2: 分别表示es    &lt;code>path.data&lt;/code>使用本地磁盘，replica分别为0，1，2时的数据；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cfs-r0，cfs-r1, cfs-r2分别表示es &lt;code>path.data&lt;/code>使用cfs 卷，replica分别为0,1,2时esrally的数据；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://esrally.readthedocs.io/en/latest/">https://esrally.readthedocs.io/en/latest/&lt;/a>&lt;u>summary_report&lt;/u>.html&lt;/li>
&lt;li>&lt;a href="https://www.jianshu.com/p/c89975b50447">https://www.jianshu.com/p/c89975b50447&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://esrally.lyremelody.org/zh_CN/latest/quickstart.html">快速入门 — Rally 0.9.0 文档&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>ES倒排索引原理</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/</guid><description>&lt;h1 id="es倒排索引原理">ES倒排索引原理&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Elasticsearch通过Lucene的倒排索引技术实现比关系型数据库更快的过滤。它对多条件的过滤支持非常好，比如年龄在18和30之间，性别为女性这样的组合查询。倒排索引很多地方都有介绍，但是其比关系型数据库的b-tree索引快在哪里？到底为什么快呢？&lt;/p>
&lt;p>笼统的来说，b-tree索引是为写入优化的索引结构。当我们不需要支持快速的更新的时候，可以用预先排序等方式换取更小的存储空间，更快的检索速度等好处，其代价就是更新慢。要进一步深入的化，还是要看一下Lucene的倒排索引是怎么构成的。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-378bc62acf1a493c402291a8f8e99e6a_720w.jpg" alt="">&lt;/p>
&lt;p>这里有好几个概念。我们来看一个实际的例子，假设有如下的数据：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-e6b81003803254b1d11b3384626c93ab_720w.jpg" alt="">&lt;/p>
&lt;p>这里每一行是一个document。每个document都有一个docid。那么给这些document建立的倒排索引就是：&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-c1cf40e4c4218fd3e992258c08e4e334_720w.jpg" alt="">&lt;/p>
&lt;p>可以看到，倒排索引是per field的，一个字段由一个自己的倒排索引。18,20这些叫做 term，而[1,3]就是posting list。Posting list就是一个int的数组，存储了所有符合某个term的文档id。那么什么是term dictionary 和 term index？&lt;/p>
&lt;p>假设我们有很多个term，比如：&lt;/p>
&lt;p>Carla,Sara,Elin,Ada,Patty,Kate,Selena&lt;/p>
&lt;p>如果按照这样的顺序排列，找出某个特定的term一定很慢，因为term没有排序，需要全部过滤一遍才能找出特定的term。排序之后就变成了：&lt;/p>
&lt;p>Ada,Carla,Elin,Kate,Patty,Sara,Selena&lt;/p>
&lt;p>这样我们可以用二分查找的方式，比全遍历更快地找出目标的term。这个就是 term dictionary。有了term dictionary之后，可以用 logN 次磁盘查找得到目标。但是磁盘的随机读操作仍然是非常昂贵的（一次random access大概需要10ms的时间）。所以尽量少的读磁盘，有必要把一些数据缓存到内存里。但是整个term dictionary本身又太大了，无法完整地放到内存里。于是就有了term index。term index有点像一本字典的大的章节表。比如：&lt;/p>
&lt;p>A开头的term ……………. Xxx页&lt;/p>
&lt;p>C开头的term ……………. Xxx页&lt;/p>
&lt;p>E开头的term ……………. Xxx页&lt;/p>
&lt;p>如果所有的term都是英文字符的话，可能这个term index就真的是26个英文字符表构成的了。但是实际的情况是，term未必都是英文字符，term可以是任意的byte数组。而且26个英文字符也未必是每一个字符都有均等的term，比如x字符开头的term可能一个都没有，而s开头的term又特别多。实际的term index是一棵trie 树：&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-e4632ac1392b01f7a39d963fddb1a1e0_720w.jpg" alt="">&lt;/p>
&lt;p>例子是一个包含 &amp;ldquo;A&amp;rdquo;, &amp;ldquo;to&amp;rdquo;, &amp;ldquo;tea&amp;rdquo;, &amp;ldquo;ted&amp;rdquo;, &amp;ldquo;ten&amp;rdquo;, &amp;ldquo;i&amp;rdquo;, &amp;ldquo;in&amp;rdquo;, 和 &amp;ldquo;inn&amp;rdquo; 的 trie 树。这棵树不会包含所有的term，它包含的是term的一些前缀。通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找。再加上一些压缩技术（搜索 Lucene Finite State Transducers） term index 的尺寸可以只有所有term的尺寸的几十分之一，使得用内存缓存整个term index变成可能。整体上来说就是这样的效果。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-e4599b618e270df9b64a75eb77bfb326_720w.jpg" alt="">&lt;/p>
&lt;p>现在我们可以回答“为什么Elasticsearch/Lucene检索可以比mysql快了。Mysql只有term dictionary这一层，是以b-tree排序的方式存储在磁盘上的。检索一个term需要若干次的random access的磁盘操作。而Lucene在term dictionary的基础上添加了term index来加速检索，term index以树的形式缓存在内存中。从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘的random access次数。&lt;/p>
&lt;p>额外值得一提的两点是：term index在内存中是以FST（finite state transducers）的形式保存的，其特点是非常节省内存。Term dictionary在磁盘上是以分block的方式保存的，一个block内部利用公共前缀压缩，比如都是Ab开头的单词就可以把Ab省去。这样term dictionary可以比b-tree更节约磁盘空间。&lt;/p>
&lt;h2 id="如何联合索引查询">如何联合索引查询？&lt;/h2>
&lt;p>所以给定查询过滤条件 age=18 的过程就是先从term index找到18在term dictionary的大概位置，然后再从term dictionary里精确地找到18这个term，然后得到一个posting list或者一个指向posting list位置的指针。然后再查询 gender=女 的过程也是类似的。最后得出 age=18 AND gender=女 就是把两个 posting list 做一个“与”的合并。&lt;/p>
&lt;p>这个理论上的“与”合并的操作可不容易。对于mysql来说，如果你给age和gender两个字段都建立了索引，查询的时候只会选择其中最selective的来用，然后另外一个条件是在遍历行的过程中在内存中计算之后过滤掉。那么要如何才能联合使用两个索引呢？有两种办法：&lt;/p>
&lt;ul>
&lt;li>使用skip list数据结构。同时遍历gender和age的posting list，互相skip；&lt;/li>
&lt;li>使用bitset数据结构，对gender和age两个filter分别求出bitset，对两个bitset做AN操作。&lt;/li>
&lt;/ul>
&lt;p>PostgreSQL 从 8.4 版本开始支持通过bitmap联合使用两个索引，就是利用了bitset数据结构来做到的。当然一些商业的关系型数据库也支持类似的联合索引的功能。Elasticsearch支持以上两种的联合索引方式，如果查询的filter缓存到了内存中（以bitset的形式），那么合并就是两个bitset的AND。如果查询的filter没有缓存，那么就用skip list的方式去遍历两个on disk的posting list。&lt;/p>
&lt;h2 id="利用-skip-list-合并">利用 Skip List 合并&lt;/h2>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-eafa46683272ff1b2081edbc8db5469f_720w.jpg" alt="">&lt;/p>
&lt;p>以上是三个posting list。我们现在需要把它们用AND的关系合并，得出posting list的交集。首先选择最短的posting list，然后从小到大遍历。遍历的过程可以跳过一些元素，比如我们遍历到绿色的13的时候，就可以跳过蓝色的3了，因为3比13要小。&lt;/p>
&lt;p>整个过程如下&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">Next -&amp;gt; 2
Advance(2) -&amp;gt; 13
Advance(13) -&amp;gt; 13
Already on 13
Advance(13) -&amp;gt; 13 MATCH!!!
Next -&amp;gt; 17
Advance(17) -&amp;gt; 22
Advance(22) -&amp;gt; 98
Advance(98) -&amp;gt; 98
Advance(98) -&amp;gt; 98 MATCH!!!
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>最后得出的交集是[13,98]，所需的时间比完整遍历三个posting list要快得多。但是前提是每个list需要指出Advance这个操作，快速移动指向的位置。什么样的list可以这样Advance往前做蛙跳？skip list：&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-a8b78c8e861c34a1afd7891284852b34_720w.jpg" alt="">&lt;/p>
&lt;p>从概念上来说，对于一个很长的posting list，比如：&lt;/p>
&lt;p>[1,3,13,101,105,108,255,256,257]&lt;/p>
&lt;p>我们可以把这个list分成三个block：&lt;/p>
&lt;p>[1,3,13] [101,105,108] [255,256,257]&lt;/p>
&lt;p>然后可以构建出skip list的第二层：&lt;/p>
&lt;p>[1,101,255]&lt;/p>
&lt;p>1,101,255分别指向自己对应的block。这样就可以很快地跨block的移动指向位置了。&lt;/p>
&lt;p>Lucene自然会对这个block再次进行压缩。其压缩方式叫做Frame Of Reference编码。示例如下：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-9c03d3e449e3f8fb8182287048ad6db7_720w.jpg" alt="">&lt;/p>
&lt;p>考虑到频繁出现的term（所谓low cardinality的值），比如gender里的男或者女。如果有1百万个文档，那么性别为男的posting list里就会有50万个int值。用Frame of Reference编码进行压缩可以极大减少磁盘占用。这个优化对于减少索引尺寸有非常重要的意义。当然mysql b-tree里也有一个类似的posting list的东西，是未经过这样压缩的。&lt;/p>
&lt;p>因为这个Frame of Reference的编码是有解压缩成本的。利用skip list，除了跳过了遍历的成本，也跳过了解压缩这些压缩过的block的过程，从而节省了cpu。&lt;/p>
&lt;h2 id="利用bitset合并">利用bitset合并&lt;/h2>
&lt;p>Bitset是一种很直观的数据结构，对应posting list如：&lt;/p>
&lt;p>[1,3,4,7,10]&lt;/p>
&lt;p>对应的bitset就是：&lt;/p>
&lt;p>[1,0,1,1,0,0,1,0,0,1]&lt;/p>
&lt;p>每个文档按照文档id排序对应其中的一个bit。Bitset自身就有压缩的特点，其用一个byte就可以代表8个文档。所以100万个文档只需要12.5万个byte。但是考虑到文档可能有数十亿之多，在内存里保存bitset仍然是很奢侈的事情。而且对于个每一个filter都要消耗一个bitset，比如age=18缓存起来的话是一个bitset，18&amp;lt;=age&amp;lt;25是另外一个filter缓存起来也要一个bitset。&lt;/p>
&lt;p>所以秘诀就在于需要有一个数据结构：&lt;/p>
&lt;ul>
&lt;li>可以很压缩地保存上亿个bit代表对应的文档是否匹配filter；&lt;/li>
&lt;li>这个压缩的bitset仍然可以很快地进行AND和 OR的逻辑操作。&lt;/li>
&lt;/ul>
&lt;p>Lucene使用的这个数据结构叫做 Roaring Bitmap。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-9482b84c4aa3fb77a959c1ead553037e_720w.jpg" alt="">&lt;/p>
&lt;p>其压缩的思路其实很简单。与其保存100个0，占用100个bit。还不如保存0一次，然后声明这个0重复了100遍。&lt;/p>
&lt;p>这两种合并使用索引的方式都有其用途。Elasticsearch对其性能有详细的对比（&lt;a href="https://link.zhihu.com/?target=https%3A//www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps">https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps&lt;/a>）。简单的结论是：因为Frame of Reference编码是如此 高效，对于简单的相等条件的过滤缓存成纯内存的bitset还不如需要访问磁盘的skip list的方式要快。&lt;/p>
&lt;h2 id="如何减少文档数">如何减少文档数？&lt;/h2>
&lt;p>一种常见的压缩存储时间序列的方式是把多个数据点合并成一行。Opentsdb支持海量数据的一个绝招就是定期把很多行数据合并成一行，这个过程叫compaction。类似的vivdcortext使用mysql存储的时候，也把一分钟的很多数据点合并存储到mysql的一行里以减少行数。&lt;/p>
&lt;p>这个过程可以示例如下：&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-252d8f8ebe62e508f62049e80a9b9468_720w.jpg" alt="">&lt;/p>
&lt;p>可以看到，行变成了列了。每一列可以代表这一分钟内一秒的数据。&lt;/p>
&lt;p>Elasticsearch有一个功能可以实现类似的优化效果，那就是Nested Document。我们可以把一段时间的很多个数据点打包存储到一个父文档里，变成其嵌套的子文档。示例如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">{timestamp:12:05:01, idc:sz, value1:10,value2:11}
{timestamp:12:05:02, idc:sz, value1:9,value2:9}
{timestamp:12:05:02, idc:sz, value1:18,value:17}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以打包成：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="p">{&lt;/span>
    &lt;span class="err">max_timestamp:12:05:02,&lt;/span>
    &lt;span class="err">min_timestamp:&lt;/span> &lt;span class="err">1205:01,&lt;/span>
    &lt;span class="err">idc:sz,&lt;/span>
    &lt;span class="err">records:&lt;/span> &lt;span class="err">[&lt;/span>
&lt;span class="err">{timestamp:12:05:01,&lt;/span> &lt;span class="err">value1:10,value2:11&lt;/span>&lt;span class="p">}&lt;/span>
        &lt;span class="p">{&lt;/span>&lt;span class="err">timestamp:12:05:02,&lt;/span> &lt;span class="err">value1:9,value2:9&lt;/span>&lt;span class="p">}&lt;/span>
        &lt;span class="p">{&lt;/span>&lt;span class="err">timestamp:12:05:02,&lt;/span> &lt;span class="err">value1:18,value:17&lt;/span>&lt;span class="p">}&lt;/span>
    &lt;span class="err">]&lt;/span>
&lt;span class="err">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这样可以把数据点公共的维度字段上移到父文档里，而不用在每个子文档里重复存储，从而减少索引的尺寸。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-917578288797efab8f67e7b74d5ec6a3_720w.jpg" alt="">&lt;/p>
&lt;p>在存储的时候，无论父文档还是子文档，对于Lucene来说都是文档，都会有文档Id。但是对于嵌套文档来说，可以保存起子文档和父文档的文档id是连续的，而且父文档总是最后一个。有这样一个排序性作为保障，那么有一个所有父文档的posting list就可以跟踪所有的父子关系。也可以很容易地在父子文档id之间做转换。把父子关系也理解为一个filter，那么查询时检索的时候不过是又AND了另外一个filter而已。前面我们已经看到了Elasticsearch可以非常高效地处理多filter的情况，充分利用底层的索引。&lt;/p>
&lt;p>使用了嵌套文档之后，对于term的posting list只需要保存父文档的doc id就可以了，可以比保存所有的数据点的doc id要少很多。如果我们可以在一个父文档里塞入50个嵌套文档，那么posting list可以变成之前的1/50。&lt;/p></description></item><item><title>ES冷热分离</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%B7%E7%83%AD%E5%88%86%E7%A6%BB/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%B7%E7%83%AD%E5%88%86%E7%A6%BB/</guid><description>&lt;h1 id="es冷热分离">ES冷热分离&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>elasticsearch 从6.6版本增加了冷热(hot-warm)特性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>该特性可以将同一个es集群中的不同es节点根据硬件性能分为&lt;code>hot&lt;/code>/&lt;code>warm&lt;/code>不同的类型(node type)。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="配置">配置&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>条件： elasticsearch version &amp;gt;= 6.6.0&lt;/p>
&lt;/li>
&lt;li>
&lt;p>配置&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="c"># $ES_HOME/config/elasticsearch.yml&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1"># $ES_HOME/start.sh&lt;/span>
&lt;span class="nv">OPTS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34; -Enode.attr.box_type=hot -Enode.attr.resource_level=high -p &lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">PID_FILE&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2"> -d &amp;#34;&lt;/span>
bin/elasticsearch &lt;span class="nv">$OPTS&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>迁移节点到温节点&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">curl -X PUT /&amp;lt;INDEX_NAME&amp;gt;/_settings
&lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;settings&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;span class="s2">&amp;#34;index.routing.allocation.require.box_type&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;warm&amp;#34;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://www.elastic.co/cn/blog/hot-warm-architecture-in-elasticsearch-5-x">Elasticsearch Hot Warm Architecture | Elastic Blog&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.elastic.co/cn/blog/implementing-hot-warm-cold-in-elasticsearch-with-index-lifecycle-management">使用索引生命周期管理在 Elasticsearch 中实现热温冷架构 | Elastic Blog&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>ES存储详解</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%AD%98%E5%82%A8%E8%AF%A6%E8%A7%A3/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%AD%98%E5%82%A8%E8%AF%A6%E8%A7%A3/</guid><description>&lt;h1 id="es存储详解">ES存储详解&lt;/h1>
&lt;h2 id="elasticsearch路径">Elasticsearch路径&lt;/h2>
&lt;p>Elasticsearch配置了多个路径：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>path.home&lt;/code>：运行Elasticsearch进程的用户的主目录。默认为Java系统属性user.dir，它是进程所有者的默认主目录。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>path.conf&lt;/code>：包含配置文件的目录。这通常通过设置Java系统属性es.config来设置，因为在找到配置文件之前它必然会被解析。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>path.plugins&lt;/code>：子文件夹为Elasticsearch插件的目录。这里支持Sym-links，当从同一个可执行文件运行多个Elasticsearch实例时，可以使用它来有选择地启用/禁用某个Elasticsearch实例的一组插件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>path.logs&lt;/code>：存储生成的日志的位置。如果其中一个卷的磁盘空间不足，则将它放在与数据目录不同的卷上可能是有意义的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>path.data&lt;/code>：包含Elasticsearch存储的数据的文件夹的路径。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>在本文中，我们将仔细研究数据目录（path.data）的实际内容，并尝试了解所有文件的用途。&lt;/p>
&lt;h3 id="2文件从哪里来">2、文件从哪里来？&lt;/h3>
&lt;p>由于Elasticsearch使用Lucene来处理分片级别的索引和查询，因此数据目录中的文件由Elasticsearch和Lucene写入。&lt;br>
两者的职责都非常明确：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Lucene负责写和维护Lucene索引文件，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>而Elasticsearch在Lucene之上写与功能相关的元数据，例如字段映射，索引设置和其他集群元数据。最终用户和支持功能&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在低级Lucene中不存在，由Elasticsearch提供。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>在深入研究并最终找到Lucene索引文件之前，让我们看看Elasticsearch编写的外部级别数据。&lt;/p>
&lt;h3 id="3节点数据">3、节点数据&lt;/h3>
&lt;p>只需从空数据目录启动Elasticsearch即可生成以下目录树：&lt;/p>
&lt;p>&lt;img src="https://img0.tuicool.com/AbYBVra.png" alt="">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>node.lock文件用于确保一次只能从一个数据目录读取/写入一个Elasticsearch相关安装信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>有趣的是global-0.st文件。global-前缀表示这是一个全局状态文件，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>而.st扩展名表示这是一个包含元数据的状态文件。您可能已经猜到，此二进制文件包含有关您的集群的全局元数据，前缀后的数字表示集群元数据版本，遵循跟随您的集群严格增加的版本控制方案。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>注意：虽然在紧急情况下使用十六进制编辑器在技术上可以编辑这些文件，但强烈建议不要这样做，因为它很快就会导致数据丢失。&lt;/p>
&lt;h3 id="4索引数据">4、索引数据&lt;/h3>
&lt;p>让我们创建一个分片索引并查看Elasticsearch更改的文件。&lt;/p>
&lt;p>&lt;img src="https://img2.tuicool.com/J3uuInA.png" alt="">&lt;/p>
&lt;p>我们看到已经创建了与索引名称对应的新目录。此目录有两个子文件夹：_state和0.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>前者&lt;em>state包含所谓的索引状态文件（indices / {index-name} /&lt;/em> state / state- {version} .st），&lt;br>
其中包含有关索引的元数据，例如它的创建时间戳。它还包含唯一标识符以及索引的设置和映射。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>后者0包含与索引的第一个（也是唯一的）分片相关的数据（分片0）。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>接下来，我们将仔细研究一下。&lt;/p>
&lt;h3 id="5分片数据">5、分片数据&lt;/h3>
&lt;p>分片数据目录包含分片的状态文件，其中包括版本控制以及有关分片是主分片还是副本的信息。&lt;/p>
&lt;p>&lt;img src="https://img2.tuicool.com/JVvmymQ.png" alt="">&lt;/p>
&lt;p>在早期的Elasticsearch版本中，还在分片数据目录中找到了单独的{shard_id} / index / _checksums-文件（和.cks-files）。在当前版本中，这些校验和现在可以在Lucene文件的页脚中找到，因为Lucene已经为其所有索引文件添加了端到端校验和。&lt;/p>
&lt;p>{shard_id} / index目录包含Lucene拥有的文件。Elasticsearch通常不直接写入此文件夹（除了早期版本中的旧校验和实现）。这些目录中的文件构成了任何Elasticsearch数据目录的大小。&lt;/p>
&lt;p>在我们进入Lucene的世界之前，我们将看一下Elasticsearch 事务日志，这在每个分片translog目录中的前缀translog-中存在。Translog日志对于Elasticsearch的功能和性能非常重要，因此我们将在下一节中更详细地解释它的用法。&lt;/p>
&lt;h3 id="6每个分片的事务日志transaction-log">6、每个分片的事务日志（Transaction Log）&lt;/h3>
&lt;p>Elasticsearch事务日志确保可以安全地将数据索引到Elasticsearch，而无需为每个文档执行低级Lucene提交。提交Lucene索引会在Lucene级别创建一个新的segment，即执行fsync（），会导致大量磁盘I / O影响性能。&lt;/p>
&lt;p>为了接受索引文档并使其可搜索而不需要完整的Lucene提交，Elasticsearch将其添加到Lucene IndexWriter并将其附加到事务日志中。在每个refresh_interval之后，它将在Lucene索引上调用reopen（），这将使数据可以在不需要提交的情况下进行搜索。这是Lucene Near Real Time API的一部分。当IndexWriter最终由于自动刷新事务日志或由于显式刷新操作而提交时，先前的事务日志将被丢弃并且新的事务日志将取代它。&lt;/p>
&lt;p>如果需要恢复，将首先恢复在Lucene中写入磁盘的segments，然后重放事务日志，以防止丢失尚未完全提交到磁盘的操作。&lt;/p>
&lt;h3 id="7lucene索引文件">7、Lucene索引文件&lt;/h3>
&lt;p>Lucene在记录Lucene索引目录中的文件方面做得很好，为了方便起见，这里重现了这些文件（Lucene中的链接文档也详细介绍了这些文件从Lucene 2.1返回后所经历的变化，所以检查一下出来）：&lt;/p>
&lt;p>&lt;img src="https://img1.tuicool.com/jymmIjJ.jpg" alt="">&lt;/p>
&lt;p>通常，您还会在Lucene索引目录中看到一个&lt;code>segments.gen&lt;/code>文件，该文件是一个帮助文件，其中包含有关当前/最新segments_N文件的信息，并用于可能无法通过目录列表返回足够信息的文件系统，以确定最新一代段文件。在较旧的Lucene版本中，您还可以找到带有.del后缀的文件。它们与Live Documents（.liv）文件的用途相同- 换句话说，这些是删除列表。&lt;/p>
&lt;h3 id="8修复有问题的碎片">8、修复有问题的碎片&lt;/h3>
&lt;p>由于Elasticsearch分片包含Lucene索引，我们可以使用Lucene的强大的CheckIndex工具（http://t.cn/Rs0gKjCl），这使我们能够扫描和修复有问题的段，通常只需要很少的数据丢失。我们通常会建议Elasticsearch用户简单地重新索引数据（re-index），但如果由于某种原因这是不可能的并且数据非常重要，那么这是一条可以采取的路线，即使它需要相当多的手工工作和时间， 取决于碎片的数量和它们的大小。&lt;/p>
&lt;p>Lucene CheckIndex工具包含在默认的Elasticsearch发行版中，无需额外下载。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback"># change this to reflect your shard path, the format is
# {path.data}/{cluster_name}/nodes/{node_id}/indices/{index_name}/{shard_id}/index/
$ export SHARD_PATH=data /elasticsearch/nodes/ 0 /indices/foo/ 0 /index/ 5
$ java -cp lib/elasticsearch-*. jar: lib/* :lib/sigar/* - ea: org.apache.lucene... org. apache.lucene.index.CheckIndex $SHARD_PATH
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果CheckIndex检测到问题并且其建议修复它看起来很合理，您可以通过添加-fix命令行参数吿诉CheckIndex应用修复程序。&lt;/p>
&lt;h3 id="9存储快照">9、存储快照&lt;/h3>
&lt;p>您可能想知道所有这些文件如何转换为快照存储库使用的存储。不用再想了：拿这个集群，将它作为我的快照快照到基于文件系统的网关，并检查存储库中的文件，我们会找到这些文件（为简洁起见省略了一些文件）：&lt;/p>
&lt;p>&lt;img src="https://img2.tuicool.com/ye6NnaQ.png" alt="">&lt;/p>
&lt;p>在根目录下，我们有一个索引文件，其中包含有关此存储库中所有快照的信息，每个快照都有一个关联的快照和元数据文件。 &lt;/p>
&lt;p>根目录下的快照文件包含有关快照状态，快照包含的索引等信息。根目录下的元数据文件包含快照时的群集元数据。&lt;/p>
&lt;p>当设置compress：true时，使用LZF压缩元数据和快照文件，LZF专注于压缩和解压缩速度，这使其非常适合Elasticsearch。&lt;/p>
&lt;p>数据存储有标题：ZV + 1字节，指示数据是否被压缩。在标题之后，格式上将存在一个或多个压缩的64K块：2字节块长度+2字节未压缩大小+压缩数据。使用此信息，您可以使用任何兼容LibLZF的解压缩程序。&lt;/p>
&lt;p>在索引级别，还有另一个文件indices / {index_name} / snapshot- {snapshot_name}，其中包含索引元数据，例如快照时索引的设置和映射。&lt;/p>
&lt;p>在分片级别，您将找到两种文件：重命名的Lucene索引文件和分片快照文件：indices / {index_name} / {shard_id} / snapshot- {snapshot_name}。此文件包含有关快照中使用的分片目录中的哪些文件的信息，以及从快照中的逻辑文件名到具体文件名的映射，这些文件名在还原时应存储为磁盘。它还包含可用于检测和防止数据损坏的所有相关文件的校验和，Lucene版本控制和大小信息。.&lt;/p>
&lt;p>您可能想知道为什么这些文件已被重命名而不是仅保留其原始文件名，这可能更容易直接在磁盘上使用。&lt;/p>
&lt;p>原因很简单：可以在再次快照之前对索引进行快照，删除并重新创建它。在这种情况下，几个文件最终会有相同的名称，但内容不同。&lt;/p>
&lt;h3 id="10小结">10、小结&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>在本文中，我们查看了各种级别的Elasticsearch写入数据目录的文件：节点，索引和分片级别。&lt;br>
我们已经看到了Lucene索引存储在磁盘上的位置，并简要描述了如何使用Lucene CheckIndex工具来验证和修复有问题的碎片。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>希望您不需要对Elasticsearch数据目录的内容执行任何操作，但是了解您最喜欢的基于搜索的数据库将哪种数据写入文件系统总是有帮助的！&lt;/p>
&lt;/li>
&lt;li>
&lt;p>不需要完整记住每个文件的确切含义，关键的时候知道去哪里更快的查找最重要。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="11补充认知">11、补充认知&lt;/h3>
&lt;p>一份数据写入es会产生多份数据用于不同查询方式，会比原数据占用更多磁盘空间。而索引setting里&amp;quot;codec&amp;quot;: &amp;ldquo;best_compression&amp;quot;是针对_source进行压缩的，压缩算法是deflate压缩比为6。&lt;/p>
&lt;p>对照上面的lucene表进行如下的关联。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>原文_source 的文件: .fdt .fdm .fdx;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>倒排索引 的文件: .tim .tip .doc;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>聚合排序 的列存文件: .dvd .dvm;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>全文检索文件: . pos .pay .nvd .nvm等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>加载到内存 中的文件有: .fdx .tip .dvm，&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>其中.tip占用内存最大，而.fdt . tim .dvd文件占用磁盘最大，例如&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">11 .5M _ ap9_1w3 .liv
25 .0G _ ap9 .fdt
31 .9M _ ap9 .fdx
444 K _ ap9 .fnm
53 .1G _ ap9_Lucene50_0 .doc
64 .2G _ ap9_Lucene50_0 .tim
781 M _ ap9_Lucene50_0 .tip
87 .7G _ ap9_Lucene54_0 .dvd
920 K _ ap9_Lucene54_0 .dvm
104 .0K _ ap9 .si
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>另外segment较小时文件内容是保存在.cfs文件中，.cfe文件保存Lucene各文件在.cfs文件的位置信息，这是为了减少Lucene打开的文件句柄数。&lt;/p>
&lt;p>es节点上shard过多了会导致内存不够，可以对静态的索引进行&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">POST {indexName}/_forcemerge?max_num_segments=1
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>HBase Compaction分析</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-compact%E5%88%86%E6%9E%90/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-compact%E5%88%86%E6%9E%90/</guid><description>&lt;h1 id="hbase-compaction分析">HBase Compaction分析&lt;/h1>
&lt;h2 id="compact-流程">compact 流程&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-50-22-image-20180822111406478.png" alt="image-20180822111406478">&lt;/p>
&lt;h2 id="compact-触发条件">compact 触发条件&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>memstore flush：&lt;/p>
&lt;p>memstore flush会产生HFile文件，文件越来越多就需要compact。因此在每次执行完Flush操作之后，都会对当前Store中的文件数进行判断，一旦store 中的HFile文件数 - 正在compacting的文件数 &amp;gt; minFilesToCompact，就会触发compaction。默认：&amp;ldquo;hbase.hstore.compaction.min&amp;rdquo; 为：3。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kt">boolean&lt;/span> &lt;span class="n">needsCompaction&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">flush&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">commit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">status&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">needsCompaction&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">compactionRequested&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">needsCompaction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Collection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">HStoreFile&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">storeFiles&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">HStoreFile&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">filesCompacting&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">numCandidates&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">storeFiles&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">size&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">filesCompacting&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">size&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">numCandidates&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="n">comConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMinFilesToCompact&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">minFilesToCompact&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">max&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getInt&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.hstore.compaction.min&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>周期检查：(CompactionChecker)&lt;/p>
&lt;p>后台线程CompactionChecker定期触发检查是否需要执行compaction，检查周期为：hbase.server.thread.wakefrequency*hbase.server.compactchecker.interval.multiplier。默认为10000 * 1000 ms，就是2个多小时。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kt">long&lt;/span> &lt;span class="n">multiplier&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getCompactionCheckMultiplier&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">assert&lt;/span> &lt;span class="n">multiplier&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">iteration&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="n">multiplier&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">continue&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">needsCompaction&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Queue a compaction. Will recognize if major is needed.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">instance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compactSplitThread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">requestSystemCompaction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hr&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">getName&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; requests compaction&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>手动触发：&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>一般来讲，手动触发compaction通常是为了执行major compaction，原因有三，&lt;/p>
&lt;p>其一是因为很多业务担心自动major compaction影响读写性能，因此会选择低峰期手动触发；&lt;/p>
&lt;p>其二也有可能是用户在执行完alter操作之后希望立刻生效，执行手动触发major compaction；&lt;/p>
&lt;p>其三是HBase管理员发现硬盘容量不够的情况下手动触发major compaction删除大量过期数据；&lt;/p>
&lt;p>无论哪种触发动机，一旦手动触发，HBase会不做很多自动化检查，直接执行合并。&lt;/p>
&lt;h2 id="compact-文件选择策略">compact 文件选择策略&lt;/h2>
&lt;p>选择合适的文件进行合并是整个compaction的核心，因为合并文件的大小以及其当前承载的IO数直接决定了compaction的效果。最理想的情况是，这些文件承载了大量IO请求但是大小很小，这样compaction本身不会消耗太多IO，而且合并完成之后对读的性能会有显著提升。然而现实情况可能大部分都不会是这样。都会首先对该Store中所有HFile进行一一排查，排除不满足条件的部分文件：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>排除当前正在执行compact的文件及其比这些文件更新的所有文件（SequenceId更大）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>排除某些过大的单个文件，如果文件大小大于hbase.hzstore.compaction.max.size（默认Long最大值），则被排除，否则会产生大量IO消耗&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>经过排除的文件称为候选文件。&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2019-12-31-19-39-28-image.png" alt="">&lt;/p>
&lt;p>文件现在策略有：&lt;/p>
&lt;ul>
&lt;li>RatioBasedCompactionPolicy：从最旧文件开始遍历到最新候选文件，找到小于［hbase.hstore.compaction.min.size（默认为memstore的flush大小，128M）和compact文件总大小*ratio 的最大值］的符合条件文件，如果发现不符合则马上停止搜索。ratio是一个可变的比例，可以通过设置高峰期的时间来改变这个比例，在高峰期时ratio为1.2，非高峰期为5，也就是非高峰期允许compact更大的文件（非高峰期可以耗费更大IO）。 目的是尽可能找到小文件进行minor compact。如果判断这个compact操作后文件数仍然过多会阻塞flush操作，则只是简单选择从最老的文件起，候选文件数减去hbase.hstore.compaction.min（默认3）个文件。&lt;/li>
&lt;li>ExploringCompactionPolicy：从最旧文件开始遍历&lt;strong>所有的&lt;/strong>候选文件，找出符合［compact文件大小 小于 hbase.hstore.compaction.max.size（默认Long最大值）且所有文件的大小都不会超过其它文件大小*ratio］并且效率最高［compact文件数最多或compact大小最小］。ratio是高峰期比例。注意，由于存在限制，因此可能候选文件被排除到为0个，这时如果判断这个compact操作后文件数仍然过多会阻塞flush操作，则会选择hbase.hstore.compaction.min（默认3）个文件起，符合最大（Long最大值）最小compact大小（128MB）的总大小最小的一个子集合。&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h2 id="minor-compact和-major-compact">minor compact和 major compact&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>minor compact&lt;/strong>：将store 中 相邻的 flie 合并为一个大的 file，只用来做部分文件的合并操作以及包括minVersion=0并且设置ttl的过期版本清理，不做任何删除数据、多版本数据的清理工作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>major compact&lt;/strong>：对Region下的HStore下的所有StoreFile执行合并操作，会做删除数据，多版本数据清理工作，最终的结果是整理合并出一个文件。&lt;/p>
&lt;p>major compaction的判断条件如下（满足任意一个）：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>用户强制执行major compaction;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>长时间没有进行compact（CompactionChecker的判断条件2）且候选文件数小于hbase.hstore.compaction.max（默认10）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Store中含有Reference文件，Reference文件是split region产生的临时文件，只是简单的引用文件，一般必须在compact过程中删除。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>如果不满足major compaction条件，就必然为minor compaction。&lt;/p>
&lt;h2 id="compact-线程池选择">compact 线程池选择&lt;/h2>
&lt;p>compact 有 largeCompaction、smallCompaction这两个线程池负责处理compact 请求。&lt;/p>
&lt;ul>
&lt;li>largeCompaction (longCompaction)：大文件合并线程，当合并的文件总大小大于阈值(throttlePoint)时处理；&lt;/li>
&lt;li>smallCompaction (shortCompaction)：小文件合并线程池。处理合并文件总大小小于阈值时的情况。&lt;/li>
&lt;/ul>
&lt;p>大小合并的阈值（throttlePoint）由参数&lt;code>hbase.regionserver.thread.compaction.throttle&lt;/code>决定，没有设置的话，由：&lt;code>2 * &amp;quot;hbase.hstore.compaction.max&amp;quot; * &amp;quot;hbase.hregion.memstore.flush.size&amp;quot;&lt;/code>， 默认的2.5GB。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">throttlePoint&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.regionserver.thread.compaction.throttle&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">maxFilesToCompact&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">storeConfigInfo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMemStoreFlushSize&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="compact过程">Compact过程&lt;/h2>
&lt;p>源码&lt;code>HStore::compact()&lt;/code>中，具体流程如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>分别读出待合并hfile文件的KV，并顺序写到位于./tmp目录下的临时文件中&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将临时文件移动到对应region的数据目录&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将compaction的输入文件路径和输出文件路径封装为KV写入WAL日志，并打上compaction标记，最后强制执行sync&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将对应region数据目录下的compaction输入文件全部删除&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>上述四个步骤看起来简单，但实际是很严谨的，具有很强的容错性和完美的幂等性：&lt;/p>
&lt;p>A. 如果RS在步骤2之前发生异常，本次compaction会被认为失败，如果继续进行同样的compaction，上次异常对接下来的compaction不会有任何影响，也不会对读写有任何影响。唯一的影响就是多了一份多余的数据。&lt;/p>
&lt;p>B. 如果RS在步骤2之后、步骤3之前发生异常，同样的，仅仅会多一份冗余数据。&lt;/p>
&lt;p>C. 如果在步骤3之后、步骤4之前发生异常，RS在重新打开region之后首先会从WAL中看到标有compaction的日志，因为此时输入文件和输出文件已经持久化到HDFS，因此只需要根据WAL移除掉compaction输入文件即可&lt;/p>
&lt;p>in-memory Compaction策略
当一个active segment被flush到pipeline中之后，后台会触发一个任务对pipeline中的数据进行合并。合并任务会对pipeline中所有segment进行scan，将他们的索引合并为一个。有三种合并策略可供选择：Basic,Eager,Adaptive。
Basic compaction策略和Eager compaction策略的区别在于如何处理cell数据。Basic compaction不会清理多余的数据版本，这样就不需要对cell的内存进行拷贝。而Eager compaction会过滤重复的数据，并清理多余的版本，这意味着会有额外的开销：例如如果使用了MSLAB存储cell数据，就需要把经过清理之后的cell从旧的MSLAB拷贝到新的MSLAB。basic适用于所有写入模式，eager则主要针对数据大量淘汰的场景：例如消息队列、购物车等。
Adaptive策略则是根据数据的重复情况来决定是否使用Eager策略。在Adaptive策略中，首先会对待合并的segment进行评估，方法是在已经统计过不重复key个数的segment中，找出cell个数最多的一个，然后用这个segment的numUniqueKeys / getCellsCount得到一个比例，如果比例小于设定的阈值，则使用Eager策略，否则使用Basic策略。&lt;/p>
&lt;h2 id="compact流控">Compact流控&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.hstore.flush.throughput.lower.bound， 100M
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://www.cnblogs.com/cenyuhai/p/3746473.html">https://www.cnblogs.com/cenyuhai/p/3746473.html&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://cloud.tencent.com/developer/article/1005586">Hbase Region Split compaction 过程分析以及调优 - 云+社区 - 腾讯云&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>HBase MemStore 分析</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-memstore%E5%88%86%E6%9E%90/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-memstore%E5%88%86%E6%9E%90/</guid><description>&lt;h1 id="hbase-memstore-分析">HBase MemStore 分析&lt;/h1>
&lt;p>&lt;strong>Memstore Flush触发条件&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Memstore&lt;/strong>级别：当Region中任意一个MemStore的大小达到了上限（hbase.hregion.memstore.flush.size，默认128MB），会触发Memstore flush。&lt;/li>
&lt;li>&lt;strong>Region&lt;/strong>级别：当Region中所有Memstore的大小总和达到了上限（hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size，默认 2* 128M = 256M），会触发memstore flush, 此时会阻塞update操作。&lt;/li>
&lt;li>&lt;strong>Region Server&lt;/strong>级别：当一个RS中所有Memstore的大小总和达到了上限（hbase.regionserver.global.memstore.upperLimit ＊ hbase_heapsize，默认 40%的JVM内存使用量），会触发部分Memstore刷新。Flush顺序是按照Memstore由大到小执行，先Flush Memstore最大的Region，再执行次大的，直至总体Memstore内存使用量低于阈值（hbase.regionserver.global.memstore.lowerLimit ＊ hbase_heapsize，默认 38%的JVM内存使用量）。&lt;/li>
&lt;li>&lt;strong>WAL&lt;/strong>: 当一个Region Server中HLog数量达到上限（可通过参数hbase.regionserver.maxlogs配置）时，系统会选取最早的一个 HLog对应的一个或多个Region进行flush&lt;/li>
&lt;li>&lt;strong>定期刷新&lt;/strong>：默认周期为1小时，确保Memstore不会长时间没有持久化。为避免所有的MemStore在同一时间都进行flush导致的问题，定期的flush操作有20000左右的随机延时。&lt;/li>
&lt;li>手动执行flush：用户可以通过shell命令 flush ‘tablename’或者flush ‘region name’分别对一个表或者一个Region进行flush。&lt;/li>
&lt;/ol>
&lt;p>MemStore的最小flush单元是HRegion而不是单个MemStore。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="http://hbasefly.com/2019/10/18/hbase-memstore-evolution/">HBase内存管理之MemStore进化论 – 有态度的HBase/Spark/BigData&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase python client</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-python-client%E6%93%8D%E4%BD%9C/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-python-client%E6%93%8D%E4%BD%9C/</guid><description>&lt;h1 id="hbase-python-client">HBase python client&lt;/h1>
&lt;h2 id="介绍">介绍&lt;/h2>
&lt;p>hbase 提供thrift接口，python可通过该接口和hbase通信。happybase是python基于thrift协议的一个hbase客户端库，其配置使用简单。使用步骤如下：&lt;/p>
&lt;h2 id="happybase-使用">happybase 使用&lt;/h2>
&lt;ol>
&lt;li>启动hbase master 节点上的thrift接口服务：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ bin/hbase thrift start
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>thrift默认端口是9090。&lt;/p>
&lt;ol start="2">
&lt;li>
&lt;p>安装happybase&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ pip install happybase
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>python&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="kn">import&lt;/span> &lt;span class="nn">happybase&lt;/span>
&lt;span class="n">hbase_host&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;10.0.48.219&amp;#39;&lt;/span>
&lt;span class="n">conn&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">happybase&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Connection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hbase_host&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nb">print&lt;/span> &lt;span class="n">conn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tables&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">conn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">create_table&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;table_name&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;cf1&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">dict&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="s1">&amp;#39;cf2&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">dict&lt;/span>&lt;span class="p">()})&lt;/span>
&lt;span class="n">t1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">table&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;table_name&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">put&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;row-key-1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;cf1:name1&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="s1">&amp;#39;value1&amp;#39;&lt;/span>&lt;span class="p">})&lt;/span>
&lt;span class="c1">#&lt;/span>
&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;row-key-1&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">delete&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;row-key-1&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;span class="s1">批量
&lt;/span>&lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;span class="n">b&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">batch&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">b&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">put&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="n">b&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">send&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol>
&lt;h2 id="常见问题">常见问题&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>TTransportException: TTransportException(message=&amp;lsquo;TSocket read 0 bytes&amp;rsquo;, type=4)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>原因&lt;/strong>：thrift 的server端和client端的协议不匹配造成的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>解决&lt;/strong>：&lt;/p>
&lt;p>修改hbase-site.xml，禁用TFramedTransport和TCompactProtocol功能，即：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml"> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.thrift.framed&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>false&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.thrift.compact&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>false&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase Region Split</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-split/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-split/</guid><description>&lt;h1 id="hbase-region-split">HBase Region Split&lt;/h1>
&lt;h2 id="split-作用">split 作用&lt;/h2>
&lt;p>在 HBase 中，split 其实是进行 sharding 的一种技术手段，通过 HBase 的 split 条件和 split 策略，将 region 进行合理的 split，再通过 HBase 的 balance 策略，将分裂的 region 负载均衡到各个 regionserver 上，最大化的发挥分布式系统的优点。HBase 这种自动的 sharding 技术比传统的数据库 sharding 要省事的多，减轻了维护的成本，但是这样也会给 HBase 带来额外的 IO 开销，因此在很多系统中如果能很好的预计 rowkey 的分布和数据增长情况，可以通过预先分区，事先将 region 分配好，再将 HBase 的自动分区禁掉。&lt;/p>
&lt;h2 id="split-触发条件">split 触发条件&lt;/h2>
&lt;ul>
&lt;li>自动&lt;/li>
&lt;li>手动&lt;/li>
&lt;/ul>
&lt;h2 id="split-策略">split 策略&lt;/h2>
&lt;h2 id="步骤">步骤&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">private&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">flushRegion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kd">final&lt;/span> &lt;span class="n">Region&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">emergencyFlush&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">forceFlushAllStores&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">synchronized&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">regionsInQueue&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">FlushRegionEntry&lt;/span> &lt;span class="n">fqe&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">regionsInQueue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">remove&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Use the start time of the FlushRegionEntry if available
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">fqe&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">emergencyFlush&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Need to remove from region from delay queue. When NOT an
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// emergencyFlush, then item was removed via a flushQueue.poll.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">flushQueue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">remove&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">fqe&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">lock&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readLock&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">lock&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">notifyFlushRequest&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">emergencyFlush&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">FlushResult&lt;/span> &lt;span class="n">flushResult&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">flush&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">forceFlushAllStores&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">shouldCompact&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">flushResult&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">isCompactionNeeded&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// We just want to check the size
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">shouldSplit&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">((&lt;/span>&lt;span class="n">HRegion&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">checkSplit&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">shouldSplit&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">server&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compactSplitThread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">requestSplit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">shouldCompact&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">server&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compactSplitThread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">requestSystemCompaction&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">region&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Thread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">currentThread&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">DroppedSnapshotException&lt;/span> &lt;span class="n">ex&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>HBase 将整个切分过程包装成了一个事务，意图能够保证切分事务的原子性。整个分裂事务过程分为三个阶段：prepare – execute – (rollback) ，操作模版如下：&lt;/p>
&lt;ul>
&lt;li>prepare 阶段：&lt;/li>
&lt;/ul>
&lt;p>在内存中初始化两个子 region，具体是生成两个 HRegionInfo 对象，包含 tableName、regionName、startkey、endkey 等。同时会生成一个 transaction journal，这个对象用来记录切分的进展，具体见 rollback 阶段。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>execute 阶段：&lt;/p>
&lt;p>切分的核心操作。见下图（来自&lt;a href="http://zh.hortonworks.com/blog/apache-hbase-region-splitting-and-merging/">Hortonworks&lt;/a>）：&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-53-10-image-20190430151418404.png" alt="image-20190430151418404">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>
&lt;p>regionserver 更改 ZK 节点 /region-in-transition 中该 region 的状态为 SPLITING。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>master 通过 watch 节点/region-in-transition 检测到 region 状态改变，并修改内存中 region 的状态，在 master 页面 RIT 模块就可以看到 region 执行 split 的状态信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在父存储目录下新建临时文件夹.split 保存 split 后的 daughter region 信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>关闭 parent region：parent region 关闭数据写入并触发 flush 操作，将写入 region 的数据全部持久化到磁盘。此后短时间内客户端落在父 region 上的请求都会抛出异常 NotServingRegionException。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>核心分裂步骤：在.split 文件夹下新建两个子文件夹，称之为 daughter A、daughter B，并在文件夹中生成 reference 文件，分别指向父 region 中对应文件。这个步骤是所有步骤中最核心的一个环节，生成 reference 文件日志如下所示：&lt;/p>
&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2019-12-24-09-38-29-image.png" title="" alt="" data-align="center">
&lt;/li>
&lt;li>
&lt;p>父 region 分裂为两个子 region 后，将 daughter A、daughter B 拷贝到 HBase 根目录下，形成两个新的 region。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>父 region 通知修改 hbase.meta 表后下线，不再提供服务。下线后 parent region 在 meta 表中的信息并不会马上删除，而是标注 split 列、offline 列为 true，并记录两个子 region&lt;/p>
&lt;/li>
&lt;li>
&lt;p>开启 daughter A、daughter B 两个子 region。通知修改 hbase.meta 表，正式对外提供服务。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>rollback&lt;/p>
&lt;p>如果 execute 阶段出现异常，则执行 rollback 操作。为了实现回滚，整个切分过程被分为很多子阶段，回滚程序会根据当前进展到哪个子阶段清理对应的垃圾数据。代码中使用 JournalEntryType 来表征各个子阶段，具体见下图：&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-52-59-image-20190430151907154.png" alt="image-20190430151907154">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="自定义拆分策略">自定义拆分策略&lt;/h2>
&lt;p>您可以使用自定义 RegionSplitPolicy（HBase 0.94+）重写默认拆分策略。通常，自定义拆分策略应该扩展 HBase 的默认拆分策略： IncreasingToUpperBoundRegionSplitPolicy。&lt;/p>
&lt;p>该策略可以通过 HBase 配置或者也可以基于每个表在全局范围内进行设置。&lt;/p>
&lt;p>在 hbase-site.xml 中全局配置拆分策略：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.region.split.policy&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用 Java API 在表上配置拆分策略：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">HTableDescriptor tableDesc = new HTableDescriptor(&amp;#34;test&amp;#34;);
tableDesc.setValue(HTableDescriptor.SPLIT_POLICY, ConstantSizeRegionSplitPolicy.class.getName());
tableDesc.addFamily(new HColumnDescriptor(Bytes.toBytes(&amp;#34;cf1&amp;#34;)));
admin.createTable(tableDesc);
----
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用 HBase Shell 在表上配置拆分策略：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">hbase&amp;gt; create &lt;span class="s1">&amp;#39;test&amp;#39;&lt;/span>, &lt;span class="o">{&lt;/span>&lt;span class="nv">METADATA&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="o">{&lt;/span>&lt;span class="s1">&amp;#39;SPLIT_POLICY&amp;#39;&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="s1">&amp;#39;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;#39;&lt;/span>， &lt;span class="o">}}&lt;/span>,&lt;span class="o">{&lt;/span>&lt;span class="nv">NAME&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="s1">&amp;#39;cf1&amp;#39;&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>该策略可以通过使用的 HBaseConfiguration 或按表进行全局设置：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">myHtd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">myHtd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SPLIT_POLICY&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyCustomSplitPolicy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>该&lt;code>DisabledRegionSplitPolicy&lt;/code>策略阻止手动区域拆分。&lt;/p>
&lt;p>在线修改 split 策略&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">hbase&amp;gt; &lt;span class="nv">t&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;test_66_snappy5&amp;#34;&lt;/span>
hbase&amp;gt; disable t&lt;span class="p">;&lt;/span> alter t, &lt;span class="o">{&lt;/span>&lt;span class="nv">METADATA&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="o">{&lt;/span>&lt;span class="s1">&amp;#39;SPLIT_POLICY&amp;#39;&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="s1">&amp;#39;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;MAX_FILESIZE&amp;#39;&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="m">214748364800&lt;/span> &lt;span class="o">}}&lt;/span> &lt;span class="p">;&lt;/span> &lt;span class="nb">enable&lt;/span> t
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/39648692">https://zhuanlan.zhihu.com/p/39648692&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.tencent.com/developer/article/1005586">https://cloud.tencent.com/developer/article/1005586&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.jianshu.com/p/f9abe7ddf5a1">HBase 原理–所有 Region 切分的细节都在这里了 - 简书&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://andr-robot.github.io/HBase%E4%B8%ADRegion%E7%9A%84%E5%88%87%E5%88%86/">https://andr-robot.github.io/HBase%E4%B8%ADRegion%E7%9A%84%E5%88%87%E5%88%86/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.csdn.net/u010039929/article/details/74295869">Hbase Split 解析_大数据_Kuzury-CSDN 博客&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase Region 自动拆分策略</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase_split_policy/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase_split_policy/</guid><description>&lt;h1 id="hbase-region-自动拆分策略">HBase Region 自动拆分策略&lt;/h1>
&lt;p>HBase-2.x支持7种Region自动拆分Region的策略，类图如下:&lt;/p>
&lt;p>&lt;img src="assets/2020-04-02-17-31-02-image.png" alt="">&lt;/p>
&lt;p>设置自动拆分策略的关键配置如下:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.regionserver.region.split.policy
description: Region自动拆分的策略
default:
HBase-1.2.x: org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy
HBase-2.x: org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy
option:
org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy
org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.BusyRegionSplitPolicy (HBase-2.x Only)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>配置方法：&lt;/p>
&lt;ul>
&lt;li>在hbase-site.xml中配置，例如：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.region.split.policy&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在HBase Configuration中配置&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">HBaseConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.regionserver.region.split.policy&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在创建表的时候配置
Region的拆分策略需要根据表的属性来合理的配置，所以建议不要使用前两种方法来配置拆分策略，关于在建表的时候怎么配置，会在下面解释每种策略的时候说明。&lt;/li>
&lt;/ul>
&lt;p>接下来将详细介绍这7种Region自动拆分的策略。&lt;/p>
&lt;h2 id="1-constantsizeregionsplitpolicy">1. ConstantSizeRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述">策略描述&lt;/h3>
&lt;p>这种策略非常简单，只要Region的大小达到了&lt;code>hbase.hregion.max.filesize&lt;/code>所定义的大小，就进行拆分。&lt;/p>
&lt;h3 id="相关参数">相关参数&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.hregion.max.filesize
    default: 10737418240 (10GB)
    description: 当一个Region的容量达到这个配置定义的大小后,就会拆分Region
hbase.server.thread.wakefrequency
    default: 10000 (10s)
    description: 检测Region的大小是否超过限制的时间间隔
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="部分源码">部分源码&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="cm">/** Conf key for the max file size after which we split the region */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">HREGION_MAX_FILESIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hbase.hregion.max.filesize&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="cm">/** Default maximum file size */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">DEFAULT_MAX_FILE_SIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">10&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">1024&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">1024&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">1024L&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm">
&lt;/span>&lt;span class="cm">* 获取拆分上限值
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="kd">protected&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">configureForRegion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HRegion&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">getConf&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">desc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTableDesc&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">desc&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// 如果用户在建表时指定了该表的单个Region的上限, 取用户定义的这个值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">desiredMaxFileSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">desc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMaxFileSize&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果用户没有定义, 取&amp;#39;hbase.hregion.max.filesize&amp;#39;这个配置定义的值, 如果这个配置没有定义, 取默认值 10G
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">desiredMaxFileSize&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">desiredMaxFileSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HREGION_MAX_FILESIZE&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DEFAULT_MAX_FILE_SIZE&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm">
&lt;/span>&lt;span class="cm">* 判断是否进行拆分
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="kd">protected&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">shouldSplit&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">force&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">shouldForceSplit&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">foundABigStore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Store&lt;/span> &lt;span class="n">store&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getStores&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// 如果有任何一个Region此时不能被拆分(例如还有一些代码或者线程在访问它), 那么返回false
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">((!&lt;/span>&lt;span class="n">store&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">canSplit&lt;/span>&lt;span class="o">()))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果Region的大小已经大于desiredMaxFileSize这个值, 返回true
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">store&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getSize&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">desiredMaxFileSize&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">foundABigStore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">foundABigStore&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">force&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="c1">// 只要shouldSplit()方法返回true, 就进行Region的拆分
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="拆分效果">拆分效果&lt;/h3>
&lt;p>经过这种策略的拆分后，Region的大小是均匀的，例如一个10G的Region，拆分为两个Region后，这两个新的Region的大小是相差不大的，理想状态是每个都是5G。&lt;/p>
&lt;h3 id="设置方法">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;tableName&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要配置或者不配置
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMaxFileSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addFamily&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="n">admin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2-increasingtoupperboundregionsplitpolicy">2. IncreasingToUpperBoundRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-1">策略描述&lt;/h3>
&lt;p>这种拆分策略是HBase-1.2.x的默认使用的拆分策略，Region的前几次拆分的阈值不是固定的数值，是需要进行计算得到，计算过程在源码中说明。&lt;/p>
&lt;h3 id="相关配置">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.hregion.memstore.flush.size
    default: 134217728 (128MB)
    description: 如果Memstore的大小超过这个字节数,它将被刷新到磁盘.
hbase.increasing.policy.initial.size
    default: none
    description: IncreasingToUpperBoundRegionSplitPolicy拆分策略下用于计算Region阈值的一个初始值
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="部分源码-1">部分源码&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">protected&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">getSizeToCheck&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kd">final&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">0&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">100&lt;/span>
&lt;span class="o">?&lt;/span> &lt;span class="n">getDesiredMaxFileSize&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">:&lt;/span> &lt;span class="n">Math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">min&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">getDesiredMaxFileSize&lt;/span>&lt;span class="o">(),&lt;/span>
&lt;span class="n">initialSize&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果表目前的Region个数为0或者大于100，那么Region拆分上限值是10G，因为getDesiredMaxFileSize()方法是父类ConstantSizeRegionSplitPolicy的方法，而我们上面分析过，上限大小默认是10G。&lt;/p>
&lt;p>如果表目前的Region个数在[1,100]之间，那么使用以下公式来确定Region的上限大小:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">Math.min(
getDesiredMaxFileSize(),
initialSize * tableRegionsCount * tableRegionsCount * tableRegionsCount
)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>initialSize的计算过程如下:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">HREGION_MEMSTORE_FLUSH_SIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hbase.hregion.memstore.flush.size&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">DEFAULT_MEMSTORE_FLUSH_SIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">1024&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">1024&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">128L&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">protected&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">configureForRegion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HRegion&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">getConf&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// 如果配置了&amp;#39;hbase.increasing.policy.initial.size&amp;#39;, 取这个值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">initialSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.increasing.policy.initial.size&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">initialSize&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果设置了MemStoreFlushSize, initialSize的值为该值 * 2
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">desc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTableDesc&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">desc&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">initialSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">desc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMemStoreFlushSize&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果用户没有设置MemStoreFlushSize,配置文件中也没有&amp;#39;hbase.increasing.policy.initial.size&amp;#39;这个配置
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 那么initialSize = 2 * hbase.hregion.memstore.flush.size的值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">initialSize&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">initialSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HREGION_MEMSTORE_FLUSH_SIZE&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DEFAULT_MEMSTORE_FLUSH_SIZE&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>根据以上内容我们可以得知，在默认情况，即我们什么都没有配置的情况下，使用IncreasingToUpperBoundRegionSplitPolicy策略拆分Region的过程是:&lt;/p>
&lt;ul>
&lt;li>某张表刚开始只有一个Region, 此时&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">tableRegionsCount = 1
initialSize = 2 * 128M = 256M
getDesiredMaxFileSize() = 10G
min(getDesiredMaxFileSize(), initialSize * tableRegionsCount * tableRegionsCount * tableRegionsCount) = min(10G, 256M) = 256M
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>即当第一个Region达到256M的时候开始拆分&lt;/p>
&lt;ul>
&lt;li>拆分后这张表有两个Region&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">tableRegionsCount = 2
initialSize = 2 * 128M = 256M
getDesiredMaxFileSize() = 10G
min(getDesiredMaxFileSize(), initialSize * tableRegionsCount * tableRegionsCount * tableRegionsCount)
= min(10G, 2 * 2 * 2 * 256M)
= min(10G, 2G)
= 2G
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>即当Region大小达到2GB时开始拆分&lt;/p>
&lt;ul>
&lt;li>以此类推，当表有3个Region的时候，Region的最大容量为6.75G&lt;/li>
&lt;li>当表有4个Region的时候，计算出来的结果大于10GB，所以使用10GB作为以后的拆分上限&lt;/li>
&lt;/ul>
&lt;p>总结一下就是，使用IncreasingToUpperBoundRegionSplitPolicy策略，Region最大容量为:
&lt;code>256M -&amp;gt; 2GB -&amp;gt; 6.75GB -&amp;gt; 10GB -&amp;gt; 10GB -&amp;gt; ...&lt;/code>&lt;/p>
&lt;h3 id="设置方法-1">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;tableName&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要配置或者不配置
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.increasing.policy.initial.size&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;1048576000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMaxFileSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMemStoreFlushSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addFamily&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="n">admin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="拆分效果-1">拆分效果&lt;/h3>
&lt;p>均匀拆分&lt;/p>
&lt;h2 id="3-keyprefixregionsplitpolicy">3. KeyPrefixRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-2">策略描述&lt;/h3>
&lt;p>除了简单粗暴地根据大小来拆分，我们还可以自己定义拆分点。KeyPrefixRegionSplitPolicy是IncreasingToUpperBoundRegionSplitPolicy的子类，在前者的基础上增加了对拆分点(splitPoint，拆分点就是Region被拆分处的rowkey)的定义。它保证了有相同前缀的rowkey不会被拆分到两个不同的Region里面。&lt;/p>
&lt;h3 id="相关配置-1">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">KeyPrefixRegionSplitPolicy.prefix_length
### 注意，有的博客中这个配置是
`prefix_split_key_policy.prefix_length
# 这个配置在HBase-1.2.x版本中已经标志为 Deprecated
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以上参数指定了在rowkey中，取前几个字符作为前缀，例如这个设置这个值为5，那么在rowkey中，如果前5个字符是相同的，拆分后也一定会在一个Region中。&lt;/p>
&lt;p>&lt;strong>拆分效果&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>普通的拆分&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-04-02-17-45-44-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>按照Rowkey前缀拆分&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-04-02-17-46-10-image.png" alt="">&lt;/p>
&lt;h3 id="设置方法-2">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;KeyPrefixRegionSplitPolicy.prefix_length&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;5&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要配置或者不配置
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.increasing.policy.initial.size&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;1048576000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMaxFileSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMemStoreFlushSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addFamily&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="n">admin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>说明&lt;/strong>&lt;/p>
&lt;p>KeyPrefixRegionSplitPolicy是IncreasingToUpperBoundRegionSplitPolicy类的子类，就是按照rowkey的前缀去拆分Region，但是什么时候拆分，原Region容量的最大值是多少还是需要使用IncreasingToUpperBoundRegionSplitPolicy的方法去计算。SteppingSplitPolicy、DelimitedKeyPrefixRegionSplitPolicy、BusyRegionSplitPolicy (HBase-2.x Only)，他们获取Region的拆分阈值的方式都是继承自IncreasingToUpperBoundRegionSplitPolicy。&lt;/p>
&lt;h3 id="适用场景">适用场景&lt;/h3>
&lt;p>如果你的所有数据都只有一两个前缀，那么采用默认的策略较好。
如果你的前缀划分的比较细，你的查询就比较容易发生跨Region查询的情况，此时采用KeyPrefixRegionSplitPolicy较好。
所以这个策略适用的场景是：&lt;/p>
&lt;ul>
&lt;li>数据有多种前缀。&lt;/li>
&lt;li>查询多是针对前缀，较少跨越多个前缀来查询数据。&lt;/li>
&lt;/ul>
&lt;h2 id="4-delimitedkeyprefixregionsplitpolicy">4. DelimitedKeyPrefixRegionSplitPolicy&lt;/h2>
&lt;h3 id="拆分策略">拆分策略&lt;/h3>
&lt;p>该策略也是继承自IncreasingToUpperBoundRegionSplitPolicy，它也是根据你的rowkey前缀来进行拆分的。唯一的不同就是：KeyPrefixRegionSplitPolicy是根据rowkey的固定前几位字符来进行判断，而DelimitedKeyPrefixRegionSplitPolicy是根据分隔符来判断的。&lt;/p>
&lt;p>在有些系统中rowkey的前缀可能不一定都是定长的，比如你拿服务器的名字来当前缀，有的服务器叫host12有的叫host1。这些场景下严格地要求所有前缀都定长可能比较难，而且这个定长如果未来想改也不容易。DelimitedKeyPrefixRegionSplitPolicy就给了你一个定义长度字符前缀的自由。&lt;/p>
&lt;h3 id="相关配置-2">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">DelimitedKeyPrefixRegionSplitPolicy.delimiter
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用该参数定义的分隔符分隔rowkey，分隔后的前部分相同的rowkey拆分后一定会在一个Region中。&lt;/p>
&lt;h3 id="配置方法">配置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;DelimitedKeyPrefixRegionSplitPolicy.delimiter&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;_&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="拆分效果-2">拆分效果&lt;/h3>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-04-02-17-47-18-image.png" alt="">&lt;/p>
&lt;h2 id="5-steppingsplitpolicy">5. SteppingSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-3">策略描述&lt;/h3>
&lt;p>这种策略和&lt;code>IncreasingToUpperBoundRegionSplitPolicy&lt;/code>策略很相似，但更简单，第一个Region容量的上限为256M，之后都是10G，这个策略考虑到&lt;code>IncreasingToUpperBoundRegionSplitPolicy&lt;/code>会多拆分几个Region(256M -&amp;gt; 2G -&amp;gt; 6.75G -&amp;gt; 10G)，所以进行了简化，它的源码只有一个方法，其他都是继承自&lt;code>IncreasingToUpperBoundRegionSplitPolicy&lt;/code>类&lt;/p>
&lt;h3 id="源码">源码&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">protected&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">getSizeToCheck&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kd">final&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">1&lt;/span> &lt;span class="o">?&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">initialSize&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">getDesiredMaxFileSize&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="设置方法-3">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="6-busyregionsplitpolicy-hbase-2x-only">6. BusyRegionSplitPolicy (HBase-2.x Only)&lt;/h2>
&lt;h3 id="策略描述-4">策略描述&lt;/h3>
&lt;p>此前的拆分策略都没有考虑热点问题。所谓热点问题就是数据库中的Region被访问的频率并不一样，某些Region在短时间内被访问的很频繁，承载了很大的压力，这些Region就是热点Region。&lt;/p>
&lt;h3 id="相关配置-3">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.busy.policy.blockedRequests
default: 0.2f
description: 请求阻塞率，即请求被阻塞的严重程度。
取值范围是[0.0, 1.0]，默认是0.2，即20%的请求被阻塞的意思。
hbase.busy.policy.minAge
default: 600000 (10min)
description: 拆分最小年龄。
当Region的年龄比这个小的时候不拆分，这是为了防止在判断是否要拆分的时候出现了短时间的访问频率波峰，结果没必要拆分的Region被拆分了，因为短时间的波峰会很快地降回到正常水平。单位毫秒，默认值是600000，即10分钟。
hbase.busy.policy.aggWindow
default: 300000 (5min)
description: 计算是否繁忙的时间窗口，单位毫秒，默认值是300000，即5分钟。
用以控制计算的频率。
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>如何确定为热点Region(Busy Region)&lt;/strong>&lt;/p>
&lt;p>如果&amp;quot;当前时间 – 上次检测时间&amp;quot; &amp;gt;= hbase.busy.policy.aggWindow，则进行如下计算：&lt;/p>
&lt;p>请求的被阻塞率(aggBlockedRate) = 这段时间被阻塞的请求 / 这段时间的总请求&lt;/p>
&lt;p>如果 aggBlockedRate &amp;gt; hbase.busy.policy.blockedRequests 且该Region的 hbase.busy.policy.minAge &amp;gt; 10min，则判断该Region为Busy Region&lt;/p>
&lt;p>当Region被判定为Busy Region，就会被拆分。&lt;/p>
&lt;h3 id="设置方法-4">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.BusyRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要适当修改
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.busy.policy.blockedRequests&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;0.2&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.busy.policy.minAge&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;600000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.busy.policy.aggWindow&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;300000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="适用场景-1">适用场景&lt;/h3>
&lt;p>如果你的系统常常会出现热点Region，而你对性能有很高的追求，那么这种策略可能会比较适合你。它会通过拆分热点Region来缓解热点Region的压力，但是根据热点来拆分Region也会带来很多不确定性因素，因为你也不知道下一个被拆分的Region是哪个。&lt;/p>
&lt;h2 id="7-disabledregionsplitpolicy">7. DisabledRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-5">策略描述&lt;/h3>
&lt;p>禁止Region拆分，这个策略是极少使用的，因为就算是你按照自己数据的特性在建表的时候合理的进行了预拆分（即还没有写入的数据的时候就已经手动分好了Region），但是后续随着数据的持续写入，我们自己预先分好的Region的大小也一定会达到阈值，那时候还是要依靠HBase的自动拆分策略去拆分Region。&lt;/p>
&lt;p>当然，这种策略也有它的用途：&lt;/p>
&lt;p>假如我们有一批数据，根据它的用途我们知道它分为几个Region或者在什么时候拆分最合适，例如有一批数据，rowkey是手机号，而且每个手机号码前缀下（手机号码前三位）的数据量都差不多，而且这批数据主要是用于查询，要求查询的性能好一些，而且这批数据是一批静态数据，即一次存入后以后不会再加入新数据，而且这批数据的量很大，那么此时预先设置好拆分点（比如每个相同的手机号前缀一定要分到一个Region下），设置拆分策略为禁止拆分，然后导入数据即可。&lt;/p>
&lt;p>在使用禁止自动拆分策略的诸多条件中，数据量大是很重要的一点，因为当使用自动拆分时，无论你设置了哪种拆分策略，一开始数据进入HBase的时候都只会往一个Region塞数据。必须要等到一个Region的大小膨胀到某个阀值的时候才会根据拆分策略来进行拆分。但是当大量的数据涌入的时候，可能会出现一边拆分一边写入大量数据的情况，由于拆分要占用大量IO，此时HBase数据库的压力是很大的。&lt;/p>
&lt;h3 id="设置方法-5">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>HBase RPC</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-rpc/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-rpc/</guid><description>&lt;h1 id="hbase-rpc">HBase RPC&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>HBase主要包含Master，RegionServer，Client 3个组件组成。组件之间通过Rpc 和 zk进行通信。RPC通信功能主要基于Protobuf和NIO这两个组件来实现，&lt;/p>
&lt;p>&lt;img src="assets/2020-01-07-11-42-09-image.png" alt="">&lt;/p>
&lt;h2 id="配置参数">配置参数&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>hbase.ipc.server.listen.queue.size :&lt;/p>
&lt;p>存放连接请求的等待队列长度,默认与ipc.server.listen.queue.size参数值相同，为128个。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.regionserver.handler.count&lt;/p>
&lt;p>regionserver 的 rpc请求队列处理线程数，默认为 30&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.master.handler.count&lt;/p>
&lt;p>master rpc请求队列处理线程数，默认为 25&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.read.threadpool.size&lt;/p>
&lt;p>Reader线程数，默认为10个。reader 的个数决定了从网络 io 里读取数据的速度也就是网络吞吐量&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.max.callqueue.size&lt;/p>
&lt;p>单个消费队列所允许的存储空间上限(默认为1GB)，超过该上限客户端会抛出以下异常&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.max.callqueue.length&lt;/p>
&lt;p>单个消费队列的长度限制，默认值为10倍的Handler数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.callqueue.handler.factor&lt;/p>
&lt;p>该参数用于决定消费队列的个数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.callqueue.read.share&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.ipc.server.read.threadpool.size
默认： 10
Reader线程数
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="结构">结构&lt;/h2>
&lt;p>RPC报文&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-11-06-09-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>请求头&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="assets/2020-01-07-11-06-34-image.png" alt="">&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-protobuf" data-lang="protobuf">&lt;span class="kd">message&lt;/span> &lt;span class="nc">RequestHeader&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">uint32&lt;/span> &lt;span class="n">call_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="n">RPCTInfo&lt;/span> &lt;span class="n">trace_info&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="n">method_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">bool&lt;/span> &lt;span class="n">request_param&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="assets/2020-01-07-11-07-17-image.png" alt="">&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-protobuf" data-lang="protobuf">&lt;span class="kd">message&lt;/span> &lt;span class="nc">ResponseHeader&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">uint32&lt;/span> &lt;span class="n">call_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="rpc实现">RPC实现&lt;/h2>
&lt;p>RpcServer配置三个队列：&lt;/p>
&lt;ul>
&lt;li>callQueue&lt;/li>
&lt;/ul>
&lt;p>绝大部分Call请求存在该队列中：callQueue上maxQueueLength为${ipc.server.max.callqueue.length},默认是${hbase.master.handler.count}*DEFAULT_MAX_CALLQUEUE_LENGTH_PER_HANDLER，目前0.95.1中，每个Handler上CallQueue的最大个数默认值(DEFAULT_MAX_CALLQUEUE_LENGTH_PER_HANDLER)为10。&lt;/p>
&lt;ul>
&lt;li>PriorityQueue&lt;/li>
&lt;/ul>
&lt;p>如果设置priorityHandlerCount的个数，会创建与callQueue相当容量的queue存储Call，该优先级队列对应的Handler的个数由rpcServer实例化时传入。&lt;/p>
&lt;ul>
&lt;li>replicationQueue&lt;/li>
&lt;/ul>
&lt;p>由于RpcServer由HMaster和RegionServer共用，该功能仅为RegionServer提供，queue的大小为${ipc.server.max.callqueue.size}指定，默认为1024&lt;em>1024&lt;/em>1024，handler的个数为hbase.regionserver.replication.handler.count。&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-11-18-46-image.png" alt="">&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-11-29-06-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>rpc-client&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-12-34-08-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>rpc-server&lt;/li>
&lt;/ul>
&lt;p>rpc-server基于nio 的reactor模型设计，其主要流程如下：&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-12-34-46-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>scheduler&lt;/li>
&lt;/ul>
&lt;p>hbase rpc实现了两种调度器（FifoRpcScheduler和SimpleRpcScheduler）。FifoRpcScheduler是master默认的调度器，直接将CallRunner对象放到线程池中去执行。而SimpleRpcScheduler是RS默认调度器，分成三种不同的executor，对于不同的请求，使用的不同的executor去执行。&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-12-35-19-image.png" alt="">&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://cloud.tencent.com/developer/article/1005560">Hbase 调优之 RPC - 云+社区 - 腾讯云&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.csdn.net/yangzishiw/article/details/78840107">https://blog.csdn.net/yangzishiw/article/details/78840107&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://www.binospace.com/index.php/in-depth-analysis-hbase-rpc-0-95-version-implementation-mechanism/">The internals of HBase Rpc (Protobuf) | Binospace&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://09itblog.site/?p=874">http://09itblog.site/?p=874&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase Scan</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-scan/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-scan/</guid><description>&lt;h1 id="hbase-scan">HBase Scan&lt;/h1>
&lt;h2 id="filter">Filter&lt;/h2>
&lt;ul>
&lt;li>过滤器是在get或者scan时候过滤结果用的. HBase中的过滤器被用户创建出来后会被序列化为可以网络传输的格式,然后被分发到各个RegionServer.然后在RegionServer中Filter被还原出来,这样在Scan遍历过程中,不满足条件的结果都不会被返回客户端，叫做谓语下推(predicate push down), 可以保证被过滤掉的数据不会被传送到客户端。&lt;/li>
&lt;li>所有的过滤器都要实现Filter接口.HBase同时还提供了FilterBase抽象类,它提供了Filter接口的默认实现&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-54-39-image-20190816095904279.png" alt="image-20190816095904279">&lt;/p>
&lt;h3 id="比较器">比较器&lt;/h3>
&lt;p>HBase的filter有四种比较器：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>binary&lt;/strong>：二进制比较器，如’binary:abc’，按字典排序跟’abc’进行比较&lt;/li>
&lt;li>&lt;strong>binaryprefix&lt;/strong>：二进制前缀比较器：如’binaryprefix:abc’，按字典顺序只跟’abc’比较前3个字符&lt;/li>
&lt;li>&lt;strong>regexstring&lt;/strong>：正则表达式比较器：如’regexstring:ab*yz’，按正则表达式匹配以ab开头，以yz结尾的值。这个比较器只能使用=、!=两个比较运算符。&lt;/li>
&lt;li>&lt;strong>substring&lt;/strong>：子串比较器：如’substring:abc123’，匹配以abc123开头的值。这个比较顺也只能使用=、!=两个比较运算符。&lt;/li>
&lt;/ul>
&lt;h3 id="比较运算符">比较运算符&lt;/h3>
&lt;ul>
&lt;li>LESS (&amp;lt;)&lt;/li>
&lt;li>LESS_OR_EQUAL (&amp;lt;=)&lt;/li>
&lt;li>EQUAL (=)&lt;/li>
&lt;li>NOT_EQUAL (!=)&lt;/li>
&lt;li>GREATER_OR_EQUAL (&amp;gt;=)&lt;/li>
&lt;li>GREATER (&amp;gt;)&lt;/li>
&lt;li>NO_OP (no operation)（不知道这个怎么用）&lt;/li>
&lt;/ul>
&lt;h3 id="singlecolumnvaluefilter">SingleColumnValueFilter&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#//&lt;/span>
hbase&amp;gt; scan ‘tweet0’, &lt;span class="o">{&lt;/span>&lt;span class="nv">FILTER&lt;/span>&lt;span class="o">=&lt;/span>&amp;gt;”SingleColumnValueFilter&lt;span class="o">(&lt;/span>‘info’,’pubtime’,&amp;gt;&lt;span class="o">=&lt;/span>,’binary:2014-11-08 19:26:27’&lt;span class="o">)&lt;/span> AND SingleColumnValueFilter&lt;span class="o">(&lt;/span>‘info’,’pubtime’,&amp;lt;&lt;span class="o">=&lt;/span>,’binary:2014-11-10 20:20:00’&lt;span class="o">)&lt;/span>”&lt;span class="o">}&lt;/span>
hbase&amp;gt; scan ‘tweet0’, &lt;span class="o">{&lt;/span>&lt;span class="nv">FILTER&lt;/span>&lt;span class="o">=&lt;/span>&amp;gt;”SingleColumnValueFilter&lt;span class="o">(&lt;/span>‘emotion’,’PB’,&lt;span class="o">=&lt;/span>,’binary:&lt;span class="se">\x&lt;/span>00&lt;span class="se">\x&lt;/span>00&lt;span class="se">\x&lt;/span>00&lt;span class="se">\x&lt;/span>05’&lt;span class="o">)&lt;/span>”, &lt;span class="nv">COLUMNS&lt;/span>&lt;span class="o">=&lt;/span>&amp;gt;&lt;span class="o">[&lt;/span>‘emotion:PB’&lt;span class="o">]}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>SingleColumnValueFilter 这个过滤器有6个参数：列族、列名、比较运算符、比较器和两个可选参数：filterIfColumnMissing和setLatestVersionOnly。&lt;/p>
&lt;ul>
&lt;li>filterIfColumnMissing：如果设置为true，则会把没有过滤器所指定列的行都过滤掉。默认值是false，所以看上去，当没有过滤器所指定的列时，过滤器不起作用。&lt;/li>
&lt;li>setLatestVersionOnly：如果设置为false，则除了检查最新版本，还会检查以前的版本。默认值是true，只检查最新版本的值。
这两个参数要么一起使用，要么都不使用。&lt;/li>
&lt;/ul>
&lt;h3 id="fuzzyrowfilter">FuzzyRowFilter&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// rowkey: 2016_06_22_beijing
&lt;/span>&lt;span class="c1">// 查找2016年什么时间去北京了和2012年什么时间去干什么了
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">par1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;2016_??_??_beijing&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]{&lt;/span>
&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>
&lt;span class="o">});&lt;/span>
&lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">par2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;2012&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]{&lt;/span>
&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>
&lt;span class="o">});&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">fuzzy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">par1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">par2&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">FuzzyRowFilter&lt;/span> &lt;span class="n">filter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">FuzzyRowFilter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">fuzzy&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">Scan&lt;/span> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Scan&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setFilter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">filter&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">scan &amp;#39;blog&amp;#39;, FILTER =&amp;gt; org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;00?&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x01&amp;#34;))))
scan &amp;#34;journalq:send_log&amp;#34;, {LIMIT=&amp;gt;10, STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xDA\x9F\x85\x17\xF7\xBDbr&amp;#34; }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0008????????0000000000000000????????????????&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x00\x01\x01\x01\x01\x01\x01\x01\x01\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01&amp;#34;)))) }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0008????????0000000000000000????????????????&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x00\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01&amp;#34;)))) }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0000&amp;#34;),Bytes.toBytes(&amp;#34;\x01\x01\x01\x01&amp;#34;)))), LIMIT=&amp;gt; 10 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x13\x00\x00\x01&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0000&amp;#34;),Bytes.toBytes(&amp;#34;\x01\x01\x01\x01&amp;#34;)))), LIMIT=&amp;gt; 1000 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, LIMIT=&amp;gt;10 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x02\x00\x00\x01k\x0C\x168\x92\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xC2\x8Fl-\xD3\x04\xB5F(\x9F\x89\xED\x13\xDD\xE5!&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x8D\x00\x00\x01l#]\xAF)&amp;#34;, LIMIT=&amp;gt;10 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x02\x00\x00\x01k\x0C\x168\x92\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xC2\x8Fl-\xD3\x04\xB5F(\x9F\x89\xED\x13\xDD\xE5!&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x8D\x00\x00\x01l#]\xAF)&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0008????0000????0000????&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&amp;#34;)))) }
scan &amp;#34;journalq:send_log&amp;#34;, {FILTER=&amp;gt;&amp;#34;SingleColumnValueFilter(&amp;#39;cf&amp;#39;,&amp;#39;create_time&amp;#39;,=,&amp;#39;regexstring:2014-11-08.*&amp;#39;)&amp;#34;}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">\x00\x00\x00\x02\x00\x00\x01k\x0C\x168\x92\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xC2\x8Fl-\xD3\x04\xB5F(\x9F\x89\xED\x13\xDD\xE5!
\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A
\x00\x00\x00\x01\x00\x00\x01jD3\x06\xEC\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xDA\x9EtW\x86\xD0\xF9o&amp;#39;\xB3\xEC\xFF\x14\xC6\xD5F
\x00\x00\x00\x08\x00\x00\x01j\xC16=\x97r\x02~\x0C\xC0^\xADM\x84\x10\xB3\xFB\x8FW\xF3\xE8\xFD\xEF\xCE\xDFd.}\x90\x1Dj\x9A\xBB\x9F\x98\x19
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://yq.aliyun.com/articles/676094">https://yq.aliyun.com/articles/676094&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item></channel></rss>