<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Justice的小站</title><link>https://justice.bj.cn/</link><description>Recent content on Justice的小站</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 08 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://justice.bj.cn/index.xml" rel="self" type="application/rss+xml"/><item><title>Justice's Blog</title><link>https://justice.bj.cn/homepage/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/about/</guid><description>&lt;h2 id="self-introduction">Self Introduction&lt;/h2>
&lt;p>Cras ex dui, tristique a libero eget, consectetur semper ligula. Nunc augue arcu, malesuada a nisi et, molestie finibus metus. Sed lacus odio, ultricies a nisl vitae, sollicitudin tempor ipsum. Vivamus quis feugiat arcu. Sed mi nunc, efficitur quis tellus vitae, posuere mattis metus. Phasellus in mattis dui. Nullam blandit, augue non ullamcorper dapibus, lacus dui molestie massa, in iaculis purus lectus eu lectus. Duis hendrerit lacinia tellus, sit amet feugiat dolor placerat id. Aenean ac velit massa. Vivamus feugiat dui at magna viverra, ut dictum nunc rutrum. Duis eget sapien finibus, lobortis orci id, vestibulum tellus. Maecenas lobortis urna libero, quis fermentum lectus lobortis nec. Nullam laoreet volutpat libero, ac mattis magna ullamcorper quis. Duis eget ipsum eu nisi mattis cursus et vitae turpis.&lt;/p>
&lt;p>Aliquam pretium diam eget leo feugiat finibus. Donec malesuada commodo ipsum. Aenean a massa in lacus venenatis vestibulum. Duis vel sem quis elit iaculis consectetur et quis dolor. Morbi eu ipsum hendrerit, malesuada ante sed, dapibus est. Suspendisse feugiat nulla ut gravida convallis. Phasellus id massa posuere, rhoncus justo ut, porttitor dolor. Nulla ultrices malesuada egestas. Nunc fermentum tincidunt sem ac vulputate. Donec mollis sollicitudin justo eget varius. Donec ornare velit et felis blandit, id molestie sapien lobortis. Morbi eget tristique justo. Mauris posuere, nibh eu laoreet ultricies, ligula erat iaculis sapien, vel dapibus lacus libero ut diam. Etiam viverra ante felis, et scelerisque nunc pellentesque vitae. Praesent feugiat dictum molestie.&lt;/p>
&lt;h2 id="details">Details&lt;/h2>
&lt;p>Nunc pellentesque vitae:&lt;/p>
&lt;ul>
&lt;li>Morbi accumsan nibh efficitur diam molestie, non dignissim diam facilisis.&lt;/li>
&lt;li>Donec dignissim leo in mollis faucibus.&lt;/li>
&lt;li>Donec blandit lacus a pellentesque fermentum.&lt;/li>
&lt;/ul>
&lt;p>Donec mollis sollicitudin:&lt;/p>
&lt;ul>
&lt;li>Nunc dictum purus ornare purus consectetur, eu pellentesque massa ullamcorper.&lt;/li>
&lt;li>Aliquam eu leo vitae justo aliquam tincidunt.&lt;/li>
&lt;li>Fusce non massa id augue interdum feugiat sed et nulla.&lt;/li>
&lt;li>Vivamus molestie augue in tristique laoreet.&lt;/li>
&lt;/ul></description></item><item><title>Pages</title><link>https://justice.bj.cn/homepage/pages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/pages/</guid><description/></item><item><title>Experiences</title><link>https://justice.bj.cn/homepage/experiences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/experiences/</guid><description/></item><item><title>Vintage</title><link>https://justice.bj.cn/homepage/vintage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/vintage/</guid><description/></item><item><title>Blank</title><link>https://justice.bj.cn/homepage/blank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/blank/</guid><description>
&lt;div style="text-align:center">
&lt;p>Write anything you like here!&lt;/p>
&lt;/div></description></item><item><title>ChubaoFS DataNode</title><link>https://justice.bj.cn/post/40.storage/chubaofs/chubaofs-datanode/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/40.storage/chubaofs/chubaofs-datanode/</guid><description>&lt;h1 id="chubaofs-datanode">ChubaoFS DataNode&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>chubaofs datanode 是chubaofs中的数据存储节点，用于将chubaofs中的文件数据存储在磁盘中；&lt;/p>
&lt;p>chubaofs 中的datanode数据以&lt;code>dataPartition&lt;/code>为单位进行管理。&lt;code>dataPartition&lt;/code>是datanode中进行数据管理的最高单位。&lt;/p>
&lt;h2 id="大文件小文件">大文件/小文件&lt;/h2>
&lt;p>文件系统中，每个文件存在元数据。由于磁盘和内存的性能成本差别，导致同一个文件系统对于大小文件的操作管理成本存在显著的差异。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>对于小文件，其单个文件数据量少，平均磁盘操作成本巨大，且元数据数量膨胀快；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>大文件数据文件大，顺序读写可以获得较低的磁盘操作成本，取得较高的性能，元数据相对总数据量成本低；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>因此同一个文件系统对于大小文件很难使用同一策略来满足高效低费存储需求。&lt;/p>
&lt;p>chubaofs对于大小文件的读写使用了不同的策略，以此满足大小文件的不同需求。&lt;/p>
&lt;p>chubaofs中的小文件是客户端指定，小于一定大小（默认为：1MB）的文件。可以通过客户端配置参数&lt;code>tinySize&lt;/code>指定。&lt;/p>
&lt;p>每个客户端文件的前1MB字节内的文件都使用&lt;code>TinyExtent&lt;/code>进行存储管理，&lt;/p>
&lt;p>大于&lt;code>1MB&lt;/code>的文件部分使用&lt;code>NormalExtent&lt;/code>方式进行存储管理。&lt;/p>
&lt;h2 id="顺序写随机写">顺序写/随机写&lt;/h2>
&lt;p>ChubaoFS同时支持&lt;code>顺序写&lt;/code>和&lt;code>随机写&lt;/code>两种文件写入方式。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>顺序写&lt;/code>: 指写入的数据每次只往文件末尾追加;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>随机写&lt;/code>:指覆盖之前已经写过的文件内容;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>客户端在发起写请求时，根据写入数据的偏移是否已经存在，来决定使用那种写入方式；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>顺序写&lt;/code>: 使用主从方式进行副本间同步数据, 对应的存储引擎；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>随机写&lt;/code>:使用Raft协议来在数据副本间同步数据；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// sdk/data/stream/stream_writer.go
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">func&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">s&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">Streamer&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="nf">write&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">data&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">offset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">flags&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">total&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="kt">error&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="nx">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">req&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="k">range&lt;/span> &lt;span class="nx">requests&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="kd">var&lt;/span> &lt;span class="nx">writeSize&lt;/span> &lt;span class="kt">int&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nx">req&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">ExtentKey&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">nil&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="c1">//已存在旧写入数据extentkey
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">writeSize&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">s&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">doOverwrite&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">req&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">direct&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">//随机覆盖写
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">writeSize&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">s&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">doWrite&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">req&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">req&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">FileOffset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">req&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">direct&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">//顺序写
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="datapartition">DataPartition&lt;/h2>
&lt;h3 id="dp存储">dp存储&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>datanode配置文件中的&lt;code>disks&lt;/code>指定了每个datanode dp的存储磁盘；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个&lt;code>disk&lt;/code>中包含一系列&lt;code>datapartition_&amp;lt;id&amp;gt;_&amp;lt;dp_size&amp;gt;&lt;/code>和命名的目录，用于存储对应dp；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个&lt;code>disk&lt;/code>中还可能包含&lt;code>expired_dataparition_&amp;lt;id&amp;gt;_&amp;lt;dp_size&amp;gt;&lt;/code>的过期dp，这些dp是在master中不存在的；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个dp&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="status">&lt;strong>Status&lt;/strong>&lt;/h4>
&lt;h2 id="extent">Extent&lt;/h2>
&lt;p>每个dp包含多个&lt;code>extent&lt;/code>, 每个extent 对应一个extent file，用于存储数据。&lt;/p>
&lt;p>extent file大小限制为128MB, 每个datapartition 包含的extent 个数不超过2000个(256GB)&lt;/p>
&lt;p>extent分为&lt;code>NormalExtent&lt;/code> 和 &lt;code>TinyExtent&lt;/code> 两种类型。&lt;/p>
&lt;h3 id="tinyextent">TinyExtent&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>id范围: [1, 64]&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h3 id="normalextent">NormalExtent&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>id: [1000, +)&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h2 id="extentstore">ExtentStore&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">type&lt;/span> &lt;span class="nx">ExtentStore&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">partitionID&lt;/span> &lt;span class="kt">uint64&lt;/span> &lt;span class="c1">// partition ID
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">dataPath&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="c1">// data path for this partition
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="nx">extentInfoMap&lt;/span> &lt;span class="kd">map&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="kt">uint64&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="nx">ExtentInfo&lt;/span> &lt;span class="c1">// map that stores all the extent information
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">eiMutex&lt;/span> &lt;span class="nx">sync&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">RWMutex&lt;/span> &lt;span class="c1">// mutex for extent info
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="nx">cache&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">ExtentCache&lt;/span> &lt;span class="c1">// extent cache
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">mutex&lt;/span> &lt;span class="nx">sync&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Mutex&lt;/span>
&lt;span class="nx">storeSize&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="c1">// limit size for the extent store, default is 120GB
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">blockSize&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="c1">// block size for extent, default is 128KB, unused
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="nx">hasAllocSpaceExtentIDOnVerfiyFile&lt;/span> &lt;span class="kt">uint64&lt;/span> &lt;span class="c1">// 预分配空间extent ID
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">baseExtentID&lt;/span> &lt;span class="kt">uint64&lt;/span> &lt;span class="c1">// 可分配的起始extent ID
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="nx">metadataFp&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">os&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">File&lt;/span> &lt;span class="c1">// EXTENT_META，存储baseExtentID 和 hasAllocSpaceExtentIDOnVerfiyFile
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">verifyExtentFp&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">os&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">File&lt;/span> &lt;span class="c1">// EXTENT_CRC, 存储所有extent crc校验头
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">tinyExtentDeleteFp&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">os&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">File&lt;/span> &lt;span class="c1">// TINYEXTENT_DELETE,
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">normalExtentDeleteFp&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">os&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">File&lt;/span> &lt;span class="c1">// NORMALEXTENT_DELETE
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="nx">availableTinyExtentC&lt;/span> &lt;span class="kd">chan&lt;/span> &lt;span class="kt">uint64&lt;/span> &lt;span class="c1">// available tinyExtent channel
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">availableTinyExtentMap&lt;/span> &lt;span class="nx">sync&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Map&lt;/span>
&lt;span class="nx">brokenTinyExtentC&lt;/span> &lt;span class="kd">chan&lt;/span> &lt;span class="kt">uint64&lt;/span> &lt;span class="c1">// broken tinyExtent channel
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">brokenTinyExtentMap&lt;/span> &lt;span class="nx">sync&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Map&lt;/span>
&lt;span class="nx">tinyRocks&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">gorocksdb&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">DB&lt;/span>
&lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">closeC&lt;/span> &lt;span class="kd">chan&lt;/span> &lt;span class="kt">bool&lt;/span>
&lt;span class="nx">closed&lt;/span> &lt;span class="kt">bool&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>datanode 数据存储目录结构&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>EXTENT_META&lt;/code>: &lt;code>metadataFp&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>EXTENT_CRC&lt;/code>: &lt;code>verifyExtentFp&lt;/code>, 存储当前datapartition 的所有&lt;code>normal_extent&lt;/code>crc校验数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>TINYEXTENT_DELETE&lt;/code>: &lt;code>tinyExtentDeleteFp&lt;/code>,&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="extent_crc">EXTENT_CRC&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>每个datapartition存储目录中有一个&lt;code>EXTENT_CRC&lt;/code>文件，用于保存该datapartition 所有&lt;code>normal_extent&lt;/code>的crc校验头；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>EXTENT_CRC&lt;/code>文件由多个4KB大小的校验块组成，每个校验块存储一个&lt;code>normal_extent&lt;/code>的crc校验；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个4KB的校验块由1000个4B的CRC检验数据组成；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>datanode节点在加载normal_extent时，&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>CrateDB</title><link>https://justice.bj.cn/post/30.architech/cratedb/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/cratedb/</guid><description>&lt;h1 id="cratedb">CrateDB&lt;/h1>
&lt;h3 id="简介">简介&lt;/h3>
&lt;p>CrateDB是一个基于ElasticSearch的开源的分布式数据库， 使用SQL处理结构化和非结构化数据；&lt;/p>
&lt;h3 id="特点">特点&lt;/h3>
&lt;ul>
&lt;li>shared-nothing架构&lt;/li>
&lt;li>集群中每一个节点都是一样的，Master通过选举产生，当正在服务的Master挂掉，很快就会选举出新的Master&lt;/li>
&lt;li>分布式SQL查询：支持查询、关联、聚合、搜索等；其中用于搜索的字段可指定native和full text索引。&lt;/li>
&lt;li>支持二进制数据存储：BLOB 可存储图片、视频以及超大非结构化文本数据；&lt;/li>
&lt;li>动态Schema：可以在已有表中动态增加字段或嵌套的数据结构；&lt;/li>
&lt;li>支持Update和Delete；&lt;/li>
&lt;li>不支持事务；&lt;/li>
&lt;/ul></description></item><item><title>Elasticsearch内核解析 - 查询篇</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E8%AF%BB%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E8%AF%BB%E6%B5%81%E7%A8%8B/</guid><description>&lt;h1 id="elasticsearch内核解析---查询篇">Elasticsearch内核解析 - 查询篇&lt;/h1>
&lt;h2 id="读操作">读操作&lt;/h2>
&lt;p>实时性和《&lt;a href="https://zhuanlan.zhihu.com/p/34669354">Elasticsearch内核解析 - 写入篇&lt;/a>》中的“写操作”一样，对于搜索而言是近实时的，延迟在100ms以上，对于NoSQL则需要是实时的。&lt;/p>
&lt;p>一致性指的是写入成功后，下次读操作一定要能读取到最新的数据。对于搜索，这个要求会低一些，可以有一些延迟。但是对于NoSQL数据库，则一般要求最好是强一致性的。&lt;/p>
&lt;p>结果匹配上，NoSQL作为数据库，查询过程中只有符合不符合两种情况，而搜索里面还有是否相关，类似于NoSQL的结果只能是0或1，而搜索里面可能会有0.1，0.5，0.9等部分匹配或者更相关的情况。&lt;/p>
&lt;p>结果召回上，搜索一般只需要召回最满足条件的Top N结果即可，而NoSQL一般都需要返回满足条件的所有结果。&lt;/p>
&lt;p>搜索系统一般都是两阶段查询，第一个阶段查询到对应的Doc ID，也就是PK；第二阶段再通过Doc ID去查询完整文档，而NoSQL数据库一般是一阶段就返回结果。在Elasticsearch中两种都支持。&lt;/p>
&lt;p>目前NoSQL的查询，聚合、分析和统计等功能上都是要比搜索弱的。&lt;/p>
&lt;h2 id="lucene的读">Lucene的读&lt;/h2>
&lt;p>Elasticsearch使用了Lucene作为搜索引擎库，通过Lucene完成特定字段的搜索等功能，在Lucene中这个功能是通过IndexSearcher的下列接口实现的：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="n">TopDocs&lt;/span> &lt;span class="nf">search&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Query&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Document&lt;/span> &lt;span class="nf">doc&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">docID&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">count&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Query&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">......(&lt;/span>&lt;span class="n">其他&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>第一个search接口实现搜索功能，返回最满足Query的N个结果；第二个doc接口通过doc id查询Doc内容；第三个count接口通过Query获取到命中数。&lt;/p>
&lt;p>这三个功能是搜索中的最基本的三个功能点，对于大部分Elasticsearch中的查询都是比较复杂的，直接用这个接口是无法满足需求的，比如分布式问题。这些问题都留给了Elasticsearch解决，我们接下来看Elasticsearch中相关读功能的剖析。&lt;/p>
&lt;h2 id="elasticsearch的读">Elasticsearch的读&lt;/h2>
&lt;p>Elasticsearch中每个Shard都会有多个Replica，主要是为了保证数据可靠性，除此之外，还可以增加读能力，因为写的时候虽然要写大部分Replica Shard，但是查询的时候只需要查询Primary和Replica中的任何一个就可以了。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-1ad1351408bdf0ce7f76f251d6ef8bc4_720w.jpg" alt="">&lt;/p>
&lt;p>Search On Replicas&lt;/p>
&lt;p>在上图中，该Shard有1个Primary和2个Replica Node，当查询的时候，从三个节点中根据Request中的preference参数选择一个节点查询。preference可以设置_local，_primary，_replica以及其他选项。如果选择了primary，则每次查询都是直接查询Primary，可以保证每次查询都是最新的。如果设置了其他参数，那么可能会查询到R1或者R2，这时候就有可能查询不到最新的数据。&lt;/p>
&lt;blockquote>
&lt;p>上述代码逻辑在OperationRouting.Java的searchShards方法中。&lt;/p>
&lt;/blockquote>
&lt;p>接下来看一下，Elasticsearch中的查询是如何支持分布式的。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-737f6cb48ccf22c50c2e630433c6ad48_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch中通过分区实现分布式，数据写入的时候根据_routing规则将数据写入某一个Shard中，这样就能将海量数据分布在多个Shard以及多台机器上，已达到分布式的目标。这样就导致了查询的时候，潜在数据会在当前index的所有的Shard中，所以Elasticsearch查询的时候需要查询所有Shard，同一个Shard的Primary和Replica选择一个即可，查询请求会分发给所有Shard，每个Shard中都是一个独立的查询引擎，比如需要返回Top 10的结果，那么每个Shard都会查询并且返回Top 10的结果，然后在Client Node里面会接收所有Shard的结果，然后通过优先级队列二次排序，选择出Top 10的结果返回给用户。&lt;/p>
&lt;p>这里有一个问题就是请求膨胀，用户的一个搜索请求在Elasticsearch内部会变成Shard个请求，这里有个优化点，虽然是Shard个请求，但是这个Shard个数不一定要是当前Index中的Shard个数，只要是当前查询相关的Shard即可，这个需要基于业务和请求内容优化，通过这种方式可以优化请求膨胀数。&lt;/p>
&lt;p>Elasticsearch中的查询主要分为两类:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Get请求：通过ID查询特定Doc；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search请求：通过Query查询匹配Doc。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-1f4c1cf921049b841ae2612b4734cdb1_720w.jpg" alt="">&lt;/p>
&lt;blockquote>
&lt;p>上图中内存中的Segment是指刚Refresh Segment，但是还没持久化到磁盘的新Segment，而非从磁盘加载到内存中的Segment。&lt;/p>
&lt;/blockquote>
&lt;p>对于Search类请求，查询的时候是一起查询内存和磁盘上的Segment，最后将结果合并后返回。这种查询是近实时（Near Real Time）的，主要是由于内存中的Index数据需要一段时间后才会刷新为Segment。&lt;/p>
&lt;p>对于Get类请求，查询的时候是先查询内存中的TransLog，如果找到就立即返回，如果没找到再查询磁盘上的TransLog，如果还没有则再去查询磁盘上的Segment。这种查询是实时（Real Time）的。这种查询顺序可以保证查询到的Doc是最新版本的Doc，这个功能也是为了保证NoSQL场景下的实时性要求。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-c5455432442548d1f12c975684fc4a00_720w.jpg" alt="">&lt;/p>
&lt;p>多阶段查询&lt;/p>
&lt;p>所有的搜索系统一般都是两阶段查询，&lt;/p>
&lt;p>第一阶段查询到匹配的DocID，&lt;/p>
&lt;p>第二阶段再查询DocID对应的完整文档，这种在Elasticsearch中称为query_then_fetch，&lt;/p>
&lt;p>还有一种是一阶段查询的时候就返回完整Doc，在Elasticsearch中称作query_and_fetch，一般第二种适用于只需要查询一个Shard的请求。&lt;/p>
&lt;p>除了一阶段，两阶段外，还有一种三阶段查询的情况。&lt;/p>
&lt;p>搜索里面有一种算分逻辑是根据TF（Term Frequency）和IDF（Document Frequency）计算基础分，但是Elasticsearch中查询的时候，是在每个Shard中独立查询的，每个Shard中的TF和DF也是独立的，虽然在写入的时候通过_routing保证Doc分布均匀，但是没法保证TF和DF均匀，那么就有会导致局部的TF和DF不准的情况出现，这个时候基于TF、DF的算分就不准。为了解决这个问题，Elasticsearch中引入了DFS查询，比如DFS_query_then_fetch，会先收集所有Shard中的TF和DF值，然后将这些值带入请求中，再次执行query_then_fetch，这样算分的时候TF和DF就是准确的，类似的有DFS_query_and_fetch。这种查询的优势是算分更加精准，但是效率会变差。另一种选择是用BM25代替TF/DF模型。&lt;/p>
&lt;p>在新版本Elasticsearch中，用户没法指定DFS_query_and_fetch和query_and_fetch，这两种只能被Elasticsearch系统改写。&lt;/p>
&lt;h2 id="elasticsearch查询流程">Elasticsearch查询流程&lt;/h2>
&lt;p>Elasticsearch中的大部分查询，以及核心功能都是Search类型查询，上面我们了解到查询分为一阶段，二阶段和三阶段，这里我们就以最常见的的二阶段查询为例来介绍查询流程。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-10acab5576a2359ca279331e81adc1e2_720w.jpg" alt="">&lt;/p>
&lt;p>查询流程&lt;/p>
&lt;p>&lt;strong>注册Action&lt;/strong>&lt;/p>
&lt;p>Elasticsearch中，查询和写操作一样都是在ActionModule.java中注册入口处理函数的。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">registerHandler.accept(new RestSearchAction(settings, restController));
......
actions.register(SearchAction.INSTANCE, TransportSearchAction.class);
......
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果请求是Rest请求，则会在RestSearchAction中解析请求，检查查询类型，不能设置为dfs_query_and_fetch或者query_and_fetch，这两个目前只能用于Elasticsearch中的优化场景，然后将请求发给后面的TransportSearchAction处理。然后构造SearchRequest，将请求发送给TransportSearchAction处理。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-02fdc9375a9d6af62ac6c2035b5a9730_720w.jpg" alt="">&lt;/p>
&lt;p>如果是第一阶段的Query Phase请求，则会调用SearchService的executeQueryPhase方法。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-be3a37c7fe08d4f1559b9eb0aaa8d37a_720w.jpg" alt="">&lt;/p>
&lt;p>如果是第二阶段的Fetch Phase请求，则会调用SearchService的executeFetchPhase方法。&lt;/p>
&lt;h2 id="client-node">&lt;strong>Client Node&lt;/strong>&lt;/h2>
&lt;p>Client Node 也包括了前面说过的Parse Request，这里就不再赘述了，接下来看一下其他的部分。&lt;/p>
&lt;p>&lt;strong>1. Get Remove Cluster Shard&lt;/strong>&lt;/p>
&lt;p>判断是否需要跨集群访问，如果需要，则获取到要访问的Shard列表。&lt;/p>
&lt;p>&lt;strong>2. Get Search Shard Iterator&lt;/strong>&lt;/p>
&lt;p>获取当前Cluster中要访问的Shard，和上一步中的Remove Cluster Shard合并，构建出最终要访问的完整Shard列表。&lt;/p>
&lt;p>这一步中，会根据Request请求中的参数从Primary Node和多个Replica Node中选择出一个要访问的Shard。&lt;/p>
&lt;p>&lt;strong>3. For Every Shard:Perform&lt;/strong>&lt;/p>
&lt;p>遍历每个Shard，对每个Shard执行后面逻辑。&lt;/p>
&lt;p>&lt;strong>4. Send Request To Query Shard&lt;/strong>&lt;/p>
&lt;p>将查询阶段请求发送给相应的Shard。&lt;/p>
&lt;p>&lt;strong>5. Merge Docs&lt;/strong>&lt;/p>
&lt;p>上一步将请求发送给多个Shard后，这一步就是异步等待返回结果，然后对结果合并。这里的合并策略是维护一个Top N大小的优先级队列，每当收到一个shard的返回，就把结果放入优先级队列做一次排序，直到所有的Shard都返回。&lt;/p>
&lt;p>翻页逻辑也是在这里，如果需要取Top 30~ Top 40的结果，这个的意思是所有Shard查询结果中的第30到40的结果，那么在每个Shard中无法确定最终的结果，每个Shard需要返回Top 40的结果给Client Node，然后Client Node中在merge docs的时候，计算出Top 40的结果，最后再去除掉Top 30，剩余的10个结果就是需要的Top 30~ Top 40的结果。&lt;/p>
&lt;p>上述翻页逻辑有一个明显的缺点就是每次Shard返回的数据中包括了已经翻过的历史结果，如果翻页很深，则在这里需要排序的Docs会很多，比如Shard有1000，取第9990到10000的结果，那么这次查询，Shard总共需要返回1000 * 10000，也就是一千万Doc，这种情况很容易导致OOM。&lt;/p>
&lt;p>另一种翻页方式是使用search_after，这种方式会更轻量级，如果每次只需要返回10条结构，则每个Shard只需要返回search_after之后的10个结果即可，返回的总数据量只是和Shard个数以及本次需要的个数有关，和历史已读取的个数无关。这种方式更安全一些，推荐使用这种。&lt;/p>
&lt;p>如果有aggregate，也会在这里做聚合，但是不同的aggregate类型的merge策略不一样，具体的可以在后面的aggregate文章中再介绍。&lt;/p>
&lt;p>&lt;strong>6. Send Request To Fetch Shard&lt;/strong>&lt;/p>
&lt;p>选出Top N个Doc ID后发送给这些Doc ID所在的Shard执行Fetch Phase，最后会返回Top N的Doc的内容。&lt;/p>
&lt;h2 id="query-phase">Query Phase&lt;/h2>
&lt;p>接下来我们看第一阶段查询的步骤：&lt;/p>
&lt;p>&lt;strong>1. Create Search Context&lt;/strong>&lt;/p>
&lt;p>创建Search Context，之后Search过程中的所有中间状态都会存在Context中，这些状态总共有50多个，具体可以查看DefaultSearchContext或者其他SearchContext的子类。&lt;/p>
&lt;p>&lt;strong>2. Parse Query&lt;/strong>&lt;/p>
&lt;p>解析Query的Source，将结果存入Search Context。这里会根据请求中Query类型的不同创建不同的Query对象，比如TermQuery、FuzzyQuery等，最终真正执行TermQuery、FuzzyQuery等语义的地方是在Lucene中。&lt;/p>
&lt;p>这里包括了dfsPhase、queryPhase和fetchPhase三个阶段的preProcess部分，只有queryPhase的preProcess中有执行逻辑，其他两个都是空逻辑，执行完preProcess后，所有需要的参数都会设置完成。&lt;/p>
&lt;p>由于Elasticsearch中有些请求之间是相互关联的，并非独立的，比如scroll请求，所以这里同时会设置Context的生命周期。&lt;/p>
&lt;p>同时会设置lowLevelCancellation是否打开，这个参数是集群级别配置，同时也能动态开关，打开后会在后面执行时做更多的检测，检测是否需要停止后续逻辑直接返回。&lt;/p>
&lt;p>&lt;strong>3. Get From Cache&lt;/strong>&lt;/p>
&lt;p>判断请求是否允许被Cache，如果允许，则检查Cache中是否已经有结果，如果有则直接读取Cache，如果没有则继续执行后续步骤，执行完后，再将结果加入Cache。&lt;/p>
&lt;p>&lt;strong>4. Add Collectors&lt;/strong>&lt;/p>
&lt;p>Collector主要目标是收集查询结果，实现排序，对自定义结果集过滤和收集等。这一步会增加多个Collectors，多个Collector组成一个List。&lt;/p>
&lt;ol>
&lt;li>FilteredCollector*：*先判断请求中是否有Post Filter，Post Filter用于Search，Agg等结束后再次对结果做Filter，希望Filter不影响Agg结果。如果有Post Filter则创建一个FilteredCollector，加入Collector List中。&lt;/li>
&lt;li>PluginInMultiCollector：判断请求中是否制定了自定义的一些Collector，如果有，则创建后加入Collector List。&lt;/li>
&lt;li>MinimumScoreCollector：判断请求中是否制定了最小分数阈值，如果指定了，则创建MinimumScoreCollector加入Collector List中，在后续收集结果时，会过滤掉得分小于最小分数的Doc。&lt;/li>
&lt;li>EarlyTerminatingCollector：判断请求中是否提前结束Doc的Seek，如果是则创建EarlyTerminatingCollector，加入Collector List中。在后续Seek和收集Doc的过程中，当Seek的Doc数达到Early Terminating后会停止Seek后续倒排链。&lt;/li>
&lt;li>CancellableCollector：判断当前操作是否可以被中断结束，比如是否已经超时等，如果是会抛出一个TaskCancelledException异常。该功能一般用来提前结束较长的查询请求，可以用来保护系统。&lt;/li>
&lt;li>EarlyTerminatingSortingCollector：如果Index是排序的，那么可以提前结束对倒排链的Seek，相当于在一个排序递减链表上返回最大的N个值，只需要直接返回前N个值就可以了。这个Collector会加到Collector List的头部。EarlyTerminatingSorting和EarlyTerminating的区别是，EarlyTerminatingSorting是一种对结果无损伤的优化，而EarlyTerminating是有损的，人为掐断执行的优化。&lt;/li>
&lt;li>TopDocsCollector：这个是最核心的Top N结果选择器，会加入到Collector List的头部。TopScoreDocCollector和TopFieldCollector都是TopDocsCollector的子类，TopScoreDocCollector会按照固定的方式算分，排序会按照分数+doc id的方式排列，如果多个doc的分数一样，先选择doc id小的文档。而TopFieldCollector则是根据用户指定的Field的值排序。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>5. lucene::search&lt;/strong>&lt;/p>
&lt;p>这一步会调用Lucene中IndexSearch的search接口，执行真正的搜索逻辑。每个Shard中会有多个Segment，每个Segment对应一个LeafReaderContext，这里会遍历每个Segment，到每个Segment中去Search结果，然后计算分数。&lt;/p>
&lt;p>搜索里面一般有两阶段算分，第一阶段是在这里算的，会对每个Seek到的Doc都计算分数，为了减少CPU消耗，一般是算一个基本分数。这一阶段完成后，会有个排序。然后在第二阶段，再对Top 的结果做一次二阶段算分，在二阶段算分的时候会考虑更多的因子。二阶段算分在后续操作中。&lt;/p>
&lt;p>具体请求，比如TermQuery、WildcardQuery的查询逻辑都在Lucene中，后面会有专门文章介绍。&lt;/p>
&lt;p>&lt;strong>6. rescore&lt;/strong>&lt;/p>
&lt;p>根据Request中是否包含rescore配置决定是否进行二阶段排序，如果有则执行二阶段算分逻辑，会考虑更多的算分因子。二阶段算分也是一种计算机中常见的多层设计，是一种资源消耗和效率的折中。&lt;/p>
&lt;p>Elasticsearch中支持配置多个Rescore，这些rescore逻辑会顺序遍历执行。每个rescore内部会先按照请求参数window选择出Top window的doc，然后对这些doc排序，排完后再合并回原有的Top 结果顺序中。&lt;/p>
&lt;p>&lt;strong>7. suggest::execute()&lt;/strong>&lt;/p>
&lt;p>如果有推荐请求，则在这里执行推荐请求。如果请求中只包含了推荐的部分，则很多地方可以优化。推荐不是今天的重点，这里就不介绍了，后面有机会再介绍。&lt;/p>
&lt;p>&lt;strong>8. aggregation::execute()&lt;/strong>&lt;/p>
&lt;p>如果含有聚合统计请求，则在这里执行。Elasticsearch中的aggregate的处理逻辑也类似于Search，通过多个Collector来实现。在Client Node中也需要对aggregation做合并。aggregate逻辑更复杂一些，就不在这里赘述了，后面有需要就再单独开文章介绍。&lt;/p>
&lt;p>上述逻辑都执行完成后，如果当前查询请求只需要查询一个Shard，那么会直接在当前Node执行Fetch Phase。&lt;/p>
&lt;h2 id="fetch-phase">Fetch Phase&lt;/h2>
&lt;p>Elasticsearch作为搜索系统时，或者任何搜索系统中，除了Query阶段外，还会有一个Fetch阶段，这个Fetch阶段在数据库类系统中是没有的，是搜索系统中额外增加的阶段。搜索系统中额外增加Fetch阶段的原因是搜索系统中数据分布导致的，在搜索中，数据通过routing分Shard的时候，只能根据一个主字段值来决定，但是查询的时候可能会根据其他非主字段查询，那么这个时候所有Shard中都可能会存在相同非主字段值的Doc，所以需要查询所有Shard才能不会出现结果遗漏。同时如果查询主字段，那么这个时候就能直接定位到Shard，就只需要查询特定Shard即可，这个时候就类似于数据库系统了。另外，数据库中的二级索引又是另外一种情况，但类似于查主字段的情况，这里就不多说了。&lt;/p>
&lt;p>基于上述原因，第一阶段查询的时候并不知道最终结果会在哪个Shard上，所以每个Shard中管都需要查询完整结果，比如需要Top 10，那么每个Shard都需要查询当前Shard的所有数据，找出当前Shard的Top 10，然后返回给Client Node。如果有100个Shard，那么就需要返回100 * 10 = 1000个结果，而Fetch Doc内容的操作比较耗费IO和CPU，如果在第一阶段就Fetch Doc，那么这个资源开销就会非常大。所以，一般是当Client Node选择出最终Top N的结果后，再对最终的Top N读取Doc内容。通过增加一点网络开销而避免大量IO和CPU操作，这个折中是非常划算的。&lt;/p>
&lt;p>Fetch阶段的目的是通过DocID获取到用户需要的完整Doc内容。这些内容包括了DocValues，Store，Source，Script和Highlight等，具体的功能点是在SearchModule中注册的，系统默认注册的有：&lt;/p>
&lt;ul>
&lt;li>ExplainFetchSubPhase&lt;/li>
&lt;li>DocValueFieldsFetchSubPhase&lt;/li>
&lt;li>ScriptFieldsFetchSubPhase&lt;/li>
&lt;li>FetchSourceSubPhase&lt;/li>
&lt;li>VersionFetchSubPhase&lt;/li>
&lt;li>MatchedQueriesFetchSubPhase&lt;/li>
&lt;li>HighlightPhase&lt;/li>
&lt;li>ParentFieldSubFetchPhase&lt;/li>
&lt;/ul>
&lt;p>除了系统默认的8种外，还有通过插件的形式注册自定义的功能，这些SubPhase中最重要的是Source和Highlight，Source是加载原文，Highlight是计算高亮显示的内容片断。&lt;/p>
&lt;p>上述多个SubPhase会针对每个Doc顺序执行，可能会产生多次的随机IO，这里会有一些优化方案，但是都是针对特定场景的，不具有通用性。&lt;/p>
&lt;p>Fetch Phase执行完后，整个查询流程就结束了。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Elasticsearch中的查询流程比较简单，更多的查询原理都在Lucene中，后续我们会有针对不同请求的Lucene原理介绍性文章。&lt;/p></description></item><item><title>Elasticsearch写流程</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</guid><description>&lt;h1 id="elasticsearch写流程">Elasticsearch写流程&lt;/h1>
&lt;h2 id="lucene的写操作及其问题">lucene的写操作及其问题&lt;/h2>
&lt;p>Elasticsearch底层使用Lucene来实现doc的读写操作，Lucene通过&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">addDocument&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">deleteDocuments&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">updateDocument&lt;/span>&lt;span class="o">(...);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>三个方法来实现文档的写入，更新和删除操作。但是存在如下问题&lt;/p>
&lt;ol>
&lt;li>&lt;strong>没有并发设计&lt;/strong>。 lucene只是一个搜索引擎库，并没有涉及到分布式相关的设计，因此要想使用Lucene来处理海量数据，并利用分布式的能力，就必须在其之上进行分布式的相关设计。&lt;/li>
&lt;li>&lt;strong>非实时&lt;/strong>。 将文件写入lucence后并不能立即被检索，需要等待lucene生成一个完整的segment才能被检索&lt;/li>
&lt;li>&lt;strong>数据存储不可靠&lt;/strong>。 写入lucene的数据不会立即被持久化到磁盘，如果服务器宕机，那存储在内存中的数据将会丢失&lt;/li>
&lt;li>&lt;strong>不支持部分更新&lt;/strong> 。lucene中提供的updateDocuments仅支持对文档的全量更新，对部分更新不支持&lt;/li>
&lt;/ol>
&lt;h2 id="2-elasticsearch的写入方案">2. Elasticsearch的写入方案&lt;/h2>
&lt;p>针对Lucene的问题，ES做了如下设计&lt;/p>
&lt;h3 id="21-分布式设计">2.1 分布式设计：&lt;/h3>
&lt;p>为了支持对海量数据的存储和查询，Elasticsearch引入分片的概念，一个索引被分成多个分片，每个分片可以有一个主分片和多个副本分片，每个分片副本都是一个具有完整功能的lucene实例。分片可以分配在不同的服务器上，同一个分片的不同副本不能分配在相同的服务器上。&lt;/p>
&lt;p>在进行写操作时，ES会根据传入的_routing参数（或mapping中设置的_routing, 如果参数和设置中都没有则默认使用_id), 按照公式 &lt;code>shard_num=hash(\routing)%num_primary_shards&lt;/code>,计算出文档要分配到的分片，在从集群元数据中找出对应主分片的位置，将请求路由到该分片进行文档写操作。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-8ce7b65ede7b511a2d6d02530ed501d6_720w.jpg" alt="">&lt;/p>
&lt;h3 id="22-近实时性-refresh操作">2.2 近实时性-refresh操作&lt;/h3>
&lt;p>当一个文档写入Lucene后是不能被立即查询到的，Elasticsearch提供了一个refresh操作，会定时地调用lucene的reopen(新版本为openIfChanged)为内存中新写入的数据生成一个新的segment，此时被处理的文档均可以被检索到。refresh操作的时间间隔由 &lt;code>refresh_interval&lt;/code>参数控制，默认为1s, 当然还可以在写入请求中带上refresh表示写入后立即refresh，另外还可以调用refresh API显式refresh。&lt;/p>
&lt;h3 id="23-数据存储可靠性">2.3 数据存储可靠性&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>引入translog&lt;/strong> 当一个文档写入Lucence后是存储在内存中的，即使执行了refresh操作仍然是在文件系统缓存中，如果此时服务器宕机，那么这部分数据将会丢失。为此ES增加了translog， 当进行文档写操作时会先将文档写入Lucene，然后写入一份到translog，写入translog是落盘的(如果对可靠性要求不是很高，也可以设置异步落盘，可以提高性能，由配置 &lt;code>index.translog.durability&lt;/code>和 &lt;code>index.translog.sync_interval&lt;/code>控制)，这样就可以防止服务器宕机后数据的丢失。由于translog是追加写入，因此性能要比随机写入要好。与传统的分布式系统不同，这里是先写入Lucene再写入translog，原因是写入Lucene可能会失败，为了减少写入失败回滚的复杂度，因此先写入Lucene.&lt;/li>
&lt;li>&lt;strong>flush操作&lt;/strong> 另外每30分钟或当translog达到一定大小(由 &lt;code>index.translog.flush_threshold_size&lt;/code>控制，默认512mb), ES会触发一次flush操作，此时ES会先执行refresh操作将buffer中的数据生成segment，然后调用lucene的commit方法将所有内存中的segment fsync到磁盘。此时lucene中的数据就完成了持久化，会清空translog中的数据(6.x版本为了实现sequenceIDs,不删除translog)&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-9418f89986e3a141b3acf83cf158885a_720w.jpg" alt="">&lt;/p>
&lt;ol>
&lt;li>&lt;strong>merge操作&lt;/strong> 由于refresh默认间隔为1s中，因此会产生大量的小segment，为此ES会运行一个任务检测当前磁盘中的segment，对符合条件的segment进行合并操作，减少lucene中的segment个数，提高查询速度，降低负载。不仅如此，merge过程也是文档删除和更新操作后，旧的doc真正被删除的时候。用户还可以手动调用_forcemerge API来主动触发merge，以减少集群的segment个数和清理已删除或更新的文档。&lt;/li>
&lt;li>&lt;strong>多副本机制&lt;/strong> 另外ES有多副本机制，一个分片的主副分片不能分片在同一个节点上，进一步保证数据的可靠性。&lt;/li>
&lt;/ol>
&lt;h3 id="24-部分更新">2.4 部分更新&lt;/h3>
&lt;p>lucene仅支持对文档的整体更新，ES为了支持局部更新，在Lucene的Store索引中存储了一个_source字段，该字段的key值是文档ID， 内容是文档的原文。当进行更新操作时先从_source中获取原文，与更新部分合并后，再调用lucene API进行全量更新， 对于写入了ES但是还没有refresh的文档，可以从translog中获取。另外为了防止读取文档过程后执行更新前有其他线程修改了文档，ES增加了版本机制，当执行更新操作时发现当前文档的版本与预期不符，则会重新获取文档再更新。&lt;/p>
&lt;h2 id="3-es的写入流程">3. ES的写入流程&lt;/h2>
&lt;p>ES的任意节点都可以作为协调节点(coordinating node)接受请求，当协调节点接受到请求后进行一系列处理，然后通过_routing字段找到对应的primary shard，并将请求转发给primary shard, primary shard完成写入后，将写入并发发送给各replica， raplica执行写入操作后返回给primary shard， primary shard再将请求返回给协调节点。大致流程如下图：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-b0b0c96aaeadfde4da0685dae4b9908f_720w.jpg" alt="">&lt;/p>
&lt;h3 id="31-coordinating节点">3.1 coordinating节点&lt;/h3>
&lt;p>ES中接收并转发请求的节点称为&lt;code>coordinating&lt;/code>节点，ES中所有节点都可以接受并转发请求。当一个节点接受到写请求或更新请求后，会执行如下操作：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>ingest pipeline&lt;/strong> 查看该请求是否符合某个ingest pipeline的pattern, 如果符合则执行pipeline中的逻辑，一般是对文档进行各种预处理，如格式调整，增加字段等。如果当前节点没有ingest角色，则需要将请求转发给有ingest角色的节点执行。&lt;/li>
&lt;li>&lt;strong>自动创建索引&lt;/strong> 判断索引是否存在，如果开启了自动创建则自动创建，否则报错&lt;/li>
&lt;li>&lt;strong>设置routing&lt;/strong> 获取请求URL或mapping中的_routing，如果没有则使用_id, 如果没有指定_id则ES会自动生成一个全局唯一ID。该_routing字段用于决定文档分配在索引的哪个shard上。&lt;/li>
&lt;li>&lt;strong>构建BulkShardRequest&lt;/strong> 由于Bulk Request中包含多种(Index/Update/Delete)请求，这些请求分别需要到不同的shard上执行，因此协调节点，会将请求按照shard分开，同一个shard上的请求聚合到一起，构建BulkShardRequest&lt;/li>
&lt;li>&lt;strong>将请求发送给primary shard&lt;/strong> 因为当前执行的是写操作，因此只能在primary上完成，所以需要把请求路由到primary shard所在节点&lt;/li>
&lt;li>&lt;strong>等待primary shard返回&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>目前的Elasticsearch有两个明显的身份，一个是分布式搜索系统，另一个是分布式NoSQL数据库，对于这两种不同的身份，读写语义基本类似，但也有一点差异。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-aced78c779161b2a5baa366f63d86883_720w.jpg" alt="">&lt;/p>
&lt;h2 id="写操作">&lt;strong>写操作&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>实时性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>搜索系统的Index一般都是NRT（Near Real Time），近实时的，比如Elasticsearch中，Index的实时性是由refresh控制的，默认是1s，最快可到100ms，那么也就意味着Index doc成功后，需要等待一秒钟后才可以被搜索到。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NoSQL数据库的Write基本都是RT（Real Time），实时的，写入成功后，立即是可见的。Elasticsearch中的Index请求也能保证是实时的，因为Get请求会直接读内存中尚未Flush到存储介质的TransLog。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>可靠性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>搜索系统对可靠性要求都不高，一般数据的可靠性通过将原始数据存储在另一个存储系统来保证，当搜索系统的数据发生丢失时，再从其他存储系统导一份数据过来重新rebuild就可以了。在Elasticsearch中，通过设置TransLog的Flush频率可以控制可靠性，要么是按请求，每次请求都Flush；要么是按时间，每隔一段时间Flush一次。一般为了性能考虑，会设置为每隔5秒或者1分钟Flush一次，Flush间隔时间越长，可靠性就会越低。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NoSQL数据库作为一款数据库，必须要有很高的可靠性，数据可靠性是生命底线，决不能有闪失。如果把Elasticsearch当做NoSQL数据库，此时需要设置TransLog的Flush策略为每个请求都要Flush，这样才能保证当前Shard写入成功后，数据能尽量持久化下来。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="读操作">读操作&lt;/h2>
&lt;p>下一篇《Elasticsearch内核解析 - 查询篇》中再详细介绍。&lt;/p>
&lt;p>上面大概对比了下搜索和NoSQL在写方面的特点，接下来，我们看一下Elasticsearch 6.0.0版本中写入流程都做了哪些事情，希望能对大家有用。&lt;/p>
&lt;h2 id="关键点">&lt;strong>关键点&lt;/strong>&lt;/h2>
&lt;p>在考虑或分析一个分布式系统的写操作时，一般需要从下面几个方面考虑：&lt;/p>
&lt;ul>
&lt;li>可靠性：或者是持久性，数据写入系统成功后，数据不会被回滚或丢失。&lt;/li>
&lt;li>一致性：数据写入成功后，再次查询时必须能保证读取到最新版本的数据，不能读取到旧数据。&lt;/li>
&lt;li>原子性：一个写入或者更新操作，要么完全成功，要么完全失败，不允许出现中间状态。&lt;/li>
&lt;li>隔离性：多个写入操作相互不影响。&lt;/li>
&lt;li>实时性：写入后是否可以立即被查询到。&lt;/li>
&lt;li>性能：写入性能，吞吐量到底怎么样。&lt;/li>
&lt;/ul>
&lt;p>Elasticsearch作为分布式系统，也需要在写入的时候满足上述的四个特点，我们在后面的写流程介绍中会涉及到上述四个方面。&lt;/p>
&lt;p>接下来,我们一层一层剖析Elasticsearch内部的写机制。&lt;/p>
&lt;h2 id="lucene的写">&lt;strong>Lucene的写&lt;/strong>&lt;/h2>
&lt;p>众所周知，Elasticsearch内部使用了Lucene完成索引创建和搜索功能，Lucene中写操作主要是通过IndexWriter类实现，IndexWriter提供三个接口：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">addDocument&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">updateDocuments&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">deleteDocuments&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>通过这三个接口可以完成单个文档的写入，更新和删除功能，包括了分词，倒排创建，正排创建等等所有搜索相关的流程。只要Doc通过IndesWriter写入后，后面就可以通过IndexSearcher搜索了，看起来功能已经完善了，但是仍然有一些问题没有解：&lt;/p>
&lt;ol>
&lt;li>上述操作是单机的，而不是我们需要的分布式。&lt;/li>
&lt;li>文档写入Lucene后并不是立即可查询的，需要生成完整的Segment后才可被搜索，如何保证实时性？&lt;/li>
&lt;li>Lucene生成的Segment是在内存中，如果机器宕机或掉电后，内存中的Segment会丢失，如何保证数据可靠性 ？&lt;/li>
&lt;li>Lucene不支持部分文档更新，但是这又是一个强需求，如何支持部分更新？&lt;/li>
&lt;/ol>
&lt;p>上述问题，在Lucene中是没有解决的，那么就需要Elasticsearch中解决上述问题。&lt;/p>
&lt;p>Elasticsearch在解决上述问题时，除了我们在上一篇《Elasticsearch数据模型简介》中介绍的几种系统字段外，在引擎架构上也引入了多重机制来解决问题。我们再来看Elasticsearch中的写机制。&lt;/p>
&lt;h2 id="elasticsearch的写">&lt;strong>Elasticsearch的写&lt;/strong>&lt;/h2>
&lt;p>Elasticsearch采用多Shard方式，通过配置routing规则将数据分成多个数据子集，每个数据子集提供独立的索引和搜索功能。当写入文档的时候，根据routing规则，将文档发送给特定Shard中建立索引。这样就能实现分布式了。&lt;/p>
&lt;p>此外，Elasticsearch整体架构上采用了一主多副的方式：&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-8203d235d8cfc14849012e6ea229fa89_720w.jpg" alt="">&lt;/p>
&lt;p>Elasticsearch一主多副&lt;/p>
&lt;p>每个Index由多个Shard组成，每个Shard有一个主节点和多个副本节点，副本个数可配。但每次写入的时候，写入请求会先根据_routing规则选择发给哪个Shard，Index Request中可以设置使用哪个Filed的值作为路由参数，如果没有设置，则使用Mapping中的配置，如果mapping中也没有配置，则使用_id作为路由参数，然后通过_routing的Hash值选择出Shard（在OperationRouting类中），最后从集群的Meta中找出出该Shard的Primary节点。&lt;/p>
&lt;p>请求接着会发送给Primary Shard，在Primary Shard上执行成功后，再从Primary Shard上将请求同时发送给多个Replica Shard，请求在多个Replica Shard上执行成功并返回给Primary Shard后，写入请求执行成功，返回结果给客户端。&lt;/p>
&lt;p>这种模式下，写入操作的延时就等于latency = Latency(Primary Write) + Max(Replicas Write)。只要有副本在，写入延时最小也是两次单Shard的写入时延总和，写入效率会较低，但是这样的好处也很明显，避免写入后，单机或磁盘故障导致数据丢失，在数据重要性和性能方面，一般都是优先选择数据，除非一些允许丢数据的特殊场景。&lt;/p>
&lt;p>采用多个副本后，避免了单机或磁盘故障发生时，对已经持久化后的数据造成损害，但是Elasticsearch里为了减少磁盘IO保证读写性能，一般是每隔一段时间（比如5分钟）才会把Lucene的Segment写入磁盘持久化，对于写入内存，但还未Flush到磁盘的Lucene数据，如果发生机器宕机或者掉电，那么内存中的数据也会丢失，这时候如何保证？&lt;/p>
&lt;p>对于这种问题，Elasticsearch学习了数据库中的处理方式：增加CommitLog模块，Elasticsearch中叫TransLog。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-20a780ddd33a74b37a81e18d3baf8983_720w.jpg" alt="">&lt;/p>
&lt;p>Refresh &amp;amp;&amp;amp; Flush&lt;/p>
&lt;p>在每一个Shard中，写入流程分为两部分，先写入Lucene，再写入TransLog。&lt;/p>
&lt;p>写入请求到达Shard后，先写Lucene文件，创建好索引，此时索引还在内存里面，接着去写TransLog，写完TransLog后，刷新TransLog数据到磁盘上，写磁盘成功后，请求返回给用户。这里有几个关键点，一是和数据库不同，数据库是先写CommitLog，然后再写内存，而Elasticsearch是先写内存，最后才写TransLog，一种可能的原因是Lucene的内存写入会有很复杂的逻辑，很容易失败，比如分词，字段长度超过限制等，比较重，为了避免TransLog中有大量无效记录，减少recover的复杂度和提高速度，所以就把写Lucene放在了最前面。二是写Lucene内存后，并不是可被搜索的，需要通过Refresh把内存的对象转成完整的Segment后，然后再次reopen后才能被搜索，一般这个时间设置为1秒钟，导致写入Elasticsearch的文档，最快要1秒钟才可被从搜索到，所以Elasticsearch在搜索方面是NRT（Near Real Time）近实时的系统。三是当Elasticsearch作为NoSQL数据库时，查询方式是GetById，这种查询可以直接从TransLog中查询，这时候就成了RT（Real Time）实时系统。四是每隔一段比较长的时间，比如30分钟后，Lucene会把内存中生成的新Segment刷新到磁盘上，刷新后索引文件已经持久化了，历史的TransLog就没用了，会清空掉旧的TransLog。&lt;/p>
&lt;p>上面介绍了Elasticsearch在写入时的两个关键模块，Replica和TransLog，接下来，我们看一下Update流程：&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-e728bc042a75f8798925d708dc61b1ef_720w.jpg" alt="">&lt;/p>
&lt;p>Update&lt;/p>
&lt;p>Lucene中不支持部分字段的Update，所以需要在Elasticsearch中实现该功能，具体流程如下：&lt;/p>
&lt;ol>
&lt;li>收到Update请求后，从Segment或者TransLog中读取同id的完整Doc，记录版本号为V1。&lt;/li>
&lt;li>将版本V1的全量Doc和请求中的部分字段Doc合并为一个完整的Doc，同时更新内存中的VersionMap。获取到完整Doc后，Update请求就变成了Index请求。&lt;/li>
&lt;li>加锁。&lt;/li>
&lt;li>再次从versionMap中读取该id的最大版本号V2，如果versionMap中没有，则从Segment或者TransLog中读取，这里基本都会从versionMap中获取到。&lt;/li>
&lt;li>检查版本是否冲突(V1==V2)，如果冲突，则回退到开始的“Update doc”阶段，重新执行。如果不冲突，则执行最新的Add请求。&lt;/li>
&lt;li>在Index Doc阶段，首先将Version + 1得到V3，再将Doc加入到Lucene中去，Lucene中会先删同id下的已存在doc id，然后再增加新Doc。写入Lucene成功后，将当前V3更新到versionMap中。&lt;/li>
&lt;li>释放锁，部分更新的流程就结束了。&lt;/li>
&lt;/ol>
&lt;p>介绍完部分更新的流程后，大家应该从整体架构上对Elasticsearch的写入有了一个初步的映象，接下来我们详细剖析下写入的详细步骤。&lt;/p>
&lt;h2 id="elasticsearch写入请求类型">&lt;strong>Elasticsearch写入请求类型&lt;/strong>&lt;/h2>
&lt;p>Elasticsearch中的写入请求类型，主要包括下列几个：Index(Create)，Update，Delete和Bulk，其中前3个是单文档操作，后一个Bulk是多文档操作，其中Bulk中可以包括Index(Create)，Update和Delete。&lt;/p>
&lt;p>在6.0.0及其之后的版本中，前3个单文档操作的实现基本都和Bulk操作一致，甚至有些就是通过调用Bulk的接口实现的。估计接下来几个版本后，Index(Create)，Update，Delete都会被当做Bulk的一种特例化操作被处理。这样，代码和逻辑都会更清晰一些。&lt;/p>
&lt;p>下面，我们就以Bulk请求为例来介绍写入流程。&lt;/p>
&lt;h2 id="elasticsearch写入流程图">&lt;strong>Elasticsearch写入流程图&lt;/strong>&lt;/h2>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-4e32cd77e69ae4932665d110d6bf13a1_720w.jpg" alt="">&lt;/p>
&lt;p>写入流程图&lt;/p>
&lt;ul>
&lt;li>红色：Client Node。&lt;/li>
&lt;li>绿色：Primary Node。&lt;/li>
&lt;li>蓝色：Replica Node。&lt;/li>
&lt;/ul>
&lt;h2 id="注册action">&lt;strong>注册Action&lt;/strong>&lt;/h2>
&lt;p>在Elasticsearch中，所有action的入口处理方法都是注册在ActionModule.java中，比如Bulk Request有两个注册入口，分别是Rest和Transport入口：&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-7506f5d87f80ec63cbd2030b785441ec_720w.jpg" alt="">&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-ac3d0e6ee82d507d38110565d121febf_720w.jpg" alt="">&lt;/p>
&lt;p>如果请求是Rest请求，则会在RestBulkAction中Parse Request，构造出BulkRequest，然后发给后面的TransportAction处理。&lt;/p>
&lt;p>TransportShardBulkAction的基类TransportReplicationAction中注册了对Primary，Replica等的不同处理入口:&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-4ac69cd72079de47adfb2d81906579db_720w.jpg" alt="">&lt;/p>
&lt;p>这里对原始请求，Primary Node请求和Replica Node请求各自注册了一个handler处理入口。&lt;/p>
&lt;h2 id="client-node">&lt;strong>Client Node&lt;/strong>&lt;/h2>
&lt;p>Client Node 也包括了前面说过的Parse Request，这里就不再赘述了，接下来看一下其他的部分。&lt;/p>
&lt;p>&lt;strong>1. Ingest Pipeline&lt;/strong>&lt;/p>
&lt;p>在这一步可以对原始文档做一些处理，比如HTML解析，自定义的处理，具体处理逻辑可以通过插件来实现。在Elasticsearch中，由于Ingest Pipeline会比较耗费CPU等资源，可以设置专门的Ingest Node，专门用来处理Ingest Pipeline逻辑。&lt;/p>
&lt;p>如果当前Node不能执行Ingest Pipeline，则会将请求发给另一台可以执行Ingest Pipeline的Node。&lt;/p>
&lt;p>&lt;strong>2. Auto Create Index&lt;/strong>&lt;/p>
&lt;p>判断当前Index是否存在，如果不存在，则需要自动创建Index，这里需要和Master交互。也可以通过配置关闭自动创建Index的功能。&lt;/p>
&lt;p>&lt;strong>3. Set Routing&lt;/strong>&lt;/p>
&lt;p>设置路由条件，如果Request中指定了路由条件，则直接使用Request中的Routing，否则使用Mapping中配置的，如果Mapping中无配置，则使用默认的_id字段值。&lt;/p>
&lt;p>在这一步中，如果没有指定&lt;em>id字段，则会自动生成一个唯一的_id字段，目前使用的是UUID。&lt;/em>&lt;/p>
&lt;p>&lt;em>&lt;strong>4. Construct BulkShardRequest&lt;/strong>&lt;/em>&lt;/p>
&lt;p>&lt;em>由于Bulk Request中会包括多个(Index/Update/Delete)请求，这些请求根据routing可能会落在多个Shard上执行，这一步会按Shard挑拣Single Write Request，同一个Shard中的请求聚集在一起，构建BulkShardRequest，每个BulkShardRequest对应一个Shard。&lt;/em>&lt;/p>
&lt;p>&lt;em>&lt;strong>5. Send Request To Primary&lt;/strong>&lt;/em>&lt;/p>
&lt;p>&lt;em>这一步会将每一个BulkShardRequest请求发送给相应Shard的Primary Node。&lt;/em>&lt;/p>
&lt;h2 id="primary-node">&lt;strong>Primary Node&lt;/strong>&lt;/h2>
&lt;p>Primary 请求的入口是在PrimaryOperationTransportHandler的messageReceived，我们来看一下相关的逻辑流程。&lt;/p>
&lt;p>&lt;strong>1. Index or Update or Delete&lt;/strong>&lt;/p>
&lt;p>循环执行每个Single Write Request，对于每个Request，根据操作类型(&lt;em>CREATE/INDEX/UPDATE/DELETE&lt;/em>)选择不同的处理逻辑。&lt;/p>
&lt;p>其中，Create/Index是直接新增Doc，Delete是直接根据_id删除Doc，Update会稍微复杂些，我们下面就以Update为例来介绍。&lt;/p>
&lt;p>&lt;strong>2. Translate Update To Index or Delete&lt;/strong>&lt;/p>
&lt;p>这一步是Update操作的特有步骤，在这里，会将Update请求转换为Index或者Delete请求。首先，会通过GetRequest查询到已经存在的同_id Doc（如果有）的完整字段和值（依赖_source字段），然后和请求中的Doc合并。同时，这里会获取到读到的Doc版本号，记做V1。&lt;/p>
&lt;p>&lt;strong>3. Parse Doc&lt;/strong>&lt;/p>
&lt;p>这里会解析Doc中各个字段。生成ParsedDocument对象，同时会生成uid Term。在Elasticsearch中，_uid = type # _id，对用户，_Id可见，而Elasticsearch中存储的是_uid。这一部分生成的ParsedDocument中也有Elasticsearch的系统字段，大部分会根据当前内容填充，部分未知的会在后面继续填充ParsedDocument。&lt;/p>
&lt;p>&lt;strong>4. Update Mapping&lt;/strong>&lt;/p>
&lt;p>Elasticsearch中有个自动更新Mapping的功能，就在这一步生效。会先挑选出Mapping中未包含的新Field，然后判断是否运行自动更新Mapping，如果允许，则更新Mapping。&lt;/p>
&lt;p>&lt;strong>5. Get Sequence Id and Version&lt;/strong>&lt;/p>
&lt;p>由于当前是Primary Shard，则会从SequenceNumber Service获取一个sequenceID和Version。SequenceID在Shard级别每次递增1，SequenceID在写入Doc成功后，会用来初始化LocalCheckpoint。Version则是根据当前Doc的最大Version递增1。&lt;/p>
&lt;p>&lt;strong>6. Add Doc To Lucene&lt;/strong>&lt;/p>
&lt;p>这一步开始的时候会给特定_uid加锁，然后判断该_uid对应的Version是否等于之前Translate Update To Index步骤里获取到的Version，如果不相等，则说明刚才读取Doc后，该Doc发生了变化，出现了版本冲突，这时候会抛出一个VersionConflict的异常，该异常会在Primary Node最开始处捕获，重新从“Translate Update To Index or Delete”开始执行。&lt;/p>
&lt;p>如果Version相等，则继续执行，如果已经存在同id的Doc，则会调用Lucene的UpdateDocument(uid, doc)接口，先根据uid删除Doc，然后再Index新Doc。如果是首次写入，则直接调用Lucene的AddDocument接口完成Doc的Index，AddDocument也是通过UpdateDocument实现。&lt;/p>
&lt;p>这一步中有个问题是，如何保证Delete-Then-Add的原子性，怎么避免中间状态时被Refresh？答案是在开始Delete之前，会加一个Refresh Lock，禁止被Refresh，只有等Add完后释放了Refresh Lock后才能被Refresh，这样就保证了Delete-Then-Add的原子性。&lt;/p>
&lt;p>Lucene的UpdateDocument接口中就只是处理多个Field，会遍历每个Field逐个处理，处理顺序是invert index，store field，doc values，point dimension，后续会有文章专门介绍Lucene中的写入。&lt;/p>
&lt;p>&lt;strong>7. Write Translog&lt;/strong>&lt;/p>
&lt;p>写完Lucene的Segment后，会以keyvalue的形式写TransLog，Key是_id，Value是Doc内容。当查询的时候，如果请求是GetDocByID，则可以直接根据_id从TransLog中读取到，满足NoSQL场景下的实时性要去。&lt;/p>
&lt;p>需要注意的是，这里只是写入到内存的TransLog，是否Sync到磁盘的逻辑还在后面。&lt;/p>
&lt;p>这一步的最后，会标记当前SequenceID已经成功执行，接着会更新当前Shard的LocalCheckPoint。&lt;/p>
&lt;p>&lt;strong>8. Renew Bulk Request&lt;/strong>&lt;/p>
&lt;p>这里会重新构造Bulk Request，原因是前面已经将UpdateRequest翻译成了Index或Delete请求，则后续所有Replica中只需要执行Index或Delete请求就可以了，不需要再执行Update逻辑，一是保证Replica中逻辑更简单，性能更好，二是保证同一个请求在Primary和Replica中的执行结果一样。&lt;/p>
&lt;p>&lt;strong>9. Flush Translog&lt;/strong>&lt;/p>
&lt;p>这里会根据TransLog的策略，选择不同的执行方式，要么是立即Flush到磁盘，要么是等到以后再Flush。Flush的频率越高，可靠性越高，对写入性能影响越大。&lt;/p>
&lt;p>&lt;strong>10. Send Requests To Replicas&lt;/strong>&lt;/p>
&lt;p>这里会将刚才构造的新的Bulk Request并行发送给多个Replica，然后等待Replica的返回，这里需要等待所有Replica返回后（可能有成功，也有可能失败），Primary Node才会返回用户。如果某个Replica失败了，则Primary会给Master发送一个Remove Shard请求，要求Master将该Replica Shard从可用节点中移除。&lt;/p>
&lt;p>这里，同时会将SequenceID，PrimaryTerm，GlobalCheckPoint等传递给Replica。&lt;/p>
&lt;p>发送给Replica的请求中，Action Name等于原始ActionName + [R]，这里的R表示Replica。通过这个[R]的不同，可以找到处理Replica请求的Handler。&lt;/p>
&lt;p>&lt;strong>11. Receive Response From Replicas&lt;/strong>&lt;/p>
&lt;p>Replica中请求都处理完后，会更新Primary Node的LocalCheckPoint。&lt;/p>
&lt;h2 id="replica-node">&lt;strong>Replica Node&lt;/strong>&lt;/h2>
&lt;p>Replica 请求的入口是在ReplicaOperationTransportHandler的messageReceived，我们来看一下相关的逻辑流程。&lt;/p>
&lt;p>&lt;strong>1. Index or Delete&lt;/strong>&lt;/p>
&lt;p>根据请求类型是Index还是Delete，选择不同的执行逻辑。这里没有Update，是因为在Primary Node中已经将Update转换成了Index或Delete请求了。&lt;/p>
&lt;p>&lt;strong>2. Parse Doc&lt;/strong>&lt;/p>
&lt;p>&lt;strong>3. Update Mapping&lt;/strong>&lt;/p>
&lt;p>以上都和Primary Node中逻辑一致。&lt;/p>
&lt;p>&lt;strong>4. Get Sequence Id and Version&lt;/strong>&lt;/p>
&lt;p>Primary Node中会生成Sequence ID和Version，然后放入ReplicaRequest中，这里只需要从Request中获取到就行。&lt;/p>
&lt;p>&lt;strong>5. Add Doc To Lucene&lt;/strong>&lt;/p>
&lt;p>由于已经在Primary Node中将部分Update请求转换成了Index或Delete请求，这里只需要处理Index和Delete两种请求，不再需要处理Update请求了。比Primary Node会更简单一些。&lt;/p>
&lt;p>&lt;strong>6. Write Translog&lt;/strong>&lt;/p>
&lt;p>&lt;strong>7. Flush Translog&lt;/strong>&lt;/p>
&lt;p>以上都和Primary Node中逻辑一致。&lt;/p>
&lt;h2 id="最后">&lt;strong>最后&lt;/strong>&lt;/h2>
&lt;p>上面详细介绍了Elasticsearch的写入流程及其各个流程的工作机制，我们在这里再次总结下之前提出的分布式系统中的六大特性：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>可靠性&lt;/strong>：由于Lucene的设计中不考虑可靠性，在Elasticsearch中通过Replica和TransLog两套机制保证数据的可靠性。&lt;/li>
&lt;li>&lt;strong>一致性&lt;/strong>：Lucene中的Flush锁只保证Update接口里面Delete和Add中间不会Flush，但是Add完成后仍然有可能立即发生Flush，导致Segment可读。这样就没法保证Primary和所有其他Replica可以同一时间Flush，就会出现查询不稳定的情况，这里只能实现最终一致性。&lt;/li>
&lt;li>&lt;strong>原子性&lt;/strong>：Add和Delete都是直接调用Lucene的接口，是原子的。当部分更新时，使用Version和锁保证更新是原子的。&lt;/li>
&lt;li>&lt;strong>隔离性&lt;/strong>：仍然采用Version和局部锁来保证更新的是特定版本的数据。&lt;/li>
&lt;li>&lt;strong>实时性&lt;/strong>：使用定期Refresh Segment到内存，并且Reopen Segment方式保证搜索可以在较短时间（比如1秒）内被搜索到。通过将未刷新到磁盘数据记入TransLog，保证对未提交数据可以通过ID实时访问到。&lt;/li>
&lt;li>性能：性能是一个系统性工程，所有环节都要考虑对性能的影响，在Elasticsearch中，在很多地方的设计都考虑到了性能，一是不需要所有Replica都返回后才能返回给用户，只需要返回特定数目的就行；二是生成的Segment现在内存中提供服务，等一段时间后才刷新到磁盘，Segment在内存这段时间的可靠性由TransLog保证；三是TransLog可以配置为周期性的Flush，但这个会给可靠性带来伤害；四是每个线程持有一个Segment，多线程时相互不影响，相互独立，性能更好；五是系统的写入流程对版本依赖较重，读取频率较高，因此采用了versionMap，减少热点数据的多次磁盘IO开销。Lucene中针对性能做了大量的优化。后面我们也会有文章专门介绍Lucene中的优化思路。&lt;/li>
&lt;/ol></description></item><item><title>ElasticSearch基础</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/elasticsearch%E5%9F%BA%E7%A1%80/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/elasticsearch%E5%9F%BA%E7%A1%80/</guid><description>&lt;h1 id="elasticsearch基础">ElasticSearch基础&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Elasticsearch 是一个基于lucene的分布式可扩展的实时搜索和分析引擎。&lt;/p>
&lt;h2 id="架构">架构&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2022/01/07-14-03-48-2022-01-07-14-03-43-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>一个 ES Index 在集群模式下，有多个 Node （节点）组成。每个节点就是 ES 的Instance (实例)。&lt;/li>
&lt;li>每个节点上会有多个 shard （分片）， P1 P2 是主分片, R1 R2 是副本分片&lt;/li>
&lt;li>每个分片上对应着就是一个 Lucene Index（底层索引文件）&lt;/li>
&lt;li>Lucene Index 是一个统称
&lt;ul>
&lt;li>由多个 Segment （段文件，就是倒排索引）组成。每个段文件存储着就是 Doc 文档。&lt;/li>
&lt;li>commit point记录了所有 segments 的信息&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Lucene索引结构&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2022/01/07-14-07-11-2022-01-07-14-07-06-image.png" alt="">&lt;/p>
&lt;h2 id="特点">特点&lt;/h2>
&lt;ul>
&lt;li>分布式存储&lt;/li>
&lt;li>近实时检索&lt;/li>
&lt;/ul>
&lt;h2 id="核心概念">核心概念&lt;/h2>
&lt;ul>
&lt;li>索引(index)：&lt;/li>
&lt;li>分片(shard):&lt;/li>
&lt;li>分段(segment):&lt;/li>
&lt;li>Translog:&lt;/li>
&lt;/ul>
&lt;h3 id="写流程">写流程&lt;/h3>
&lt;h2 id="常用操作">常用操作&lt;/h2>
&lt;ul>
&lt;li>清空index数据&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1"># create index&lt;/span>
curl -X PUT http://192.168.0.10:20000/test6 --header &lt;span class="s2">&amp;#34;Content-Type: application/json&amp;#34;&lt;/span> -d index.json
cat index.json
&lt;span class="c1"># delete index&lt;/span>
curl -X DELETE http://192.168.0.10:20000/test6
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://pdai.tech/md/db/nosql-es/elasticsearch-y-th-2.html">ES详解 - 原理：ES原理知识点补充和整体结构 | Java 全栈知识体系&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Flink WordCount程序背后的万字深度解析</title><link>https://justice.bj.cn/post/30.architech/flink/flink-wordcoun%E8%A7%A3%E6%9E%90/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink-wordcoun%E8%A7%A3%E6%9E%90/</guid><description>&lt;h1 id="flink-wordcount程序背后的万字深度解析">Flink WordCount程序背后的万字深度解析&lt;/h1>
&lt;h2 id="1-flink数据流图简介">1 Flink数据流图简介&lt;/h2>
&lt;h3 id="11-flink样例程序">1.1 Flink样例程序&lt;/h3>
&lt;p>我们开始对数据流做处理，计算数据流中单词出现的频次。从这个样例中，我们可以一窥Flink设计和运行原理。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-e1b66eda2016d10813d481b7182a461a_1440w.jpg" alt="">&lt;/p>
&lt;p>图 1 Flink样例程序示意图&lt;/p>
&lt;p>程序分为三大部分：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>第一部分读取数据源（Source），&lt;/p>
&lt;/li>
&lt;li>
&lt;p>第二部分对数据做转换操作（Transformation），&lt;/p>
&lt;/li>
&lt;li>
&lt;p>最后将转换结果输出到一个目的地（Sink）。&lt;/p>
&lt;p>代码中的函数被称为算子（Operator），是Flink提供给程序员的接口，程序员需要通过这些算子对数据做操作。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="算子">算子&lt;/h2>
&lt;p>我们可以把算子理解为1 + 2 运算中的加号，加号（+）是这个算子的一个符号表示，它表示对数字1和数字2做加法运算。&lt;/p>
&lt;p>同样，在Flink或Spark这样的大数据引擎中，算子对数据进行某种操作，程序员可以根据自己的需求调用合适的算子，完成所需计算任务。&lt;/p>
&lt;p>常用的算子有map、flatMap、keyBy、timeWindow等，它们分别对数据流执行不同类型的操作。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-b5bed65bb0ad05515e95c7b9686e0f1b_1440w.jpg" alt="">&lt;/p>
&lt;p>图 2 WordCont程序的逻辑视图&lt;/p>
&lt;p>图 2展示了WordCount程序中数据从不同算子间流动的情况。&lt;/p>
&lt;p>图中，圆圈代表算子，圆圈间的箭头代表数据流，数据流在Flink程序中经过不同算子的计算，最终生成为目标数据。&lt;/p>
&lt;p>按照算子对数据的操作内容，一般将算子分为Source算子、Transformation算子和Sink算子。&lt;/p>
&lt;p>Source算子读取数据源中的数据，数据源可以是数据流、也可以存储在文件系统中的文件。&lt;/p>
&lt;p>Transformation算子对数据进行必要的计算处理。&lt;/p>
&lt;p>Sink算子将处理结果输出，数据一般被输出到数据库、文件系统或下一个数据流程序。&lt;/p>
&lt;p>我们先对这个样例程序中各个算子做一个简单的介绍：&lt;/p>
&lt;ul>
&lt;li>map&lt;/li>
&lt;/ul>
&lt;p>map函数对数据流中每一条数据做一个操作，生成一条新的数据。本例中&lt;code>map(word =&amp;gt; (word, 1))&lt;/code>表示取输入的每个单词，用变量word表示，然后生成一个二元对（word, 1），1是表示出现了一次。注意，map的一条输入数据对应一条输出数据。&lt;/p>
&lt;ul>
&lt;li>flatMap&lt;/li>
&lt;/ul>
&lt;p>在解释flatMap前，我们先对&lt;code>split&lt;/code>函数做一个简单介绍。&lt;code>split(“\\s”)&lt;/code>函数以空白字符为分隔符，将文本切分成单词列表。如果输入为“Hello Flink“，那么经过这个函数切分后，得到结果为[“Hello”,”Flink”]组成的单词列表。&lt;/p>
&lt;p>本例中&lt;code>flatMap(line =&amp;gt; line.split(“\\s”))&lt;/code>表示取出输入的每一行文本，用变量line表示，将文本中以空格做切分，生成一个单词列表，到这里仍然列表，flatMap接着对列表打平，输出单个单词。&lt;code>flatMap&lt;/code>先做&lt;code>map&lt;/code>所做的操作，然后对输出的各个列表打平，因此，&lt;code>flatMap&lt;/code>的一条输入数据可能有多条输出。&lt;/p>
&lt;ul>
&lt;li>keyBy&lt;/li>
&lt;/ul>
&lt;p>&lt;code>keyBy&lt;/code>根据某个Key做数据重分布，将所有数据中包含该Key的数据都发送到同一个分区上。本例中是将二元组中第一项作为Key，即以单词为Key，包含同样单词的二元对都发送到同一分区上。&lt;/p>
&lt;ul>
&lt;li>timeWindow&lt;/li>
&lt;/ul>
&lt;p>&lt;code>timeWindow&lt;/code>是时间窗口函数，以界定对多长时间之内的数据做统计。&lt;/p>
&lt;ul>
&lt;li>sum&lt;/li>
&lt;/ul>
&lt;p>&lt;code>sum&lt;/code>为求和函数。&lt;code>sum(1)&lt;/code>表示对二元组中第二个元素求和，因为经过前面的&lt;code>keyBy&lt;/code>，所有单词都被发送到了同一个分区，因此，在这一个分区上，将单词出现次数做加和，就得到出现的总次数。&lt;/p>
&lt;p>对于词频统计这个案例，逻辑上来讲无非是对数据流中的单词做提取，然后使用一个Key-Value结构对单词做词频计数，最后输出结果即可，这样的逻辑本可以用几行代码完成，改成这样的算子形式，反而让新人看着一头雾水，为什么一定要用算子的形式来写程序呢？实际上，算子进化成当前这个形态，就像人类从石块计数，到手指计数，到算盘计数，再到计算器计数这样的进化过程一样，尽管更低级的方式可以完成一定的计算任务，但是随着计算规模的增长，古老的计数方式存在着低效的弊端，无法完成更高级别和更大规模的计算需求。试想，如果我们不使用大数据引擎提供的算子，而是自己实现一套上述的计算逻辑，尽管我们可以快速完成当前的词频统计的任务，但是当面临一个新计算任务时，我们需要再次重新编写程序，完成一整套计算任务。我们自己编写代码的横向扩展性可能很低，当输入数据暴增时，我们需要做很大改动，以部署在更多机器上。&lt;/p>
&lt;p>大数据引擎的算子对计算做了一些抽象，对于新人来说有一定学习成本，而一旦掌握这门技术，人们所能处理的数据规模将成倍增加。大数据引擎的算子出现，正是针对数据分布在多个分区的大数据场景需要一种统一的计算描述语言来对数据做计算而进化出的新计算形态。基于大数据引擎的算子，我们可以定义一个数据流的逻辑视图，以此完成对大数据的计算。剩下那些数据交换、横向扩展、故障恢复等问题全交由大数据引擎来解决。&lt;/p>
&lt;h3 id="12-从逻辑视图到物理执行">1.2 从逻辑视图到物理执行&lt;/h3>
&lt;p>在绝大多数的大数据处理场景下，一台机器节点无法处理所有数据，数据被切分到多台节点上。&lt;/p>
&lt;p>在大数据领域，当数据量大到超过单台机器处理能力时，就将一份数据切分到多个分区（Partition）上，每个分区分布在一台虚拟机或物理机上。&lt;/p>
&lt;p>前一小节已经提到，大数据引擎的算子提供了编程接口，使用算子我们可以构建数据流的逻辑视图。&lt;/p>
&lt;p>考虑到数据分布在多个节点的情况，逻辑视图只是一种抽象，需要将逻辑视图转化为物理执行图，才能在分布式环境下执行。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-aa0776d3be9a46cdd945aab42a12346d_1440w.jpg" alt="">&lt;/p>
&lt;p>图 3 样例程序物理执行示意图&lt;/p>
&lt;p>图 3为1.1中的样例程序的物理执行图，这里数据流分布在2个分区上。箭头部分表示数据流分区，圆圈部分表示算子在分区上的算子子任务（Operator Subtask）。&lt;/p>
&lt;p>从逻辑视图变为物理执行图后，&lt;/p>
&lt;p>map算子在每个分区都有一个算子子任务，以处理该分区上的数据：map[1/2]算子子任务处理第一个数据流分区上的数据，map[2/2]算子子任务处理第二个数据流分区上的数据。&lt;/p>
&lt;p>keyBy算子会将数据按照某个key做数据重分布，在词频统计的例子中是以单词为key，例如，输入数据为“Hello Flink Hello World”，keyBy算子会将所有的”Hello”归结到一个分区上。&lt;/p>
&lt;p>算子子任务是物理执行的基本单元，算子子任务之间是相互独立的，某个算子子任务有自己的线程，不同算子子任务可能分布在不同的节点上。后文在Flink的资源分配部分我们还会重点介绍算子子任务。&lt;/p>
&lt;p>从图 3中可以看到，除去Sink外的算子都被分成了2个算子子任务，这样配置的并行度（Parallelism）为2，Sink算子的并行度为1。并行度是可以被设置的，实际应用中一般根据数据量的大小，计算资源的多少等多方面的因素来设置并行度。&lt;/p>
&lt;h3 id="13-数据交换策略">1.3 数据交换策略&lt;/h3>
&lt;p>图 3中keyBy算子子任务将数据做了重新分配，即数据在不同分区上进行着数据交换，产生了数据流动的现象。无论是Hadoop、Spark还是Flink，当涉及数据分布在多个分区时，对数据的处理都会涉及到数据交换策略。在Flink中，数据交换策略包括图 4中涉及到的四种策略：&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-f4e055bfad75c037ea5c07acc26481bd_1440w.jpg" alt="">&lt;/p>
&lt;p>图 4 Flink数据交换策略&lt;/p>
&lt;ol>
&lt;li>前向传播（Forward）：前一个算子子任务将数据直接传递给后一个算子子任务，数据不存在跨分区的交换，也避免了因数据交换产生的各类开销，图 3中Source和和flatMap之间就是这样的情形。&lt;/li>
&lt;li>全局广播（Broadcast）:将某份数据发送到所有分区上，这种策略涉及到了数据拷贝和网络通信，因此非常消耗资源。&lt;/li>
&lt;li>基于Key的数据重分布：数据以(Key, Value)形式存在，该策略将所有数据做一次重新分布，并保证相同Key的数据被发送到同一个分区上。图 3中keyBy算子将单词作为Key，把某个单词都发送到同一分区，以方便后续算子来统计这个单词出现的频次。&lt;/li>
&lt;li>随机策略（Random）：该策略将所有数据随机均匀地发送到多个分区上，以保证数据平均分配到不同分区上。该策略通常为了防止数据倾斜到某些分区，导致部分分区数据稀疏，部分分区数据拥堵，甚至超过该分区上算子的处理能力。&lt;/li>
&lt;/ol>
&lt;h2 id="2-flink架构与核心组件">2 Flink架构与核心组件&lt;/h2>
&lt;p>为了实现支持分布式运行，Flink跟其他大数据引擎一样，采用了主从（Master-Worker）架构，运行时主要包括两个组件：&lt;/p>
&lt;p>• JobManager，又被称为Master，是一个Flink应用的主节点。&lt;/p>
&lt;p>• TaskManager，又被称为Worker，执行计算任务的节点。&lt;/p>
&lt;p>一个Flink应用一般含有至少一个JobManager，一个或多个TaskManager。&lt;/p>
&lt;h3 id="21-flink作业执行过程">2.1 Flink作业执行过程&lt;/h3>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-14d66043dde3ab8abf2af3845c4b4ffe_1440w.jpg" alt="">&lt;/p>
&lt;p>图 5 Flink作业提交流程&lt;/p>
&lt;p>用户编写Flink程序并提交任务的具体流程为：&lt;/p>
&lt;ol>
&lt;li>用户编写应用程序代码，并通过Flink客户端（Client）提交作业。程序一般为Java或Scala语言，调用Flink API，构建基于逻辑视角的数据流图，代码和相关配置文件被编译打包，并被提交到JobManager上，形成一个应用作业（Application）。&lt;/li>
&lt;li>JobManager接受到作业后，将逻辑视图转化成可并行的物理执行图。&lt;/li>
&lt;li>JobManager将物理执行图发送给各TaskManager。&lt;/li>
&lt;li>TaskManager接收到物理执行图后，会初始化并开始执行被分配的任务。&lt;/li>
&lt;li>TaskManager在执行任务过程中可能会与其他TaskManager交换数据，会使用图 4提到的一些数据交换策略。&lt;/li>
&lt;li>TaskManager将任务启动、运行、性能指标、结束或终止等状态信息会反馈给JobManager。&lt;/li>
&lt;li>用户可以使用Flink Web仪表盘来监控提交的作业。&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-4cd8011a2888f0349716e74ef402157c_1440w.jpg" alt="">&lt;/p>
&lt;p>图 6 Flink主从架构架构图&lt;/p>
&lt;p>图 6对Flink的各个组件描述得更为详细，我们再对涉及到的各个组件进行更为详细的介绍。&lt;/p>
&lt;h3 id="client">Client&lt;/h3>
&lt;p>当用户提交一个Flink程序时，会首先创建一个客户端（Client）。该Client会对用户提交的Flink程序进行预处理，并把作业提交到Flink集群中处理。Client需要从用户提交的Flink程序配置中获取JobManager的地址，并建立到JobManager的连接，将Flink作业提交给JobManager。Client会将用户提交的Flink程序组装一个JobGraph。&lt;/p>
&lt;h3 id="jobmanager">JobManager&lt;/h3>
&lt;p>JobManager是Flink的协调者，它负责接收Flink作业，调度任务。同时，JobManager还负责管理TaskManager，收集作业的状态信息，生成检查点和故障恢复等问题。JobManager会将Client提交的JobGraph转化为ExceutionGraph，ExecutionGraph是JobGraph的并行版本，但还不是最终的物理执行图。&lt;/p>
&lt;h3 id="taskmanager">TaskManager&lt;/h3>
&lt;p>TaskManager是实际负责执行计算的节点，在其上执行物理执行图。同时，TaskManager还要处理必要的数据缓存和交换。每个TaskManager负责管理其所在节点上的资源信息，包括内存、磁盘、网络，TaskManager启动的时候会将资源的状态向JobManager汇报。&lt;/p>
&lt;h3 id="22-逻辑视图到物理执行图">2.2 逻辑视图到物理执行图&lt;/h3>
&lt;p>逻辑视图转化为物理执行图过程，该过程可以分成四层：StreamGraph -&amp;gt; JobGraph -&amp;gt; ExecutionGraph -&amp;gt; 物理执行图。&lt;/p>
&lt;ul>
&lt;li>StreamGraph：是根据用户通过 DataStream API 编写的代码生成的最初的图，用来表示程序的拓扑结构。在这张图中，节点就是用户调用的算子，边表示数据流。&lt;/li>
&lt;li>JobGraph：JobGraph是提交给 JobManager 的数据结构。StreamGraph经过优化后生成了 JobGraph，主要的优化为，将多个符合条件的节点链接在一起作为一个节点，这样可以减少数据交换所需要的序列化、反序列化以及传输消耗。这个链接的过程叫做算子链，会在下一节简单介绍。&lt;/li>
&lt;li>ExecutionGraph：JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。&lt;/li>
&lt;li>物理执行图：JobManager 根据 ExecutionGraph 对作业进行调度后，在各个TaskManager 上部署任务形成的图，物理执行并不是一个具体的数据结构。&lt;/li>
&lt;/ul>
&lt;p>可以看到，Flink在数据流图上可谓煞费苦心，仅各类图就有四种之多。对于新人来说，可以不用太关心这些非常细节的底层实现，只需要了解以下几个核心概念：&lt;/p>
&lt;ul>
&lt;li>Flink采用主从架构，JobManager起着管理协调作用，TaskManager负责物理执行，在执行过程中会发生一些数据交换、生命周期管理等事情。&lt;/li>
&lt;li>用户调用Flink API，构造逻辑视图，Flink会对逻辑视图优化，并转化为物理执行图，最后被执行的是物理执行图。&lt;/li>
&lt;/ul>
&lt;h3 id="23-任务算子子任务与算子链">2.3 任务、算子子任务与算子链&lt;/h3>
&lt;p>在分布式运行的过程中，Flink将一些算子子任务（Subtask）链接在一起，组成算子链（Operator Chain），链接后将以任务(Task)的形式被TaskManager调度执行。使用算子链是一个非常有效的优化，它可以有效降低算子子任务之间的传输开销。链接之后形成的Task是TaskManager中的一个线程。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-6144acbff5daf063d5da085a67447d18_1440w.jpg" alt="">&lt;/p>
&lt;p>图 7 任务、子任务与算子链&lt;/p>
&lt;p>例如，数据从Source算子前向传播到 flatMap算子，再由flatMap算子前向传播到map算子，中间没有发生跨分区的数据交换，因此，我们完全可以将Source、flatMap和map几个Operator Subtask组合在一起，形成一个Task。keyBy算子发生了数据重分布，数据会跨越分区，因此map和keyBy无法被链接到一起。同样，我们也不能把sum和Sink链接到一起。&lt;/p>
&lt;p>默认情况下，Flink会尽量将更多的Subtask链接在一起，但一个Subtask有超过一个输入或发生数据交换时，链接就无法建立。尽管将算子链接到一起会降低一些传输开销，但是也有一些情况并不需要太多链接。比如，有时候我们需要将一个非常长的算子链拆开，这样我们就可以将原来集中在一个线程中的计算拆分到多个线程中来并行计算。Flink手动配置是否对某些算子启用算子链。&lt;/p>
&lt;h3 id="24-任务槽位与计算资源">2.4 任务槽位与计算资源&lt;/h3>
&lt;h3 id="任务槽位的概念">任务槽位的概念&lt;/h3>
&lt;p>根据前文的介绍，我们已经了解到TaskManager负责具体的任务执行。TaskManager是一个Java虚拟机进程，在TaskManager中可以并行运行多个Task。在程序执行之前，经过优化，部分Subtask被链接在一起，组成一个Task。每个Task是一个线程，需要TaskManager为其分配相应的资源，TaskManager使用任务槽位（Task Slot）给任务分配资源，简称槽位（Slot）。&lt;/p>
&lt;p>在解释任务槽位的概念前，我们先回顾一下进程与线程的概念。在操作系统层面，进程（Process）是进行资源分配和调度的一个独立单位，线程（Thread）是是CPU调度的基本单位。比如，我们常用的Office Word软件，在启动后就占用操作系统的一个进程。Windows上可以使用任务管理器来查看当前活跃进程，Linux上可以使用top命令来查看。线程是进程的一个子集，一个线程一般专注于处理一些特定任务，不独立拥有系统资源，只拥有一些运行中必要的资源，如程序计数器。一个进程至少有一个线程，也可以有多个线程。多线程场景下，每个线程都处理一小个任务，多个线程以高并发的方式同时处理多个小任务，可以提高处理能力。&lt;/p>
&lt;p>回到Flink的槽位分配机制上，一个TaskManager是一个进程，TaskManager可以管理一至多个Task，每个Task是一个线程，占用一个槽位。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-0b7a01d48b30a4d6cdab65f23488933f_1440w.jpg" alt="">&lt;/p>
&lt;p>图 8 Task Slot与Task Manager&lt;/p>
&lt;p>假设我们给WordCount程序分配两个TaskManager，每个TaskManager又分配3个槽位，所以总共是6个槽位。结合图 7中对这个作业的并行度设置，整个作业被划分为5个Task，使用5个线程，这5个线程可以按照图 8所示的方式分配到6个槽位中。&lt;/p>
&lt;p>每个槽位的资源是整个TaskManager资源的子集，比如这里的TaskManager下有3个槽位，每个槽位占用TaskManager所管理的1/3的内存，在第一个槽位内运行的任务不会与在第二个槽位内运行的任务互相争抢内存资源。注意，在分配资源时，Flink并没有将CPU资源明确分配给各个槽位。&lt;/p>
&lt;p>Flink允许用户设置TaskManager中槽位的数目，这样用户就可以确定以怎样的粒度将任务做相互隔离。如果每个TaskManager只包含一个槽位，那么运行在该槽位内的任务将独享JVM。如果TaskManager包含多个槽位，那么多个槽位内的任务可以共享JVM资源，比如共享TCP连接、心跳信息、部分数据结构等。如无特殊需要，可以将槽位数目设置为TaskManager下可用的CPU核心数，那么平均下来，每个槽位都能获得至少一个CPU核心。&lt;/p>
&lt;h3 id="槽位共享">槽位共享&lt;/h3>
&lt;p>图 8中展示了任务的一种资源分配方式，默认情况下， Flink还提供了一种槽位共享（Slot Sharing）的优化机制，进一步优化数据传输开销，充分利用计算资源。将图 8中的任务做槽位共享优化后，结果如图 9所示。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-c9f3ee4b18d9600b17359bad8731428e_1440w.jpg" alt="">&lt;/p>
&lt;p>图 9 槽位共享示意图&lt;/p>
&lt;p>开启槽位共享后，Flink允许将独占一个槽位的任务与同一个作业中的其他任务共享槽位。于是可以将一个作业从开头到结尾的所有Subtask都放置在一个槽位中，如图 9中最左侧的数据流，这样槽位内的数据交换成本更低。而且，对于一个数据流图来说，Source、map等算子的计算量相对不大，window算子的计算量比较大，计算量较大的Subtask与计算量较小的Subtask相互互补，可以腾出更多的槽位，分配给更多Task，这样可以更好地利用资源。而不开启槽位共享，计算量小的Source、map算子子任务独占了槽位，造成一定的资源浪费。&lt;/p>
&lt;h3 id="并行度与槽位数目">并行度与槽位数目&lt;/h3>
&lt;p>图 3中提到了并行度，在WordCount的例子中，除去Sink算子的并行度为1外，其他算子的并行度均为2，也就是说在并行度为2的情况下，每个算子只能拆分为2个Subtask。图 8中的方式共占用5个槽位，支持槽位共享后，图 9只占用2个槽位，这里故意将剩下的几个槽位置空，只是为了演示需要，如果这个作业的数据量非常大，占用的数据分区很多，其实完全可以通过增加并行度，将这些槽位填充，为更多的并行任务提供资源。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-067c1f2c3f4ba050f727e6aaf5543329_1440w.jpg" alt="">&lt;/p>
&lt;p>图 10 并行度与槽位数目&lt;/p>
&lt;p>为了充分利用空槽位，占满图 9中多余的4个槽位，我们可以把除Sink外的其他算子的并行度都设置为6。图 2‑10展示了将并行度增加后，资源分配情况。&lt;/p>
&lt;p>并行度和槽位数目的概念可能容易让人混淆，这里再次阐明一下。用户使用Flink提供的API算子可以构建一个逻辑视图，需要将任务并行才能被物理执行。整个作业将被切分为多个实例，每个实例处理整个作业输入数据的一部分。如果输入数据过大，增大并行度可以增加更多的实例，加快数据处理速度。可见，并行度是Flink对任务并行切分的一种描述。槽位数目是在资源设置时，对单个TaskManager的资源切分粒度。并行度、槽位数目和TaskManager数可大致按照公式 1来计算。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-451fd1da5531072d356b1ec1ba93c370_1440w.png" alt="">&lt;/p>
&lt;p>公式 1 并行度、TaskManager数与Task Slot数关系&lt;/p>
&lt;p>其中，ceil为上限函数，表示对除法结果向上取整。关于并行度、槽位数目等配置，将在后续文章中详细说明。&lt;/p>
&lt;h3 id="25-flink-api结构">2.5 Flink API结构&lt;/h3>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-6118b07dff5f00d58f06db2b82207ccb_1440w.jpg" alt="">&lt;/p>
&lt;p>图 11 Flink API结构&lt;/p>
&lt;p>我们之前讨论的WordCount例子中，一直使用的是Flink提供的DataStream API，即在数据流上的操作。除了DataStream API，Flink给编程人员不同层次API，主要有三层：&lt;/p>
&lt;ol>
&lt;li>Flink最底层提供的是有状态的流式计算引擎，流（Stream）、状态（State）和时间（Time）等流式计算概念都在这一层得到了实现。&lt;/li>
&lt;li>一般情况下，应用程序不会使用上述底层接口，而是使用Flink提供的核心API：针对有界和无界数据流的DataStream API和针对有界数据集的DataSet API。用户可以使用这两个API进行常用的数据处理：转换（Transformation）、连接（Join）、聚合（Aggregation）、窗口（Window）以及对状态（State）的操作。这一层有点像Spark提供的RDD级别的接口。&lt;/li>
&lt;li>Table API和SQL是更高级别的抽象。在这一层，数据被转换成了关系型数据库式的表格，每个表格拥有一个表模式（Schema），用户可以像操作表格那样操作流式数据，例如可以使用针对结构化数据的select、join、group-by等操作。如果用户熟悉SQL语句，那么可以很快上手Flink的Table API和SQL。很多公司的数据流非常依赖SQL，Flink SQL降低了从其他框架迁移至Flink的成本。&lt;/li>
&lt;/ol>
&lt;p>我们将在后续文章中介绍DataStream API、Table API和SQL。&lt;/p>
&lt;h3 id="26-flink组件栈">2.6 Flink组件栈&lt;/h3>
&lt;p>了解Flink的主从架构以及API结构后，我们可以将Flink的核心组件分层来剖析。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-31dac21c9812c8b19f5a432929521ce3_1440w.jpg" alt="">&lt;/p>
&lt;p>图 12 Flink组件栈&lt;/p>
&lt;h3 id="部署层">部署层&lt;/h3>
&lt;p>大数据引擎首先需要部署在物理机或虚拟机上。Flink支持多种部署方式，可以部署在单机、集群，以及云上。&lt;/p>
&lt;h3 id="运行时层">运行时层&lt;/h3>
&lt;p>运行时（Runtime）层为Flink各类计算提供了实现。这一层做了前面章节中提到的将数据流图转化为物理执行图、资源分配以及分布式调度与执行等大部分工作。&lt;/p>
&lt;h3 id="api层">API层&lt;/h3>
&lt;p>API层主要实现了面向数据流的流处理DataStream API和面向数据集的批处理DataSet API。在这两个API之上，Flink还提供了更丰富的工具：&lt;/p>
&lt;ul>
&lt;li>面向数据流处理的：CEP（Complex Event Process，复杂事件处理）、基于类SQL的Table API和SQL&lt;/li>
&lt;li>面向数据集批处理的：FlinkML（机器学习计算库）、Gelly（图计算库）&lt;/li>
&lt;/ul>
&lt;h2 id="3-flink时间处理机制">3 Flink时间处理机制&lt;/h2>
&lt;h3 id="31-时间窗口">3.1 时间窗口&lt;/h3>
&lt;p>在批处理场景下，数据已经是按照某个时间维度分批次地存储了。一些公司经常将用户行为日志按天存储在一个文件目录下，另外一些开放数据集都会说明数据采集的时间始末。因此，对于批处理任务，处理一个数据集，其实就是对该数据集对应的时间窗口内的数据进行处理。在流计算场景下，数据以源源不断的流的形式存在，数据一直在产生，没有始末。我们要对数据进行处理时，往往需要明确一个时间窗口，比如，数据在“每秒”、“每小时”、“每天”的维度下的一些特性。一般有如下几种定义时间窗口的方式。&lt;/p>
&lt;h3 id="滚动窗口">滚动窗口&lt;/h3>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-dbfc6013f3dadf1bae2c6802ae35ff97_1440w.jpg" alt="">&lt;/p>
&lt;p>图 13 固定数据数目的滚动窗口&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-36611d45c569176cc03ab990bf7acfc8_1440w.jpg" alt="">&lt;/p>
&lt;p>图 14 固定时间间隔的滚动窗口&lt;/p>
&lt;p>滚动窗口（Tumbling Window）模式下窗口之间互不重叠，且窗口长度是固定的，长度可以是数据的条数，也可以是时间间隔。图 13是固定长度为4的滚动窗口，图 14是固定长度为10分钟的滚动窗口。定长滚动窗口是经常用到的一种窗口模式。在本文最开始的WordCount例子中，我们使用的是定长为5秒的滚动窗口。&lt;/p>
&lt;h3 id="滑动窗口">滑动窗口&lt;/h3>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-6666b3b8ccf8e39d18d558770f5a3d86_1440w.jpg" alt="">&lt;/p>
&lt;p>图 15 滑动窗口&lt;/p>
&lt;p>滑动窗口（Sliding Window）也是一种窗口长度定长的模式。与滚动窗口不同，滑动窗口模式下窗口和窗口之间有滑动间隔（Slide）。再以WordCount为例，我们要统计10分钟内的词频，并且每隔1分钟统计一次，就需要使用滑动窗口。&lt;/p>
&lt;h3 id="会话窗口">会话窗口&lt;/h3>
&lt;p>会话（Session）是一个用户交互概念，常常出现在互联网应用上，一般指用户在某APP或某网站上短期内产生的一系列行为。比如，用户在手机淘宝上短时间有大量的搜索和点击的行为，这系列行为事件组成了一个Session，接着可能因为一些其他因素，用户暂停了与APP的交互，过一会用户又返回APP，经过一系列搜索、点击、与客服沟通，最终下单。Session窗口的长度并不固定，因此不能用上面两种形式的窗口来建模。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-b34efc018a871410e8747363c53754be_1440w.jpg" alt="">&lt;/p>
&lt;p>图 16 会话窗口&lt;/p>
&lt;p>Session没有固定长度，那如何将数据划分到不同的窗口呢？Flink提供了Session Gap的概念。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-3c9b7e4acb22d6ba56009888d74fb9ed_1440w.jpg" alt="">&lt;/p>
&lt;p>图 17 session gap示意图&lt;/p>
&lt;p>我们继续以用户在手机淘宝上的行为为例，现在有3个用户，每个用户产生了不同的行为，果两个行为数据的时间戳小于session gap，则被划归到同一个窗口中，图 17中user2的window4，如两个行为数据的时间戳大于了session gap，则被划归到两个不同的窗口中，user2的window1和window2之间的时间间隔大于最小的session gap，数据被划归为了两个窗口。&lt;/p>
&lt;p>我们将在后续文章详细介绍以上几种窗口的使用方法。&lt;/p>
&lt;h3 id="32-flink三种时间语义">3.2 Flink三种时间语义&lt;/h3>
&lt;p>如果我们要定义基于时间的窗口，那么首先要定义时间。在程序中，时间一般基于Unix时间戳，即以1970-01-01-00:00:00.000为起始点。时间戳毫秒精度是时间距离该起点的毫秒总数，时间戳微秒精度是事件距离该起点的微秒总数。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-c9384bef28395bd0385aeaca71ab5717_1440w.jpg" alt="">&lt;/p>
&lt;p>图 18 三种时间语义&lt;/p>
&lt;p>之前文章中我们提到了流处理的时间语义问题，在Flink中一般有三种时间概念，如图 18所示。&lt;/p>
&lt;ul>
&lt;li>事件时间（Event Time）是事件实际发生的时间，通常是事件发生时嵌入到事件上的时间，比如某个传感器在生成数据时，会将时间戳打入这个数据上。&lt;/li>
&lt;li>接收时间（Ingestion Time）是事件进入Flink的时间，确切的说，是该事件进入Source算子时，Source算子的当前时间。&lt;/li>
&lt;li>处理时间（Processing Time）是各个时间算子处理该事件的当前时间。一般情况下，处理时间会比摄入时间更晚一些。&lt;/li>
&lt;/ul>
&lt;p>Processing Time是最简单的时间概念，只需要算子获取当前运行机器的系统时间，不需要考虑其他任何因素，因此使用Processing Time作为时间，可以获得最好的性能和最低的延迟。但Processing Time并不能代表事件实际发生的时间，从事件实际发生到算子处理的过程有大量的不确定性，以Processing Time来计算，很可能导致事件的处理是乱序的，产生不可复现的结果。&lt;/p>
&lt;p>Event Time可以保证事件顺序的可靠性，因此可以得到一致的、可复现的结果。Event Time虽然准确，但也有其弊端：我们无法预知某个时间下，是否所有数据均已到达，因此需要使用水位线机制处理延迟数据。&lt;/p>
&lt;h3 id="33-水位线">3.3 水位线&lt;/h3>
&lt;p>之前文章已经提到，水位线（Watermark）机制假设在某个时间点上，不会有比这个时间点更晚的上报数据。Watermark常被作为一个时间窗口的结束时间。&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-446814cd3f7eef0e87447156e979cb93_1440w.jpg" alt="">&lt;/p>
&lt;p>图 19 一个带有Watermark的数据流&lt;/p>
&lt;p>Flink中的Watermark是被系统插入到数据流的特殊数据。Watermark的时间戳单调递增，且与事件时间戳相关。如上图的数据流所示，方块是事件，三角形是该事件对应的时间戳，圆圈为Watermark。当Flink接受到时间戳值为5的Watermark时，系统假设时间戳小于5的事件均已到达，后续到达的小于5的事件均为延迟数据。Flink处理到最新的Watermark，会开启这个时间窗口的计算，把这个Watermark之前的数据纳入进此次计算，延迟数据则不能被纳入进来，因此使用Watermark会导致微小的误差。&lt;/p>
&lt;h3 id="生成watermark">生成Watermark&lt;/h3>
&lt;p>流数据中的事件时间戳与Watermark高度相关，事件时间戳的抽取和Watermark的生成也基本是同时进行的，抽取的过程会遇到下面两种情况：&lt;/p>
&lt;ol>
&lt;li>数据流中已经包含了事件时间戳和Watermark。&lt;/li>
&lt;li>使用抽取算子生成事件时间戳和Watermark，这也是实际应用中更为常见的场景。因为后续的计算都依赖时间，Watermark抽取算子最好在数据接入后马上调用。具体而言，Watermark抽取算子包含两个函数：第一个函数从数据流的事件中抽取时间戳，并将时间戳赋值到事件的元数据上，第二个函数生成Watermark。&lt;/li>
&lt;/ol>
&lt;p>Flink有两种方式来生成Watermark：&lt;/p>
&lt;ol>
&lt;li>周期性（Periodic）生成Watermark：Flink每隔一定时间间隔，定期调用Watermark生成函数。这种方式下，Watermark的生成与时间有周期性的关系。&lt;/li>
&lt;li>断点式（Punctuated）生成Watermark：数据流中某些带有特殊标记的数据自带了Watermark信息，Flink监控数据流中的每个事件，当接收到带有特殊标记数据时，会触发Watermark的生成。这种方式下，Watermark的生成与时间无关，与何时接收到特殊标记数据有关。&lt;/li>
&lt;/ol>
&lt;p>无论是以上那种方式，Flink都会生成Watermark并插入到数据流中。一旦时间戳和Watermark生成后，后续的算子将以Event Time的时间语义来处理这个数据流。Flink把时间处理部分的代码都做了封装，会在内部处理各类时间问题，用户不需要担心延迟数据等任何时间相关问题。用户只需要在数据接入的一开始生成时间戳和Watermark，Flink会负责剩下的事情。&lt;/p>
&lt;h3 id="延迟数据">延迟数据&lt;/h3>
&lt;p>Flink有一些机制专门收集和处理延迟数据。迟到事件在Watermark之后到达，一般处理的方式有三种：&lt;/p>
&lt;ol>
&lt;li>将迟到事件作为错误事件直接丢弃&lt;/li>
&lt;li>将迟到事件收集起来另外再处理&lt;/li>
&lt;li>重新触发计算&lt;/li>
&lt;/ol>
&lt;p>对于第二种方式，用户可以使用Flink提供的“Side Output”机制，将迟到事件放入一个单独的数据流，以便再对其单独处理。&lt;/p>
&lt;p>对于第三种方式，用户可以使用Flink提供的“Allowed Lateness”机制，设置一个允许的最大迟到时长，原定的时间窗口关闭后，Flink仍然会保存该窗口的状态，直至超过迟到时长，迟到的事件加上原来的事件一起重新被计算。&lt;/p>
&lt;p>我们将在后续文章中详细介绍Event Time的使用、Watermark生成、延迟数据处理等技术细节。&lt;/p>
&lt;h2 id="4-flink的状态和检查点">4 Flink的状态和检查点&lt;/h2>
&lt;h3 id="41-状态">4.1 状态&lt;/h3>
&lt;p>在之前的文章中我们已经提到了状态的概念：流式大数据处理引擎会根据流入数据持续更新状态数据。状态可以是当前所处理事件的位置偏移（Offset）、一个时间窗口内的某种输入数据、或与具体作业有关的自定义变量。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-24d6d4959a1643bb586d10cd738effb5_1440w.jpg" alt="">&lt;/p>
&lt;p>图 20 数据流与状态示意图&lt;/p>
&lt;p>对于WordCount的例子来说，已经处理了一个”Hello”单词，并且正在处理一个”Hello”，对于Source算子来说，当前数据的位置偏移为3，所有已处理的数据中，单词”Hello”的出现次数为2。这个作业的状态包括当前处理的位置偏移、已处理过的单词出现次数等变量信息。&lt;/p>
&lt;h3 id="42-检查点">4.2 检查点&lt;/h3>
&lt;h3 id="一致性检查点">一致性检查点&lt;/h3>
&lt;p>在一个有状态的流处理作业中，为保证高吞吐和低延迟，Flink的每个Task需要高效读写状态数据，Task会在本地的TaskManager中存储状态数据。然而，由于大数据系统一般运行在多台机器上，可能会遇到进程被杀、机器宕机、网络抖动等问题，一旦出现宕机等问题，该机器上的状态以及相应的计算会丢失，因此需要一种恢复机制来应对这些潜在问题。&lt;/p>
&lt;p>Flink使用一致性检查点（Consistent Checkpoint）技术来做故障恢复。检查点机制一般是定期将状态数据生成快照（Snapshot），持久化存储起来，一旦发生意外，Flink主动重启应用，并从最近的快照中恢复，再继续处理新流入数据。一致性检查点技术可以将分布在多台节点上的所有状态都记录下来，并提供了Exactly-Once的投递保障，其背后是使用了Chandy-Lamport算法，将本地的状态数据保存到一个存储空间上，故障发生后及时恢复最近的快照数据。我们将在后续文章中详细介绍一致性检查点的算法原理。&lt;/p>
&lt;h3 id="状态后端">状态后端&lt;/h3>
&lt;p>Task在本地内存中保存一份状态数据，但在分布式系统中，某个Task在任意时间点都可能发生故障，因此Task上的本地状态数据可以被认为是脆弱的。Flink定期将本地的状态数据持久化保存到一个存储空间上。用户可以选择以怎样的方式来保存这些状态数据，这种机制被称为状态后端（State Backend）。Flink提供了三种状态后端：内存、文件系统和RocksDB。&lt;/p>
&lt;p>内存肯定是读写性能最优的方式，单个节点的内存有限，因此这种状态后端会对状态数据的大小有限制。相比内存，本地磁盘的速度更慢，其所能承担的数据量更大，RocksDB 就是一种基于本地磁盘的状态后端。此外，Flink还允许将数据存储到分布式文件系统，如Hadoop的HDFS和AWS的S3上，分布式文件系统的数据存储能力非常大，足以应付海量数据的存储需求。我们将在后续文章中详细介绍三种状态后端的使用方法。&lt;/p>
&lt;h3 id="savepoint">Savepoint&lt;/h3>
&lt;p>在容错上，除了Checkpoint，Flink还提供了Savepoint机制。从名称和实现上，这两个机制都极其相似，甚至Savepoint会使用Checkpoint的数据，但实际上，这两个机制的定位不同。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-a7083a338d25958556531caf71ffccc5_1440w.jpg" alt="">&lt;/p>
&lt;p>图 21 Checkpoint和Savepoint&lt;/p>
&lt;p>Checkpoint是Flink定期触发并自动执行的故障恢复机制，以应对各种意外情况，其设计初衷主要是针对容错和故障恢复。Savepoint会使用Checkpoint生成的快照数据，但与Checkpoint不同点在于，Savepoint需要编程人员手动介入，用来恢复暂停作业。相比而言，Checkpoint是自动执行，Savepoint是手动管理。&lt;/p>
&lt;p>当我们想要手动处理之前已经处理过的数据，就可以使用Savepoint，因此Savepoint经常被用来调试程序：&lt;/p>
&lt;ul>
&lt;li>我们可以给同一份作业设置不同的并行度，来找到最佳的并行度设置&lt;/li>
&lt;li>我们想测试一个新功能或修复一个已知的bug，并用新的程序逻辑处理原来的数据&lt;/li>
&lt;li>进行一些A/B实验，使用相同的数据源测试程序的不同版本&lt;/li>
&lt;li>因为状态可以被持久化存储到分布式文件系统上，我们甚至可以将同样一份应用程序从一个集群迁移到另一个集群，只需保证不同的集群都可以访问这个文件系统&lt;/li>
&lt;/ul>
&lt;p>Checkpoint 和 Savepoint 是Flink提供的两个相似的功能，它们满足了不同的需求，以确保一致性、容错性，满足了作业升级、BUG 修复、迁移、A/B测试等不同需求。&lt;/p></description></item><item><title>Flink 消费消息的流程</title><link>https://justice.bj.cn/post/30.architech/flink/flink-%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E7%9A%84%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink-%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E7%9A%84%E6%B5%81%E7%A8%8B/</guid><description>&lt;h1 id="flink-消费消息的流程">Flink 消费消息的流程&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>准备一个ResultPartition；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通知JobMaster；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>JobMaster通知下游节点；如果下游节点尚未部署，则部署之；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>下游节点向上游请求数据&lt;/p>
&lt;/li>
&lt;li>
&lt;p>开始传输数据&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2022/01/03-21-34-50-2022-01-03-21-34-42-image.png" alt="">&lt;/p>
&lt;h3 id="数据跨-task-传输">数据跨 task 传输&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>数据在本operator处理完后，交给RecordWriter。每条记录都要选择一个下游节点，所以要经过ChannelSelector。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个channel都有一个serializer（我认为这应该是为了避免多线程写的麻烦），把这条Record序列化为ByteBuffer&lt;/p>
&lt;/li>
&lt;li>
&lt;p>接下来数据被写入ResultPartition下的各个subPartition里，此时该数据已经存入DirectBuffer（MemorySegment）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>单独的线程控制数据的flush速度，一旦触发flush，则通过Netty的nio通道向对端写入&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对端的netty client接收到数据，decode出来，把数据拷贝到buffer里，然后通知InputChannel&lt;/p>
&lt;/li>
&lt;li>
&lt;p>有可用的数据时，下游算子从阻塞醒来，从InputChannel取出buffer，再解序列化成record，交给算子执行用户代码&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2022/01/03-21-39-06-2022-01-03-21-39-02-image.png" alt="">&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://blog.csdn.net/jsjsjs1789/article/details/106526982">一文搞定 Flink 消费消息的全流程_shengjk1的博客-CSDN博客_flink阻塞消费&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Flink-基本</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E5%9F%BA%E7%A1%80/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E5%9F%BA%E7%A1%80/</guid><description>&lt;h1 id="flink-基本">Flink-基本&lt;/h1>
&lt;h2 id="数据流">数据流&lt;/h2>
&lt;p>数据流就是一个无界（unbounded）的事件序列。事件（Event）可以是监控报警数据、传感器感知数据、信用卡交易、用户在APP上的行为&amp;hellip;随着数据量的爆炸式增长，单台机器无法处理庞大的数据流，一般需要多台机器并行地处理，因此需要一种并行的流式计算引擎来对大数据场景下的数据流做处理。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-44a4023fff6f8d0944cece45b24a25ec_1440w.jpg" alt="">&lt;/p>
&lt;p>有界和无界数据 来源：Flink官网&lt;/p>
&lt;h2 id="流式计算的衡量指标延迟和吞吐">流式计算的衡量指标：延迟和吞吐&lt;/h2>
&lt;p>在批量计算场景，主要通过一次计算的总时间来评价性能。在流式计算场景，数据源源不断地流入系统，计算引擎对每个数据处理地越快越好，计算引擎能处理的数据量越大越好。例如处理实时的Twitter文本数据案例，如果系统只能处理一个人发的Tweet或处理时间长达一天，那说明这个系统非常不靠谱。为了衡量流式计算的“快”和“量”两方面的性能，一般用延迟（Latency）和吞吐（Throughput）这两个指标。&lt;/p>
&lt;p>&lt;strong>延迟 Latency&lt;/strong>&lt;/p>
&lt;p>延迟表示一个事件被系统处理的总时间，一般以毫秒为单位。根据业务应用不同，我们一般关心平均延迟和分位延迟（Percentile Latency）。假设一个煎饼摊就是一个流式计算系统，每个顾客来购买煎饼是它所需要处理的事件，从顾客到达到顾客拿到购买的煎饼并付费离开，就是这个顾客的延迟。如果正赶上了早餐高峰期，顾客极有可能排队，这个排队时间也要算在延迟时间中。例如，99分位延迟表示系统处理前99%顾客所需的最长时间，也就是对所有顾客延迟排名后，第99%的那个时间。一般商业系统更关注分位延迟，因为分位延迟比平均延迟能反应出这个系统的一些潜在问题。还是以煎饼摊为例，一般煎饼中都有薄脆，薄脆是单独制作的，如果薄脆制作的速度跟不上煎饼制作的速度，那在高峰期，将拖慢整个过程的延迟，部分用户会因为等待时间过久而放弃排队。&lt;/p>
&lt;p>延迟对于很多流式计算非常重要，比如欺诈检测、告警监控等等。像Flink这样的流式计算引擎可以将延迟降到毫秒级别，如果用mini-batch的方法处理同样的问题，很可能是分钟级到小时级的延迟，因为计算引擎必须等待一批数据达到才开始进行计算。&lt;/p>
&lt;p>&lt;strong>吞吐 Throughput&lt;/strong>&lt;/p>
&lt;p>吞吐表示一个系统最大能处理多少事件，一般以单位时间处理的事件数量为单位。需要注意的是，吞吐除了与引擎自身设计有关，也与数据源发送过来的事件数据量有关，有可能计算引擎的最大吞吐量远大于数据源的数据量。比如，煎饼摊可能在早七点到九点的需求最高，很可能出现大量排队的情况，但另外的时间几乎不需要排队等待。假设一天能提供1000个煎饼，服务10个小时，那它的平均吞吐量为100个/小时；仅早上2小时的高峰期就提供了600个煎饼，它的峰值吞吐量是300个/小时。比起平均吞吐量，峰值吞吐量更影响用户体验，如果峰值吞吐量低，也会导致用户等待时间过久而放弃排队。早高峰时，一般用户都需要排队等待，排队的过程被称作缓存（Buffering）。如果仍然有大量事件进入缓存，很可能超出系统的极限，就会出现反压问题（Backpressure），这时候就需要一些优雅的策略来处理类似问题，否则会造成系统崩溃，用户体验极差。&lt;/p>
&lt;p>&lt;strong>延迟与吞吐&lt;/strong>&lt;/p>
&lt;p>延迟与吞吐其实并不是相互孤立的，他们相互影响。如果延迟高，那么很可能造成吞吐低，系统处理不了太多事件。为了优化这两个指标，一种办法是提高煎饼师傅的制作速度，当用户量大到超过单个煎饼师傅的瓶颈时，接着就需要考虑再增加一个煎饼师傅。这也是当前大数据系统都在采用的并行(parallelism)策略，如果一个机器做不了或做得不够快，那就用更多的机器一起来做。&lt;/p>
&lt;h2 id="数据流图">数据流图&lt;/h2>
&lt;p>数据流图描述了数据如何在不同的操作间流动。数据流图一般是一个有向图，图中的节点是一个算子（Operator），表示某种运算，边表示数据间的相互依赖关系或数据的流动方向。算子从输入读取数据，进行一些计算，接着将计算结果发送到下一个算子。Source是所有计算的开始，Sink是所有计算的终点。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-e9d18ef9720eb373896825ccfd66635c_1440w.png" alt="">&lt;/p>
&lt;p>一个解析Twitter标签的数据流图逻辑视角 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>上图从逻辑角度描述数据的流动，对于一个Twitter数据流，接收输入源后需要将Twitter文本中的#井号标签去除，提取关键词，再对关键词做词频统计。这样一个图并没有考虑大数据情况下跨计算节点计算的问题，它只是一种处理问题的逻辑思路，因此称之为逻辑视角。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-aa6d4062c5fbe69b8f118823a8a72c76_1440w.jpg" alt="">&lt;/p>
&lt;p>数据流图的物理视角 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>实现一个能够处理大数据的分布式系统，需要考虑在多个节点上并行计算。上图将逻辑视角细化为物理视角。Source发出的数据会兵分两路，被分配到两个节点上，在各自节点上进行&amp;quot;Extract hashtags&amp;quot;和&amp;quot;Count&amp;quot;运算。每个&amp;quot;Extract hashtags&amp;quot;和&amp;quot;Count&amp;quot;运算只处理一部分数据。最终数据要聚合到Sink上。&lt;/p>
&lt;h2 id="数据交换策略">数据交换策略&lt;/h2>
&lt;p>在物理视角中，我们看到数据经历了跨节点的数据交换。比如，我们要统计&amp;quot;Flink&amp;quot;这个单词出现的次数，各个节点可能都会解析出&amp;quot;Flink&amp;quot;这个单词，但是我们最终要的是所有节点上的&amp;quot;Flink&amp;quot;单词的总和。因此从&amp;quot;Extract hashtags&amp;quot;到&amp;quot;Count&amp;quot;，发生了数据交换，所有的&amp;quot;Flink&amp;quot;被发送到第一个节点上，才能做词频求和统计。在这个任务中，同一个词需要交换到同一个节点上，就是一种数据交换。&lt;/p>
&lt;p>在流式计算场景，某个节点及节点上的数据通常被称为分区（partition）。&lt;/p>
&lt;p>数据交换一般有以下几种策略。&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-f4e055bfad75c037ea5c07acc26481bd_1440w.jpg" alt="">&lt;/p>
&lt;p>数据交换策略 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;ul>
&lt;li>Forward：数据在一个分区上前向传播，无需跨节点通信。&lt;/li>
&lt;li>Broadcast：将数据发送到所有分区上，需要大量的跨节点通信开销。&lt;/li>
&lt;li>Key-Based：按照某个key将数据做分片，某个key的所有数据都会分配到一个分区上。刚才词频统计的例子中，就是以单词为key进行的分片处理。&lt;/li>
&lt;li>Random：将数据做随机均匀分片，以避某个分区上的数据过大。&lt;/li>
&lt;/ul>
&lt;h2 id="状态-state">状态 State&lt;/h2>
&lt;p>状态是流式计算特有的概念。比如刚才计算词频的例子，要统计实时数据流一分钟内的单词词频，一方面要处理每一瞬间新流入的数据，另一方面要保存之前一分钟内已经进入系统的单词词频。再举一个告警的例子，当系统在监听到“高温”事件后10分钟内又监听到“冒烟”的事件，系统必须及时报警，系统必须把“高温”的事件作为状态记录下来，并判断这个状态下十分钟内是否有“冒烟”事件。&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-48e2ac54d3ca4a9040e4b37a71f31d20_1440w.jpg" alt="">&lt;/p>
&lt;p>无状态算子 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>上图中的圆圈就是一个无状态算子，它将每个输入方框都转化成黑色。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-1f07121b4f763eca8a89057add6ac6a2_1440w.jpg" alt="">&lt;/p>
&lt;p>有状态算子 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>上图的圆圈是一个有状态算子，计算的是一个数据流中的最小值。它需要保存一个当前的最小值作为状态，并根据新事件来不断更新这个状态。&lt;/p>
&lt;p>流式计算要处理无界的数据流，要注意如果将这些状态不断增长，最后造成数据爆炸，因此会使用一些机制来限制状态的数据总量。&lt;/p>
&lt;p>综上，实现一个流式计算系统非常复杂，需要考虑几个因素：&lt;/p>
&lt;ol>
&lt;li>系统必须能有效管理状态。因为一般的计算既依赖当前事件，也依赖之前事件产生的状态。&lt;/li>
&lt;li>设计能够管理状态的并行算法极具挑战。一般将数据按照某个key进行切片，将一组大数据切分成小的分区，每个分区单独维护状态数据。&lt;/li>
&lt;li>当系统出现错误而挂掉重启时，必须能够保证之前保存的状态数据也能恢复，否则重启后很多计算结果有可能是错误的。一般使用checkpoint来解决这个问题。&lt;/li>
&lt;/ol>
&lt;p>可见，流式计算系统比批量计算系统更难实现。&lt;/p>
&lt;h2 id="窗口">窗口&lt;/h2>
&lt;p>我们一般要对流式数据以窗口的形式做聚合统计分析。一般有如下几种定义窗口的方式。&lt;/p>
&lt;p>&lt;strong>Tumbling&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://pic4.zhimg.com/80/v2-dbfc6013f3dadf1bae2c6802ae35ff97_1440w.jpg" alt="">&lt;/p>
&lt;p>Count-Based Tumbling Window 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-36611d45c569176cc03ab990bf7acfc8_1440w.jpg" alt="">&lt;/p>
&lt;p>Time-based Tumbing Window 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>Tumbling窗口互不重叠且一般是定长的，可以是固定事件数目，也可以是固定时间间隔。&lt;/p>
&lt;p>&lt;strong>Sliding&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-6666b3b8ccf8e39d18d558770f5a3d86_1440w.jpg" alt="">&lt;/p>
&lt;p>Sliding Window 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>滑动窗口的窗口与窗口之间有滑动间隔（Slide）。&lt;/p>
&lt;p>&lt;strong>Session&lt;/strong>&lt;/p>
&lt;p>Session是一个用户与互联网应用交互的概念，一般指用户在APP或网站上的一系列行为。比如，用户在淘宝上短时间有大量的搜索和点击的行为，这一些列行为组成了一个Session，接着可能因为一些其他因素，用户暂停了与APP的交互，过一会用户又返回了APP，经过一系列搜索、点击、与客服沟通，最终下单。Session窗口的长度并不固定，因此不能简单用上面两种形式的窗口来建模。&lt;/p>
&lt;p>&lt;img src="https://pic3.zhimg.com/80/v2-b34efc018a871410e8747363c53754be_1440w.jpg" alt="">&lt;/p>
&lt;p>Session Window 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>Session窗口没有固定长度，一般使用Session Gap将数据做分组。&lt;/p>
&lt;p>&lt;strong>并行物理视角&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://pic2.zhimg.com/80/v2-7ea5729416de90dffe8f1414e6484e49_1440w.jpg" alt="">&lt;/p>
&lt;p>Parallel Count-based Tumbling Window 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>前面讲的几种窗口都是从全局视角定义的逻辑窗口，实际上数据是在不同分区上的。例如，接受一个传感器数据流，我们可以根据传感器id作为key，将来自同一个传感器的事件都切分到一个分区上。每个分区的数据是独立的，其窗口策略也是独立的。例如上图所示的，同一颜色的事件被分到同一个分区上，组成固定长度为2的窗口。&lt;/p>
&lt;h2 id="时间语义">时间语义&lt;/h2>
&lt;p>&lt;strong>“一分钟”真的是一分钟吗？&lt;/strong>&lt;/p>
&lt;p>你可能觉得时间是最简单不过的事情，没什么可讨论的，恰恰相反，在很多应用场景，时间有着不同的意义。“一分钟”真的是一分钟吗？&lt;/p>
&lt;p>&lt;img src="https://pic1.zhimg.com/80/v2-36ba1b13b076e27eac94a37077165604_1440w.jpg" alt="">&lt;/p>
&lt;p>穿越隧道的一分钟 来源：Streaming Processing With Apache Flink&lt;/p>
&lt;p>假设你坐高铁并玩王者荣耀消磨时间，王者荣耀在最终计算MVP时，要考虑的一个因素是玩家每分钟释放技能次数。在一波团战中，你疯狂抢了三个人头，正当你觉得稳拿MVP时，高铁穿越进了隧道，手机丢失信号，你掉线了！好在高铁在隧道里只停留了几十秒，APP缓存了你掉线时的数据，并在信号恢复后将缓存数据传回了服务器。在这种情形下，时间比想象中更复杂，有一个时间记录事件实际发生的时间（Event Time），还有一个时间是事件上传到服务器后，服务器处理时间（Processing Time）。&lt;/p>
&lt;p>比如，你旁边的小伙伴跟你一起开黑，他的手机运营商更给力，进隧道后没有丢信号，如果都使用Processing Time，在丢失信号的这段时间，你的数据没有计算进去，显然对你来说是不公平的。但是当信号恢复，数据重传到服务器，再根据Event Time重新计算一次，那就非常公平了。我们可以根据Event Time复现一个事件序列的顺序，因此，使用Event Time是最准确的。&lt;/p>
&lt;p>&lt;strong>Watermark&lt;/strong>&lt;/p>
&lt;p>虽然使用Event Time更准确，但问题在于，因为各种不可控因素，事件上报会有延迟，那么最多要等待多长时间呢？从服务器的角度来看，在事件到达之前，我们也无法确定是否有事件已经延迟，如何设置Event Time时间窗口成了很大的问题。比如刚才的例子，我们要统计一分钟内的实时数据，考虑到事件的延迟，如何设置合理的等待时间，以等待一分钟内所有事件都到达服务器？也正因为这个问题，流式计算比批量计算在准确性上有差距，因为批量计算一般以更长的一段时间为一个批次，一个批次内延迟上报的数据比一个时间窗口内延迟上报的数据相对比例更少。比如某个电商平台上，去计算一件商品每分钟点击次数，使用一天的总数除以分钟数的计算方法，比使用一分钟时间窗口实时的点击次数更准确。可以看到，数据的实时性和准确性二者不可得兼，必须取一个平衡。&lt;/p>
&lt;p>Watermark是一种折中解决方案，它假设某个时间点上，不会有比这个时间点更晚的上报数据。当算子接受到一个Watermark后，它会假定后续不会再接收到这个时间窗口的内容，然后会触发对当前时间窗口的计算。比如，一种 Eager Watermark 策略的等待延迟上报的时间非常短，这样能保证低延迟，但是会导致错误率上升。在实际应用中，Watermark设计多长非常有挑战。还是以刚才手机游戏的例子，系统不知道玩家这次掉线的原因是什么，可能是在穿越隧道，也可能是坐飞机进入飞行模式，还有可能把这个游戏删了再也不玩了。&lt;/p>
&lt;p>&lt;strong>Processing Time 与 Event Time&lt;/strong>&lt;/p>
&lt;p>那既然Event Time似乎可以解决一切问题，为什么还要使用Processing Time？前面也提到了，为了处理延迟上报或顺序错乱的事件，需要使用一些机制来做等待，这样会导致延迟上升。在某些场景可能对准确性要求不高，但是要求实时性更高，Processing Time就更合适一些。&lt;/p>
&lt;h2 id="投递保障">投递保障&lt;/h2>
&lt;p>事件进入到计算引擎，如果引擎遇到故障并重启，该事件是否被成功处理了呢？一般有三种结果。&lt;/p>
&lt;p>&lt;strong>At Most Once&lt;/strong>&lt;/p>
&lt;p>每个事件最多被处理一次，也就是说，有可能某些事件没有被处理。&lt;/p>
&lt;p>&lt;strong>At Least Once&lt;/strong>&lt;/p>
&lt;p>每个事件至少被处理一次，如果系统遇到故障，系统重启后该事件会被再次处理一次。&lt;/p>
&lt;p>&lt;strong>Exactly Once&lt;/strong>&lt;/p>
&lt;p>每个事件只被处理一次，无论是否有故障重启。&amp;ldquo;Exactly Once&amp;quot;意味着事件不能有任何丢失，也必须保障状态也&amp;quot;Exactly Once&amp;rdquo;。Flink实现了&amp;quot;Exactly Once&amp;quot;语义。&lt;/p>
&lt;h2 id="小结">小结&lt;/h2>
&lt;p>本文简述了流式大数据处理引擎的一些基础概念，包括数据流、数据流图、衡量指标、状态、时间、以及投递保障，每个流式计算引擎的实现过程都要面对这些问题，Flink对这些问题做出了具体实现。&lt;/p></description></item><item><title>Flink入门</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E5%85%A5%E9%97%A8/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E5%85%A5%E9%97%A8/</guid><description>&lt;h1 id="flink入门">Flink入门&lt;/h1>
&lt;h2 id="启动本地flink实例">启动本地flink实例&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">## 下载flink&lt;/span>
$ java -version
$ wget https://www.apache.org/dyn/closer.lua/flink/flink-1.14.2/flink-1.14.2-bin-scala_2.12.tgz
$ tar -xzf flink-1.14.2-bin-scala_2.11.tgz
$ &lt;span class="nb">cd&lt;/span> flink-1.14.2-bin-scala_2.11
&lt;span class="c1">## 启动本地实例&lt;/span>
$ ./bin/start-cluster.sh
Starting cluster.
Starting standalonesession daemon on host.
Starting taskexecutor daemon on host.
&lt;span class="c1">## 提交wordcount作业&lt;/span>
$ ./bin/flink run examples/streaming/WordCount.jar
$ tail log/flink-*-taskexecutor-*.out
&lt;span class="o">(&lt;/span>nymph,1&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>in,3&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>thy,1&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>orisons,1&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>be,4&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>all,2&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>my,1&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>sins,1&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>remember,1&lt;span class="o">)&lt;/span>
&lt;span class="o">(&lt;/span>d,4&lt;span class="o">)&lt;/span>
&lt;span class="c1">## 停止flink集群&lt;/span>
$ ./bin/stop-cluster.sh
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/zh/docs/try-flink/local_installation/">https://nightlies.apache.org/flink/flink-docs-release-1.14/zh/docs/try-flink/local_installation/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Flink内存管理</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid><description>&lt;h1 id="flink内存管理">Flink内存管理&lt;/h1>
&lt;h3 id="jvm存在的问题">JVM存在的问题&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>对象存储密度低&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full GC 影响性能&lt;/p>
&lt;/li>
&lt;li>
&lt;p>OOM 影响稳定&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cache Miss&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="代码结构">代码结构：&lt;/h3>
&lt;ul>
&lt;li>基础数据结构（package:org.apache.flink.core.memory）&lt;/li>
&lt;li>内存管理机制(package:org.apache.flink.runtime.memory)&lt;/li>
&lt;/ul>
&lt;h3 id="内存布局">内存布局&lt;/h3>
&lt;p>Flink 中的 Worker 名叫 TaskManager，是用来运行用户代码的 JVM 进程。&lt;/p>
&lt;p>入口：&lt;/p>
&lt;p>&lt;code>TaskManagerRunner.main() --&amp;gt; runTaskManager() --&amp;gt; ... --&amp;gt;TaskManagerServices &lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TaskManagerServices&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">MemoryManager&lt;/span> &lt;span class="n">memoryManager&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">NetworkEnvironment&lt;/span> &lt;span class="n">networkEnvironment&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">TaskManagerServices&lt;/span> &lt;span class="nf">fromConfiguration&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">NetworkEnvironment&lt;/span> &lt;span class="n">network&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">createNetworkEnvironment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">taskManagerServicesConfiguration&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">maxJvmHeapMemory&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">final&lt;/span> &lt;span class="n">MemoryManager&lt;/span> &lt;span class="n">memoryManager&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">createMemoryManager&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">taskManagerServicesConfiguration&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">freeHeapMemoryWithDefrag&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">maxJvmHeapMemory&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-57-36-TB17qs5JpXXXXXhXpXXXXXXXXXX.png" alt="img">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Network Buffers:&lt;/strong> 一定数量的32KB大小的 buffer，主要用于数据的网络传输。在 TaskManager 启动的时候就会分配。默认数量是 2048 个，可以通过 &lt;code>taskmanager.network.numberOfBuffers&lt;/code> 来配置。&lt;/li>
&lt;li>&lt;strong>Memory Manager Pool:&lt;/strong> 这是一个由 &lt;code>MemoryManager&lt;/code> 管理的，由众多&lt;code>MemorySegment&lt;/code>组成的超大集合。Flink 中的算法（如 sort/shuffle/join）会向这个内存池申请 MemorySegment，将序列化后的数据存于其中，使用完后释放回内存池。默认情况下，池子占了堆内存的 70% 的大小。&lt;/li>
&lt;li>&lt;strong>Remaining (Free) Heap:&lt;/strong> 这部分的内存是留给用户代码以及 TaskManager 的数据结构使用的。因为这些数据结构一般都很小，所以基本上这些内存都是给用户代码使用的。从GC的角度来看，可以把这里看成的新生代，也就是说这里主要都是由用户代码生成的短期对象。&lt;/li>
&lt;/ul>
&lt;h3 id="数据结构">数据结构&lt;/h3>
&lt;p>基础的内存数据结构：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>内存管理器：MemoryManager&lt;/p>
&lt;/li>
&lt;li>
&lt;p>内存池: MemoryPool/HybridHeapMemoryPool/HybridOffHeapMemoryPool&lt;/p>
&lt;/li>
&lt;li>
&lt;p>内存片段：MemorySegment/HeapMemorySegment/HybridMemorySegment&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据视图：DataInputView/DataOutputView&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>内存管理器（MemoryManager）&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MemoryManager&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">MemoryPool&lt;/span> &lt;span class="n">memoryPool&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//内存池
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">MemoryType&lt;/span> &lt;span class="n">memoryType&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//内存类型，HEAP/OFF_HEAP
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">isPreAllocated&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//是否预先分配
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">HashMap&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Object&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Set&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MemorySegment&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">allocatedSegments&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//已分配的内存片段
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="nf">MemoryManager&lt;/span>&lt;span class="o">(...)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="k">switch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">memoryType&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">case&lt;/span> &lt;span class="n">HEAP&lt;/span>&lt;span class="o">:&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">memoryPool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HybridHeapMemoryPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">memToAllocate&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">pageSize&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">break&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">case&lt;/span> &lt;span class="n">OFF_HEAP&lt;/span>&lt;span class="o">:&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(!&lt;/span>&lt;span class="n">preAllocateMemory&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">LOG&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">warn&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;It is advisable to set &amp;#39;taskmanager.memory.preallocate&amp;#39; to true when&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="s">&amp;#34; the memory type &amp;#39;taskmanager.memory.off-heap&amp;#39; is set to true.&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">memoryPool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HybridOffHeapMemoryPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">memToAllocate&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">pageSize&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">break&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">default&lt;/span>&lt;span class="o">:&lt;/span>
&lt;span class="k">throw&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">IllegalArgumentException&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;unrecognized memory type: &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">memoryType&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">allocatePages&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">MemorySegment&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">numPages&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">release&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MemorySegment&lt;/span> &lt;span class="n">segment&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">releaseAll&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>内存池（MemoryPool）&lt;/strong>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">abstract&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MemoryPool&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">abstract&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">getNumberOfAvailableMemorySegments&lt;/span>&lt;span class="o">();&lt;/span> &lt;span class="c1">//获取有效内存片段数
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="n">MemorySegment&lt;/span> &lt;span class="nf">allocateNewSegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span> &lt;span class="c1">//分配新的内存片段
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="n">MemorySegment&lt;/span> &lt;span class="nf">requestSegmentFromPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span> &lt;span class="c1">//从内存池中获取内存片段
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">returnSegmentToPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MemorySegment&lt;/span> &lt;span class="n">segment&lt;/span>&lt;span class="o">);&lt;/span> &lt;span class="c1">//将内存片段还给内存池
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">HybridHeapMemoryPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">numInitialSegments&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">segmentSize&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">availableMemory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">ArrayDeque&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">numInitialSegments&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">segmentSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">segmentSize&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">numInitialSegments&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">++)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// 使用 new 在 jvm 堆上分配内存
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">availableMemory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">segmentSize&lt;/span>&lt;span class="o">]);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">HybridOffHeapMemoryPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">numInitialSegments&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">segmentSize&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">availableMemory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">ArrayDeque&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">numInitialSegments&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">segmentSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">segmentSize&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">numInitialSegments&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">++)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// 使用 allocateDirect 直接堆外内存
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">availableMemory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ByteBuffer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">allocateDirect&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">segmentSize&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>内存片段工厂&lt;/strong>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MemorySegmentFactory&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="c1">// 从池外(jvm堆中)分配内存段
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">MemorySegment&lt;/span> &lt;span class="nf">allocateUnpooledSegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">size&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HybridMemorySegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="o">],&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 从内存池 中 获取堆内存片段
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">MemorySegment&lt;/span> &lt;span class="nf">wrapPooledHeapMemory&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">memory&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HybridMemorySegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">memory&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 从内存池中 获取 非堆内存片段
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">MemorySegment&lt;/span> &lt;span class="nf">wrapPooledOffHeapMemory&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ByteBuffer&lt;/span> &lt;span class="n">memory&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HybridMemorySegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">memory&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>
&lt;p>&lt;strong>内存片段(MemorySegment)&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>HeapMemorySegment : 管理的内存还是JVM堆内存的一部分&lt;/p>
&lt;/li>
&lt;li>
&lt;p>HybridMemorySegment : Hybrid(on-heap or off-heap)MemorySegment，内存可能为JVM堆内存，也可能不是。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MemorySegment&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">protected&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">heapMemory&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//堆内存
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">protected&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">address&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//字节数组对应的相对地址（若heapMemory为null，即可能为off-heap内存的绝对地址
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">protected&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">addressLimit&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">protected&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">sun&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">misc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Unsafe&lt;/span> &lt;span class="n">UNSAFE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MemoryUtils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">UNSAFE&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//用来对堆/非堆内存进行操作，是JVM的非安全的API
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">protected&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">BYTE_ARRAY_BASE_OFFSET&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">UNSAFE&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">arrayBaseOffset&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[].&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">);&lt;/span> &lt;span class="c1">//二进制字节数组的起始索引，相对于字节数组对象
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">LITTLE_ENDIAN&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">ByteOrder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">nativeOrder&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">ByteOrder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">LITTLE_ENDIAN&lt;/span>&lt;span class="o">);&lt;/span> &lt;span class="c1">//字节序
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">protected&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">size&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//内存段的字节数
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//该内存段owner
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>HeapMemorySegment&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">//堆内存
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">HeapMemorySegment&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">MemorySegment&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// 指向heapMemory的额外引用，用来如数组越界的检查
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">private&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">memory&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="c1">// 只能初始化堆内存
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">HeapMemorySegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">memory&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">super&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Objects&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">requireNonNull&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">memory&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">memory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">memory&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">//...
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>HybridMemorySegment&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="c1">//混合内存
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">HybridMemorySegment&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">MemorySegment&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">ByteBuffer&lt;/span> &lt;span class="n">offHeapBuffer&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="c1">// 非堆内存
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">HybridMemorySegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ByteBuffer&lt;/span> &lt;span class="n">buffer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">super&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">checkBufferAndGetAddress&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">buffer&lt;/span>&lt;span class="o">),&lt;/span> &lt;span class="n">buffer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">capacity&lt;/span>&lt;span class="o">(),&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">offHeapBuffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">buffer&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 堆内存初始化
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">HybridMemorySegment&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">buffer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Object&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">super&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">buffer&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">owner&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">offHeapBuffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>数据视图&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-57-49-flink-source-code-analysis-memory-management_dataview-class-diagram.png" alt="dataview-class-diagram">&lt;/p>
&lt;p>提供内存逻辑视图操作&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">DataInputView&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">DataInput&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">skipBytesToRead&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">numBytes&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="nf">read&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">off&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">len&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//读取数据到b中
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">read&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">DataOutputView&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">DataOutput&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">skipBytesToWrite&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">numBytes&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DataInputView&lt;/span> &lt;span class="n">source&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">numBytes&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span>&lt;span class="o">;&lt;/span> &lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="序列化">序列化&lt;/h3>
&lt;p>Flink 中处理的数据流通常是同一类型，由于数据集对象的类型固定，对于数据集可以只保存一份对象Schema信息，节省大量的存储空间。同时，对于固定大小的类型，也可通过固定的偏移位置存取。当我们需要访问某个对象成员变量的时候，通过定制的序列化工具，并不需要反序列化整个Java对象，而是可以直接通过偏移量，只是反序列化特定的对象成员变量。如果对象的成员变量较多时，能够大大减少Java对象的创建开销，以及内存数据的拷贝大小。&lt;/p>
&lt;p>Flink支持任意的Java或是Scala类型。Flink 在数据类型上有很大的进步，不需要实现一个特定的接口（像Hadoop中的&lt;code>org.apache.hadoop.io.Writable&lt;/code>），Flink 能够自动识别数据类型。Flink 通过 Java Reflection 框架分析基于 Java 的 Flink 程序 UDF (User Define Function)的返回类型的类型信息，通过 Scala Compiler 分析基于 Scala 的 Flink 程序 UDF 的返回类型的类型信息。类型信息由 &lt;code>TypeInformation&lt;/code> 类表示，TypeInformation 支持以下几种类型：&lt;/p>
&lt;ul>
&lt;li>&lt;code>BasicTypeInfo&lt;/code>: 任意Java 基本类型（装箱的）或 String 类型。&lt;/li>
&lt;li>&lt;code>BasicArrayTypeInfo&lt;/code>: 任意Java基本类型数组（装箱的）或 String 数组。&lt;/li>
&lt;li>&lt;code>WritableTypeInfo&lt;/code>: 任意 Hadoop Writable 接口的实现类。&lt;/li>
&lt;li>&lt;code>TupleTypeInfo&lt;/code>: 任意的 Flink Tuple 类型(支持Tuple1 to Tuple25)。Flink tuples 是固定长度固定类型的Java Tuple实现。&lt;/li>
&lt;li>&lt;code>CaseClassTypeInfo&lt;/code>: 任意的 Scala CaseClass(包括 Scala tuples)。&lt;/li>
&lt;li>&lt;code>PojoTypeInfo&lt;/code>: 任意的 POJO (Java or Scala)，例如，Java对象的所有成员变量，要么是 public 修饰符定义，要么有 getter/setter 方法。&lt;/li>
&lt;li>&lt;code>GenericTypeInfo&lt;/code>: 任意无法匹配之前几种类型的类。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-57-56-image-20180513121031892.png" alt="image-20180513121031892">&lt;/p>
&lt;p>如下图展示 一个内嵌型的Tuple3 对象的序列化过程。&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-58-03-TB1lvdbJFXXXXa9XVXXXXXXXXXX.png" alt="img">&lt;/p>
&lt;p>可以看出这种序列化方式存储密度是相当紧凑的。其中 int 占4字节，double 占8字节，POJO多个一个字节的header，PojoSerializer只负责将header序列化进去，并委托每个字段对应的serializer对字段进行序列化。&lt;/p>
&lt;p>Flink 的类型系统可以很轻松地扩展出自定义的TypeInformation、Serializer以及Comparator，来提升数据类型在序列化和比较时的性能。&lt;/p>
&lt;h3 id="数据操作">数据操作&lt;/h3>
&lt;p>Flink 提供了如 group、sort、join 等操作，这些操作都需要访问海量数据。这里，我们以sort为例，这是一个在 Flink 中使用非常频繁的操作。&lt;/p>
&lt;p>首先，Flink 会从 MemoryManager 中申请一批 MemorySegment，我们把这批 MemorySegment 称作 sort buffer，用来存放排序的数据。&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-58-12-TB1_hhgJFXXXXc2XFXXXXXXXXXX.png" alt="img">&lt;/p>
&lt;p>我们会把 sort buffer 分成两块区域。一个区域是用来存放所有对象完整的二进制数据。另一个区域用来存放指向完整二进制数据的指针以及定长的序列化后的key（key+pointer）。如果需要序列化的key是个变长类型，如String，则会取其前缀序列化。如上图所示，当一个对象要加到 sort buffer 中时，它的二进制数据会被加到第一个区域，指针（可能还有key）会被加到第二个区域。&lt;/p>
&lt;p>将实际的数据和指针加定长key分开存放有两个目的:&lt;/p>
&lt;p>第一，交换定长块（key+pointer）更高效，不用交换真实的数据也不用移动其他key和pointer。&lt;/p>
&lt;p>第二，这样做是缓存友好的，因为key都是连续存储在内存中的，可以大大减少 cache miss。&lt;/p>
&lt;p>排序的关键是比大小和交换。Flink 中，会先用 key 比大小，这样就可以直接用二进制的key比较而不需要反序列化出整个对象。因为key是定长的，所以如果key相同（或者没有提供二进制key），那就必须将真实的二进制数据反序列化出来，然后再做比较。之后，只需要交换key+pointer就可以达到排序的效果，真实的数据不用移动。&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-58-20-TB1f6BnJFXXXXbnXFXXXXXXXXXX.png" alt="img">&lt;/p>
&lt;h3 id="flink内存管理优势">Flink内存管理优势：&lt;/h3>
&lt;ol>
&lt;li>节省内存空间&lt;/li>
&lt;li>高效的内存操作&lt;/li>
&lt;li>缓存友好的计算&lt;/li>
&lt;li>减少OOM&lt;/li>
&lt;li>减少GC&lt;/li>
&lt;/ol>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://juejin.im/post/5c4f16dbe51d454f342fb7e7">https://juejin.im/post/5c4f16dbe51d454f342fb7e7&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Flink简介</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E7%AE%80%E4%BB%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E7%AE%80%E4%BB%8B/</guid><description>&lt;h1 id="flink简介">Flink简介&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Flink是开始于2008年，原生的流处理系统，提供high level的API。Flink也提供 API来像Spark一样进行批处理，但两者处理的基础是完全不同的。Flink把批处理当作流处理中的一种特殊情况。在Flink中，所有 的数据都看作流，是一种很好的抽象，因为这更接近于现实世界。&lt;/p>
&lt;p>Flink 是一个批处理和流处理结合的统一计算框架，其核心是一个提供了数据分发以及并行化计算的流数据处理引擎。它的最大亮点是流处理，是业界最顶级的开源流处理引擎。Flink 与 Storm 类似，属于事件驱动型实时流系统。&lt;/p>
&lt;h2 id="组成">组成&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-56-59-2020-01-22-17-24-41-image.png" alt="">&lt;/p>
&lt;h2 id="架构">架构&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2020/11/13-09-57-12-2020-01-22-17-23-16-image.png" alt="">&lt;/p>
&lt;h2 id="特性">特性&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>高吞吐 &amp;amp; 低延迟;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>支持 Event Time 和乱序事件;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>状态计算的 exactly-once 语义;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>高度灵活的流式窗口;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>带反压的连续流模型;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Flink 的容错机制是基于 Chandy-Lamport distributed snapshots 来实现的&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/36022692">https://zhuanlan.zhihu.com/p/36022692&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/91383709">https://zhuanlan.zhihu.com/p/91383709&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Golang之mutex</title><link>https://justice.bj.cn/post/14.language/golang/golang%E4%B9%8Bmutex/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/golang%E4%B9%8Bmutex/</guid><description>&lt;h1 id="golang之mutex">Golang之mutex&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>sync.Mutex是一个不可重入的排他锁;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>当一个 goroutine 获得了这个锁的拥有权后， 其它请求锁的 goroutine 就会阻塞在 Lock 方法的调用上，直到锁被释放;&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">type&lt;/span> &lt;span class="nx">Mutex&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">state&lt;/span> &lt;span class="kt">int32&lt;/span> &lt;span class="c1">//锁的状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">sema&lt;/span> &lt;span class="kt">uint32&lt;/span> &lt;span class="c1">//控制锁状态的信号量
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="c1">//state
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="cm">/*
&lt;/span>&lt;span class="cm">32 3 2 1 0
&lt;/span>&lt;span class="cm"> | | | | |
&lt;/span>&lt;span class="cm"> | | | | |
&lt;/span>&lt;span class="cm"> v-----------------------------------------------v-------------v-------------v-------------+
&lt;/span>&lt;span class="cm"> | | | | v
&lt;/span>&lt;span class="cm"> | waitersCount |mutexStarving| mutexWoken | mutexLocked |
&lt;/span>&lt;span class="cm"> | | | | |
&lt;/span>&lt;span class="cm"> +-----------------------------------------------+-------------+-------------+-------------+
&lt;/span>&lt;span class="cm">*/&lt;/span>
&lt;span class="kd">const&lt;/span> &lt;span class="p">(&lt;/span>
&lt;span class="nx">mutexLocked&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="kc">iota&lt;/span> &lt;span class="c1">// mutex is locked
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">mutexWoken&lt;/span> &lt;span class="c1">//2
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">mutexStarving&lt;/span> &lt;span class="c1">//4
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">mutexWaiterShift&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kc">iota&lt;/span> &lt;span class="c1">//3
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Mutex一旦使用之后，一定不要做copy操作。&lt;/p>
&lt;p>最低三位分别表示 mutexLocked、mutexWoken 和 mutexStarving，剩下的位置用来表示当前有多少个 Goroutine 等待互斥锁的释放：&lt;/p>
&lt;p>在默认情况下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态：&lt;/p>
&lt;ul>
&lt;li>mutexLocked — 表示互斥锁的锁定状态；&lt;/li>
&lt;li>mutexWoken — 表示从正常模式被从唤醒；&lt;/li>
&lt;li>mutexStarving — 当前的互斥锁进入饥饿状态；&lt;/li>
&lt;li>waitersCount — 当前互斥锁上等待的 goroutine 个数；&lt;/li>
&lt;/ul>
&lt;p>为了保证锁的公平性，设计上互斥锁有两种状态：正常状态和饥饿状态。&lt;/p>
&lt;p>&lt;code>正常模式&lt;/code>下，所有等待锁的goroutine按照FIFO顺序等待。唤醒的goroutine不会直接拥有锁，而是会和新请求锁的goroutine竞争锁的拥有。新请求锁的goroutine具有优势：它正在CPU上执行，而且可能有好几个，所以刚刚唤醒的goroutine有很大可能在锁竞争中失败。在这种情况下，这个被唤醒的goroutine会加入到等待队列的前面。 &lt;code>如果一个等待的goroutine超过1ms没有获取锁，那么它将会把锁转变为饥饿模式&lt;/code>。&lt;/p>
&lt;p>&lt;code>饥饿模式&lt;/code>下，锁的所有权将从unlock的gorutine直接交给交给等待队列中的第一个。新来的goroutine将不会尝试去获得锁，即使锁看起来是unlock状态, 也不会去尝试自旋操作，而是放在等待队列的尾部。&lt;/p>
&lt;p>如果一个等待的goroutine获取了锁，并且满足一以下其中的任何一个条件：(1)它是队列中的最后一个；(2)它等待的时候小于1ms。它会将锁的状态转换为正常状态。&lt;/p>
&lt;p>正常状态有很好的性能表现，饥饿模式也是非常重要的，因为它能阻止尾部延迟的现象。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">func&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">m&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">Mutex&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="nf">Lock&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// 如果mutex的state没有被锁，也没有等待/唤醒的goroutine, 锁处于正常状态，那么获得锁，返回.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 比如锁第一次被goroutine请求时，就是这种状态。或者锁处于空闲的时候，也是这种状态。
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">atomic&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">CompareAndSwapInt32&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">mutexLocked&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="k">return&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// Slow path (outlined so that the fast path can be inlined)
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">lockSlow&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">m&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">Mutex&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="nf">lockSlow&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// 标记本goroutine的等待时间
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">var&lt;/span> &lt;span class="nx">waitStartTime&lt;/span> &lt;span class="kt">int64&lt;/span>
&lt;span class="c1">// 本goroutine是否已经处于饥饿状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">starving&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="kc">false&lt;/span>
&lt;span class="c1">// 本goroutine是否已唤醒
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">awoke&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="kc">false&lt;/span>
&lt;span class="c1">// 自旋次数
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">iter&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="nx">old&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// 第一个条件：1.mutex已经被锁了；2.不处于饥饿模式(如果时饥饿状态，自旋时没有用的，锁的拥有权直接交给了等待队列的第一个。)
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 尝试自旋的条件：参考runtime_canSpin函数
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">mutexLocked&lt;/span>&lt;span class="p">|&lt;/span>&lt;span class="nx">mutexStarving&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="nx">mutexLocked&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="nf">runtime_canSpin&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">iter&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// 进入这里肯定是普通模式
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 自旋的过程中如果发现state还没有设置woken标识，则设置它的woken标识， 并标记自己为被唤醒。
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="p">!&lt;/span>&lt;span class="nx">awoke&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">mutexWoken&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>&lt;span class="nx">mutexWaiterShift&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span>
&lt;span class="nx">atomic&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">CompareAndSwapInt32&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="p">|&lt;/span>&lt;span class="nx">mutexWoken&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">awoke&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kc">true&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="nf">runtime_doSpin&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="nx">iter&lt;/span>&lt;span class="o">++&lt;/span>
&lt;span class="nx">old&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>
&lt;span class="k">continue&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 到了这一步， state的状态可能是：
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 1. 锁还没有被释放，锁处于正常状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 2. 锁还没有被释放， 锁处于饥饿状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 3. 锁已经被释放， 锁处于正常状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 4. 锁已经被释放， 锁处于饥饿状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 并且本gorutine的 awoke可能是true, 也可能是false (其它goutine已经设置了state的woken标识)
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">// new 复制 state的当前状态， 用来设置新的状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// old 是锁当前的状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">new&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">old&lt;/span>
&lt;span class="c1">// 如果old state状态不是饥饿状态, new state 设置锁， 尝试通过CAS获取锁,
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 如果old state状态是饥饿状态, 则不设置new state的锁，因为饥饿状态下锁直接转给等待队列的第一个.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">mutexStarving&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">new&lt;/span> &lt;span class="o">|=&lt;/span> &lt;span class="nx">mutexLocked&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 将等待队列的等待者的数量加1
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">mutexLocked&lt;/span>&lt;span class="p">|&lt;/span>&lt;span class="nx">mutexStarving&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">new&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="nx">mutexWaiterShift&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 如果当前goroutine已经处于饥饿状态， 并且old state的已被加锁,
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 将new state的状态标记为饥饿状态, 将锁转变为饥饿状态.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">starving&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">mutexLocked&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">new&lt;/span> &lt;span class="o">|=&lt;/span> &lt;span class="nx">mutexStarving&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 如果本goroutine已经设置为唤醒状态, 需要清除new state的唤醒标记, 因为本goroutine要么获得了锁，要么进入休眠，
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 总之state的新状态不再是woken状态.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">awoke&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// The goroutine has been woken from sleep,
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// so we need to reset the flag in either case.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">new&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">mutexWoken&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nf">throw&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;sync: inconsistent mutex state&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="nx">new&lt;/span> &lt;span class="o">&amp;amp;^=&lt;/span> &lt;span class="nx">mutexWoken&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 通过CAS设置new state值.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 注意new的锁标记不一定是true, 也可能只是标记一下锁的state是饥饿状态.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">atomic&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">CompareAndSwapInt32&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">new&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// 如果old state的状态是未被锁状态，并且锁不处于饥饿状态,
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 那么当前goroutine已经获取了锁的拥有权，返回
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">mutexLocked&lt;/span>&lt;span class="p">|&lt;/span>&lt;span class="nx">mutexStarving&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="k">break&lt;/span> &lt;span class="c1">// locked the mutex with CAS
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="c1">// If we were already waiting before, queue at the front of the queue.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 设置并计算本goroutine的等待时间
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">queueLifo&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">waitStartTime&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nx">waitStartTime&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">waitStartTime&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nf">runtime_nanotime&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 既然未能获取到锁， 那么就使用sleep原语阻塞本goroutine
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 如果是新来的goroutine,queueLifo=false, 加入到等待队列的尾部，耐心等待
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 如果是唤醒的goroutine, queueLifo=true, 加入到等待队列的头部
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nf">runtime_SemacquireMutex&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">sema&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">queueLifo&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">// sleep之后，此goroutine被唤醒
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 计算当前goroutine是否已经处于饥饿状态.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">starving&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">starving&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="nf">runtime_nanotime&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nx">waitStartTime&lt;/span> &lt;span class="p">&amp;gt;&lt;/span> &lt;span class="nx">starvationThresholdNs&lt;/span>
&lt;span class="c1">// 得到当前的锁状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">old&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>
&lt;span class="c1">// 如果当前的state已经是饥饿状态
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 那么锁应该处于Unlock状态，那么应该是锁被直接交给了本goroutine
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">mutexStarving&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// If this goroutine was woken and mutex is in starvation mode,
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// ownership was handed off to us but mutex is in somewhat
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// inconsistent state: mutexLocked is not set and we are still
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// accounted as waiter. Fix that.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">mutexLocked&lt;/span>&lt;span class="p">|&lt;/span>&lt;span class="nx">mutexWoken&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>&lt;span class="nx">mutexWaiterShift&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nf">throw&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;sync: inconsistent mutex state&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 当前goroutine用来设置锁，并将等待的goroutine数减1.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">delta&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nb">int32&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">mutexLocked&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">&amp;lt;&amp;lt;&lt;/span>&lt;span class="nx">mutexWaiterShift&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">// 如果本goroutine是最后一个等待者，或者它并不处于饥饿状态，
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 那么我们需要把锁的state状态设置为正常模式.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="p">!&lt;/span>&lt;span class="nx">starving&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="nx">old&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span>&lt;span class="nx">mutexWaiterShift&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1">// 退出饥饿模式
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">delta&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="nx">mutexStarving&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">// 设置新state, 因为已经获得了锁，退出、返回
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">atomic&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">AddInt32&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">delta&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">break&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="nx">awoke&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kc">true&lt;/span>
&lt;span class="nx">iter&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;span class="p">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">old&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">m&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">state&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>整个过程比较复杂，这里总结一下一些重点：&lt;/p>
&lt;ol>
&lt;li>如果锁处于初始状态(unlock, 正常模式)，则通过CAS(0 -&amp;gt; Locked)获取锁；如果获取失败，那么就进入slowLock的流程：&lt;/li>
&lt;/ol>
&lt;p>slowLock的获取锁流程有两种模式： 饥饿模式 和 正常模式。&lt;/p>
&lt;h2 id="1正常模式">(1)正常模式&lt;/h2>
&lt;ol>
&lt;li>mutex已经被locked了，处于正常模式下；&lt;/li>
&lt;li>前 Goroutine 为了获取该锁进入自旋的次数小于四次；&lt;/li>
&lt;li>当前机器CPU核数大于1；&lt;/li>
&lt;li>当前机器上至少存在一个正在运行的处理器 P 并且处理的运行队列为空；&lt;/li>
&lt;/ol>
&lt;p>满足上面四个条件的goroutine才可以做自旋。自旋就会调用sync.runtime_doSpin 和 runtime.procyield 并执行 30 次的 PAUSE 指令，该指令只会占用 CPU 并消耗 CPU 时间。&lt;/p>
&lt;p>处理了自旋相关的特殊逻辑之后，互斥锁会根据上下文计算当前互斥锁最新的状态new。几个不同的条件分别会更新 state 字段中存储的不同信息 — mutexLocked、mutexStarving、mutexWoken 和 mutexWaiterShift：&lt;/p>
&lt;p>计算最新的new之后，CAS更新，如果更新成功且old状态是未被锁状态，并且锁不处于饥饿状态，就代表当前goroutine竞争成功并获取到了锁返回。(这也就是当前goroutine在正常模式下竞争时更容易获得锁的原因)&lt;/p>
&lt;p>如果当前goroutine竞争失败，会调用 &lt;code>sync.runtime_SemacquireMutex&lt;/code> 使用信号量保证资源不会被两个 Goroutine 获取。&lt;code>sync.runtime_SemacquireMutex&lt;/code> 会在方法中不断调用尝试获取锁并休眠当前 Goroutine 等待信号量的释放，一旦当前 Goroutine 可以获取信号量，它就会立刻返回，sync.Mutex.Lock 方法的剩余代码也会继续执行。&lt;/p>
&lt;h2 id="2-饥饿模式">(2) 饥饿模式&lt;/h2>
&lt;p>饥饿模式本身是为了一定程度保证公平性而设计的模式。所以饥饿模式不会有自旋的操作，新的 Goroutine 在该状态下不能获取锁、也不会进入自旋状态，它们只会在队列的末尾等待。&lt;/p>
&lt;p>不管是正常模式还是饥饿模式，获取信号量，它就会从阻塞中立刻返回，并执行剩下代码：&lt;/p>
&lt;ol>
&lt;li>在正常模式下，这段代码会设置唤醒和饥饿标记、重置迭代次数并重新执行获取锁的循环；&lt;/li>
&lt;li>在饥饿模式下，当前 Goroutine 会获得互斥锁，如果等待队列中只存在当前 Goroutine，互斥锁还会从饥饿模式中退出；&lt;/li>
&lt;/ol>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://segmentfault.com/a/1190000023874384">【golang】sync.Mutex互斥锁的实现原理&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>Golang之syscall</title><link>https://justice.bj.cn/post/14.language/golang/golang%E4%B9%8Bsyscall/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/golang%E4%B9%8Bsyscall/</guid><description>&lt;h1 id="golang之syscall">Golang之syscall&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ User Mode ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─
│
│ Application syscall library
program /src/syscall │
│
│
│ ┌───────────────────┐ ┌──────────────────────┐
│ │ ┌────────────▶│Faccessat { │ │
│ │ │ │ │ │
│ │ │ │ runtime·Syscall6 { │ │
│ │... │ │ │ │
│syscall.Access( │ │ │ ... │ │
│ │ path, mode)───┼────────┘ │ SYSCALL ──────────┼────────────────┐
│... ◀──────────┼──────┐ │ ... ◀──────────┼──────────┼─────┼────────┐
│ │ │ └───────────────┼─── return; │ │ │
│ │ │ } │ │ │ │
│ │ │ │} │ │ │
└───────────────────┘ └──────────────────────┘ │ │ │
│ │ │
─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ │ ▲
│ │
switch to kernel mode │
┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ Kernel Mode ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ▼ │
│ │ │
│ System call Trap handler │ │
service routine │ │ │
│ ┌──────────────────┐ ┌───────────────────────┐ │ │
│sys_faccessat() ◀─┼───────────┐ │system call: ◀───────┼────────┼─────┘ │
│ │{ │ │ │ │ │
│ │ │ │ │ │ │
│ │ │ │ │ ... │ │
│ │ │ │ │ │ │
│ │ ... │ └───────────┼───call sys_call_table │ switch to user mode
│ │ │ │ │ │
│ │ │ ┌───────────┼─▶ ... │ │
│ return error; ──┼───────────┘ │ │ │ │
│ │} │ │ ───────────────────┼───────────▶───────────┘
└──────────────────┘ └───────────────────────┘ │
│
─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">/syscall/syscall_linux.go
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以把系统调用分为三类:&lt;/p>
&lt;ol>
&lt;li>阻塞系统调用&lt;/li>
&lt;li>非阻塞系统调用&lt;/li>
&lt;li>wrapped 系统调用&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">//sys Madvise(b []byte, advice int) (err error)
&lt;/span>&lt;span class="c1">//sysnb EpollCreate(size int) (fd int, err error)
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="c1">//mksyscall.pl 脚本 将上面的定义生成如下
&lt;/span>&lt;span class="c1">//sys
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">func&lt;/span> &lt;span class="nf">Madvise&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">b&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">advice&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">err&lt;/span> &lt;span class="kt">error&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="kd">var&lt;/span> &lt;span class="nx">_p0&lt;/span> &lt;span class="nx">unsafe&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Pointer&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">b&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">_p0&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">unsafe&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Pointer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">b&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="p">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">_p0&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">unsafe&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Pointer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nx">_zero&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="nx">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">e1&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nf">Syscall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">SYS_MADVISE&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">uintptr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">_p0&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="nb">uintptr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">b&lt;/span>&lt;span class="p">)),&lt;/span> &lt;span class="nb">uintptr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">advice&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nx">e1&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">err&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nf">errnoErr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">e1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="k">return&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">//sysnb
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">func&lt;/span> &lt;span class="nf">EpollCreate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">size&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">fd&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="kt">error&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">r0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">e1&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nf">RawSyscall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">SYS_EPOLL_CREATE&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">uintptr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">size&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nx">fd&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">r0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nx">e1&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">err&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nf">errnoErr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">e1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="k">return&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="c1">//wrapped
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">func&lt;/span> &lt;span class="nf">Rename&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">oldpath&lt;/span> &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">newpath&lt;/span> &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">err&lt;/span> &lt;span class="kt">error&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="nf">Renameat&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">_AT_FDCWD&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">oldpath&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">_AT_FDCWD&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">newpath&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>入口：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">func&lt;/span> &lt;span class="nf">Syscall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">trap&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a3&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">r1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">r2&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="nx">syscall&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Errno&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">Syscall6&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">trap&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a6&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">r1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">r2&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="nx">syscall&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Errno&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">RawSyscall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">trap&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a3&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">r1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">r2&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="nx">syscall&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Errno&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="kd">func&lt;/span> &lt;span class="nf">RawSyscall6&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">trap&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">a6&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">r1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">r2&lt;/span> &lt;span class="kt">uintptr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="nx">syscall&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Errno&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这些函数的实现都是汇编，按照 linux 的 syscall 调用规范，我们只要在汇编中把参数依次传入寄存器，并调用 SYSCALL 指令即可进入内核处理逻辑，系统调用执行完毕之后，返回值放在 RAX 中:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>RDI&lt;/th>
&lt;th>RSI&lt;/th>
&lt;th>RDX&lt;/th>
&lt;th>R10&lt;/th>
&lt;th>R8&lt;/th>
&lt;th>R9&lt;/th>
&lt;th>RAX&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>参数一&lt;/td>
&lt;td>参数二&lt;/td>
&lt;td>参数三&lt;/td>
&lt;td>参数四&lt;/td>
&lt;td>参数五&lt;/td>
&lt;td>参数六&lt;/td>
&lt;td>系统调用编号/返回值&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Syscall 和 Syscall6 的区别只有传入参数不一样&lt;/p>
&lt;p>Syscall 和 Syscall6在进入和退出Syscall时，分别调用了&lt;code>runtime·entersyscall(SB)&lt;/code>和&lt;code>runtime·exitsyscall(SB)&lt;/code>;&lt;/p>
&lt;p>RawSyscall 和 RawSyscall6 在进入和退出Syscall 时候没有调用；&lt;/p>
&lt;h4 id="新版本抢占式调度中的-rawsyscall-和-syscall">新版本抢占式调度中的 RawSyscall 和 Syscall&lt;/h4>
&lt;p>由于 &lt;code>RawSyscall&lt;/code> 相较于 &lt;code>Syscall&lt;/code> 缺少了 &lt;code>runtime·entersyscall(SB)&lt;/code> 以及 &lt;code>runtime·exitsyscall(SB)&lt;/code> 的调用，当 &lt;code>g&lt;/code> 执行的是阻塞性质的系统调用的时候，当前 &lt;code>g&lt;/code> 会维持 &lt;code>running&lt;/code> 状态，runtime 系统监控在进行全局调度的时候一旦发现运行超过 10ms 的 &lt;code>g&lt;/code> 就会执行抢占操作（1.14.3 版本, linux_amd64 下为例），通过发送信号量给 &lt;code>g&lt;/code> 对应的线程，而由于线程在初始化的时候进行了信号量的监听以及设置了相应的 &lt;code>sa_flags&lt;/code> 参数，虽然包含诸如&lt;code>SA_RESTART&lt;/code>参数会让系统调用在信号中断后自动恢复，但是不是对所有系统调用都会有效，这将会导致在收到信号量的时候对正在阻塞的系统调用产生中断，&lt;/p>
&lt;h2 id="vsdo">vsdo&lt;/h2>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://github.com/cch123/golang-notes/blob/master/syscall.md">https://github.com/cch123/golang-notes/blob/master/syscall.md&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>go常用技巧</title><link>https://justice.bj.cn/post/14.language/golang/golang%E5%B8%B8%E8%A7%81%E6%8A%80%E5%B7%A7/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/golang/golang%E5%B8%B8%E8%A7%81%E6%8A%80%E5%B7%A7/</guid><description>&lt;h1 id="go常用技巧">go常用技巧&lt;/h1>
&lt;ul>
&lt;li>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">// []byte -&amp;gt; string
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Java线程池</title><link>https://justice.bj.cn/post/14.language/java/java%E7%BA%BF%E7%A8%8B%E6%B1%A0/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/14.language/java/java%E7%BA%BF%E7%A8%8B%E6%B1%A0/</guid><description>&lt;h1 id="java线程池">Java线程池&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>创建线程需要操作系统资源（线程资源，栈空间等），频繁创建和销毁大量线程需要消耗大量时间。&lt;/p>
&lt;p>可以把很多小任务让一组线程来执行，而不是一个任务对应一个新线程。这种能接收大量小任务并进行分发处理的就是线程池。&lt;/p>
&lt;p>线程池内部维护了若干个线程，没有任务的时候，这些线程都处于等待状态。如果有新任务，就分配一个空闲线程执行。如果所有线程都处于忙碌状态，新任务要么放入队列等待，要么增加一个新线程进行处理。&lt;/p>
&lt;h2 id="java线程实现方式">java线程实现方式&lt;/h2>
&lt;p>Thread、Runnable、Callable&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">//实现Runnable接口的类将被Thread执行，表示一个基本任务
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">Runnable&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">//run方法就是它所有内容，就是实际执行的任务
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kd">abstract&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">run&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">//Callable同样是任务，与Runnable接口的区别在于它接口泛型，同时它执行任务候带有返回值；
&lt;/span>&lt;span class="c1">//Callable的使用通过外层封装成Future来使用
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">interface&lt;/span> &lt;span class="nc">Callable&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">V&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">//相对于run方法，call方法带有返回值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">V&lt;/span> &lt;span class="nf">call&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Java标准库提供了&lt;code>ExecutorService&lt;/code>接口表示线程池；&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// 创建固定大小的线程池:
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">ExecutorService&lt;/span> &lt;span class="n">executor&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Executors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newFixedThreadPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">3&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 提交任务:
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">executor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">submit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">task1&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">executor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">submit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">task2&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">executor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">submit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">task3&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">executor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">submit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">task4&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">executor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">submit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">task5&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>ExecutorService&lt;/code>是接口，Java标准库提供的几个常用实现类有：&lt;/p>
&lt;ul>
&lt;li>FixedThreadPool：线程数固定的线程池；&lt;/li>
&lt;li>CachedThreadPool：线程数根据任务动态调整的线程池；&lt;/li>
&lt;li>SingleThreadExecutor：仅单线程执行的线程池。&lt;/li>
&lt;/ul>
&lt;h2 id="executor">Executor&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2022/01/03-17-27-59-2022-01-03-17-27-55-image.png" alt="">&lt;/p>
&lt;h2 id="原理">原理&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2022/01/03-17-19-56-2022-01-03-17-19-48-image.png" alt="">&lt;/p>
&lt;p>线程池的状态：&lt;/p>
&lt;p>RUNNING = ­1 &amp;laquo; COUNT_BITS; //高3位为111
SHUTDOWN = 0 &amp;laquo; COUNT_BITS; //高3位为000
STOP = 1 &amp;laquo; COUNT_BITS; //高3位为001
TIDYING = 2 &amp;laquo; COUNT_BITS; //高3位为010
TERMINATED = 3 &amp;laquo; COUNT_BITS; //高3位为011&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2022/01/03-19-51-15-2022-01-03-19-51-02-image.png" alt="">&lt;/p>
&lt;h2 id="线程池的使用">线程池的使用&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">//
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">RunTask&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">Runnable&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">run&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Thread name:&amp;#34;&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">Thread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">currentThread&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ExecutorSample&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">ExecutorService&lt;/span> &lt;span class="n">executor&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Executors&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newFixedThreadPool&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">5&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">20&lt;/span>&lt;span class="o">;&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">++){&lt;/span>
&lt;span class="c1">//提交任务无返回值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">executor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">execute&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">RunTask&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="c1">//任务执行完成后有返回值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">Future&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Object&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">future&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">executor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">submit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">RunTask&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="threadpoolexecutor">ThreadPoolExecutor&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="nf">ThreadPoolExecutor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">corePoolSize&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">maximumPoolSize&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="kt">long&lt;/span> &lt;span class="n">keepAliveTime&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">TimeUnit&lt;/span> &lt;span class="n">unit&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">BlockingQueue&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Runnable&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">workQueue&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">ThreadFactory&lt;/span> &lt;span class="n">threadFactory&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">RejectedExecutionHandler&lt;/span> &lt;span class="n">handler&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">corePoolSize&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">maximumPoolSize&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">keepAliveTime&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">unit&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">workQueue&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">threadFactory&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">defaultHandler&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>corePoolSize：线程池中的核心线程数。当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。&lt;/li>
&lt;li>maximumPoolSize：线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize。&lt;/li>
&lt;li>keepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize时候，如果这时候没有新的任务提交，核心线程外的线程不会立即被销毁，而是会等待，直到等待的时间超过了keepAliveTime&lt;br>
unit：keepAliveTime的单位时间&lt;/li>
&lt;li>workQueue：用于保存等待被执行的任务的阻塞队列，且任务必须实现Runnable接口，在JDK中提供了如下阻塞队列：&lt;br>
ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务。&lt;br>
LinkedBlockingQueue：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQueue。&lt;br>
SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常高于LinkedBlockingQueue。&lt;/li>
&lt;li>PriorityBlockingQueue：具有优先级的无界阻塞队列。&lt;/li>
&lt;li>threadFactory：ThreadFactory 类型的变量，用来创建新线程。默认使用ThreadFactory.defaultThreadFactory来创建线程， 会使新创建线程具有相同的NORM_PRIORITY优先级并且都是非守护线程，同时也设置了线程名称。&lt;/li>
&lt;li>handler：线程池的饱和策略。当阻塞队列满了，且没有空闲的工作队列，如果继续提交任务，必须采用一种策略处理该任务.&lt;/li>
&lt;/ul>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1306581130018849">使用线程池 - 廖雪峰的官方网站&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://juejin.cn/post/6844903920511221768">Executor线程池只看这一篇就够了 - 掘金&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item></channel></rss>