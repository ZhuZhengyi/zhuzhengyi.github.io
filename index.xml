<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Justice的小站</title><link>https://justice.bj.cn/</link><description>Recent content on Justice的小站</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 10 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://justice.bj.cn/index.xml" rel="self" type="application/rss+xml"/><item><title>Justice's Blog</title><link>https://justice.bj.cn/homepage/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/about/</guid><description>&lt;h2 id="self-introduction">Self Introduction&lt;/h2>
&lt;p>Cras ex dui, tristique a libero eget, consectetur semper ligula. Nunc augue arcu, malesuada a nisi et, molestie finibus metus. Sed lacus odio, ultricies a nisl vitae, sollicitudin tempor ipsum. Vivamus quis feugiat arcu. Sed mi nunc, efficitur quis tellus vitae, posuere mattis metus. Phasellus in mattis dui. Nullam blandit, augue non ullamcorper dapibus, lacus dui molestie massa, in iaculis purus lectus eu lectus. Duis hendrerit lacinia tellus, sit amet feugiat dolor placerat id. Aenean ac velit massa. Vivamus feugiat dui at magna viverra, ut dictum nunc rutrum. Duis eget sapien finibus, lobortis orci id, vestibulum tellus. Maecenas lobortis urna libero, quis fermentum lectus lobortis nec. Nullam laoreet volutpat libero, ac mattis magna ullamcorper quis. Duis eget ipsum eu nisi mattis cursus et vitae turpis.&lt;/p>
&lt;p>Aliquam pretium diam eget leo feugiat finibus. Donec malesuada commodo ipsum. Aenean a massa in lacus venenatis vestibulum. Duis vel sem quis elit iaculis consectetur et quis dolor. Morbi eu ipsum hendrerit, malesuada ante sed, dapibus est. Suspendisse feugiat nulla ut gravida convallis. Phasellus id massa posuere, rhoncus justo ut, porttitor dolor. Nulla ultrices malesuada egestas. Nunc fermentum tincidunt sem ac vulputate. Donec mollis sollicitudin justo eget varius. Donec ornare velit et felis blandit, id molestie sapien lobortis. Morbi eget tristique justo. Mauris posuere, nibh eu laoreet ultricies, ligula erat iaculis sapien, vel dapibus lacus libero ut diam. Etiam viverra ante felis, et scelerisque nunc pellentesque vitae. Praesent feugiat dictum molestie.&lt;/p>
&lt;h2 id="details">Details&lt;/h2>
&lt;p>Nunc pellentesque vitae:&lt;/p>
&lt;ul>
&lt;li>Morbi accumsan nibh efficitur diam molestie, non dignissim diam facilisis.&lt;/li>
&lt;li>Donec dignissim leo in mollis faucibus.&lt;/li>
&lt;li>Donec blandit lacus a pellentesque fermentum.&lt;/li>
&lt;/ul>
&lt;p>Donec mollis sollicitudin:&lt;/p>
&lt;ul>
&lt;li>Nunc dictum purus ornare purus consectetur, eu pellentesque massa ullamcorper.&lt;/li>
&lt;li>Aliquam eu leo vitae justo aliquam tincidunt.&lt;/li>
&lt;li>Fusce non massa id augue interdum feugiat sed et nulla.&lt;/li>
&lt;li>Vivamus molestie augue in tristique laoreet.&lt;/li>
&lt;/ul></description></item><item><title>Pages</title><link>https://justice.bj.cn/homepage/pages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/pages/</guid><description/></item><item><title>Experiences</title><link>https://justice.bj.cn/homepage/experiences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/experiences/</guid><description/></item><item><title>Vintage</title><link>https://justice.bj.cn/homepage/vintage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/vintage/</guid><description/></item><item><title>Blank</title><link>https://justice.bj.cn/homepage/blank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/homepage/blank/</guid><description>
&lt;div style="text-align:center">
&lt;p>Write anything you like here!&lt;/p>
&lt;/div></description></item><item><title>HBase Compaction分析</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-compact%E5%88%86%E6%9E%90/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-compact%E5%88%86%E6%9E%90/</guid><description>&lt;h1 id="hbase-compaction分析">HBase Compaction分析&lt;/h1>
&lt;h2 id="compact-流程">compact 流程&lt;/h2>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-50-22-image-20180822111406478.png" alt="image-20180822111406478">&lt;/p>
&lt;h2 id="compact-触发条件">compact 触发条件&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>memstore flush：&lt;/p>
&lt;p>memstore flush会产生HFile文件，文件越来越多就需要compact。因此在每次执行完Flush操作之后，都会对当前Store中的文件数进行判断，一旦store 中的HFile文件数 - 正在compacting的文件数 &amp;gt; minFilesToCompact，就会触发compaction。默认：&amp;ldquo;hbase.hstore.compaction.min&amp;rdquo; 为：3。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kt">boolean&lt;/span> &lt;span class="n">needsCompaction&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">flush&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">commit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">status&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">needsCompaction&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">compactionRequested&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">needsCompaction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Collection&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">HStoreFile&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">storeFiles&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">HStoreFile&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">filesCompacting&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">numCandidates&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">storeFiles&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">size&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">filesCompacting&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">size&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">numCandidates&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="n">comConf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMinFilesToCompact&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">minFilesToCompact&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">max&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">2&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getInt&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.hstore.compaction.min&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>周期检查：(CompactionChecker)&lt;/p>
&lt;p>后台线程CompactionChecker定期触发检查是否需要执行compaction，检查周期为：hbase.server.thread.wakefrequency*hbase.server.compactchecker.interval.multiplier。默认为10000 * 1000 ms，就是2个多小时。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kt">long&lt;/span> &lt;span class="n">multiplier&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getCompactionCheckMultiplier&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">assert&lt;/span> &lt;span class="n">multiplier&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">iteration&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="n">multiplier&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">continue&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">needsCompaction&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Queue a compaction. Will recognize if major is needed.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">instance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compactSplitThread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">requestSystemCompaction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hr&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">getName&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34; requests compaction&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>手动触发：&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>一般来讲，手动触发compaction通常是为了执行major compaction，原因有三，&lt;/p>
&lt;p>其一是因为很多业务担心自动major compaction影响读写性能，因此会选择低峰期手动触发；&lt;/p>
&lt;p>其二也有可能是用户在执行完alter操作之后希望立刻生效，执行手动触发major compaction；&lt;/p>
&lt;p>其三是HBase管理员发现硬盘容量不够的情况下手动触发major compaction删除大量过期数据；&lt;/p>
&lt;p>无论哪种触发动机，一旦手动触发，HBase会不做很多自动化检查，直接执行合并。&lt;/p>
&lt;h2 id="compact-文件选择策略">compact 文件选择策略&lt;/h2>
&lt;p>选择合适的文件进行合并是整个compaction的核心，因为合并文件的大小以及其当前承载的IO数直接决定了compaction的效果。最理想的情况是，这些文件承载了大量IO请求但是大小很小，这样compaction本身不会消耗太多IO，而且合并完成之后对读的性能会有显著提升。然而现实情况可能大部分都不会是这样。都会首先对该Store中所有HFile进行一一排查，排除不满足条件的部分文件：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>排除当前正在执行compact的文件及其比这些文件更新的所有文件（SequenceId更大）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>排除某些过大的单个文件，如果文件大小大于hbase.hzstore.compaction.max.size（默认Long最大值），则被排除，否则会产生大量IO消耗&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>经过排除的文件称为候选文件。&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2019-12-31-19-39-28-image.png" alt="">&lt;/p>
&lt;p>文件现在策略有：&lt;/p>
&lt;ul>
&lt;li>RatioBasedCompactionPolicy：从最旧文件开始遍历到最新候选文件，找到小于［hbase.hstore.compaction.min.size（默认为memstore的flush大小，128M）和compact文件总大小*ratio 的最大值］的符合条件文件，如果发现不符合则马上停止搜索。ratio是一个可变的比例，可以通过设置高峰期的时间来改变这个比例，在高峰期时ratio为1.2，非高峰期为5，也就是非高峰期允许compact更大的文件（非高峰期可以耗费更大IO）。 目的是尽可能找到小文件进行minor compact。如果判断这个compact操作后文件数仍然过多会阻塞flush操作，则只是简单选择从最老的文件起，候选文件数减去hbase.hstore.compaction.min（默认3）个文件。&lt;/li>
&lt;li>ExploringCompactionPolicy：从最旧文件开始遍历&lt;strong>所有的&lt;/strong>候选文件，找出符合［compact文件大小 小于 hbase.hstore.compaction.max.size（默认Long最大值）且所有文件的大小都不会超过其它文件大小*ratio］并且效率最高［compact文件数最多或compact大小最小］。ratio是高峰期比例。注意，由于存在限制，因此可能候选文件被排除到为0个，这时如果判断这个compact操作后文件数仍然过多会阻塞flush操作，则会选择hbase.hstore.compaction.min（默认3）个文件起，符合最大（Long最大值）最小compact大小（128MB）的总大小最小的一个子集合。&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h2 id="minor-compact和-major-compact">minor compact和 major compact&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>minor compact&lt;/strong>：将store 中 相邻的 flie 合并为一个大的 file，只用来做部分文件的合并操作以及包括minVersion=0并且设置ttl的过期版本清理，不做任何删除数据、多版本数据的清理工作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>major compact&lt;/strong>：对Region下的HStore下的所有StoreFile执行合并操作，会做删除数据，多版本数据清理工作，最终的结果是整理合并出一个文件。&lt;/p>
&lt;p>major compaction的判断条件如下（满足任意一个）：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>用户强制执行major compaction;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>长时间没有进行compact（CompactionChecker的判断条件2）且候选文件数小于hbase.hstore.compaction.max（默认10）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Store中含有Reference文件，Reference文件是split region产生的临时文件，只是简单的引用文件，一般必须在compact过程中删除。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>如果不满足major compaction条件，就必然为minor compaction。&lt;/p>
&lt;h2 id="compact-线程池选择">compact 线程池选择&lt;/h2>
&lt;p>compact 有 largeCompaction、smallCompaction这两个线程池负责处理compact 请求。&lt;/p>
&lt;ul>
&lt;li>largeCompaction (longCompaction)：大文件合并线程，当合并的文件总大小大于阈值(throttlePoint)时处理；&lt;/li>
&lt;li>smallCompaction (shortCompaction)：小文件合并线程池。处理合并文件总大小小于阈值时的情况。&lt;/li>
&lt;/ul>
&lt;p>大小合并的阈值（throttlePoint）由参数&lt;code>hbase.regionserver.thread.compaction.throttle&lt;/code>决定，没有设置的话，由：&lt;code>2 * &amp;quot;hbase.hstore.compaction.max&amp;quot; * &amp;quot;hbase.hregion.memstore.flush.size&amp;quot;&lt;/code>， 默认的2.5GB。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java"> &lt;span class="n">throttlePoint&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.regionserver.thread.compaction.throttle&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">maxFilesToCompact&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">storeConfigInfo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMemStoreFlushSize&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="compact过程">Compact过程&lt;/h2>
&lt;p>源码&lt;code>HStore::compact()&lt;/code>中，具体流程如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>分别读出待合并hfile文件的KV，并顺序写到位于./tmp目录下的临时文件中&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将临时文件移动到对应region的数据目录&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将compaction的输入文件路径和输出文件路径封装为KV写入WAL日志，并打上compaction标记，最后强制执行sync&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将对应region数据目录下的compaction输入文件全部删除&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>上述四个步骤看起来简单，但实际是很严谨的，具有很强的容错性和完美的幂等性：&lt;/p>
&lt;p>A. 如果RS在步骤2之前发生异常，本次compaction会被认为失败，如果继续进行同样的compaction，上次异常对接下来的compaction不会有任何影响，也不会对读写有任何影响。唯一的影响就是多了一份多余的数据。&lt;/p>
&lt;p>B. 如果RS在步骤2之后、步骤3之前发生异常，同样的，仅仅会多一份冗余数据。&lt;/p>
&lt;p>C. 如果在步骤3之后、步骤4之前发生异常，RS在重新打开region之后首先会从WAL中看到标有compaction的日志，因为此时输入文件和输出文件已经持久化到HDFS，因此只需要根据WAL移除掉compaction输入文件即可&lt;/p>
&lt;p>in-memory Compaction策略
当一个active segment被flush到pipeline中之后，后台会触发一个任务对pipeline中的数据进行合并。合并任务会对pipeline中所有segment进行scan，将他们的索引合并为一个。有三种合并策略可供选择：Basic,Eager,Adaptive。
Basic compaction策略和Eager compaction策略的区别在于如何处理cell数据。Basic compaction不会清理多余的数据版本，这样就不需要对cell的内存进行拷贝。而Eager compaction会过滤重复的数据，并清理多余的版本，这意味着会有额外的开销：例如如果使用了MSLAB存储cell数据，就需要把经过清理之后的cell从旧的MSLAB拷贝到新的MSLAB。basic适用于所有写入模式，eager则主要针对数据大量淘汰的场景：例如消息队列、购物车等。
Adaptive策略则是根据数据的重复情况来决定是否使用Eager策略。在Adaptive策略中，首先会对待合并的segment进行评估，方法是在已经统计过不重复key个数的segment中，找出cell个数最多的一个，然后用这个segment的numUniqueKeys / getCellsCount得到一个比例，如果比例小于设定的阈值，则使用Eager策略，否则使用Basic策略。&lt;/p>
&lt;h2 id="compact流控">Compact流控&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.hstore.flush.throughput.lower.bound， 100M
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://www.cnblogs.com/cenyuhai/p/3746473.html">https://www.cnblogs.com/cenyuhai/p/3746473.html&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://cloud.tencent.com/developer/article/1005586">Hbase Region Split compaction 过程分析以及调优 - 云+社区 - 腾讯云&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>HBase MemStore 分析</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-memstore%E5%88%86%E6%9E%90/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-memstore%E5%88%86%E6%9E%90/</guid><description>&lt;h1 id="hbase-memstore-分析">HBase MemStore 分析&lt;/h1>
&lt;p>&lt;strong>Memstore Flush触发条件&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Memstore&lt;/strong>级别：当Region中任意一个MemStore的大小达到了上限（hbase.hregion.memstore.flush.size，默认128MB），会触发Memstore flush。&lt;/li>
&lt;li>&lt;strong>Region&lt;/strong>级别：当Region中所有Memstore的大小总和达到了上限（hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size，默认 2* 128M = 256M），会触发memstore flush, 此时会阻塞update操作。&lt;/li>
&lt;li>&lt;strong>Region Server&lt;/strong>级别：当一个RS中所有Memstore的大小总和达到了上限（hbase.regionserver.global.memstore.upperLimit ＊ hbase_heapsize，默认 40%的JVM内存使用量），会触发部分Memstore刷新。Flush顺序是按照Memstore由大到小执行，先Flush Memstore最大的Region，再执行次大的，直至总体Memstore内存使用量低于阈值（hbase.regionserver.global.memstore.lowerLimit ＊ hbase_heapsize，默认 38%的JVM内存使用量）。&lt;/li>
&lt;li>&lt;strong>WAL&lt;/strong>: 当一个Region Server中HLog数量达到上限（可通过参数hbase.regionserver.maxlogs配置）时，系统会选取最早的一个 HLog对应的一个或多个Region进行flush&lt;/li>
&lt;li>&lt;strong>定期刷新&lt;/strong>：默认周期为1小时，确保Memstore不会长时间没有持久化。为避免所有的MemStore在同一时间都进行flush导致的问题，定期的flush操作有20000左右的随机延时。&lt;/li>
&lt;li>手动执行flush：用户可以通过shell命令 flush ‘tablename’或者flush ‘region name’分别对一个表或者一个Region进行flush。&lt;/li>
&lt;/ol>
&lt;p>MemStore的最小flush单元是HRegion而不是单个MemStore。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="http://hbasefly.com/2019/10/18/hbase-memstore-evolution/">HBase内存管理之MemStore进化论 – 有态度的HBase/Spark/BigData&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase python client</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-python-client%E6%93%8D%E4%BD%9C/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-python-client%E6%93%8D%E4%BD%9C/</guid><description>&lt;h1 id="hbase-python-client">HBase python client&lt;/h1>
&lt;h2 id="介绍">介绍&lt;/h2>
&lt;p>hbase 提供thrift接口，python可通过该接口和hbase通信。happybase是python基于thrift协议的一个hbase客户端库，其配置使用简单。使用步骤如下：&lt;/p>
&lt;h2 id="happybase-使用">happybase 使用&lt;/h2>
&lt;ol>
&lt;li>启动hbase master 节点上的thrift接口服务：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ bin/hbase thrift start
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>thrift默认端口是9090。&lt;/p>
&lt;ol start="2">
&lt;li>
&lt;p>安装happybase&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ pip install happybase
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>python&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="kn">import&lt;/span> &lt;span class="nn">happybase&lt;/span>
&lt;span class="n">hbase_host&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;10.0.48.219&amp;#39;&lt;/span>
&lt;span class="n">conn&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">happybase&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Connection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hbase_host&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nb">print&lt;/span> &lt;span class="n">conn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tables&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">conn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">create_table&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;table_name&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;cf1&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">dict&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="s1">&amp;#39;cf2&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">dict&lt;/span>&lt;span class="p">()})&lt;/span>
&lt;span class="n">t1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">table&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;table_name&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">put&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;row-key-1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;cf1:name1&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="s1">&amp;#39;value1&amp;#39;&lt;/span>&lt;span class="p">})&lt;/span>
&lt;span class="c1">#&lt;/span>
&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">row&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;row-key-1&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">delete&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;row-key-1&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;span class="s1">批量
&lt;/span>&lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;span class="n">b&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">t1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">batch&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">b&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">put&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="n">b&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">send&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol>
&lt;h2 id="常见问题">常见问题&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>TTransportException: TTransportException(message=&amp;lsquo;TSocket read 0 bytes&amp;rsquo;, type=4)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>原因&lt;/strong>：thrift 的server端和client端的协议不匹配造成的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>解决&lt;/strong>：&lt;/p>
&lt;p>修改hbase-site.xml，禁用TFramedTransport和TCompactProtocol功能，即：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml"> &lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.thrift.framed&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>false&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.thrift.compact&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>false&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase Region Split</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-split/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-split/</guid><description>&lt;h1 id="hbase-region-split">HBase Region Split&lt;/h1>
&lt;h2 id="split-作用">split 作用&lt;/h2>
&lt;p>在 HBase 中，split 其实是进行 sharding 的一种技术手段，通过 HBase 的 split 条件和 split 策略，将 region 进行合理的 split，再通过 HBase 的 balance 策略，将分裂的 region 负载均衡到各个 regionserver 上，最大化的发挥分布式系统的优点。HBase 这种自动的 sharding 技术比传统的数据库 sharding 要省事的多，减轻了维护的成本，但是这样也会给 HBase 带来额外的 IO 开销，因此在很多系统中如果能很好的预计 rowkey 的分布和数据增长情况，可以通过预先分区，事先将 region 分配好，再将 HBase 的自动分区禁掉。&lt;/p>
&lt;h2 id="split-触发条件">split 触发条件&lt;/h2>
&lt;ul>
&lt;li>自动&lt;/li>
&lt;li>手动&lt;/li>
&lt;/ul>
&lt;h2 id="split-策略">split 策略&lt;/h2>
&lt;h2 id="步骤">步骤&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">private&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">flushRegion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kd">final&lt;/span> &lt;span class="n">Region&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">emergencyFlush&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">forceFlushAllStores&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">synchronized&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">regionsInQueue&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">FlushRegionEntry&lt;/span> &lt;span class="n">fqe&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">regionsInQueue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">remove&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// Use the start time of the FlushRegionEntry if available
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">fqe&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">emergencyFlush&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// Need to remove from region from delay queue. When NOT an
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// emergencyFlush, then item was removed via a flushQueue.poll.
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">flushQueue&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">remove&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">fqe&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">lock&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">readLock&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">lock&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">notifyFlushRequest&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">emergencyFlush&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">FlushResult&lt;/span> &lt;span class="n">flushResult&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">flush&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">forceFlushAllStores&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">shouldCompact&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">flushResult&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">isCompactionNeeded&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// We just want to check the size
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">shouldSplit&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">((&lt;/span>&lt;span class="n">HRegion&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">checkSplit&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">shouldSplit&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">server&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compactSplitThread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">requestSplit&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">region&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">shouldCompact&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">server&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">compactSplitThread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">requestSystemCompaction&lt;/span>&lt;span class="o">(&lt;/span>
&lt;span class="n">region&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Thread&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">currentThread&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">DroppedSnapshotException&lt;/span> &lt;span class="n">ex&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>HBase 将整个切分过程包装成了一个事务，意图能够保证切分事务的原子性。整个分裂事务过程分为三个阶段：prepare – execute – (rollback) ，操作模版如下：&lt;/p>
&lt;ul>
&lt;li>prepare 阶段：&lt;/li>
&lt;/ul>
&lt;p>在内存中初始化两个子 region，具体是生成两个 HRegionInfo 对象，包含 tableName、regionName、startkey、endkey 等。同时会生成一个 transaction journal，这个对象用来记录切分的进展，具体见 rollback 阶段。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>execute 阶段：&lt;/p>
&lt;p>切分的核心操作。见下图（来自&lt;a href="http://zh.hortonworks.com/blog/apache-hbase-region-splitting-and-merging/">Hortonworks&lt;/a>）：&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-53-10-image-20190430151418404.png" alt="image-20190430151418404">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>
&lt;p>regionserver 更改 ZK 节点 /region-in-transition 中该 region 的状态为 SPLITING。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>master 通过 watch 节点/region-in-transition 检测到 region 状态改变，并修改内存中 region 的状态，在 master 页面 RIT 模块就可以看到 region 执行 split 的状态信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在父存储目录下新建临时文件夹.split 保存 split 后的 daughter region 信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>关闭 parent region：parent region 关闭数据写入并触发 flush 操作，将写入 region 的数据全部持久化到磁盘。此后短时间内客户端落在父 region 上的请求都会抛出异常 NotServingRegionException。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>核心分裂步骤：在.split 文件夹下新建两个子文件夹，称之为 daughter A、daughter B，并在文件夹中生成 reference 文件，分别指向父 region 中对应文件。这个步骤是所有步骤中最核心的一个环节，生成 reference 文件日志如下所示：&lt;/p>
&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2019-12-24-09-38-29-image.png" title="" alt="" data-align="center">
&lt;/li>
&lt;li>
&lt;p>父 region 分裂为两个子 region 后，将 daughter A、daughter B 拷贝到 HBase 根目录下，形成两个新的 region。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>父 region 通知修改 hbase.meta 表后下线，不再提供服务。下线后 parent region 在 meta 表中的信息并不会马上删除，而是标注 split 列、offline 列为 true，并记录两个子 region&lt;/p>
&lt;/li>
&lt;li>
&lt;p>开启 daughter A、daughter B 两个子 region。通知修改 hbase.meta 表，正式对外提供服务。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>rollback&lt;/p>
&lt;p>如果 execute 阶段出现异常，则执行 rollback 操作。为了实现回滚，整个切分过程被分为很多子阶段，回滚程序会根据当前进展到哪个子阶段清理对应的垃圾数据。代码中使用 JournalEntryType 来表征各个子阶段，具体见下图：&lt;/p>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-52-59-image-20190430151907154.png" alt="image-20190430151907154">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="自定义拆分策略">自定义拆分策略&lt;/h2>
&lt;p>您可以使用自定义 RegionSplitPolicy（HBase 0.94+）重写默认拆分策略。通常，自定义拆分策略应该扩展 HBase 的默认拆分策略： IncreasingToUpperBoundRegionSplitPolicy。&lt;/p>
&lt;p>该策略可以通过 HBase 配置或者也可以基于每个表在全局范围内进行设置。&lt;/p>
&lt;p>在 hbase-site.xml 中全局配置拆分策略：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.region.split.policy&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用 Java API 在表上配置拆分策略：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">HTableDescriptor tableDesc = new HTableDescriptor(&amp;#34;test&amp;#34;);
tableDesc.setValue(HTableDescriptor.SPLIT_POLICY, ConstantSizeRegionSplitPolicy.class.getName());
tableDesc.addFamily(new HColumnDescriptor(Bytes.toBytes(&amp;#34;cf1&amp;#34;)));
admin.createTable(tableDesc);
----
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用 HBase Shell 在表上配置拆分策略：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">hbase&amp;gt; create &lt;span class="s1">&amp;#39;test&amp;#39;&lt;/span>, &lt;span class="o">{&lt;/span>&lt;span class="nv">METADATA&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="o">{&lt;/span>&lt;span class="s1">&amp;#39;SPLIT_POLICY&amp;#39;&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="s1">&amp;#39;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;#39;&lt;/span>， &lt;span class="o">}}&lt;/span>,&lt;span class="o">{&lt;/span>&lt;span class="nv">NAME&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="s1">&amp;#39;cf1&amp;#39;&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>该策略可以通过使用的 HBaseConfiguration 或按表进行全局设置：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">myHtd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...;&lt;/span>
&lt;span class="n">myHtd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">SPLIT_POLICY&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">MyCustomSplitPolicy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>该&lt;code>DisabledRegionSplitPolicy&lt;/code>策略阻止手动区域拆分。&lt;/p>
&lt;p>在线修改 split 策略&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">hbase&amp;gt; &lt;span class="nv">t&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;test_66_snappy5&amp;#34;&lt;/span>
hbase&amp;gt; disable t&lt;span class="p">;&lt;/span> alter t, &lt;span class="o">{&lt;/span>&lt;span class="nv">METADATA&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="o">{&lt;/span>&lt;span class="s1">&amp;#39;SPLIT_POLICY&amp;#39;&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="s1">&amp;#39;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;MAX_FILESIZE&amp;#39;&lt;/span> &lt;span class="o">=&lt;/span>&amp;gt; &lt;span class="m">214748364800&lt;/span> &lt;span class="o">}}&lt;/span> &lt;span class="p">;&lt;/span> &lt;span class="nb">enable&lt;/span> t
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/39648692">https://zhuanlan.zhihu.com/p/39648692&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.tencent.com/developer/article/1005586">https://cloud.tencent.com/developer/article/1005586&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.jianshu.com/p/f9abe7ddf5a1">HBase 原理–所有 Region 切分的细节都在这里了 - 简书&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://andr-robot.github.io/HBase%E4%B8%ADRegion%E7%9A%84%E5%88%87%E5%88%86/">https://andr-robot.github.io/HBase%E4%B8%ADRegion%E7%9A%84%E5%88%87%E5%88%86/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.csdn.net/u010039929/article/details/74295869">Hbase Split 解析_大数据_Kuzury-CSDN 博客&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase Region 自动拆分策略</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase_split_policy/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase_split_policy/</guid><description>&lt;h1 id="hbase-region-自动拆分策略">HBase Region 自动拆分策略&lt;/h1>
&lt;p>HBase-2.x支持7种Region自动拆分Region的策略，类图如下:&lt;/p>
&lt;p>&lt;img src="assets/2020-04-02-17-31-02-image.png" alt="">&lt;/p>
&lt;p>设置自动拆分策略的关键配置如下:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.regionserver.region.split.policy
description: Region自动拆分的策略
default:
HBase-1.2.x: org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy
HBase-2.x: org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy
option:
org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy
org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy
org.apache.hadoop.hbase.regionserver.BusyRegionSplitPolicy (HBase-2.x Only)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>配置方法：&lt;/p>
&lt;ul>
&lt;li>在hbase-site.xml中配置，例如：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.region.split.policy&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在HBase Configuration中配置&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">HBaseConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">set&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.regionserver.region.split.policy&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在创建表的时候配置
Region的拆分策略需要根据表的属性来合理的配置，所以建议不要使用前两种方法来配置拆分策略，关于在建表的时候怎么配置，会在下面解释每种策略的时候说明。&lt;/li>
&lt;/ul>
&lt;p>接下来将详细介绍这7种Region自动拆分的策略。&lt;/p>
&lt;h2 id="1-constantsizeregionsplitpolicy">1. ConstantSizeRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述">策略描述&lt;/h3>
&lt;p>这种策略非常简单，只要Region的大小达到了&lt;code>hbase.hregion.max.filesize&lt;/code>所定义的大小，就进行拆分。&lt;/p>
&lt;h3 id="相关参数">相关参数&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.hregion.max.filesize
    default: 10737418240 (10GB)
    description: 当一个Region的容量达到这个配置定义的大小后,就会拆分Region
hbase.server.thread.wakefrequency
    default: 10000 (10s)
    description: 检测Region的大小是否超过限制的时间间隔
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="部分源码">部分源码&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="cm">/** Conf key for the max file size after which we split the region */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">HREGION_MAX_FILESIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hbase.hregion.max.filesize&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="cm">/** Default maximum file size */&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">DEFAULT_MAX_FILE_SIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">10&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">1024&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">1024&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">1024L&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm">
&lt;/span>&lt;span class="cm">* 获取拆分上限值
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="kd">protected&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">configureForRegion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HRegion&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">getConf&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">desc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTableDesc&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">desc&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// 如果用户在建表时指定了该表的单个Region的上限, 取用户定义的这个值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">desiredMaxFileSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">desc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMaxFileSize&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果用户没有定义, 取&amp;#39;hbase.hregion.max.filesize&amp;#39;这个配置定义的值, 如果这个配置没有定义, 取默认值 10G
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">desiredMaxFileSize&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">desiredMaxFileSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HREGION_MAX_FILESIZE&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DEFAULT_MAX_FILE_SIZE&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm">
&lt;/span>&lt;span class="cm">* 判断是否进行拆分
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="kd">protected&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">shouldSplit&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">force&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">shouldForceSplit&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">foundABigStore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Store&lt;/span> &lt;span class="n">store&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getStores&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// 如果有任何一个Region此时不能被拆分(例如还有一些代码或者线程在访问它), 那么返回false
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">((!&lt;/span>&lt;span class="n">store&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">canSplit&lt;/span>&lt;span class="o">()))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果Region的大小已经大于desiredMaxFileSize这个值, 返回true
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">store&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getSize&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">desiredMaxFileSize&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">foundABigStore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">foundABigStore&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">force&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="c1">// 只要shouldSplit()方法返回true, 就进行Region的拆分
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="拆分效果">拆分效果&lt;/h3>
&lt;p>经过这种策略的拆分后，Region的大小是均匀的，例如一个10G的Region，拆分为两个Region后，这两个新的Region的大小是相差不大的，理想状态是每个都是5G。&lt;/p>
&lt;h3 id="设置方法">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;tableName&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要配置或者不配置
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMaxFileSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addFamily&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="n">admin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2-increasingtoupperboundregionsplitpolicy">2. IncreasingToUpperBoundRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-1">策略描述&lt;/h3>
&lt;p>这种拆分策略是HBase-1.2.x的默认使用的拆分策略，Region的前几次拆分的阈值不是固定的数值，是需要进行计算得到，计算过程在源码中说明。&lt;/p>
&lt;h3 id="相关配置">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.hregion.memstore.flush.size
    default: 134217728 (128MB)
    description: 如果Memstore的大小超过这个字节数,它将被刷新到磁盘.
hbase.increasing.policy.initial.size
    default: none
    description: IncreasingToUpperBoundRegionSplitPolicy拆分策略下用于计算Region阈值的一个初始值
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="部分源码-1">部分源码&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">protected&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">getSizeToCheck&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kd">final&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">0&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">100&lt;/span>
&lt;span class="o">?&lt;/span> &lt;span class="n">getDesiredMaxFileSize&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">:&lt;/span> &lt;span class="n">Math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">min&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">getDesiredMaxFileSize&lt;/span>&lt;span class="o">(),&lt;/span>
&lt;span class="n">initialSize&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果表目前的Region个数为0或者大于100，那么Region拆分上限值是10G，因为getDesiredMaxFileSize()方法是父类ConstantSizeRegionSplitPolicy的方法，而我们上面分析过，上限大小默认是10G。&lt;/p>
&lt;p>如果表目前的Region个数在[1,100]之间，那么使用以下公式来确定Region的上限大小:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">Math.min(
getDesiredMaxFileSize(),
initialSize * tableRegionsCount * tableRegionsCount * tableRegionsCount
)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>initialSize的计算过程如下:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">HREGION_MEMSTORE_FLUSH_SIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hbase.hregion.memstore.flush.size&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="n">DEFAULT_MEMSTORE_FLUSH_SIZE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">1024&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">1024&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">128L&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">protected&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">configureForRegion&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HRegion&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">getConf&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="c1">// 如果配置了&amp;#39;hbase.increasing.policy.initial.size&amp;#39;, 取这个值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">initialSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.increasing.policy.initial.size&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">initialSize&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果设置了MemStoreFlushSize, initialSize的值为该值 * 2
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">desc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">region&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getTableDesc&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">desc&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">initialSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">desc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMemStoreFlushSize&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="c1">// 如果用户没有设置MemStoreFlushSize,配置文件中也没有&amp;#39;hbase.increasing.policy.initial.size&amp;#39;这个配置
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="c1">// 那么initialSize = 2 * hbase.hregion.memstore.flush.size的值
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">initialSize&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">initialSize&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLong&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HConstants&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HREGION_MEMSTORE_FLUSH_SIZE&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">DEFAULT_MEMSTORE_FLUSH_SIZE&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>根据以上内容我们可以得知，在默认情况，即我们什么都没有配置的情况下，使用IncreasingToUpperBoundRegionSplitPolicy策略拆分Region的过程是:&lt;/p>
&lt;ul>
&lt;li>某张表刚开始只有一个Region, 此时&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">tableRegionsCount = 1
initialSize = 2 * 128M = 256M
getDesiredMaxFileSize() = 10G
min(getDesiredMaxFileSize(), initialSize * tableRegionsCount * tableRegionsCount * tableRegionsCount) = min(10G, 256M) = 256M
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>即当第一个Region达到256M的时候开始拆分&lt;/p>
&lt;ul>
&lt;li>拆分后这张表有两个Region&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">tableRegionsCount = 2
initialSize = 2 * 128M = 256M
getDesiredMaxFileSize() = 10G
min(getDesiredMaxFileSize(), initialSize * tableRegionsCount * tableRegionsCount * tableRegionsCount)
= min(10G, 2 * 2 * 2 * 256M)
= min(10G, 2G)
= 2G
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>即当Region大小达到2GB时开始拆分&lt;/p>
&lt;ul>
&lt;li>以此类推，当表有3个Region的时候，Region的最大容量为6.75G&lt;/li>
&lt;li>当表有4个Region的时候，计算出来的结果大于10GB，所以使用10GB作为以后的拆分上限&lt;/li>
&lt;/ul>
&lt;p>总结一下就是，使用IncreasingToUpperBoundRegionSplitPolicy策略，Region最大容量为:
&lt;code>256M -&amp;gt; 2GB -&amp;gt; 6.75GB -&amp;gt; 10GB -&amp;gt; 10GB -&amp;gt; ...&lt;/code>&lt;/p>
&lt;h3 id="设置方法-1">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;tableName&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要配置或者不配置
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.increasing.policy.initial.size&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;1048576000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMaxFileSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMemStoreFlushSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addFamily&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="n">admin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="拆分效果-1">拆分效果&lt;/h3>
&lt;p>均匀拆分&lt;/p>
&lt;h2 id="3-keyprefixregionsplitpolicy">3. KeyPrefixRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-2">策略描述&lt;/h3>
&lt;p>除了简单粗暴地根据大小来拆分，我们还可以自己定义拆分点。KeyPrefixRegionSplitPolicy是IncreasingToUpperBoundRegionSplitPolicy的子类，在前者的基础上增加了对拆分点(splitPoint，拆分点就是Region被拆分处的rowkey)的定义。它保证了有相同前缀的rowkey不会被拆分到两个不同的Region里面。&lt;/p>
&lt;h3 id="相关配置-1">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">KeyPrefixRegionSplitPolicy.prefix_length
### 注意，有的博客中这个配置是
`prefix_split_key_policy.prefix_length
# 这个配置在HBase-1.2.x版本中已经标志为 Deprecated
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以上参数指定了在rowkey中，取前几个字符作为前缀，例如这个设置这个值为5，那么在rowkey中，如果前5个字符是相同的，拆分后也一定会在一个Region中。&lt;/p>
&lt;p>&lt;strong>拆分效果&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>普通的拆分&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-04-02-17-45-44-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>按照Rowkey前缀拆分&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-04-02-17-46-10-image.png" alt="">&lt;/p>
&lt;h3 id="设置方法-2">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;KeyPrefixRegionSplitPolicy.prefix_length&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;5&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要配置或者不配置
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.increasing.policy.initial.size&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;1048576000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMaxFileSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setMemStoreFlushSize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">1048576000&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">addFamily&lt;/span>&lt;span class="o">(...)&lt;/span>
&lt;span class="n">admin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">createTable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>说明&lt;/strong>&lt;/p>
&lt;p>KeyPrefixRegionSplitPolicy是IncreasingToUpperBoundRegionSplitPolicy类的子类，就是按照rowkey的前缀去拆分Region，但是什么时候拆分，原Region容量的最大值是多少还是需要使用IncreasingToUpperBoundRegionSplitPolicy的方法去计算。SteppingSplitPolicy、DelimitedKeyPrefixRegionSplitPolicy、BusyRegionSplitPolicy (HBase-2.x Only)，他们获取Region的拆分阈值的方式都是继承自IncreasingToUpperBoundRegionSplitPolicy。&lt;/p>
&lt;h3 id="适用场景">适用场景&lt;/h3>
&lt;p>如果你的所有数据都只有一两个前缀，那么采用默认的策略较好。
如果你的前缀划分的比较细，你的查询就比较容易发生跨Region查询的情况，此时采用KeyPrefixRegionSplitPolicy较好。
所以这个策略适用的场景是：&lt;/p>
&lt;ul>
&lt;li>数据有多种前缀。&lt;/li>
&lt;li>查询多是针对前缀，较少跨越多个前缀来查询数据。&lt;/li>
&lt;/ul>
&lt;h2 id="4-delimitedkeyprefixregionsplitpolicy">4. DelimitedKeyPrefixRegionSplitPolicy&lt;/h2>
&lt;h3 id="拆分策略">拆分策略&lt;/h3>
&lt;p>该策略也是继承自IncreasingToUpperBoundRegionSplitPolicy，它也是根据你的rowkey前缀来进行拆分的。唯一的不同就是：KeyPrefixRegionSplitPolicy是根据rowkey的固定前几位字符来进行判断，而DelimitedKeyPrefixRegionSplitPolicy是根据分隔符来判断的。&lt;/p>
&lt;p>在有些系统中rowkey的前缀可能不一定都是定长的，比如你拿服务器的名字来当前缀，有的服务器叫host12有的叫host1。这些场景下严格地要求所有前缀都定长可能比较难，而且这个定长如果未来想改也不容易。DelimitedKeyPrefixRegionSplitPolicy就给了你一个定义长度字符前缀的自由。&lt;/p>
&lt;h3 id="相关配置-2">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">DelimitedKeyPrefixRegionSplitPolicy.delimiter
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用该参数定义的分隔符分隔rowkey，分隔后的前部分相同的rowkey拆分后一定会在一个Region中。&lt;/p>
&lt;h3 id="配置方法">配置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.DelimitedKeyPrefixRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;DelimitedKeyPrefixRegionSplitPolicy.delimiter&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;_&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">...&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="拆分效果-2">拆分效果&lt;/h3>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-04-02-17-47-18-image.png" alt="">&lt;/p>
&lt;h2 id="5-steppingsplitpolicy">5. SteppingSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-3">策略描述&lt;/h3>
&lt;p>这种策略和&lt;code>IncreasingToUpperBoundRegionSplitPolicy&lt;/code>策略很相似，但更简单，第一个Region容量的上限为256M，之后都是10G，这个策略考虑到&lt;code>IncreasingToUpperBoundRegionSplitPolicy&lt;/code>会多拆分几个Region(256M -&amp;gt; 2G -&amp;gt; 6.75G -&amp;gt; 10G)，所以进行了简化，它的源码只有一个方法，其他都是继承自&lt;code>IncreasingToUpperBoundRegionSplitPolicy&lt;/code>类&lt;/p>
&lt;h3 id="源码">源码&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kd">protected&lt;/span> &lt;span class="kt">long&lt;/span> &lt;span class="nf">getSizeToCheck&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="kd">final&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">tableRegionsCount&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">1&lt;/span> &lt;span class="o">?&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">initialSize&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">getDesiredMaxFileSize&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="设置方法-3">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="6-busyregionsplitpolicy-hbase-2x-only">6. BusyRegionSplitPolicy (HBase-2.x Only)&lt;/h2>
&lt;h3 id="策略描述-4">策略描述&lt;/h3>
&lt;p>此前的拆分策略都没有考虑热点问题。所谓热点问题就是数据库中的Region被访问的频率并不一样，某些Region在短时间内被访问的很频繁，承载了很大的压力，这些Region就是热点Region。&lt;/p>
&lt;h3 id="相关配置-3">相关配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.busy.policy.blockedRequests
default: 0.2f
description: 请求阻塞率，即请求被阻塞的严重程度。
取值范围是[0.0, 1.0]，默认是0.2，即20%的请求被阻塞的意思。
hbase.busy.policy.minAge
default: 600000 (10min)
description: 拆分最小年龄。
当Region的年龄比这个小的时候不拆分，这是为了防止在判断是否要拆分的时候出现了短时间的访问频率波峰，结果没必要拆分的Region被拆分了，因为短时间的波峰会很快地降回到正常水平。单位毫秒，默认值是600000，即10分钟。
hbase.busy.policy.aggWindow
default: 300000 (5min)
description: 计算是否繁忙的时间窗口，单位毫秒，默认值是300000，即5分钟。
用以控制计算的频率。
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>如何确定为热点Region(Busy Region)&lt;/strong>&lt;/p>
&lt;p>如果&amp;quot;当前时间 – 上次检测时间&amp;quot; &amp;gt;= hbase.busy.policy.aggWindow，则进行如下计算：&lt;/p>
&lt;p>请求的被阻塞率(aggBlockedRate) = 这段时间被阻塞的请求 / 这段时间的总请求&lt;/p>
&lt;p>如果 aggBlockedRate &amp;gt; hbase.busy.policy.blockedRequests 且该Region的 hbase.busy.policy.minAge &amp;gt; 10min，则判断该Region为Busy Region&lt;/p>
&lt;p>当Region被判定为Busy Region，就会被拆分。&lt;/p>
&lt;h3 id="设置方法-4">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.BusyRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="c1">// 以下配置根据需要适当修改
&lt;/span>&lt;span class="c1">&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.busy.policy.blockedRequests&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;0.2&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.busy.policy.minAge&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;600000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;hbase.busy.policy.aggWindow&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="s">&amp;#34;300000&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="适用场景-1">适用场景&lt;/h3>
&lt;p>如果你的系统常常会出现热点Region，而你对性能有很高的追求，那么这种策略可能会比较适合你。它会通过拆分热点Region来缓解热点Region的压力，但是根据热点来拆分Region也会带来很多不确定性因素，因为你也不知道下一个被拆分的Region是哪个。&lt;/p>
&lt;h2 id="7-disabledregionsplitpolicy">7. DisabledRegionSplitPolicy&lt;/h2>
&lt;h3 id="策略描述-5">策略描述&lt;/h3>
&lt;p>禁止Region拆分，这个策略是极少使用的，因为就算是你按照自己数据的特性在建表的时候合理的进行了预拆分（即还没有写入的数据的时候就已经手动分好了Region），但是后续随着数据的持续写入，我们自己预先分好的Region的大小也一定会达到阈值，那时候还是要依靠HBase的自动拆分策略去拆分Region。&lt;/p>
&lt;p>当然，这种策略也有它的用途：&lt;/p>
&lt;p>假如我们有一批数据，根据它的用途我们知道它分为几个Region或者在什么时候拆分最合适，例如有一批数据，rowkey是手机号，而且每个手机号码前缀下（手机号码前三位）的数据量都差不多，而且这批数据主要是用于查询，要求查询的性能好一些，而且这批数据是一批静态数据，即一次存入后以后不会再加入新数据，而且这批数据的量很大，那么此时预先设置好拆分点（比如每个相同的手机号前缀一定要分到一个Region下），设置拆分策略为禁止拆分，然后导入数据即可。&lt;/p>
&lt;p>在使用禁止自动拆分策略的诸多条件中，数据量大是很重要的一点，因为当使用自动拆分时，无论你设置了哪种拆分策略，一开始数据进入HBase的时候都只会往一个Region塞数据。必须要等到一个Region的大小膨胀到某个阀值的时候才会根据拆分策略来进行拆分。但是当大量的数据涌入的时候，可能会出现一边拆分一边写入大量数据的情况，由于拆分要占用大量IO，此时HBase数据库的压力是很大的。&lt;/p>
&lt;h3 id="设置方法-5">设置方法&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">tableDesc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">TableName&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">valueOf&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">tableNameStr&lt;/span>&lt;span class="o">));&lt;/span>
&lt;span class="n">tableDesc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setRegionSplitPolicyClassName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>HBase RPC</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-rpc/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-rpc/</guid><description>&lt;h1 id="hbase-rpc">HBase RPC&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>HBase主要包含Master，RegionServer，Client 3个组件组成。组件之间通过Rpc 和 zk进行通信。RPC通信功能主要基于Protobuf和NIO这两个组件来实现，&lt;/p>
&lt;p>&lt;img src="assets/2020-01-07-11-42-09-image.png" alt="">&lt;/p>
&lt;h2 id="配置参数">配置参数&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>hbase.ipc.server.listen.queue.size :&lt;/p>
&lt;p>存放连接请求的等待队列长度,默认与ipc.server.listen.queue.size参数值相同，为128个。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.regionserver.handler.count&lt;/p>
&lt;p>regionserver 的 rpc请求队列处理线程数，默认为 30&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.master.handler.count&lt;/p>
&lt;p>master rpc请求队列处理线程数，默认为 25&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.read.threadpool.size&lt;/p>
&lt;p>Reader线程数，默认为10个。reader 的个数决定了从网络 io 里读取数据的速度也就是网络吞吐量&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.max.callqueue.size&lt;/p>
&lt;p>单个消费队列所允许的存储空间上限(默认为1GB)，超过该上限客户端会抛出以下异常&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.max.callqueue.length&lt;/p>
&lt;p>单个消费队列的长度限制，默认值为10倍的Handler数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.callqueue.handler.factor&lt;/p>
&lt;p>该参数用于决定消费队列的个数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.callqueue.read.share&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase.ipc.server.read.threadpool.size
默认： 10
Reader线程数
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="结构">结构&lt;/h2>
&lt;p>RPC报文&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-11-06-09-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>请求头&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="assets/2020-01-07-11-06-34-image.png" alt="">&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-protobuf" data-lang="protobuf">&lt;span class="kd">message&lt;/span> &lt;span class="nc">RequestHeader&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">uint32&lt;/span> &lt;span class="n">call_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="n">RPCTInfo&lt;/span> &lt;span class="n">trace_info&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="n">method_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">bool&lt;/span> &lt;span class="n">request_param&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="assets/2020-01-07-11-07-17-image.png" alt="">&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-protobuf" data-lang="protobuf">&lt;span class="kd">message&lt;/span> &lt;span class="nc">ResponseHeader&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">optional&lt;/span> &lt;span class="kt">uint32&lt;/span> &lt;span class="n">call_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="rpc实现">RPC实现&lt;/h2>
&lt;p>RpcServer配置三个队列：&lt;/p>
&lt;ul>
&lt;li>callQueue&lt;/li>
&lt;/ul>
&lt;p>绝大部分Call请求存在该队列中：callQueue上maxQueueLength为${ipc.server.max.callqueue.length},默认是${hbase.master.handler.count}*DEFAULT_MAX_CALLQUEUE_LENGTH_PER_HANDLER，目前0.95.1中，每个Handler上CallQueue的最大个数默认值(DEFAULT_MAX_CALLQUEUE_LENGTH_PER_HANDLER)为10。&lt;/p>
&lt;ul>
&lt;li>PriorityQueue&lt;/li>
&lt;/ul>
&lt;p>如果设置priorityHandlerCount的个数，会创建与callQueue相当容量的queue存储Call，该优先级队列对应的Handler的个数由rpcServer实例化时传入。&lt;/p>
&lt;ul>
&lt;li>replicationQueue&lt;/li>
&lt;/ul>
&lt;p>由于RpcServer由HMaster和RegionServer共用，该功能仅为RegionServer提供，queue的大小为${ipc.server.max.callqueue.size}指定，默认为1024&lt;em>1024&lt;/em>1024，handler的个数为hbase.regionserver.replication.handler.count。&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-11-18-46-image.png" alt="">&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-11-29-06-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>rpc-client&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-12-34-08-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>rpc-server&lt;/li>
&lt;/ul>
&lt;p>rpc-server基于nio 的reactor模型设计，其主要流程如下：&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-12-34-46-image.png" alt="">&lt;/p>
&lt;ul>
&lt;li>scheduler&lt;/li>
&lt;/ul>
&lt;p>hbase rpc实现了两种调度器（FifoRpcScheduler和SimpleRpcScheduler）。FifoRpcScheduler是master默认的调度器，直接将CallRunner对象放到线程池中去执行。而SimpleRpcScheduler是RS默认调度器，分成三种不同的executor，对于不同的请求，使用的不同的executor去执行。&lt;/p>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2020-01-07-12-35-19-image.png" alt="">&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://cloud.tencent.com/developer/article/1005560">Hbase 调优之 RPC - 云+社区 - 腾讯云&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.csdn.net/yangzishiw/article/details/78840107">https://blog.csdn.net/yangzishiw/article/details/78840107&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://www.binospace.com/index.php/in-depth-analysis-hbase-rpc-0-95-version-implementation-mechanism/">The internals of HBase Rpc (Protobuf) | Binospace&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://09itblog.site/?p=874">http://09itblog.site/?p=874&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase Scan</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-scan/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-scan/</guid><description>&lt;h1 id="hbase-scan">HBase Scan&lt;/h1>
&lt;h2 id="filter">Filter&lt;/h2>
&lt;ul>
&lt;li>过滤器是在get或者scan时候过滤结果用的. HBase中的过滤器被用户创建出来后会被序列化为可以网络传输的格式,然后被分发到各个RegionServer.然后在RegionServer中Filter被还原出来,这样在Scan遍历过程中,不满足条件的结果都不会被返回客户端，叫做谓语下推(predicate push down), 可以保证被过滤掉的数据不会被传送到客户端。&lt;/li>
&lt;li>所有的过滤器都要实现Filter接口.HBase同时还提供了FilterBase抽象类,它提供了Filter接口的默认实现&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-54-39-image-20190816095904279.png" alt="image-20190816095904279">&lt;/p>
&lt;h3 id="比较器">比较器&lt;/h3>
&lt;p>HBase的filter有四种比较器：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>binary&lt;/strong>：二进制比较器，如’binary:abc’，按字典排序跟’abc’进行比较&lt;/li>
&lt;li>&lt;strong>binaryprefix&lt;/strong>：二进制前缀比较器：如’binaryprefix:abc’，按字典顺序只跟’abc’比较前3个字符&lt;/li>
&lt;li>&lt;strong>regexstring&lt;/strong>：正则表达式比较器：如’regexstring:ab*yz’，按正则表达式匹配以ab开头，以yz结尾的值。这个比较器只能使用=、!=两个比较运算符。&lt;/li>
&lt;li>&lt;strong>substring&lt;/strong>：子串比较器：如’substring:abc123’，匹配以abc123开头的值。这个比较顺也只能使用=、!=两个比较运算符。&lt;/li>
&lt;/ul>
&lt;h3 id="比较运算符">比较运算符&lt;/h3>
&lt;ul>
&lt;li>LESS (&amp;lt;)&lt;/li>
&lt;li>LESS_OR_EQUAL (&amp;lt;=)&lt;/li>
&lt;li>EQUAL (=)&lt;/li>
&lt;li>NOT_EQUAL (!=)&lt;/li>
&lt;li>GREATER_OR_EQUAL (&amp;gt;=)&lt;/li>
&lt;li>GREATER (&amp;gt;)&lt;/li>
&lt;li>NO_OP (no operation)（不知道这个怎么用）&lt;/li>
&lt;/ul>
&lt;h3 id="singlecolumnvaluefilter">SingleColumnValueFilter&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1">#//&lt;/span>
hbase&amp;gt; scan ‘tweet0’, &lt;span class="o">{&lt;/span>&lt;span class="nv">FILTER&lt;/span>&lt;span class="o">=&lt;/span>&amp;gt;”SingleColumnValueFilter&lt;span class="o">(&lt;/span>‘info’,’pubtime’,&amp;gt;&lt;span class="o">=&lt;/span>,’binary:2014-11-08 19:26:27’&lt;span class="o">)&lt;/span> AND SingleColumnValueFilter&lt;span class="o">(&lt;/span>‘info’,’pubtime’,&amp;lt;&lt;span class="o">=&lt;/span>,’binary:2014-11-10 20:20:00’&lt;span class="o">)&lt;/span>”&lt;span class="o">}&lt;/span>
hbase&amp;gt; scan ‘tweet0’, &lt;span class="o">{&lt;/span>&lt;span class="nv">FILTER&lt;/span>&lt;span class="o">=&lt;/span>&amp;gt;”SingleColumnValueFilter&lt;span class="o">(&lt;/span>‘emotion’,’PB’,&lt;span class="o">=&lt;/span>,’binary:&lt;span class="se">\x&lt;/span>00&lt;span class="se">\x&lt;/span>00&lt;span class="se">\x&lt;/span>00&lt;span class="se">\x&lt;/span>05’&lt;span class="o">)&lt;/span>”, &lt;span class="nv">COLUMNS&lt;/span>&lt;span class="o">=&lt;/span>&amp;gt;&lt;span class="o">[&lt;/span>‘emotion:PB’&lt;span class="o">]}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>SingleColumnValueFilter 这个过滤器有6个参数：列族、列名、比较运算符、比较器和两个可选参数：filterIfColumnMissing和setLatestVersionOnly。&lt;/p>
&lt;ul>
&lt;li>filterIfColumnMissing：如果设置为true，则会把没有过滤器所指定列的行都过滤掉。默认值是false，所以看上去，当没有过滤器所指定的列时，过滤器不起作用。&lt;/li>
&lt;li>setLatestVersionOnly：如果设置为false，则除了检查最新版本，还会检查以前的版本。默认值是true，只检查最新版本的值。
这两个参数要么一起使用，要么都不使用。&lt;/li>
&lt;/ul>
&lt;h3 id="fuzzyrowfilter">FuzzyRowFilter&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="c1">// rowkey: 2016_06_22_beijing
&lt;/span>&lt;span class="c1">// 查找2016年什么时间去北京了和2012年什么时间去干什么了
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">par1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;2016_??_??_beijing&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]{&lt;/span>
&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>
&lt;span class="o">});&lt;/span>
&lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&lt;/span> &lt;span class="n">par2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&amp;gt;(&lt;/span>&lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toBytes&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;2012&amp;#34;&lt;/span>&lt;span class="o">),&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]{&lt;/span>
&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">0&lt;/span>
&lt;span class="o">});&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Pair&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="kt">byte&lt;/span>&lt;span class="o">[],&lt;/span> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">fuzzy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">asList&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">par1&lt;/span>&lt;span class="o">,&lt;/span>&lt;span class="n">par2&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">FuzzyRowFilter&lt;/span> &lt;span class="n">filter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">FuzzyRowFilter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">fuzzy&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">Scan&lt;/span> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Scan&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setFilter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">filter&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">scan &amp;#39;blog&amp;#39;, FILTER =&amp;gt; org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;00?&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x01&amp;#34;))))
scan &amp;#34;journalq:send_log&amp;#34;, {LIMIT=&amp;gt;10, STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xDA\x9F\x85\x17\xF7\xBDbr&amp;#34; }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0008????????0000000000000000????????????????&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x00\x01\x01\x01\x01\x01\x01\x01\x01\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01&amp;#34;)))) }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0008????????0000000000000000????????????????&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x00\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01&amp;#34;)))) }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0000&amp;#34;),Bytes.toBytes(&amp;#34;\x01\x01\x01\x01&amp;#34;)))), LIMIT=&amp;gt; 10 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x13\x00\x00\x01&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0000&amp;#34;),Bytes.toBytes(&amp;#34;\x01\x01\x01\x01&amp;#34;)))), LIMIT=&amp;gt; 1000 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x08\x00\x00\x01j\xC16=\x98\x03E\xD2\x02\xE1&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A&amp;#34;, LIMIT=&amp;gt;10 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x02\x00\x00\x01k\x0C\x168\x92\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xC2\x8Fl-\xD3\x04\xB5F(\x9F\x89\xED\x13\xDD\xE5!&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x8D\x00\x00\x01l#]\xAF)&amp;#34;, LIMIT=&amp;gt;10 }
scan &amp;#34;journalq:send_log&amp;#34;, {STARTROW=&amp;gt; &amp;#34;\x00\x00\x00\x02\x00\x00\x01k\x0C\x168\x92\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xC2\x8Fl-\xD3\x04\xB5F(\x9F\x89\xED\x13\xDD\xE5!&amp;#34;, STOPROW=&amp;gt;&amp;#34;\x00\x00\x00\x8D\x00\x00\x01l#]\xAF)&amp;#34;, FILTER=&amp;gt;org.apache.hadoop.hbase.filter.FuzzyRowFilter.new(Arrays.asList(Pair.new(Bytes.toBytes(&amp;#34;0008????0000????0000????&amp;#34;),Bytes.toBytes(&amp;#34;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&amp;#34;)))) }
scan &amp;#34;journalq:send_log&amp;#34;, {FILTER=&amp;gt;&amp;#34;SingleColumnValueFilter(&amp;#39;cf&amp;#39;,&amp;#39;create_time&amp;#39;,=,&amp;#39;regexstring:2014-11-08.*&amp;#39;)&amp;#34;}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">\x00\x00\x00\x02\x00\x00\x01k\x0C\x168\x92\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xC2\x8Fl-\xD3\x04\xB5F(\x9F\x89\xED\x13\xDD\xE5!
\x00\x00\x00\x14\x00\x00\x01l=.\xFB\xAF\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~7D\xD7\xF4s\xB1\x80\xB1V\xA1\xB3\xA2\xDE\x9F\xDE\x9A
\x00\x00\x00\x01\x00\x00\x01jD3\x06\xEC\xD4\x1D\x8C\xD9\x8F\x00\xB2\x04\xE9\x80\x09\x98\xEC\xF8B~\xDA\x9EtW\x86\xD0\xF9o&amp;#39;\xB3\xEC\xFF\x14\xC6\xD5F
\x00\x00\x00\x08\x00\x00\x01j\xC16=\x97r\x02~\x0C\xC0^\xADM\x84\x10\xB3\xFB\x8FW\xF3\xE8\xFD\xEF\xCE\xDFd.}\x90\x1Dj\x9A\xBB\x9F\x98\x19
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://yq.aliyun.com/articles/676094">https://yq.aliyun.com/articles/676094&lt;/a>&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>Hbase WAL 详解</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-wal/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-wal/</guid><description>&lt;h1 id="hbase-wal-详解">Hbase WAL 详解&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>HBase 为保证写入高速，先往内存 memstore 写数据，当 memstore 到一定大小时，再批量 flush 到 storefile 中进行持久化，此时如果 rs 宕机 memstore 中没有 flush 的数据将会丢失，为此在写入 memstore 前，先将数据 append 到一个顺序文件中，即&lt;strong>WAL&lt;/strong>(Write Ahead Log)。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>WAL 的主要作用就是用来进行 recovery，类似于 Mysql 中的 redo log。为保证 wal 的写不影响写入性能，wal 使用顺序 append 方式。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="组织">组织&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>wal 在 hbase 以 hlog 文件存储于 hdfs 中。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>每个 RegionServer 对应一个 Hlog,所有对于该 RegionServer 的写入都记录到 Hlog 中，一旦 region server 宕机，就可以从 log 中进行恢复。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为了保证恢复的效率，Hbase 会限制最大保存的 Hlog 数量，如果达到 Hlog 的最大个数（hase.regionserver.max.logs 参数控制）的时候，就会触发强制刷盘操作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于已经刷盘的数据，其对应的 Hlog 会有一个过期的概念，Hlog 过期后，会被监控线程移动到.oldlogs，然后会被自动删除掉。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="hlog">HLog&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>HLog 文件就是一个普通的 Hadoop Sequence File；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sequence File 的 HLogKey 对象，其中记录了写入数据的归属信息，&lt;/p>
&lt;ul>
&lt;li>
&lt;p>table&lt;/p>
&lt;/li>
&lt;li>
&lt;p>region&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sequence number：sequence number 的起始值为 0，或者是最近一次存入文件系统中的 sequence number。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>timestamp：timestamp 是写入时间&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Sequence File 的 value 是 HBase 的 KeyValue 对象，即对应 HFile 中的 KeyValue。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://justice.bj.cn/Users/zhuzhengyi/Documents/gitnote/img/2019-12-12-11-58-20-image.png" alt="">&lt;/p>
&lt;h2 id="等级">等级&lt;/h2>
&lt;p>WAL 的持久化等级分为如下四个等级：&lt;/p>
&lt;ul>
&lt;li>SKIP_WAL：只写缓存，不写 HLog 日志。这种方式因为只写内存(memstore)，因此可以提升写入性能，但是数据有丢失的风险。&lt;/li>
&lt;li>ASYNC_WAL：异步将数据写入 HLog 日志中。&lt;/li>
&lt;li>SYNC_WAL：同步将数据写入日志文件中，有可能只是被写入文件系统中，并没有真正落盘。&lt;/li>
&lt;li>FSYNC_WAL：同步将数据写入日志文件并强制落盘。最严格的日志写入等级，可以保证数据不会丢失，但是性能相对比较差。&lt;/li>
&lt;li>USER_DEFAULT：默认如果用户没有指定持久化等级，HBase 使用 SYNC_WAL 等级持久化数据。&lt;/li>
&lt;/ul>
&lt;h2 id="生命周期">生命周期&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>生成&lt;/strong>：写入 memstore 前(同时写入)，写入 WAL 到 WALs/对应的 rs 目录中；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>滚动&lt;/strong>：当一个 hlog 文件写入时间达到&lt;code>hbase.regionserver.logroll.period&lt;/code>（默认：1h）时，滚动生成新的 hlog 文件；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>阻塞&lt;/strong>：每个 rs 中的 hlog 文件个数由&lt;code>hbase.regionserver.maxlogs&lt;/code>(默认: )限制，达到改值后，将阻止对改 rs 的写入；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>过期&lt;/strong>：当 memstore 数据 flush 到 storefile 中后，会更新&lt;code>oldestUnflushedSequenceId&lt;/code>, 如果 Hlog 的最大的 sequenceid 大于等于该值，则表明该 WAL 中的所有数据已落盘，则将该 hlog 文件移动到 oldWALs 目录中；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>复制&lt;/strong>：如果开启了 replication，则复制线程将 oldWALs 中的 hlog 复制到 slave 节点中，复制完成后，将其删除；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>重放&lt;/strong>：当 rs 故障时，该 rs 上的 wal 将被重放，已恢复 wal 中的数据；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="wal-splitting">WAL splitting&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>当 Master 重启或者 RS down 掉后，会触发 WAL splitting 过程；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>wal split 和 replay 比较消耗资源。从 0.92 版开始，hbase 默认启用 distributed log 进行 wal 的并行 split，以提高 wal split 的性能。可由&lt;code>hbase.master.distributed.log.splitting&lt;/code>选项进行设置；&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h2 id="配置">配置&lt;/h2>
&lt;p>Hbase-site.xml 配置项：&lt;/p>
&lt;p>hbase.wal.hsync： hbase wal 文件同步方式 , 默认：false，先写入 fs 缓存，后 sync 到磁盘。&lt;/p>
&lt;p>hbase.wal.provider：&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/61573538">https://zhuanlan.zhihu.com/p/61573538&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cwiki.us/pages/viewpage.action?pageId=41684509">HBase：WAL 拆分 - Apache HBase - CWIKI.US&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>HBase 安装</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase%E5%AE%89%E8%A3%85/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase%E5%AE%89%E8%A3%85/</guid><description>&lt;h1 id="hbase-安装">HBase 安装&lt;/h1>
&lt;h2 id="安装">安装&lt;/h2>
&lt;h3 id="相关组件">相关组件&lt;/h3>
&lt;ul>
&lt;li>hadoop-2.7.6 (&lt;a href="http://mirrors.jd.com/apache/hadoop/common/hadoop-2.7.6/hadoop-2.7.6.tar.gz">下载&lt;/a>)&lt;/li>
&lt;li>zookeeper-3.4.12 (&lt;a href="http://mirrors.jd.com/apache/zookeeper/zookeeper-3.4.12/zookeeper-3.4.12.tar.gz">下载&lt;/a>)&lt;/li>
&lt;li>hbase-2.0.0 (&lt;a href="http://mirrors.jd.com/apache/hbase/2.0.0/hbase-2.0.0-bin.tar.gz">下载&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h3 id="部署模式">部署模式&lt;/h3>
&lt;h4 id="单机模式standalone">单机模式(standalone)&lt;/h4>
&lt;p>单机模式不依赖hadoop，直接使用本地文件系统，数据存储在本地文件系统目录。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>conf/hbase-site.xml&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;configuration&amp;gt;&lt;/span>
//Here you have to set the path where you want HBase to store its files.
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.rootdir&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>file:///hbase/data&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/configuration&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h4 id="伪分布式模式">伪分布式模式&lt;/h4>
&lt;p>伪分布式模式依赖于hadoop的hdfs提供存储，所以要先配置hadoop&lt;/p>
&lt;ul>
&lt;li>hadoop&lt;/li>
&lt;/ul>
&lt;h4 id="分布式模式">分布式模式&lt;/h4>
&lt;ul>
&lt;li>start: &lt;code>$ bin/start-hbase.sh&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="shell操作">shell操作&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>基础操作&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ bin/hbase shell
&amp;gt; list
&amp;gt; create &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;cf1&amp;#39;&lt;/span>
&amp;gt; put &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;row1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;cf1:name1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;value1&amp;#39;&lt;/span>
&amp;gt; scan &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>
&amp;gt; get &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;row1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;cf1:name1&amp;#39;&lt;/span>
&amp;gt; delete &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>,&lt;span class="s1">&amp;#39;r1&amp;#39;&lt;/span>,&lt;span class="s1">&amp;#39;cf1:name1&amp;#39;&lt;/span>
&amp;gt; count &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>
&amp;gt; disable &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>
&amp;gt; drop &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>
&amp;gt; grant &lt;span class="s1">&amp;#39;user1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;RWC&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>
&amp;gt; user_permission
&amp;gt; revoke &lt;span class="s1">&amp;#39;user1&amp;#39;&lt;/span>, &lt;span class="s1">&amp;#39;t1&amp;#39;&lt;/span>
&amp;gt; &lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;update_all_config&amp;#34;&lt;/span> &lt;span class="p">|&lt;/span> bin/hbase shell -n &lt;span class="c1">#更新配置&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;h2 id="常见问题">常见问题&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>hadoop执行warn&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">18/06/15 17:33:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>解决：&lt;/p>
&lt;pre>&lt;code>hadoop-env.sh 中增加：
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nb">export&lt;/span> &lt;span class="nv">HADOOP_OPTS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$HADOOP_OPTS&lt;/span>&lt;span class="s2"> -Djava.library.path=&lt;/span>&lt;span class="nv">$HADOOP_HOME&lt;/span>&lt;span class="s2">/lib:&lt;/span>&lt;span class="nv">$HADOOP_COMMON_LIB_NATIVE_DIR&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>authentication&lt;/p>
&lt;/li>
&lt;li>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-txt" data-lang="txt">org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): SIMPLE authentication is not enabled. Available:[TOKEN]
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>解决：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">hbase rootdir 和 hadoop 中 的 defaultFS 配置不一致
经过各方查找，最终发现问题是$HBASE_HOME/conf/hbase-site.xml中的如下属性配置错了：
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.rootdir&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>hdfs://master:8020/hbase&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
注：此配置中的IP或域名必须与$HADOOP_HOME/etc/hadoop/core-site.xml中的如下配置保持一致：
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>fs.defaultFS&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>hdfs://master:8020&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ol></description></item><item><title>hbase 节点宕机处理流程</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase%E6%BA%90%E7%A0%81/hbase-rs-crash%E6%B5%81%E7%A8%8B/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase%E6%BA%90%E7%A0%81/hbase-rs-crash%E6%B5%81%E7%A8%8B/</guid><description>&lt;h1 id="hbase-节点宕机处理流程">hbase 节点宕机处理流程&lt;/h1>
&lt;ol>
&lt;li>region server宕机后，zk检测到节点超时，将/hbase/rs/&lt;SERVERNAME>对应节点删除；&lt;/li>
&lt;li>HMaster有一个RegionServerTracker对象，监控zk上/hbase/rs目录下的结点，HMaster触发RegionServerTracker的nodeDeleted()，调用ServerManager的expireServer逻辑，对于非meta region(0.96后只有一个meta region)，提交一个ServerShutdownHanlder的任务给内部线程池处理，任务的处理逻辑在handler的process()中。&lt;/li>
&lt;li>如果开启了distributed log replay特性，那么在zk上建立一系列结点/hbase/recovering-regions/regionEncodeName/serverName，其中regionEncodeName结点内容为该region的last flush sequence id，即这个sequence id之前的所有数据都已经flush到磁盘上产生了HFile文件，这部分数据不需要进行回放。serverName结点的内容为宕机的region server上的last flushed sequence id，即所有region中最大的last flush sequence id。&lt;/li>
&lt;li>将宕掉server上的region assign通过round robin的方式assign其他的活着的region server，&lt;/li>
&lt;li>提交一个LogReplayHandler的任务给内部线程池，这个任务内部就是进行split log的准备工作，将hdfs上该region server的log改名，加上-splitting后缀，变成hbase.rootdir/WALs/serverName-splitting，&lt;/li>
&lt;li>HMaster的SplitLogManager在zk上建立节点，路径/hbase/splitWAL/对上面改写后的log路径的encode。&lt;/li>
&lt;li>HMaster等待log被其他region server上的SplitLogWorker split完成，&lt;/li>
&lt;li>将一开始建立的一系列节点/hbase/recovering-regions/regionEncodeName/serverName删掉,然后将-splitting目录删除.&lt;/li>
&lt;/ol></description></item><item><title>HBase 配置</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase%E9%85%8D%E7%BD%AE/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase%E9%85%8D%E7%BD%AE/</guid><description>&lt;h1 id="hbase-配置">HBase 配置&lt;/h1>
&lt;h2 id="hbase-envsh-配置">hbase-env.sh 配置&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1"># hbase-env.sh&lt;/span>
&lt;span class="c1"># jvm&lt;/span>
&lt;span class="nb">export&lt;/span> &lt;span class="nv">HBASE_HEAPSIZE&lt;/span>&lt;span class="o">=&lt;/span>16G &lt;span class="c1"># 堆内存大小，建议为20~24G，太大会导致GC时间过长，太小会导致频繁的flush&lt;/span>
&lt;span class="c1"># 开启jvm gc 日志&lt;/span>
&lt;span class="nb">export&lt;/span> &lt;span class="nv">SERVER_GC_OPTS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:&amp;lt;FILE-PATH&amp;gt; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=1 -XX:GCLogFileSize=512M&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="gclog-日志配置">GClog 日志配置&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">-verbose:gc
-XX:+PrintGCDetails
-XX:+PrintGCDateStamps
-XX:+PrintGCApplicationStoppedTime # 打印应用停留时间
-XX:+PrintTenuringDistribution # 老年代分布
-Xloggc:&amp;lt;FILE-PATH&amp;gt; #
-XX:+UseGCLogFileRotation
-XX:NumberOfGCLogFiles=2
-XX:GCLogFileSize=512M
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="hbase-sitexml-配置">hbase-site.xml 配置&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>参数&lt;/th>
&lt;th>说明&lt;/th>
&lt;th>默认值&lt;/th>
&lt;th>&lt;/th>
&lt;th>建议值&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hstore.blockingStoreFiles&lt;/td>
&lt;td>hflie阻塞客户端请求数&lt;/td>
&lt;td>10&lt;/td>
&lt;td>&lt;/td>
&lt;td>&amp;gt;=64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hregion.memstore.flush.size&lt;/td>
&lt;td>Memstore 触发 flush操作的大小&lt;/td>
&lt;td>128M&lt;/td>
&lt;td>&lt;/td>
&lt;td>&amp;gt;=256M&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hregion.memstore.block.multiplier&lt;/td>
&lt;td>Memstore 触发 block 异常的倍数&lt;br>(当memstore大小到达 memstore_flush_size x multiplier 时, 写请求会被block，引发异常)&lt;/td>
&lt;td>4&lt;/td>
&lt;td>&lt;/td>
&lt;td>4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hregion.memstore.chunkpool.maxsize&lt;/td>
&lt;td>memstore&lt;/td>
&lt;td>0&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MSLAB&lt;/td>
&lt;td>hbase.hregion.memstore.mslab.enalbed&lt;/td>
&lt;td>开启memstore MSLAB内存分配器&lt;/td>
&lt;td>true&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hregion.memstore.mslab.chunksize&lt;/td>
&lt;td>memstore lab 中每个 chunk的大小&lt;/td>
&lt;td>2M&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hregion.memstore.mslab.max.allocation&lt;/td>
&lt;td>通过MSLAB分配的对象不能超过256K，否则直接在Heap上分配&lt;/td>
&lt;td>256K&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.global.memstore.upperLimit&lt;/td>
&lt;td>regionserver 中 所有memstore占有jvm堆内存的上限比例。&lt;br>所有memstore超过这个上限，RS会按大到小依次flush memstore，直到小于lowerLimit。&lt;/td>
&lt;td>0.45&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.global.memstore.lowerLimit&lt;/td>
&lt;td>见上面，一般比upperLimit小0.05&lt;/td>
&lt;td>0.4&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hfile.block.cache.size&lt;/td>
&lt;td>block cache 占jvm 堆内存的比例&lt;/td>
&lt;td>0.3&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hstore.flusher.count&lt;/td>
&lt;td>memstore flush 线程数&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;/td>
&lt;td>&amp;gt;=8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.executor.openregion.threads&lt;/td>
&lt;td>&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.executor.closeregion.threads&lt;/td>
&lt;td>&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hstore.compaction.max&lt;/td>
&lt;td>minor compact 一次可合并的最多 storefile 数&lt;/td>
&lt;td>10&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hstore.compaction.min&lt;/td>
&lt;td>触发 minor compact 最少store file个数&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hstore.compaction.max&lt;/td>
&lt;td>minor compact 一次可合并的最多 storefile 数&lt;/td>
&lt;td>10&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hstore.compaction.min&lt;/td>
&lt;td>触发 minor compact 最少store file个数&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.thread.compaction.large&lt;/td>
&lt;td>major compact 线程数&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.thread.compaction.small&lt;/td>
&lt;td>minor compact 线程数&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.global.memstore.size&lt;/td>
&lt;td>rs 中 memstore 占总内存的比例&lt;/td>
&lt;td>0.4&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.regionserver.hlog.blocksize&lt;/td>
&lt;td>rs 中 block size&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hstore.compactionThreshold&lt;/td>
&lt;td>hbase.hstore.compaction.min的旧值。已被代替&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>hbase.hregion.max.filesize&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="hbase-sitexml-参数说明">hbase-site.xml 参数说明&lt;/h2>
&lt;h3 id="zk相关">zk相关&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>hbase.zookeeper.quorum&lt;/p>
&lt;p>hbase 集群的 zk链接入口。&lt;/p>
&lt;p>默认值：无&lt;/p>
&lt;p>eg：&lt;value>11-3-26-102.LOCAL:2181,11-3-26-104.LOCAL:2181,11-3-26-134.LOCAL:2181&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>zookeeper.znode.parent&lt;/p>
&lt;p>hbase 集群znode节点名称。&lt;/p>
&lt;p>默认：/hbase&lt;/p>
&lt;p>eg：&lt;value>/hbase-hdfs01&lt;/value>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="fs">fs&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>hbase.rootdir&lt;/p>
&lt;p>hbase 数据存储文件系统root目录，可设置为hdfs文件系统目录(hdfs://xxxx)或分布式fs本地目录(file:///xxxx)&lt;/p>
&lt;p>默认：无&lt;/p>
&lt;p>eg: &lt;value>hdfs://11-3-26-106.LOCAL:9000/hbase01&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.tmp.dir&lt;/p>
&lt;p>hbase 运行临时目录&lt;/p>
&lt;p>默认：&lt;/p>
&lt;p>eg：&lt;value>/export/Data/hbase/tmp&lt;/value>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="wal相关">WAL相关&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.hlog.enabled&lt;/name>&lt;/p>
&lt;p>是否启用wal。&lt;/p>
&lt;p>默认：true&lt;/p>
&lt;p>eg：&lt;value>true&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.regionserver.hlog.blocksize&lt;/p>
&lt;p>Hbase wal文件块大小。&lt;/p>
&lt;p>默认：fs 块大小，hdfs默认为：&lt;/p>
&lt;p>eg：&lt;value>134217728&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.maxlogs&lt;/name>&lt;/p>
&lt;p>regionserver上wal的最大个数，超过该个数，会触发memstore flush 操作。可引起写请求的阻塞。&lt;/p>
&lt;p>默认：32&lt;/p>
&lt;p>eg：&lt;value>81&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.hlog.slowsync.ms&lt;/name>&lt;/p>
&lt;p>regionserver wal sync 操作缓慢的定义时间。如果wal sync的时间超过该时间，则在日志中记录。&lt;/p>
&lt;p>默认：100ms&lt;/p>
&lt;p>eg：&lt;value>350&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.hlog.splitlog.writer.threads&lt;/name>&lt;/p>
&lt;p>Wal split 写入线程数。&lt;/p>
&lt;p>默认：3&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.regionserver.optionallogflushinterval&lt;/p>
&lt;p>wal log flush 间隔&lt;/p>
&lt;p>默认：1000ms&lt;/p>
&lt;p>已废弃&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.logroll.period&lt;/name>&lt;/p>
&lt;p>Wal log roll周期间隔&lt;/p>
&lt;p>默认: 3600000ms (1h)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.regionserver.hlog.syncer.count&lt;/p>
&lt;p>hlog sync 线程数。&lt;/p>
&lt;p>默认：5&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h3 id="memstore相关">memstore相关&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.global.memstore.size&lt;/name>&lt;/p>
&lt;p>rs中memstore占jvm heap的比例&lt;/p>
&lt;p>默认：0.4&lt;/p>
&lt;p>eg:&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.global.memstore.size.lower.limit&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hregion.memstore.flush.size&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hregion.memstore.block.multiplier&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hregion.memstore.chunkpool.initialsize&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hregion.memstore.chunkpool.maxsize&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.optionalcacheflushinterval&lt;/name>&lt;/p>
&lt;p>memstore周期flush的时间间隔，0禁止周期flush&lt;/p>
&lt;p>默认：36000000 1h&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.regionserver.offheap.global.memstore.size&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.offheap.global.memstore.size&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>0&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;description&amp;gt;&lt;/span>
The amount of off-heap memory all MemStores in a RegionServer may use.
A value of 0 means that no off-heap memory will be used.
&lt;span class="nt">&amp;lt;/description&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>hbase.hregion.memstore.mslab.enabled&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="storefile相关">storefile相关&lt;/h3>
&lt;ul>
&lt;li>&lt;name>hbase.hregion.max.filesize&lt;/name>&lt;/li>
&lt;li>&lt;name>hbase.hstore.blockingStoreFiles&lt;/name>&lt;/li>
&lt;li>&lt;name>hbase.hstore.blockingWaitTime&lt;/name>&lt;/li>
&lt;li>&lt;name>hbase.hstore.flusher.count&lt;/name>&lt;/li>
&lt;li>&lt;name>hbase.regionserver.storefile.refresh.period&lt;/name>&lt;/li>
&lt;/ul>
&lt;h3 id="compaction相关">compaction相关&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;name>hbase.hregion.majorcompaction&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hstore.compaction.kv.max&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.thread.compaction.small&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.thread.compaction.large&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hstore.compaction.max&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hstore.compaction.min&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hregion.compacting.memstore.type&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.throughput.controller&lt;/name>&lt;/p>
&lt;p>&lt;value>org.apache.hadoop.hbase.regionserver.throttle.NoLimitThroughputController&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.hregion.compacting.memstore.type&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>hbase.hstore.compactionThreshold&lt;/strong>：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.hregion.compacting.memstore.type&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&amp;lt;none&lt;/span>&lt;span class="err">|basic|eager|adaptive&lt;/span>&lt;span class="nt">&amp;gt;&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;description&amp;gt;&lt;/span>
Compaction策略
 当一个active segment被flush到pipeline中之后，后台会触发一个任务对pipeline中的数据进行合并。合并任务会对pipeline中所有segment进行scan，将他们的索引合并为一个。有三种合并策略可供选择：Basic,Eager,Adaptive。
 Basic compaction策略和Eager compaction策略的区别在于如何处理cell数据。Basic compaction不会清理多余的数据版本，这样就不需要对cell的内存进行拷贝。而Eager compaction会过滤重复的数据，并清理多余的版本，这意味着会有额外的开销：例如如果使用了MSLAB存储cell数据，就需要把经过清理之后的cell从旧的MSLAB拷贝到新的MSLAB。basic适用于所有写入模式，eager则主要针对数据大量淘汰的场景：例如消息队列、购物车等。
 Adaptive策略则是根据数据的重复情况来决定是否使用Eager策略。在Adaptive策略中，首先会对待合并的segment进行评估，方法是在已经统计过不重复key个数的segment中，找出cell个数最多的一个，然后用这个segment的numUniqueKeys / getCellsCount得到一个比例，如果比例小于设定的阈值，则使用Eager策略，否则使用Basic策略。
 &lt;span class="nt">&amp;lt;/description&amp;gt;&lt;/span>
 &lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>
&lt;h3 id="blockcache相关">blockcache相关&lt;/h3>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hfile.block.cache.size&lt;/name>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h3 id="复制">复制&lt;/h3>
&lt;ul>
&lt;li>
&lt;h3 id="安全">安全&lt;/h3>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;h3 id="开启压缩">开启压缩&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">create &amp;#39;test&amp;#39;, {NAME =&amp;gt; &amp;#39;info&amp;#39;, VERSIONS =&amp;gt; 1, COMPRESSION =&amp;gt; &amp;#39;snappy&amp;#39;}
alter &amp;#39;test&amp;#39;, {NAME=&amp;gt;&amp;#39;info&amp;#39;, METHOD=&amp;gt;&amp;#39;delete&amp;#39;}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="其他">其他&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;name>hbase.superuser&lt;/name>&lt;/p>
&lt;p>hbase超级用户&lt;/p>
&lt;p>默认：root&lt;/p>
&lt;p>eg: &lt;value>root,admin&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.meta.versions&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.regionserver.handler.count&lt;/name>&lt;/p>
&lt;p>rpc 线程数&lt;/p>
&lt;p>默认：200&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;name>hbase.replication&lt;/name>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.cluster.distributed&lt;/p>
&lt;p>是否启用分布式集群模式&lt;/p>
&lt;p>默认: false&lt;/p>
&lt;p>Eg: &lt;value>true&lt;/value>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.read.threadpool.size&lt;/p>
&lt;p>Hbase ipc Reader 网络 IO 个数，reader 的个数决定了从网络 io 里读取数据的速度也就是网络吞吐量。&lt;/p>
&lt;p>默认： 10。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="rpc">rpc&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>hbase.regionserver.handler.count&lt;/p>
&lt;p>handler指的是RegionServer端开启的RPC监听器实例个数，也即RegionServer能够处理的IO请求线程数。&lt;/p>
&lt;p>默认: 30。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.callqueue.read.ratio&lt;/p>
&lt;p>假如handler count设置300，那么，读的handler就有 300*0.3=90&lt;/p>
&lt;/li>
&lt;li>
&lt;p>hbase.ipc.server.callqueue.scan.ratio&lt;/p>
&lt;p>scan的90*0.3=27&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>使用堆外内存（bucketcache）：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.block.data.cachecompressed&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>true&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.bucketcache.combinedcache.enabled&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>true&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.bucketcache.ioengine&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>offheap&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.bucketcache.percentage.in.combinedcache&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>0.8984&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.bucketcache.size&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="c">&amp;lt;!-- unite MB --&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>8192&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.global.memstore.size&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>0.4&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hfile.block.cache.size&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>0.4&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="compact-限速">compact 限速&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.regionserver.throughput.controller&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;discription&amp;gt;&lt;/span>使用压力感知compaction限流策略控制器&lt;span class="nt">&amp;lt;/discription&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.hstore.compaction.throughput.higher.bound&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>209715200&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;discription&amp;gt;&lt;/span>限流上限阈值, 默认20MB/s&lt;span class="nt">&amp;lt;/discription&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.hstore.compaction.throughput.lower.bound&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>52428800&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;discription&amp;gt;&lt;/span>限流下限阈值, 默认10MB/s&lt;span class="nt">&amp;lt;/discription&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="c">&amp;lt;!--
&lt;/span>&lt;span class="c">&amp;lt;property&amp;gt;
&lt;/span>&lt;span class="c"> &amp;lt;name&amp;gt;hbase.hstore.compaction.throughput.offpeak&amp;lt;/name&amp;gt;
&lt;/span>&lt;span class="c"> &amp;lt;value&amp;gt;9223372036854775807&amp;lt;/value&amp;gt;
&lt;/span>&lt;span class="c"> &amp;lt;discription&amp;gt;非高峰期阈值,为Long.MAX即不限流&amp;lt;/discription&amp;gt;
&lt;/span>&lt;span class="c">&amp;lt;/property&amp;gt;
&lt;/span>&lt;span class="c">--&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.offpeak.start.hour&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>0&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;discription&amp;gt;&lt;/span>非高峰期开始小时时刻&lt;span class="nt">&amp;lt;/discription&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.offpeak.end.hour&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>3&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;discription&amp;gt;&lt;/span>非高峰期结束小时时刻&lt;span class="nt">&amp;lt;/discription&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.hstore.compaction.throughput.tune.period&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>60000&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;discription&amp;gt;&lt;/span>限流调整周期,单位毫秒&lt;span class="nt">&amp;lt;/discription&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="配置动态更新">配置动态更新&lt;/h2>
&lt;p>可动态更新的配置项：http://hbase.apache.org/book.html#dyn_config&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">echo &amp;#34;update_all_cfg&amp;#34; | bin/hbase shell -n
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="hbase-shell">hbase shell&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ /export/server/hbase-2.1.0/bin/hbase shell
&amp;gt; processlist &lt;span class="c1">#查看task&lt;/span>
&amp;gt; list_procedures &lt;span class="c1"># 查看procedures&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>HBase二级索引</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95/</guid><description>&lt;h1 id="hbase二级索引">HBase二级索引&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;h2 id="协处理器实现coprocessor">协处理器实现Coprocessor&lt;/h2>
&lt;p>CoProcessor相当于HBase的Observer+hook，目前支持MasterObserver、RegionObserver和WALObserver，基本上对于HBase Table的管理、数据的Put、Delete、Get等操作都可以找到对应的pre&lt;em>&lt;strong>和post&lt;/strong>&lt;/em>。这样如果需要对于某一项Column建立Secondary Indexing，就可以在Put、Delete的时候，将其信息更新到另外一张索引表中。&lt;/p>
&lt;h2 id="客户端自主设置二级索引表">客户端自主设置二级索引表&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>设置主表的TTL(Time To Live)比索引表小一点，让其略早一点消亡。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>不要在IndexingTable存储Value值，即删除如图2所示的val列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Put操作时，对于操作的主表的所有列，使用同一的Local TimeStamp的值，更新到Indexing Table，然后使用该TimeStamp插入主表数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Delete操作时，首先操作主表的数据，然后再去更新Indexing Table的数据。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="已实现方案">已实现方案&lt;/h2>
&lt;h3 id="phoneix">Phoneix&lt;/h3>
&lt;h3 id="hive">Hive&lt;/h3>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://www.jianshu.com/p/3bbb3d88dc6a">HBase二级索引总结 - 简书&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://segmentfault.com/a/1190000019794306">HBase二级索引方案 - 大数据学习笔记 - SegmentFault 思否&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/43972378">https://zhuanlan.zhihu.com/p/43972378&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>hbase写流程</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase%E6%BA%90%E7%A0%81/hbase%E5%86%99%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase%E6%BA%90%E7%A0%81/hbase%E5%86%99%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B/</guid><description>&lt;h1 id="hbase写流程">hbase写流程&lt;/h1>
&lt;p>&lt;img src="https://gitee.com/justice/gitnote-img-bed/raw/master/2021/10/10-12-47-09-image.png" alt="img">&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hbase&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">regionserver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HRegion&lt;/span>&lt;span class="err">#&lt;/span>&lt;span class="n">batchMutate&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hbase&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">regionserver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HRegion&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">BatchOperation&lt;/span>&lt;span class="o">&amp;lt;?&amp;gt;)&lt;/span>
&lt;span class="n">org&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">apache&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hadoop&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">hbase&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">regionserver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">HRegion&lt;/span>&lt;span class="err">#&lt;/span>&lt;span class="n">doMiniBatchMutate&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>HBase协处理器</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase-%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase-%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8/</guid><description>&lt;h1 id="hbase协处理器">HBase协处理器&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>HBase 的协处理器是从 0.92.0 开始引入的，参见 &lt;a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0yMDAw&amp;amp;article=true">HBASE-2000&lt;/a>。它的实现灵感来源于 Jeff Dean 在 LADIS 2009 分享主题 &lt;a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly96aC5zY3JpYmQuY29tL2RvYy8yMTYzMTQ0OC9EZWFuLUtleW5vdGUtTGFkaXMyMDA5&amp;amp;article=true">《Designs, Lessons and Advice fromBuilding LargeDistributed Systems》&lt;/a>中关于 Google 的 BigTable 协处理器的分享。当时的 BigTable 协处理器具有以下功能：&lt;/p>
&lt;ul>
&lt;li>每个表服务器的任意子表都可以运行代码；&lt;/li>
&lt;li>客户端的高层调用接口；&lt;/li>
&lt;li>跨多行的调用会自动拆分为多个并行化的 RPC 请求；&lt;/li>
&lt;li>通过协处理器可以非常灵活的构建分布式服务模型，能够自动化扩展、负载均衡、应用请求路由等。&lt;/li>
&lt;/ul>
&lt;p>HBase 当然也想要一个这么好的功能，因为通过这个功能我们可以实现二级索引（secondary indexing）、复杂过滤（complex filtering） 比如谓词下推（push down predicates）以及访问控制等功能。虽然 HBase 协处理器受 BigTable 协处理器的启发，但在实现细节方面存在差异。HBase 为我们建立了一个框架，并提供类库和运行时环境，使得我们可以在 HBase RegionServer 和 Master 上运行用户自定义代码；而 Google 的 BigTable 却不是这样的。&lt;/p>
&lt;h2 id="协处理器支持的扩展">协处理器支持的扩展&lt;/h2>
&lt;p>协处理器框架已经为我们提供了一些实现类，我们可以通过继承这些类来扩展自己的功能。这些类主要分为两大类，即 Observer 和 Endpoint。&lt;/p>
&lt;h3 id="observer">Observer&lt;/h3>
&lt;p>Observer 和 RDMBS 的触发器很类似，在一些特定的事件发生时被执行。这些事件包括用户产生的事件，也包括服务器内部产生的事件。 目前 HBase 内置实现的 Observer 主要有以下几个：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>WALObserver&lt;/strong>：提供控制 WAL 的钩子函数；&lt;/li>
&lt;li>&lt;strong>MasterObserver&lt;/strong>：可以被用作管理或 DDL 类型的操作，这些是集群级的事件；&lt;/li>
&lt;li>&lt;strong>RegionObserver&lt;/strong>：用户可以用这种处理器处理数据修改事件，它们与表的 Region 联系紧密；&lt;/li>
&lt;li>&lt;strong>BulkLoadObserver&lt;/strong>：进行 BulkLoad 的操作之前或之后会触发这个钩子函数；&lt;/li>
&lt;li>&lt;strong>RegionServerObserver&lt;/strong> ：RegionServer 上发生的一些操作可以触发一些这个钩子函数，这个是 RegionServer 级别的事件；&lt;/li>
&lt;li>&lt;strong>EndpointObserver&lt;/strong>：每当用户调用 Endpoint 之前或之后会触发这个钩子，主要提供了一些回调方法。&lt;/li>
&lt;/ul>
&lt;h3 id="endpoint">Endpoint&lt;/h3>
&lt;p>Endpoint 和 RDMBS 的存储过程很类似，用户提供一些自定义代码，并在 HBase 服务器端执行，结果通过 RPC 返回给客户。比较常见的场景包括聚合操作（求和、计数等）。有了 Endpoint ，我们就可以充分利用服务器的资源，进行一些计算，大大提升计算的效率和通讯的开销。&lt;/p>
&lt;h2 id="协处理器编写和配置">协处理器编写和配置&lt;/h2>
&lt;p>下面我将通过介绍一个计数的例子来介绍 HBase 协处理器的使用。我们知道，HBase 自带了一个 &lt;code>count&lt;/code> 命令用于计算某张表的行数，但是这个命令是单线程执行，效率非常低。我们可以通过 Endpoint 来实现一个计数类，并利用集群的资源来计算，最终将结果返回到客户端，客户端这边通过对结果进行汇总得到最终的结果。其实，HBase 自带了一个名为 &lt;code>RowCountEndpoint&lt;/code> 的例子，里面就实现了计数逻辑。注意本文基于 HBase 1.4.0 进行介绍的，HBase 2.x 的代码已经有些变化，但大部分结构都类似。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;span class="lnt">128
&lt;/span>&lt;span class="lnt">129
&lt;/span>&lt;span class="lnt">130
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="kn">package&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.coprocessor.example&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.io.IOException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.ArrayList&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">java.util.List&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.Cell&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.CellUtil&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.Coprocessor&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.CoprocessorEnvironment&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.client.Scan&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.coprocessor.CoprocessorException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.coprocessor.CoprocessorService&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.coprocessor.example.generated.ExampleProtos&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.protobuf.ResponseConverter&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.regionserver.InternalScanner&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">org.apache.hadoop.hbase.util.Bytes&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.protobuf.RpcCallback&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.protobuf.RpcController&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">com.google.protobuf.Service&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">RowCountEndpoint&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">RowCountService&lt;/span>
&lt;span class="kd">implements&lt;/span> &lt;span class="n">Coprocessor&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">CoprocessorService&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kd">private&lt;/span> &lt;span class="n">RegionCoprocessorEnvironment&lt;/span> &lt;span class="n">env&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="nf">RowCountEndpoint&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm"> * Just returns a reference to this object, which implements the RowCounterService interface.
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="n">Service&lt;/span> &lt;span class="nf">getService&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm"> * 返回表的行数
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">getRowCount&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">RpcController&lt;/span> &lt;span class="n">controller&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountRequest&lt;/span> &lt;span class="n">request&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">RpcCallback&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountResponse&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">done&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">Scan&lt;/span> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Scan&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setFilter&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">FirstKeyOnlyFilter&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountResponse&lt;/span> &lt;span class="n">response&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">InternalScanner&lt;/span> &lt;span class="n">scanner&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">scanner&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">env&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getRegion&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getScanner&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Cell&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">ArrayList&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Cell&lt;/span>&lt;span class="o">&amp;gt;();&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">hasMore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">lastRow&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kt">long&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">do&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">hasMore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">scanner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">next&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">results&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Cell&lt;/span> &lt;span class="n">kv&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">currentRow&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">CellUtil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">cloneRow&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">kv&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">lastRow&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="kc">null&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="o">!&lt;/span>&lt;span class="n">Bytes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">equals&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lastRow&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">currentRow&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">lastRow&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">currentRow&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">count&lt;/span>&lt;span class="o">++;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">results&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">while&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">hasMore&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">response&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountResponse&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newBuilder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setCount&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">IOException&lt;/span> &lt;span class="n">ioe&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">ResponseConverter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setControllerException&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">controller&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ioe&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">finally&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">scanner&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">scanner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">close&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">IOException&lt;/span> &lt;span class="n">ignored&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">done&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">run&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">response&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="cm">/**
&lt;/span>&lt;span class="cm"> * 返回表中 KV 的数量
&lt;/span>&lt;span class="cm"> */&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">getKeyValueCount&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">RpcController&lt;/span> &lt;span class="n">controller&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountRequest&lt;/span> &lt;span class="n">request&lt;/span>&lt;span class="o">,&lt;/span>
&lt;span class="n">RpcCallback&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountResponse&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">done&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountResponse&lt;/span> &lt;span class="n">response&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="n">InternalScanner&lt;/span> &lt;span class="n">scanner&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">scanner&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">env&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getRegion&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getScanner&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">Scan&lt;/span>&lt;span class="o">());&lt;/span>
&lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Cell&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">results&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">ArrayList&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">Cell&lt;/span>&lt;span class="o">&amp;gt;();&lt;/span>
&lt;span class="kt">boolean&lt;/span> &lt;span class="n">hasMore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="kt">long&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">0&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="k">do&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">hasMore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">scanner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">next&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">results&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Cell&lt;/span> &lt;span class="n">kv&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">results&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">count&lt;/span>&lt;span class="o">++;&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">results&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">clear&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">while&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">hasMore&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">response&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ExampleProtos&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CountResponse&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">newBuilder&lt;/span>&lt;span class="o">()&lt;/span>
&lt;span class="o">.&lt;/span>&lt;span class="na">setCount&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">IOException&lt;/span> &lt;span class="n">ioe&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">ResponseConverter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setControllerException&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">controller&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ioe&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">finally&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">scanner&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">scanner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">close&lt;/span>&lt;span class="o">();&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">IOException&lt;/span> &lt;span class="n">ignored&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="n">done&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">run&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">response&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">start&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CoprocessorEnvironment&lt;/span> &lt;span class="n">env&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">env&lt;/span> &lt;span class="k">instanceof&lt;/span> &lt;span class="n">RegionCoprocessorEnvironment&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">env&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">RegionCoprocessorEnvironment&lt;/span>&lt;span class="o">)&lt;/span>&lt;span class="n">env&lt;/span>&lt;span class="o">;&lt;/span>
&lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="k">throw&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">CoprocessorException&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Must be loaded on a table region!&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;span class="nd">@Override&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">stop&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">CoprocessorEnvironment&lt;/span> &lt;span class="n">env&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IOException&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="c1">// nothing to do
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>由于 HBase 内部使用 protobuf 协议进行通信，所以这个例子定义了名为 &lt;code>Examples.proto&lt;/code> 的文件：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-protobuf" data-lang="protobuf">&lt;span class="kn">package&lt;/span> &lt;span class="nn">hbase&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pb&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">option&lt;/span> &lt;span class="n">java_package&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;org.apache.hadoop.hbase.coprocessor.example.generated&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">option&lt;/span> &lt;span class="n">java_outer_classname&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;ExampleProtos&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">option&lt;/span> &lt;span class="n">java_generic_services&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">option&lt;/span> &lt;span class="n">java_generate_equals_and_hash&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="k">option&lt;/span> &lt;span class="n">optimize_for&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SPEED&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="kd">message&lt;/span> &lt;span class="nc">CountRequest&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="kd">message&lt;/span> &lt;span class="nc">CountResponse&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">required&lt;/span> &lt;span class="kt">int64&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="k">default&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">];&lt;/span> &lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="kd">service&lt;/span> &lt;span class="n">RowCountService&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">rpc&lt;/span> &lt;span class="n">getRowCount&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">CountRequest&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">returns&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">CountResponse&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">rpc&lt;/span> &lt;span class="n">getKeyValueCount&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">CountRequest&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span> &lt;span class="k">returns&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">CountResponse&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="err">
&lt;/span>&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>由于 RowCountEndpoint 类是 HBase 自带的例子，所以在我们的 HBase 类路径下已经加载了这个类，在实际的应用中，我们需要将 Examples.proto 文件生成对应的类，并将相关的类进行编译打包（具体如何编译可以参见 《在 IDEA 中使用 Maven 编译 proto 文件》）。因为这个类 HBase 其实已经编译好了，所以我就不再进行介绍了，直接讲如何部署。&lt;/p>
&lt;h2 id="协处理器部署">协处理器部署&lt;/h2>
&lt;p>协处理器的部署有很多种方法，这里我将一一进行介绍。&lt;/p>
&lt;p>通过 hbase-site.xml 文件进行配置&lt;/p>
&lt;p>我们可以直接在 hbase-site.xml 文件里面进行配置，配置完之后需要重启 HBase 集群，而且这个配置是全局影响的。如下设置：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="nt">&amp;lt;property&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;name&amp;gt;&lt;/span>hbase.coprocessor.region.classes&lt;span class="nt">&amp;lt;/name&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;value&amp;gt;&lt;/span>org.apache.hadoop.hbase.coprocessor.RowCountEndpoint&lt;span class="nt">&amp;lt;/value&amp;gt;&lt;/span>
&lt;span class="nt">&amp;lt;/property&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>因为 RowCountEndpoint 这个类是 HBase 自带的，如果是我们自定义的 Endpoint，我们需要将打包好的 jar 包放到所有节点的 $HBASE_HOME/lib/ 路径下。&lt;/p>
&lt;h3 id="通过-hbase-shell-配置">通过 HBase Shell 配置&lt;/h3>
&lt;p>如果我们只想对某一张表设置 Endpoint，那么可以直接在 HBase Shell 中进行配置，如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">hbase(main): &amp;gt; alter &amp;#39;iteblog&amp;#39;, &amp;#39;coprocessor&amp;#39; =&amp;gt; &amp;#39;|org.apache.hadoop.hbase.coprocessor.example.RowCountEndpoint ||&amp;#39;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>说明：上面的 coprocessor 设置的值为 &amp;lsquo;|org.apache.hadoop.hbase.coprocessor.example.RowCountEndpoint ||'，它的值主要由四部分组成。&amp;lsquo;coprocessor&amp;rsquo; =&amp;gt; &amp;lsquo;Jar File Path|Class Name|Priority|Arguments&amp;rsquo;。其中&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>Jar File Path&lt;/code>：协处理器实现类所在 Jar 包的路径，这个路径要求所有的 RegionServer 能够读取得到。比如放在所有 RegionServer 的本地磁盘；比较推荐的做法是将文件放到 HDFS 上。如果没有设置这个值，那么将直接从 HBase 服务的 classpath 中读取。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Class Name：协处理器实现类的类名称，包括包名。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Priority：协处理器的优先级，是一个整数。如果同一个钩子函数有多个协处理器实现，那么将按照优先级执行。如果没有指定，将按照默认优先级执行。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Arguments：传递给协处理器实现类的参数列表，可以不指定。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这四个部分使用 | 符号进行分割。&lt;/p>
&lt;h3 id="通过-hbase-api-配置">通过 HBase API 配置&lt;/h3>
&lt;p>除了可以通过 HBase Shell 和 hbase-site.xml 配置文件来加载协处理器，还可以通过 Client API 来加载协处理器。具体的方法是调用 HTableDescriptor 的 addCoprocessor 方法。该方法有两种调用形式：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>addCoprocessor(String className)：传入类名。该方法类似通过配置来加载协处理器，用户需要先把jar包分发到各个 RegionServer 的 $HBASE_HOME/lib 目录下。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>addCoprocessor(String className, Path jarFilePath, int priority, final Map kvs)：该方法类似通过 Shell 来加载协处理器。通过调用该方法可以同时传入协处理器的 className 以及 jar 所在的路径，priority 是协处理器的执行优先级，kvs 是给协处理器预定义的参数。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>使用如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="n">HTableDescriptor&lt;/span> &lt;span class="n">htd&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="n">HTableDescriptor&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;testTable&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;span class="n">htd&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setValue&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;CORPROCESSOR$1&amp;#34;&lt;/span> &lt;span class="o">,&lt;/span>
&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="s">&amp;#34;|&amp;#34;&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">RowCountEndpoint&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getCanonicalName&lt;/span>&lt;span class="o">()+&lt;/span>&lt;span class="s">&amp;#34;|&amp;#34;&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">Coprocessor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">Priority&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">USER&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="如何判断协处理器设置生效">如何判断协处理器设置生效&lt;/h3>
&lt;p>可以通过 HBase Shell 提供的 describe 命令查看的&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="使用协处理器">使用协处理器&lt;/h2>
&lt;p>通过上面几步，我们已经为表设置好了协处理器，现在我们可以编写客户端程序来调用这个协处理器，主要通过 HTable 的 coprocessorService 方法实现，这个方法主要由三种实现：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>coprocessorService(byte[] row)：这个通过 row 来定位对应的 Region，然后在这个 Region 上运行相关的协处理器代码。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>coprocessorService(final Class&lt;T> service, byte[] startKey, byte[] endKey, final Batch.Call&amp;lt;T,R&amp;gt; callable)：service 指定是调用哪个协处理器实现类，因为一个 Region 上可以部署多个协处理器，客户端必须通过指定 Service 类来区分究竟需要调用哪个协处理器提供的服务。startKey 和 endKey 主要用于确定需要与那些 Region 进行交互。callable 定义了如何调用协处理器，用户通过重载该接口的 call() 方法来实现客户端的逻辑。在 call() 方法内，可以调用 RPC，并对返回值进行任意处理。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>coprocessorService(final Class&lt;T> service, byte[] startKey, byte[] endKey, final Batch.Call&amp;lt;T,R&amp;gt; callable, final Batch.Callback&lt;R> callback)：这个方法和第二个比较多了一个 callback，coprocessorService 会为每一个 RPC 返回结果调用该 callback，用户可以在 callback 中执行需要的逻辑，比如执行 sum 累加。第二个方法，每个 Region 协处理器 RPC 的返回结果先放入一个列表，所有的 Region 都返回后，用户代码再从该列表中取出每一个结果进行累加；用这种方法，直接在 callback 中进行累加，省掉了创建结果集合和遍历该集合的开销，效率会更高一些。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这里我们调用第二种方法，具体的代码如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>运行这段代码，就可以快速算出 iteblog 表的总行数。如果我们把 counter.getRowCount(controller, request, rpcCallback); 修改成 counter.getKeyValueCount(controller, request, rpcCallback);，那么将会返回 iteblog 表 KV 的总数。上面查询运行的流程可以用下面的图来表示&lt;/p>
&lt;p>&lt;img src="assets/2020-04-03-12-59-01-image.png" alt="">&lt;/p>
&lt;p>图中 Client A 的过程就是上面程序的处理流程，主要是并行 RPC 请求。从图中可以看到，这个表的所有 Region 都会参与计算，每个 Region 计算出自己的总数，然后返回给客户端，所有的 Region 结果最后存储在 Map results 中，其中 Key 是每个 Region 的名字，Value 就是这个 Region 计算到的行数。我们只需要遍历这个 Map，然后将所有 Region 计算的行数加起来就是整个表的行数。&lt;/p>
&lt;p>如果我们仅仅想计算某个 row 对应的 Region 的行数，可以实现如下：&lt;/p>
&lt;p>上面代码可以返回 row-890 所在 Region 的行数，由于这个 Row 只对应于一个 Region，所以上面代码的运行流程见上图的 Client B 运行过程。可以看出，这个程序仅仅发出一个 RPC 请求。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://blog.csdn.net/scgaliguodong123_/article/details/46714201">HBase协处理器及实例_大数据_吃果冻不吐果冻皮-CSDN博客&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.csdn.net/wangmin1983/article/details/83507353">实际动手编写HBase Coprocessor_大数据_功夫熊猫-CSDN博客&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://cloud.tencent.com/developer/article/1158195">https://cloud.tencent.com/developer/article/1158195&lt;/a>&lt;/p>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ol></description></item><item><title>HBase读流程解析</title><link>https://justice.bj.cn/post/30.architech/hbase/hbase%E6%BA%90%E7%A0%81/hbase%E8%AF%BB%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/hbase/hbase%E6%BA%90%E7%A0%81/hbase%E8%AF%BB%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/</guid><description>&lt;h1 id="hbase读流程解析">HBase读流程解析&lt;/h1>
&lt;h3 id="pread">pread&lt;/h3>
&lt;p>在Scan中，用户可以设置ReadType:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="nd">@InterfaceAudience.Public&lt;/span>
&lt;span class="kd">public&lt;/span> &lt;span class="kd">enum&lt;/span> &lt;span class="n">ReadType&lt;/span> &lt;span class="o">{&lt;/span>
&lt;span class="n">DEFAULT&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">STREAM&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">PREAD&lt;/span>
&lt;span class="o">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>具体到HBase代码中的&lt;strong>HFileBLock#readAtOffset&lt;/strong>方法，可以比较好的说明PREAD和STREAM的区别．&lt;/p>
&lt;ol>
&lt;li>pread其实就是positional read, 每次都会发一个offset到datanode，让datanode去seek到对应的位置，然后读取数据．　在同一个DFSInputStream上可以跑多个pread操作．pread适合的场景是小数据量的随机读，就是频率高且数据量小的操作，典型的例如&lt;strong>small scan操作&lt;/strong>以及***读取meta表定位rowKey所在region的操作***，这些操作一般默认都用PREAD．&lt;/li>
&lt;li>stream其实是seek + read，就是发一个offset到datanode，然后就不需要你再发offset给datanode了，然后datanode依次吐数据给你．因此，同一个DFSInputStream上跑多个stream的话，吐出来的数据就乱了．&lt;strong>*stream更适合较大数据量的顺序scan操作&lt;/strong>*，典型的场景例如业务扫表操作以及Compaction的扫表操作．&lt;/li>
&lt;/ol>
&lt;h2 id="hbase-scan-优化">hbase scan 优化&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Lazy-seek optimization &lt;a href="https://issues.apache.org/jira/browse/HBASE-4465">https://issues.apache.org/jira/browse/HBASE-4465&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Improve performance for small scan &lt;a href="https://issues.apache.org/jira/browse/HBASE-9488">https://issues.apache.org/jira/browse/HBASE-9488&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Using pread for non-compaction read request &lt;a href="https://issues.apache.org/jira/browse/HBASE-7266">https://issues.apache.org/jira/browse/HBASE-7266&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="hdfs-2246-曾经实现的short-circuit-localreads">HDFS-2246 曾经实现的Short-Circuit LocalReads&lt;/h3>
&lt;p>其关键思想如下：因为客户端和数据在同一个节点，所以没必要再去和DN交互。客户端本身直接就从本地磁盘读出数据。这个性能优化被加入了CDH3u3。&lt;/p>
&lt;p>&lt;a href="https://www.cnblogs.com/smartloli/p/9462835.html">https://www.cnblogs.com/smartloli/p/9462835.html&lt;/a>&lt;/p>
&lt;configuration>
&lt;property>
​ &lt;name>dfs.client.read.shortcircuit&lt;/name>
​ &lt;value>true&lt;/value>
&lt;/property>
&lt;property>
​ &lt;name>dfs.domain.socket.path&lt;/name>
​ &lt;value>/var/lib/hadoop-hdfs/dn_socket&lt;/value>
&lt;/property>
&lt;/configuration>
&lt;p>如果正在读某个block比较慢，hdfs客户端会启动另一个并行的线程去读此block的副本。&lt;/p></description></item></channel></rss>