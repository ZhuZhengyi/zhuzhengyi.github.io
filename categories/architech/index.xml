<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>architech on Justice的小站</title><link>https://justice.bj.cn/categories/architech/</link><description>Recent content in architech on Justice的小站</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 10 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://justice.bj.cn/categories/architech/index.xml" rel="self" type="application/rss+xml"/><item><title>ElasticSearch基础</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/elasticsearch%E5%9F%BA%E7%A1%80/</link><pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/elasticsearch%E5%9F%BA%E7%A1%80/</guid><description>ElasticSearch基础 简介 Elasticsearch 是一个基于lucene的分布式可扩展的近实时搜索和分析引擎。 架构 一个 ES Index 在集群模式下，有多个 Node （节点）组</description></item><item><title>ES倒排索引原理</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/</guid><description>ES倒排索引原理 简介 Elasticsearch通过Lucene的倒排索引技术实现比关系型数据库更快的过滤。 它对多条件的过滤支持非常好，比如年</description></item><item><title>CrateDB</title><link>https://justice.bj.cn/post/30.architech/cratedb/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/cratedb/</guid><description>CrateDB 简介 CrateDB是一个基于ElasticSearch的开源的分布式数据库， 使用SQL处理结构化和非结构化数据； 特点 shared-noth</description></item><item><title>Elasticsearch内核解析 - 查询篇</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E8%AF%BB%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E8%AF%BB%E6%B5%81%E7%A8%8B/</guid><description>Elasticsearch内核解析 - 查询篇 读操作 实时性和《Elasticsearch内核解析 - 写入篇》中的“写操作”一样，对于搜索而言是近实</description></item><item><title>Elasticsearch写流程</title><link>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/elasticsearch/es%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/</guid><description>Elasticsearch写流程 lucene的写操作及其问题 Elasticsearch底层使用Lucene来实现doc的读写操作，Lucen</description></item><item><title>Flink WordCount程序背后的万字深度解析</title><link>https://justice.bj.cn/post/30.architech/flink/flink-wordcoun%E8%A7%A3%E6%9E%90/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink-wordcoun%E8%A7%A3%E6%9E%90/</guid><description>Flink WordCount程序背后的万字深度解析 1 Flink数据流图简介 1.1 Flink样例程序 我们开始对数据流做处理，计算数据流中单词出现的频次。从</description></item><item><title>Flink 消费消息的流程</title><link>https://justice.bj.cn/post/30.architech/flink/flink-%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E7%9A%84%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink-%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E7%9A%84%E6%B5%81%E7%A8%8B/</guid><description>Flink 消费消息的流程 简介 准备一个ResultPartition； 通知JobMaster； JobMaster通知下游节点；如果下游节点尚未部署，则</description></item><item><title>Flink-基本</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E5%9F%BA%E7%A1%80/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E5%9F%BA%E7%A1%80/</guid><description>Flink-基本 数据流 数据流就是一个无界（unbounded）的事件序列。事件（Event）可以是监控报警数据、传感器感知数据、信用卡交易、</description></item><item><title>Flink入门</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E5%85%A5%E9%97%A8/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E5%85%A5%E9%97%A8/</guid><description>Flink入门 启动本地flink实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 ## 下载flink $ java -version $ wget https://www.apache.org/dyn/closer.lua/flink/flink-1.14.2/flink-1.14.2-bin-scala_2.12.tgz $ tar -xzf flink-1.14.2-bin-scala_2.11.tgz $ cd flink-1.14.2-bin-scala_2.11 ## 启</description></item><item><title>Flink内存管理</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid><description>Flink内存管理 JVM存在的问题 对象存储密度低 Full GC 影响性能 OOM 影响稳定 Cache Miss 代码结构： 基础数据结构（package:org.apache.fl</description></item><item><title>Flink简介</title><link>https://justice.bj.cn/post/30.architech/flink/flink%E7%AE%80%E4%BB%8B/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/flink/flink%E7%AE%80%E4%BB%8B/</guid><description>Flink简介 简介 Flink是开始于2008年，原生的流处理系统，提供high level的API。Flink也提供 API来像Spark一样进</description></item><item><title>Kafka</title><link>https://justice.bj.cn/post/30.architech/kafka/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/kafka/</guid><description>Kafka 简介 Kafka是由Linkedin公司开发的分布式、支持分区（partition）、多副本（replica），基于zookeeper的分布</description></item><item><title>MySQL</title><link>https://justice.bj.cn/post/30.architech/mysql/mysql%E5%9F%BA%E7%A1%80/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/mysql/mysql%E5%9F%BA%E7%A1%80/</guid><description>MySQL 简介 特点 设计范式 1NF: 原子性，保证每列不可再分, 保证表中无表； 2NF: 消除部分依赖，在满足1NF上，每个属性完全依赖于主键； 3NF: 消除传递依赖，在满足2</description></item><item><title>MySQL锁</title><link>https://justice.bj.cn/post/30.architech/mysql/mysql%E9%94%81/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/mysql/mysql%E9%94%81/</guid><description>MySQL锁 简介 mysql中的锁是用于保证并发事务访问一致性的一种机制。 分类 按对资源的访问类型可分为： 共享锁（读锁）：其他事务可以读，但不能</description></item><item><title>Protobuf</title><link>https://justice.bj.cn/post/30.architech/protobuf/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/protobuf/</guid><description>Protobuf 简介 Protobuf 是 Google 整的一个序列化/反序列化框架，性能不算很好不过用的人比较多，各个语言的实现也比较全，其中 golang 的版本是 google 官方维护的 golang/pr</description></item><item><title>Redis基础</title><link>https://justice.bj.cn/post/30.architech/redis/redis%E5%9F%BA%E7%A1%80/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/redis/redis%E5%9F%BA%E7%A1%80/</guid><description>Redis基础 简介 Redis（Remote Dictionary Server，远程数据服务）是一款用C语言编写的内存高速缓存key-value存储系统； 支持丰富</description></item><item><title>Spark 基础知识</title><link>https://justice.bj.cn/post/30.architech/spark/spark%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/spark/spark%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</guid><description>Spark 基础知识 简介 Spark 是一种快速、通用、可扩展的大数据分析引擎，2009 年诞生于加州大学伯克利分校 AMPLab，2010 年开源，2013 年 6 月成为</description></item><item><title>数据湖(Delta Lake)</title><link>https://justice.bj.cn/post/30.architech/%E6%95%B0%E6%8D%AE%E6%B9%96/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/%E6%95%B0%E6%8D%AE%E6%B9%96/</guid><description>数据湖(Delta Lake) 简介 Data lake这个术语由Pentaho公司创始人兼CTO詹姆斯·狄克逊(James Dixon)发明，他对数据湖的解释是：</description></item><item><title>MySQL事务</title><link>https://justice.bj.cn/post/30.architech/mysql/mysql%E4%BA%8B%E5%8A%A1/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/mysql/mysql%E4%BA%8B%E5%8A%A1/</guid><description>MySQL事务 定义 数据库事务是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。 事务的使用是数据库管理系统区别文件系统</description></item><item><title>十道海量数据处理面试题</title><link>https://justice.bj.cn/post/30.architech/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%9D%A2%E8%AF%95%E9%A2%98/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://justice.bj.cn/post/30.architech/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%9D%A2%E8%AF%95%E9%A2%98/</guid><description>十道海量数据处理面试题 1、海量日志数据，提取出某日访问百度次数最多的那个IP。 当时给出的方案是：IP的数目还是有限的，最多2^32个，所以可</description></item></channel></rss>