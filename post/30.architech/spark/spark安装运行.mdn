# spark

## 简介

---

## Spark vs MapReduce

* MapReduce

![](../../img/2020-01-09-19-15-29-image.png)

* Spark

---

## 运行模式

spark支持standlone、yarn、mesos等多种运行模式，其中standlone模式主要用于线下环境的测试，线上都采用yarn或者mesos进行资源的管控、容错。

* **本地模式**
  
  * Local[N]：本地模式，使用 N 个线程。
  
  * Local Cluster[Worker,core,Memory]：伪分布式模式，可以配置所需要启动的虚拟工作节点的数量，以及每个工作节点所管理的 CPU 数量和内存尺寸
  
  * Spark://hostname:port:Standalone 模式，需要部署 Spark 到相关节点，URL 为 Spark Master 主机地址和端口。
  
  * Mesos://hostname:port:Mesos 模式，需要部署 Spark 和 Mesos 到相关节点，URL 为 Mesos 主机地址和端口。
  
  * YARN standalone/Yarn cluster:YARN 模式一，主程序逻辑和任务都运行在 YARN 集群中。
  
  * YARN client:YARN 模式二，主程序逻辑运行在本地，具体任务运行在 YARN 集群中。

* `$SPARK_HOME/conf/spark-env.sh`

```shell
#!/usr/bin/env bash

export JAVA_HOME=/export/servers/jdk1.8.0_172
export SPARK_HOME=/export/App/spark-2.3.0
export HADOOP_HOME=/export/App/hadoop-2.7.6
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_DIST_CLASSPATH=$(${HADOOP_HOME}/bin/hadoop classpath)
```

```shell
SPARK_HOME=/export/App/spark-2.3.0
SPARK_MASTER_HOST=10.194.138.200
SPARK_MASTER_PORT=7077

# start spark master
$SPARK_HOME/sbin/start-master.sh
$SPARK_HOME/sbin/start-slave.sh spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT

# 本地模式10线程
$SPARK_HOME/bin/run-example SparkPi 1000 --master 10.194.138.200[10] > /tmp/Sparkpilog.txt

#Spark Standalone 集群模式运行
$SPARK_HOME/bin/spark-submit \
        --master spark://10.194.138.200:7077 \
        --class org.apache.spark.examples.SparkPi \
        examples/jars/spark-examples_2.11-2.3.0.jar  10000

# spark yarn cluster 模式
// pi
$SPARK_HOME/bin/spark-submit --master yarn \
        --deploy-mode cluster \
        --class org.apache.spark.examples.SparkPi \
        examples/jars/spark-examples_2.11-2.3.0.jar  10000

// wordcount
$SPARK_HOME/bin/spark-submit --master yarn \
        --deploy-mode cluster \
        --class org.apache.spark.examples.JavaWordCount \
        examples/jars/spark-examples_2.11-2.3.0.jar  hdfs://10.194.138.200:9000/tmp/sample.txt hdfs://10.194.138.200:9000/tmp/output


$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.JavaWordCount \
       --master yarn-cluster examples/jars/spark-examples_2.11-2.3.0.jar  /tmp/sample.txt


//spark stream
$ tail -f /data1/cfs/log/*/*.log | nc -lk 9999
$ $SPARK_HOME/bin/run-example org.apache.spark.examples.streaming.NetworkWordCount 10.199.136.40 9999 > /tmp/output.txt
```

## yarn

需要启动：

* hdfs

* yarn

* cp /export/App/spark-2.3.0/yarn/spark-2.3.0-yarn-shuffle.jar  /export/App/hadoop-2.7.6/share/hadoop/yarn/lib

$SPARK_HOME/conf/spark-defaults.conf

### 参考

1. https://blog.csdn.net/u011094454/article/details/78992293
2. https://www.jianshu.com/p/dd7c7243e7f9?from=singlemessage
3. [Spark和MapReduce相比，都有哪些优势？ - 简书](https://www.jianshu.com/p/0dd03853b001)
4. 
